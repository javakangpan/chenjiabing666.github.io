<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[分布式锁-redis实现]]></title>
      <url>%2F2020%2F03%2F07%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-redis%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[为什么要分布式锁 在单机的情况下，可以通过jvm提供的系列线程安全的操作来处理高并发的情况，但是在分布式的环境下，jvm提供的线程安全操作明显是不能满足要求的。在一些小型的互联网公司经常做的crud操作如果在高并发的情况下会出现很大的问题，比如： 12345//伪代码：下订单1、查库存：getStock()2、判断库存：stock&gt;0下单3、下单：addOrder()4、减库存 仅仅以上三步，如果在高并发的情况下，无论是单机或者集群，如果不加锁一定会出现超卖的情况。一瞬间成千上万个请求过来，如何能够确保查询到的库存是最新的数据？ Redis实现 通过redis的setNx方法可以自己简单的实现以下分布式锁，但是在实现之前需要考虑清楚几个问题。 问题与解决思路 如何避免死锁？在高并发的情况下很可能由于服务重启，服务器宕机的等情况导致锁没有及时释放，导致其他线程不能获得锁。 setNx的使用设置一个过期时间，当锁没有手动释放的时候能够超过一定时间自动释放 这个时间如何设置？如果业务没有执行完成但是过期时间到了，这个锁释放了，怎么处理？ 过期时间最好能够是业务执行完成的时间，为了防止时间到了业务没有执行完成，可以分开一个线程或者设置一个定时器，定时的延长这个过期时间，直到当前线程完成业务。 如何避免锁的误删（设置过期时间没有设置定时器延长过期时间）？高并发的情况下瞬间几万个请求过来，很有可能A线程执行完成之后，但是B线程没有执行完成（前提：B线程先获得锁先执行并且未执行完成之后过期时间到了删除了自己持有的锁，此时A线程获得锁并率先执行完成），A线程执行deleteKey方法，删除了B的锁。 在执行每一个业务逻辑之前先生成一个唯一id作为setNx的value值标识这个线程执行的任务，删除的时候先获取和当前线程的id比对一下，如果不一样，这个锁不是当前的线程持有的。 如何保证锁的可重入性？ 在获取锁的时候先获取锁，比对一下当前的唯一标识，相同的话可重入。 如何确保获取锁和释放锁的原子性？在获取锁或者释放锁的过程中如果不是原子操作很有可能导致一系列问题 使用Lua脚本获取锁和释放锁来保证原子性 实现 根据上面的思路可以通过redis自己手写一个分布式锁的实现，当然这个例子并没有保证解锁和获得锁的原子性，不喜勿喷。 redis的工具类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class RedisUtils &#123; private static RedisTemplate redisTemplate=ApplicationContextUtils.applicationContext.getBean("redisTemplate",RedisTemplate.class); private static StringRedisTemplate stringRedisTemplate=ApplicationContextUtils.applicationContext.getBean(StringRedisTemplate.class); /** * setNx * @param key * @param value * @return */ public static Boolean setNx(String key,String value)&#123; return stringRedisTemplate.opsForValue().setIfAbsent(key,value); &#125; /** * setNx * @param key * @param value * @param seconds 过期时间，单位秒 * @return */ public static Boolean setNx(String key, String value, Long seconds)&#123; return stringRedisTemplate.opsForValue().setIfAbsent(key,value,seconds, TimeUnit.SECONDS); &#125; /** * 删除key * @param key * @return */ public static Boolean deleteKey(String key)&#123; return redisTemplate.delete(key); &#125; /** * 获取NX设置的值 * @param key * @return */ public static String getNX(String key)&#123; return stringRedisTemplate.opsForValue().get(key); &#125; /** * 设置key的过期时间 * @param key * @param seconds * @return */ public static Boolean expireKey(String key,Long seconds)&#123; return stringRedisTemplate.expire(key,seconds,TimeUnit.SECONDS); &#125;&#125; 分布式锁的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class RedisLock &#123; /** * 存储的KEY，每个业务应该不同 */ private String key; /** * 过期时间，单位秒 */ private Long expireSeconds; /** * 异步任务，用于分开一个线程延长过期时间，也可以使用定时器 */ private TaskAsync taskAsync; public RedisLock(String key,Long expireSeconds)&#123; this.key=key; this.expireSeconds=expireSeconds; taskAsync= ApplicationContextUtils.applicationContext.getBean(TaskAsync.class); &#125; /** * 上锁 * @param uuid setNx的值，唯一标识当前线程 */ public void lock(String uuid) throws InterruptedException &#123; //获取value String nx = RedisUtils.getNX(key); /** * 如果此时的uuid和redis中的一致，那么就是可重入的 */ if (StringUtils.equals(nx,uuid))&#123; return; &#125; //如果不一致，需要设置，为了避免死锁，需要设置一个过期时间 Boolean b = RedisUtils.setNx(key, uuid,expireSeconds); //加锁失败，每隔两秒重试一次 while(!b)&#123; b = RedisUtils.setNx(key, uuid,expireSeconds); Thread.sleep(2000); &#125; //开启异步线程延长过期时间 taskAsync.delayExpireTime(uuid,key,expireSeconds); &#125; /** * 解锁 * @param uuid 为了避免误删，这里的uuid是唯一标识当前方法执行的，如果和当前方法的相同才能删除 */ public void unlock(String uuid) &#123; String value= RedisUtils.getNX(key); //说明当前线程执行的方法所获得的锁已经被释放了 if (!StringUtils.equals(value,uuid))&#123; return; &#125; Boolean b = RedisUtils.deleteKey(key); while(!b)&#123; b=RedisUtils.deleteKey(key); &#125; &#125;&#125; 异步线程延长锁的过期时间： 1234567891011121314151617181920212223@Componentpublic class TaskAsync &#123; /** * 异步开一个线程延长执行的任务， * @param uuid 当前线程持有锁的唯一标识 * @param key key * @param expireSeconds 过期时间 */ @Async public void delayExpireTime(String uuid,String key,Long expireSeconds) throws InterruptedException &#123; //无限循环 while(true)&#123; String nx = RedisUtils.getNX(key); //key对应的值不存在，或者不等于当前方法的唯一id，直接跳出，不需要延长时间了 if (nx==null||!StringUtils.equals(uuid,nx)) break; //延长时间 RedisUtils.expireKey(key,expireSeconds); Thread.sleep(3000L); &#125; &#125;&#125; Redisson Redisson和jedis一样同样是redis的客户端，但是其在解决分布式问题上有着很大的优势，对分布式锁的实现更是封装的更加简洁，能够通过简单的api完成。 Redisson封装了多种锁，包括重入锁，公平锁，红锁……，这里简单的演示一下重入锁的使用方式。 可重入锁 RedissonClient通过getxxLock(name)获取不同锁的对象，RLock对应的是可重入锁的接口。与SpringBoot整合之后，配置的方式创建RedissonClient，并且注入了一个处理订单业务的锁： 123456789101112131415161718192021222324@Configuration@EnableConfigurationProperties(value = &#123;RedissonProperties.class&#125;)public class RedissonConfig &#123; /** * 注入RedissonClient对象 */ @Bean public RedissonClient redissonClient(RedissonProperties redissonProperties)&#123; Config config = new Config(); config.useSingleServer().setAddress(redissonProperties.getAddress()).setPassword(redissonProperties.getPassword()).setDatabase(redissonProperties.getDatabase()); return Redisson.create(config); &#125; /** * 注入可重入锁，用于订单业务 */ @Bean public RLock orderLock(@Qualifier(value = "redissonClient") RedissonClient redissonClient,RedissonProperties redissonProperties)&#123; return redissonClient.getLock(redissonProperties.getOrderLock()); &#125;&#125; 模拟订单的下单，如下： void lock(long leaseTime, TimeUnit unit)：获得锁，leaseTime设置的过期时间，unit是时间单位，如果设置了-1，redisson会设置默认的时间30秒，这个时间可以在config配置中修改，具体看文档。锁的值是UUID:线程Id(作为唯一标识) void unlock()：解锁 1234567891011121314151617181920public void add(String goodsId) throws Exception &#123; try &#123; //获取锁 rLock.lock(10, TimeUnit.SECONDS); //检查库存，存储在redis中 Integer stock = Integer.valueOf(stringRedisTemplate.opsForValue().get(goodsId)); if (stock&lt;0) return; //减库存 Long increment = stringRedisTemplate.opsForValue().increment(goodsId, -1); if (increment&lt;0) return; //减库存成功，下单 Order order = Order.builder().build(); orderMapper.add(order); &#125;finally &#123; //解锁 rLock.unlock(); &#125; &#125; 文档 Redisson的文档很齐全，具体可看文档https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Shiro]]></title>
      <url>%2F2019%2F08%2F17%2FShiro%2F</url>
      <content type="text"><![CDATA[项目搭建 添加Shiro的依赖 1234567891011&lt;!--Spring整合的shiro依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt; &lt;/dependency&gt; Realm Shiro的组件之一 其各个子类分别有不同职责 子类 CachingRealm：提供了缓存的功能，其中配置了缓存管理器 AuthenticatingRealm：负责认证的Realm，继承了CachingRealm，因此对认证的信息也是有缓存的功能，默认是关闭的，其中有一个重要的方法，如下： protected abstract AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token)：用于子类实现认证的真正的逻辑 AuthorizingRealm：负责授权的Realm，不过继承了AuthenticatingRealm，因此具有认证和缓存的功能 自定义Realm 通常我们只需要完成认证授权，因此只需要继承AuthorizingRealm即可，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * 自定义的Realm，完成认证和授权 */public class UserRealm extends AuthorizingRealm &#123; @Autowired private UserMapper userMapper; @Autowired private RoleMapper roleMapper; @Autowired private UserRoleMapper userRoleMapper; @Autowired private RolePermissionMapper rolePermissionMapper; @Override public String getName() &#123; return "userRealm"; &#125; /** * 完成授权，主要的作用就是从数据库中查询出用户的角色和权限封装在AuthorizationInfo返回即可 * @param principals 在认证的过程中返回的Principal，可以是一个User对象，也可以是userId等标志用户信息 * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; System.out.println("授权。。。。"); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); final HashSet&lt;String&gt; pers = Sets.newHashSet(); final HashSet&lt;String&gt; roles = Sets.newHashSet(); //获取用户信息 User user= (User) principals.getPrimaryPrincipal(); List&lt;UserRole&gt; userRole = userRoleMapper.selectByUserId(user.getId()); //如果userRole存在 if (CollectionUtils.isNotEmpty(userRole))&#123; //获取权限 userRole.stream().forEach(o-&gt;&#123; rolePermissionMapper.selectByRoleId(o.getRoleId()).stream().forEach(item-&gt;&#123; pers.add(item.getDesc()); &#125;); //获取角色 Role role = roleMapper.selectById(o.getRoleId()); roles.add(role.getRoleName()); &#125;); authorizationInfo.setRoles(roles); authorizationInfo.setStringPermissions(pers); &#125; return authorizationInfo; &#125; /** * 认证 * @param token * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; System.out.println("认证。。。。"); UsernamePasswordToken upToken= (UsernamePasswordToken) token; //用户名 String userName = (String) upToken.getPrincipal(); User user = userMapper.selectByUserName(userName); if (Objects.isNull(user))&#123; throw new AuthenticationException("用户不存在"); &#125; //该构造器还可以使用加密算法 return new SimpleAuthenticationInfo(user,user.getPassword(),getName()); &#125; /** * 清除CacheManager中的缓存，可以在用户权限改变的时候调用，这样再次需要权限的时候就会重新查询数据库不走缓存了 */ public void clearCache() &#123; Subject subject = SecurityUtils.getSubject(); //此处调用父类的方法，不仅会清除授权缓存，如果认证信息也缓存了，那么也会删除认证的缓存 super.clearCache(subject.getPrincipals()); &#125;&#125; 将其配置到安全管理器中 123456789101112131415161718192021/** * 配置UserRealm，完成认证和授权的两个流程 */ @Bean public UserRealm userRealm()&#123; return new UserRealm(); &#125; /** * 配置安全管理器 */ @Bean public SecurityManager securityManager()&#123; //使用web下的安全管理器，构造参数传入Realm DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(userRealm()); //设置缓存管理器 securityManager.setCacheManager(cacheManager()); //设置会话管理器 securityManager.setSessionManager(sessionManager()); return securityManager; &#125; 认证信息的缓存 默认是关闭的，只需要开启即可。 1234567891011 @Bean public UserRealm userRealm()&#123; UserRealm userRealm = new UserRealm(); //开启认证信息的缓存，默认关闭，key是UserNamePasswordToken，value就是principle userRealm.setAuthenticationCachingEnabled(true); //开启授权信息的缓存，默认开启 userRealm.setAuthorizationCachingEnabled(true); return userRealm; &#125;//SecurityManager中设置缓存管理器 认证信息缓存也需要在用户的个人信息改变的时候清除缓存 密码加密认证 在正常的场景中都会涉及到对密码的加密，在Shiro中也提供了密码加密的认证，只需要配置一个凭证匹配器即可，步骤如下： 在自定义的UserRealm中配置凭证匹配器 123456789101112131415@Bean public UserRealm userRealm()&#123; UserRealm userRealm = new UserRealm(); //开启认证信息的缓存，默认关闭，key是UserNamePasswordToken，value就是principle userRealm.setAuthenticationCachingEnabled(false); //开启授权信息的缓存，默认开启 userRealm.setAuthorizationCachingEnabled(true); //配置凭证匹配器，加密方式MD5 HashedCredentialsMatcher credentialsMatcher = new HashedCredentialsMatcher("MD5"); //加密两次 credentialsMatcher.setHashIterations(2); //设置凭证匹配器 userRealm.setCredentialsMatcher(credentialsMatcher); return userRealm; &#125; 在认证的方法中构建使用加密的AuthenticationInfo，如下： 12//第一个参数是principle，第二个参数是加密之后的密码，第三个参数是加密的盐，第四个参数是UserRealm的名称return new SimpleAuthenticationInfo(user,user.getPassword(),ByteSource.Util.bytes(user.getSalt()),getName()); 缓存管理器（CacheManager） 在每一次请求需要权限的时候总是会调用授权的方法查询数据库，这样的话性能很低，因此我们可以使用缓存管理器，来达到这种要求，在Shiro中有一个内存缓存管理器，内部就是使用Map实现的，但是这种缓存并不能实现跨JVM（分布式），因此我们可以使用Redis自定义一个缓存管理器，步骤如下： 实现RedisCache，用于实现对授权信息的缓存，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Redis的Cache */public class RedisCache&lt;K,V&gt; implements Cache&lt;K,V&gt; &#123; private RedisTemplate redisTemplate; /** * 存储在redis中的hash中的key */ private String name; private final static String COMMON_NAME="shiro-demo"; public RedisCache(RedisTemplate redisTemplate, String name) &#123; this.redisTemplate = redisTemplate; this.name=COMMON_NAME+":"+name; &#125; /** * 获取指定的key的缓存 * @param k * @return * @throws CacheException */ @Override public V get(K k) throws CacheException &#123; return (V) redisTemplate.opsForHash().get(name,k); &#125; /** * 添加缓存 * @param k * @param v * @return * @throws CacheException */ @Override public V put(K k, V v) throws CacheException &#123; redisTemplate.opsForHash().put(name, k, v); //设置过期时间 return v; &#125; /** * 删除指定key的缓存 * @param k 默认是principle对象，在AuthorizingRealm中设置 */ @Override public V remove(K k) throws CacheException &#123; V v = this.get(k); redisTemplate.opsForHash().delete(name, k); return v; &#125; /** * 删除所有的缓存 */ @Override public void clear() throws CacheException &#123; redisTemplate.delete(name); &#125; /** * 获取总数 * @return */ @Override public int size() &#123; return redisTemplate.opsForHash().size(name).intValue(); &#125; @Override public Set&lt;K&gt; keys() &#123; return redisTemplate.opsForHash().keys(name); &#125; @Override public Collection&lt;V&gt; values() &#123; return redisTemplate.opsForHash().values(name); &#125;&#125; 实现RedisManager，如下： 12345678910111213/** * Redis的CacheManager */public class RedisCacheManager implements CacheManager &#123; @Autowired private RedisTemplate redisTemplate; @Override public &lt;K, V&gt; Cache&lt;K, V&gt; getCache(String s) throws CacheException &#123; return new RedisCache&lt;K,V&gt;(redisTemplate, s); &#125;&#125; 在配置类中配置上缓存管理器，需要设置到Shiro的安全管理器中才能生效，如下： 123456789101112131415161718/** * 配置缓存管理器，使用自定义的Redis缓存管理器 */ @Bean public CacheManager cacheManager()&#123; return new RedisCacheManager(); &#125; /** * 配置安全管理器 */ @Bean public SecurityManager securityManager()&#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(userRealm()); //设置缓存管理器 securityManager.setCacheManager(cacheManager()); return securityManager; &#125; 清除缓存 在CachingRelam中有一个清除缓存的方法org.apache.shiro.realm.CachingRealm#clearCache，在我们自定义的Realm中覆盖该方法即可，这样就能在退出或者在业务逻辑中用户的权限改变的时候能够清除缓存的数据，如下： 12345678/** * 清除CacheManager中的缓存，可以在用户权限改变的时候调用，这样再次需要权限的时候就会重新查询数据库不走缓存了 */ public void clearCache() &#123; Subject subject = SecurityUtils.getSubject(); //调用父类的清除缓存的方法 super.clearCache(subject.getPrincipals()); &#125; 除了重写或者覆盖CachingRelam中的方法，根据源码可以知道，真正起作用的方法是AuthorizingRealm中的方法clearCachedAuthorizationInfo，因此我们也可以重写或者覆盖这个方法，这里不再演示。 实现原理 在Shiro中一旦有地方调用Subject.hasRole等校验权限的地方，那么就会检测授权信息，在org.apache.shiro.realm.AuthorizingRealm#getAuthorizationInfo的方法中会先缓存中查询是否存在，否则调用授权的方法从数据库中查询，查询之后放入缓存中，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected AuthorizationInfo getAuthorizationInfo(PrincipalCollection principals) &#123; if (principals == null) &#123; return null; &#125; AuthorizationInfo info = null; if (log.isTraceEnabled()) &#123; log.trace("Retrieving AuthorizationInfo for principals [" + principals + "]"); &#125; //获取可用的缓存管理器 Cache&lt;Object, AuthorizationInfo&gt; cache = getAvailableAuthorizationCache(); if (cache != null) &#123; if (log.isTraceEnabled()) &#123; log.trace("Attempting to retrieve the AuthorizationInfo from cache."); &#125; //获取缓存的key，这里获取的就是principal主体信息 Object key = getAuthorizationCacheKey(principals); //从缓存中获取数据 info = cache.get(key); if (log.isTraceEnabled()) &#123; if (info == null) &#123; log.trace("No AuthorizationInfo found in cache for principals [" + principals + "]"); &#125; else &#123; log.trace("AuthorizationInfo found in cache for principals [" + principals + "]"); &#125; &#125; &#125; //如果缓存中没有查到 if (info == null) &#123; //调用重写的授权方法，从数据库中查询 info = doGetAuthorizationInfo(principals); //如果查询到了，添加到缓存中 if (info != null &amp;&amp; cache != null) &#123; if (log.isTraceEnabled()) &#123; log.trace("Caching authorization info for principals: [" + principals + "]."); &#125; //获取缓存的key Object key = getAuthorizationCacheKey(principals); //放入缓存 cache.put(key, info); &#125; &#125; return info; &#125; 会话管理器（SessionManager） Shiro在开启Web功能的时候默认的会话管理器是DefaultWebSessionManager，这种管理器是针对cookie进行存储的，将sessionId存储在cookie中，但是现在的主流方向是前后端分离，我们不能再依赖Cookie，因此我们必须自定义的会话管理器，实现跨JVM，前后端分离。 自定义SessionMananger 在原有的DefaultWebSessionManager进行扩展，否则从头实现将会要写大量代码。默认的Web的会话管理器是从cookie中获取SessionId，我们只需要重写其中的方法即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 自定义的会话管理器 */@Slf4jpublic class RedisSessionManager extends DefaultWebSessionManager &#123; @Autowired private RedisTemplate redisTemplate; /** * 前后端分离不存在cookie，因此需要重写getSessionId的逻辑，从请求参数中获取 * 此处的逻辑：在登录成功之后会将sessionId作为一个token返回，下次请求的时候直接带着token即可 */ @Override protected Serializable getSessionId(ServletRequest request, ServletResponse response) &#123; //获取上传的token,这里的token就是sessionId return request.getParameter("token"); &#125; /** * 重写该方法，在SessionManager中只要涉及到Session的操作都会获取Session，获取Session主要是从缓存中获取，父类的该方法执行逻辑如下： * 1、先从RedisCache中获取，调用get方法 * 2、如果RedisCache中不存在，在从SessionDao中获取，调用get方法 * 优化：我们只需要从SessionDao中获取即可 * @param sessionKey Session的Key */ @Override protected Session retrieveSession(SessionKey sessionKey) throws UnknownSessionException &#123; //获取SessionId Serializable sessionId = getSessionId(sessionKey); if (sessionId == null) &#123; log.debug("Unable to resolve session ID from SessionKey [&#123;&#125;]. Returning null to indicate a " + "session could not be found.", sessionKey); return null; &#125; //直接调用SessionDao中的get方法获取 Session session = ((RedisSessionDao) sessionDAO).doReadSession(sessionId); if (session == null) &#123; //session ID was provided, meaning one is expected to be found, but we couldn't find one: String msg = "Could not find session with ID [" + sessionId + "]"; throw new UnknownSessionException(msg); &#125; return session; &#125; /** * 该方法是作用是当访问指定的uri的时候会更新Session中的执行时间，用来动态的延长失效时间。 * 在父类的实现方法会直接调用SessionDao中的更新方法更新缓存中的Session * 此处并没有其他的逻辑，后续可以补充 * @param key */ @Override public void touch(SessionKey key) throws InvalidSessionException &#123; super.touch(key); &#125;&#125; 自定义SessionDao SessionDao的作用是Session持久化的手段，默认的SessionDao是缓存在内存中的，此处使用Redis作为缓存的工具，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 自定义RedisSessionDao，继承CachingSessionDAO */@Slf4jpublic class RedisSessionDao extends CachingSessionDAO &#123; @Autowired private RedisTemplate redisTemplate; /** * 更新session * @param session */ @Override protected void doUpdate(Session session) &#123; log.info("执行redisdao的doUpdate方法"); redisTemplate.opsForValue().set(session.getId(), session); &#125; /** * 删除session * @param session */ @Override protected void doDelete(Session session) &#123; log.info("执行redisdao的doDelete方法"); redisTemplate.delete(session.getId()); &#125; /** * 创建一个Session，添加到缓存中 * @param session Session信息 * @return 创建的SessionId */ @Override protected Serializable doCreate(Session session) &#123; log.info("执行redisdao的doCreate方法"); Serializable sessionId = generateSessionId(session); assignSessionId(session, sessionId); redisTemplate.opsForValue().set(session.getId(), session); return sessionId; &#125; @Override protected Session doReadSession(Serializable sessionId) &#123; log.info("执行redisdao的doReadSession方法"); return (Session) redisTemplate.opsForValue().get(sessionId); &#125;&#125; 自定义SessionId生成策略 默认的Shiro的生成策略是JavaUuidSessionIdGenerator，此处也可以自定义自己的生成策略，如下： 123456789/** * 自定义的SessionId的生成策略 */public class RedisSessionIdGenerator implements SessionIdGenerator &#123; @Override public Serializable generateId(Session session) &#123; return UUID.randomUUID().toString().replaceAll("-", "").toUpperCase(); &#125;&#125; 自定义Session监听器 Session监听器能够监听Session的生命周期，包括开始、过期、失效（停止），如下： 12345678910111213141516171819202122232425/** * 自定义Session监听器 */@Slf4jpublic class RedisSessionListener implements SessionListener &#123; @Override public void onStart(Session session) &#123; log.info("开始"); &#125; /** * Session无效【停止了，stopTime！=null】 * @param session */ @Override public void onStop(Session session) &#123; log.info("session失效"); &#125; @Override public void onExpiration(Session session) &#123; log.info("超时"); &#125;&#125; 完成上述配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 配置SessionDao，使用自定义的Redis缓存 */ @Bean public SessionDAO sessionDAO()&#123; RedisSessionDao sessionDao = new RedisSessionDao(); //设置自定义的Id生成策略 sessionDao.setSessionIdGenerator(new RedisSessionIdGenerator()); return sessionDao; &#125; /** * 配置会话监听器 * @return */ @Bean public SessionListener sessionListener()&#123; return new RedisSessionListener(); &#125; /** * 配置会话管理器 */ @Bean public SessionManager sessionManager()&#123; DefaultWebSessionManager sessionManager = new RedisSessionManager(); //设置session的过期时间 sessionManager.setGlobalSessionTimeout(60000); //设置SessionDao sessionManager.setSessionDAO(sessionDAO()); //设置SessionListener sessionManager.setSessionListeners(Lists.newArrayList(sessionListener())); return sessionManager; &#125; /** * 配置安全管理器 */ @Bean public SecurityManager securityManager()&#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(userRealm()); //设置缓存管理器 securityManager.setCacheManager(cacheManager()); //设置会话管理器 securityManager.setSessionManager(sessionManager()); return securityManager; &#125; 优化 在源码中可以看到AbstractSessionDAO中的增删改查方法的执行逻辑使用的双层缓存的，还设计到查询CacheManager中的缓存，但是我们的SessionDao既然是实现了Redis的缓存，那么是没必要查询两次的，因此需要重写其中的方法，此时我们自己需要写一个抽象类覆盖其中的增删改查方法即可，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * RedisSessionDao的抽象类，重写其中的增删改查方法，原因如下： * 1、AbstractSessionDAO中的默认方法是写查询CacheManager中的缓存，既然SessionDao实现了Redis的缓存 * 那么就不需要重复查询两次，因此重写了方法，直接使用RedisSessionDao查询即可。 */public abstract class AbstractRedisSessionDao extends AbstractSessionDAO &#123; /** * 重写creat方法，直接执行sessionDao的方法，不再执行cacheManager * @param session * @return */ @Override public Serializable create(Session session) &#123; Serializable sessionId = doCreate(session); if (sessionId == null) &#123; String msg = "sessionId returned from doCreate implementation is null. Please verify the implementation."; throw new IllegalStateException(msg); &#125; return sessionId; &#125; /** * 重写删除操作 * @param session */ @Override public void delete(Session session) &#123; doDelete(session); &#125; /** * 重写update方法 * @param session * @throws UnknownSessionException */ @Override public void update(Session session) throws UnknownSessionException &#123; doUpdate(session); &#125; /** * 重写查找方法 * @param sessionId * @return * @throws UnknownSessionException */ @Override public Session readSession(Serializable sessionId) throws UnknownSessionException &#123; Session s = doReadSession(sessionId); if (s == null) &#123; throw new UnknownSessionException("There is no session with id [" + sessionId + "]"); &#125; return s; &#125; protected abstract void doDelete(Session session); protected abstract void doUpdate(Session session);&#125; 此时的上面的RedisSessionDao直接继承我们自定义的抽象类即可，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 自定义RedisSessionDao，继承AbstractRedisSessionDao，达到只查一层缓存 */@Slf4jpublic class RedisSessionDao extends AbstractRedisSessionDao &#123; @Autowired private RedisTemplate redisTemplate; private final static String HASH_NAME="shiro_user"; /** * 更新session * @param session */ @Override protected void doUpdate(Session session) &#123; log.info("执行redisdao的doUpdate方法"); redisTemplate.opsForHash().put(HASH_NAME, session.getId(), session); &#125; /** * 删除session * @param session */ @Override protected void doDelete(Session session) &#123; log.info("执行redisdao的doDelete方法"); redisTemplate.opsForHash().delete(HASH_NAME, session.getId()); &#125; /** * 创建一个Session，添加到缓存中 * @param session Session信息 * @return 创建的SessionId */ @Override protected Serializable doCreate(Session session) &#123; log.info("执行redisdao的doCreate方法"); Serializable sessionId = generateSessionId(session); assignSessionId(session, sessionId); redisTemplate.opsForHash().put(HASH_NAME, session.getId(),session); return sessionId; &#125; @Override protected Session doReadSession(Serializable sessionId) &#123; log.info("执行redisdao的doReadSession方法"); return (Session) redisTemplate.opsForHash().get(HASH_NAME,sessionId); &#125; /** * 获取所有的Session */ @Override public Collection&lt;Session&gt; getActiveSessions() &#123; List values = redisTemplate.opsForHash().values(HASH_NAME); if (CollectionUtils.isNotEmpty(values))&#123; return values; &#125; return Collections.emptySet(); &#125;&#125; 会话验证 Shiro默认是在当前用户访问页面的时候检查Session是否停止或者过期，如果过期和停止了会调用的SessionDao中的相关方法删除缓存，但是如果这是在用户名操作的情况下，如果用户一直未操作，那么Session已经失效了，但是缓存中并没有删除，这样一来将会有大量无效的Session堆积，因此我们必须定时清理失效的Session。 清理会话，有如下两种方法： 自己写一个定时器，每隔半小时或者几分钟清除清除缓存 自定义SessionValidationScheduler 使用已经实现的ExecutorServiceSessionValidationScheduler 在Shiro中默认会开启ExecutorServiceSessionValidationScheduler，执行时间是一个小时，但是如果想要使用定时器定时清除的话，那么需要关闭默认的清除器，如下： 12//禁用Session清除器，使用定时器清除 sessionManager.setSessionValidationSchedulerEnabled(false); 如何的Session是失效的 Session是如何保活的？ 在org.apache.shiro.web.servlet.AbstractShiroFilter#doFilterInternal中的一个updateSessionLastAccessTime(request, response);方法用来更新Session的最后执行时间为当前时间，最终调用的就是org.apache.shiro.session.mgt.SimpleSession#touch。 在每次请求验证Session的时候实际调用的是org.apache.shiro.session.mgt.AbstractValidatingSessionManager#doValidate方法，在其中真正调用的是org.apache.shiro.session.mgt.SimpleSession#validate来验证是否过期或者停止 核心逻辑就是验证当前的时间和最后执行时间的差值是否在设置的过期时间的范围内 何时是失效的 Session失效目前通过读源码总结出如下三点： isValid判断，这个会在访问请求的时候shiro会自动验证，并且设置进去 用户长期不请求，此时的isValid并不能验证出来，此时需要比较最后执行的时间和开始时间比较 没有登录就访问的也会在redis中生成一个Session，但是此时的Session中是没有两个属性的，以下的两个属性只有在认证成功之后才会设置查到Session中 org.apache.shiro.subject.support.DefaultSubjectContext#PRINCIPALS_SESSION_KEY org.apache.shiro.subject.support.DefaultSubjectContext#AUTHENTICATED_SESSION_KEY 通过上面的分析，此时就能写出从缓存中删除失效Session的代码，如下： 12345678910111213141516171819202122232425/** * session过期有三种可能，如下： * 1、isValid判断，这个会在访问请求的时候shiro会自动验证，并且设置进去 * 2、用户长期不请求，此时的isValid并不能验证出来，此时需要比较最后执行的时间和开始时间 * 3、没有登录就访问的也会在redis中生成一个Session，但是此时的Session中是没有两个属性的 * 1、org.apache.shiro.subject.support.DefaultSubjectContext#PRINCIPALS_SESSION_KEY * 2、org.apache.shiro.subject.support.DefaultSubjectContext#AUTHENTICATED_SESSION_KEY */ public static void clearExpireSession()&#123; //获取所有的Session Collection&lt;Session&gt; sessions = redisSessionDao.getActiveSessions(); sessions.forEach(s-&gt;&#123; SimpleSession session= (SimpleSession) s; //第一种可能 Boolean status1=!session.isValid(); //第二种可能用开始时间和过期时间比较 Boolean status2=session.getLastAccessTime().getTime()+session.getTimeout()&lt;new Date().getTime(); //第三种可能 Boolean status3= Objects.isNull(session.getAttribute(DefaultSubjectContext.AUTHENTICATED_SESSION_KEY))&amp;&amp;Objects.isNull(session.getAttribute(DefaultSubjectContext.PRINCIPALS_SESSION_KEY)); if (status1||status2||status3)&#123; //清楚session redisSessionDao.delete(session); &#125; &#125;); &#125; SSM+Shiro整合 源码地址：https://github.com/chenjiabing666/ssm-shiro]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Shiro源码解析]]></title>
      <url>%2F2019%2F08%2F13%2FShiro%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[FilterChainManager 过滤器管理器，在ShiroFilterFactoryBean创建的时候会创建管理器，将配置好的过滤器添加到其中 当发出请求的时候会其中找出和url匹配过滤器执行 ShiroFilterFactoryBean 实现了FactoryBean接口，创建了一个SpringShiroFilter对象，在getObject方法中会创建，创建的步骤如下： 创建FIlter管理器 创建11个默认的过滤器，并且其中的uri会被设置全局配置的uri，具体逻辑在org.apache.shiro.spring.web.ShiroFilterFactoryBean#applyGlobalPropertiesIfNecessary方法 将定义的Filter设置过滤器管理器中的filters属性中，并且调用applyGlobalPropertiesIfNecessary方法设置全局属性 构建过滤器链（chain），保存在filterChains的属性中 实现了BeanPostProcessor接口，在postProcessBeforeInitialization方法中就是获取到ioc容器中的Filter类型的Bean将其设置到filters属性中 12345678910111213public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof Filter) &#123; log.debug("Found filter chain candidate filter '&#123;&#125;'", beanName); Filter filter = (Filter) bean; // applyGlobalPropertiesIfNecessary(filter); //放入到filters属性中 getFilters().put(beanName, filter); &#125; else &#123; log.trace("Ignoring non-Filter bean '&#123;&#125;'", beanName); &#125; return bean; &#125; Shiro中的过滤器 Shiro中的过滤器设计的很巧妙，每一个抽象的Filter都有不同的职责 下面介绍的一些过滤器都是按照父类和子类从上向下介绍。 OncePerRequestFilter 该类是相对于有作用的过滤器的顶层，所有的过滤器都继承这个抽象类，该类保证了每一次请求只执行一次过滤器，其中的过滤器的doFilter方法就在其中定义，如下： 123456789101112131415161718192021222324252627public final void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; String alreadyFilteredAttributeName = getAlreadyFilteredAttributeName(); if ( request.getAttribute(alreadyFilteredAttributeName) != null ) &#123; log.trace("Filter '&#123;&#125;' already executed. Proceeding without invoking this filter.", getName()); filterChain.doFilter(request, response); &#125; else //noinspection deprecation if (/* added in 1.2: */ !isEnabled(request, response) || /* retain backwards compatibility: */ shouldNotFilter(request) ) &#123; log.debug("Filter '&#123;&#125;' is not enabled for the current request. Proceeding without invoking this filter.", getName()); filterChain.doFilter(request, response); &#125; else &#123; // Do invoke this filter... log.trace("Filter '&#123;&#125;' not yet executed. Executing now.", getName()); request.setAttribute(alreadyFilteredAttributeName, Boolean.TRUE); try &#123; //过滤器真正执行的逻辑方法 doFilterInternal(request, response, filterChain); &#125; finally &#123; // Once the request has finished, we're done and we don't // need to mark as 'already filtered' any more. request.removeAttribute(alreadyFilteredAttributeName); &#125; &#125; &#125; 在doFilter中有一个方法doFilterInternal(request, response, filterChain)，这个方法是执行过滤器的真正逻辑，被子类AdviceFilter实现 AdviceFilter Advice很熟悉，这个抽象类能够实现像AOP一样的功能，其中定义了两个方法，分别是preHandle、postHandle，这两个方法能在过滤器执行前后做一些事情。 其中一个重要的方法，是执行过滤器的主要方法，在其中完成AOP相应的功能，如下： 1234567891011121314151617181920212223242526272829public void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException, IOException &#123; Exception exception = null; try &#123; //在执行下一个过滤器前执行，如果返回的ttrue表示执行下一个过滤器，否则结束执行 boolean continueChain = preHandle(request, response); if (log.isTraceEnabled()) &#123; log.trace("Invoked preHandle method. Continuing chain?: [" + continueChain + "]"); &#125; if (continueChain) &#123; //执行下一个过滤器 executeChain(request, response, chain); &#125; //后置处理，过滤器执行完毕之后执行 postHandle(request, response); if (log.isTraceEnabled()) &#123; log.trace("Successfully invoked postHandle method"); &#125; &#125; catch (Exception e) &#123; exception = e; &#125; finally &#123; //清除 cleanup(request, response, exception); &#125; &#125; PathMatchingFilter 用于请求的url匹配，如果请求的url匹配了，那么需要执行onPreHandle判断是否继续执行后面的过滤器 url匹配的逻辑主要在preHandle方法中，如下： 12345678910111213141516171819202122protected boolean preHandle(ServletRequest request, ServletResponse response) throws Exception &#123; if (this.appliedPaths == null || this.appliedPaths.isEmpty()) &#123; if (log.isTraceEnabled()) &#123; log.trace("appliedPaths property is null or empty. This Filter will passthrough immediately."); &#125; return true; &#125; for (String path : this.appliedPaths.keySet()) &#123; // If the path does match, then pass on to the subclass implementation for specific checks //(first match 'wins'): if (pathsMatch(path, request)) &#123; log.trace("Current requestURI matches pattern '&#123;&#125;'. Determining filter chain execution...", path); Object config = this.appliedPaths.get(path); return isFilterChainContinued(request, response, path, config); &#125; &#125; //no path matched, allow the request to go through: return true; &#125; AccessControlFilter 用于控制访问资源的权限，该类继承上面的三个类，其中有如下几个重要的方法： protected abstract boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue)：判断当前的访问是否有权限，如果有权限，那么正常继续执行，如果返回false，那么将会执行onAccessDenied方法 protected abstract boolean onAccessDenied(ServletRequest request, ServletResponse response)：isAccessAllowed返回false的时候将会执行，表示当前没有权限访问，需要执行相应的逻辑 public boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue)：在过滤器继续执行之前执行的逻辑，其中默认就是调用了isAccessAllowed判断权限，如下： 1234public boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; //逻辑或，如果第一条件为false，将会执行第二个方法，反之不执行 return isAccessAllowed(request, response, mappedValue) || onAccessDenied(request, response, mappedValue); &#125; AuthenticationFilter 抽象类，实现了父类的isAccessAllowed方法，用于权限控制，只有当前的用户认证之后才返回true 其中的几个重要的方法如下： isAccessAllowed：实现了父类的方法，只有用户认证之后才返回true issueSuccessRedirect：重定向方法，默认重定向到配置的successUrl 实现的过滤器 上面介绍的几个都是抽象类，在DefaultFilter中的11个过滤器都是实现了上面的抽象类 FormAuthenticationFilter shiro默认配置的过滤器，名称是authc 其中实现了登录的请求和认证的功能，我们可以不用重写登录的方法，而是配置一个url映射到该过滤器即可完成登录。 默认的登录的用户名和密码的映射字段如下： 当然我们可以覆盖这个属性，只需要创建一个当前的过滤器，将其添加到IOC中即可，当然其中的beanName要是authc 12public static final String DEFAULT_USERNAME_PARAM = "username";public static final String DEFAULT_PASSWORD_PARAM = "password"; 其中实现的onAccessDenied方法有如下的两个功能： 如果和配置的loginUrlng 相同，那么表示是登录的功能（也不全然是，也可以是一个没有认证的重定向的url，这个在前后端分离的时候常用） 重定向的功能，如果既不是登录的url也没有通过认证，那么将会重定向到配置的loginUrl 自定义过滤器 在现在的项目中大多使用的是前后端分离，现在我们使用自定义一个过滤器实现登录。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 继承AccessControlFilter抽象类，实现权限控制的访问 */@Slf4jpublic class LoginFilter extends AccessControlFilter &#123; private final static String USERNAME="userName"; private final static String PASSWORD="password"; /** * 登录成功的url */ private String successUrl="success"; /** * 登录失败的url */ private String failUrl="fail"; public LoginFilter(String successUrl, String failUrl) &#123; this.successUrl = successUrl; this.failUrl = failUrl; &#125; /** * 判断是否认证成功 */ @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; Subject subject = SecurityUtils.getSubject(); return subject.isAuthenticated(); &#125; /** * 创建UserNamePasswordToken */ private UsernamePasswordToken createToken(ServletRequest request)&#123; String userName = WebUtils.getCleanParam(request, USERNAME); String password = WebUtils.getCleanParam(request, PASSWORD); return new UsernamePasswordToken(userName,password); &#125; /** * 没有认证成功执行的方法 */ @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; Subject subject=SecurityUtils.getSubject(); try &#123; //执行登录 subject.login(createToken(request)); Map&lt;String,String&gt; params=new HashMap&lt;&gt;(); params.put("token", subject.getSession().getId().toString()); //此处需要将token传入重定向的url，因为重定向的url不是匿名访问的，配置的authc，并且还需要将token返回 //如果走的是匿名的url的话，那么从Subject中获取的Session并不是认证成功的 WebUtils.issueRedirect(request, response, successUrl,params); &#125;catch (AuthenticationException ex)&#123; log.info("登录失败",ex); //登录失败，重定向到指定的url WebUtils.issueRedirect(request, response, failUrl); &#125; //不在执行下面的逻辑 return false; &#125;&#125; 配置过滤器 12345678910111213141516171819202122232425262728293031/** * 创建登录的过滤器 */ @Bean public LoginFilter loginFilter()&#123; return new LoginFilter("/user/success", "/user/unauthentic"); &#125;//配置登录的urlfilterChainDefinitionMap.put("/login", "loginFilter");//成功的重定向的请求 /** * LoginFilter登录成功重定向的请求 * @return */ @RequestMapping("success") public PageResponse success(String token)&#123; return new PageResponse("登录成功","0",token); &#125;//失败的重定向 /** * 没有登录跳转到的uri * @return */ @GetMapping("/unauthentic") public PageResponse unauthentic()&#123; return new PageResponse("尚未登录","401"); &#125; 配置好之后，就能直接通过login访问了 过滤器创建 过滤器的来源： shiro容器中默认的11个过滤器，如下： 1234567891011anon(AnonymousFilter.class), authc(FormAuthenticationFilter.class), authcBasic(BasicHttpAuthenticationFilter.class), logout(LogoutFilter.class), noSessionCreation(NoSessionCreationFilter.class), perms(PermissionsAuthorizationFilter.class), port(PortFilter.class), rest(HttpMethodPermissionFilter.class), roles(RolesAuthorizationFilter.class), ssl(SslFilter.class), user(UserFilter.class); 自定义的过滤器并且是注入IOC容器中的，这样在容器启动的时候会自动扫描到ShiroFilterFactoryBean中的filters中（后置处理器），如下： 123456789101112public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof Filter) &#123; log.debug("Found filter chain candidate filter '&#123;&#125;'", beanName); Filter filter = (Filter) bean; //设置全局属性（如果自定义的过滤器中的三个url没有改变，那么将会启用全局配置的url，否则还是使用自定义设置的url） applyGlobalPropertiesIfNecessary(filter); getFilters().put(beanName, filter); &#125; else &#123; log.trace("Ignoring non-Filter bean '&#123;&#125;'", beanName); &#125; return bean; &#125; 什么是能够被Shiro执行的过滤器？ 在Shiro中并不是只要你配置了过滤器就能工作，必要的操作就是将其设置到ShiroFilterFactoryBean中的filterChainDefinitionMap的属性中 同一个url能否配置多个过滤器？ 肯定是能的，只需要在配置filterChainDefinitionMap的时候指定多个即可，使用逗号分隔，如下： 1filterChainDefinitionMap.put("/user/login", "anon,customFilter"); 假设对于请求的url能够匹配多个filterChainDefinitionMap，那么应该使用哪一个过滤器链？ 从源码中可以看到，在获取拦截器链的逻辑是只要第一个匹配了，那么就直接返回这个拦截器链，下面的就不执行了，因此是先在filterChainDefinitionMap中配置的先被使用，后面的会被忽略，源码如下： 1234567891011121314151617181920212223242526//org.apache.shiro.web.filter.mgt.PathMatchingFilterChainResolver#getChainpublic FilterChain getChain(ServletRequest request, ServletResponse response, FilterChain originalChain) &#123; //获取管理器 FilterChainManager filterChainManager = getFilterChainManager(); if (!filterChainManager.hasChains()) &#123; return null; &#125; //获取请求的url String requestURI = getPathWithinApplication(request); //循环遍历所有配置在filterChainDefinitionMap中的过滤器的名字 for (String pathPattern : filterChainManager.getChainNames()) &#123; //url匹配 if (pathMatches(pathPattern, requestURI)) &#123; if (log.isTraceEnabled()) &#123; log.trace("Matched path pattern [" + pathPattern + "] for requestURI [" + requestURI + "]. " + "Utilizing corresponding filter chain..."); &#125; //如果匹配了直接返回过滤器链的代理对象 return filterChainManager.proxy(originalChain, pathPattern); &#125; &#125; return null; &#125; 创建过滤器的流程图如下：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mybatis源码解析]]></title>
      <url>%2F2019%2F08%2F05%2Fmybatis%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Configuration mybatis的全局配置类，其中封装了mybatis的全部配置，在mybaits加载全局配置文件和Mapper文件的时候，会将里面的xml中的各个元素解析出来，封装在其中。 主要的解析流程在org.apache.ibatis.builder.xml.XMLConfigBuilder#parseConfiguration有详细描述。 12345678910111213141516171819202122private void parseConfiguration(XNode root) &#123; try &#123; //issue #117 read properties first propertiesElement(root.evalNode("properties")); Properties settings = settingsAsProperties(root.evalNode("settings")); loadCustomVfs(settings); loadCustomLogImpl(settings); typeAliasesElement(root.evalNode("typeAliases")); pluginElement(root.evalNode("plugins")); objectFactoryElement(root.evalNode("objectFactory")); objectWrapperFactoryElement(root.evalNode("objectWrapperFactory")); reflectorFactoryElement(root.evalNode("reflectorFactory")); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 environmentsElement(root.evalNode("environments")); databaseIdProviderElement(root.evalNode("databaseIdProvider")); typeHandlerElement(root.evalNode("typeHandlers")); mapperElement(root.evalNode("mappers")); &#125; catch (Exception e) &#123; throw new BuilderException("Error parsing SQL Mapper Configuration. Cause: " + e, e); &#125; &#125; MapperRegistry 其中存放了所有的Mapper信息，相当于Mapper的注册中心 所有的Mapper信息都存放在Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers这个Map中，key是Mapper的全类名，value是MapperProxyFactory对象（用来创建代理对象） 在mybaits加载配置文件解析Mapper的时候，会调用addMapper方法，将其添加到Map中。在获取Mapper的时候会调用getMapper方法，利用MapperProxyFactory对象创建一个代理对象返回。 MappedStatement 封装了一个增删改查标签的全部属性，一个标签就是一个MappedStatement，保存在全局配置类中的Map&lt;String, MappedStatement&gt; mappedStatements中 MapperProxyFactory 创建Mapper代理对象的工厂类，其中最重要的两个方法如下： 12345678910//使用MapperProxy创建一个代理对象protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; //封装一个MapperProxy final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125; MapperProxy Mapper的代理类，实现了InvocationHandler，当mapper调用方法的时候真正执行的方法是invoke 12345678910111213public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (method.isDefault()) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125; 其中的属性有sqlSession（其中的属性有全局配置类Configuration）、mapperInterface（mapper真正的接口）、Map&lt;Method, MapperMethod&gt; methodCache MapperMethod 封装了Mapper接口中的单个方法，其中有两个重要的属性，如下： SqlCommand：封装方法的全类名和执行的增删改查的类型（SqlCommandType的枚举类型） MethodSignature：方法的签名，其中封装了该方法的一些信息，比如返回类型，返回值的类型等信息。 其中有一个public Object execute(SqlSession sqlSession, Object[] args)方法，用来执行方法，如下： 根据方法的不同类型，执行不同的逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) &#123; result = Optional.ofNullable(result); &#125; &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException("Unknown execution method for: " + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException("Mapper method '" + command.getName() + " attempted to return null from a method with a primitive return type (" + method.getReturnType() + ")."); &#125; return result; &#125; BoundSql 封装了SQL语句的信息，包括需要执行的sql语句，参数列表等信息，通过MappedStatement中getBoundSql()方法创建。 ResultHandlerTypeHandlerMybatis四大关键类Executor 执行器：在mybaits中负责执行增删改查和事务的操作，mybatis会根据不同的executorType创建不同的执行器 Mybaits的执行器主要有如下的类型： ExecutorType.SIMPLE：这个执行器类型不做特殊的事情。它为每个语句的执行创建一个新的预处理语句。 ExecutorType.REUSE：这个执行器类型会复用预处理语句。 ExecutorType.BATCH：这个执行器会批量执行所有更新语句，如果 SELECT 在它们中间执行，必要时请把它们区分开来以保证行为的易读性。 我们通过SqlSessionFactory创建sqlSession的时候可以传入执行器的类型，如果不传入，默认使用Simple类型的，在源码中的创建的执行的逻辑如下： 12345678910111213141516171819202122//org.apache.ibatis.session.Configuration#newExecutor(org.apache.ibatis.transaction.Transaction, org.apache.ibatis.session.ExecutorType)public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; //如果没有指定，使用默认的类型 executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; //批量执行的执行器 if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; //缓存执行器，实现二级缓存 if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor; &#125; 实现类型如下： BatchExecutor：批量执行器 ReuseExecutor：复用执行器 SimpleExecutor：简单执行器，默认的 CachingExecutor：缓存执行器，mybaits中默认使用的执行器，用于二级缓存 ParameterHandler 主要作用就是设置为Statement设置参数 ResultSetHandler 主要作用就是对最后的结果进行处理 StatementHandler 顾名思义就是创建JDBC中的Statement，实现类如下： SimpleStatementHandler PreparedStatementHandler CallableStatementHandler 主要的作用就是处理Statement，执行查询，对参数、查询结果进行处理。 主要的方法如下： Statement prepare(Connection connection, Integer transactionTimeout)：创建Statement void parameterize(Statement statement：设置参数 void batch(Statement statement)：批量处理 &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler)：执行查询 流程图 分析源码执行流程，画出对应的流程图，方便理解和记忆 Mybatis创建MapperProxy 包括了读取全局配置文件和Mapper文件生成全局配置类、创建Mapper代理对象的详细过程 Mybaits执行查询 主要描述了mybaits通过代理对象如何执行查询语句到对查询结果的处理过程的详细描述 Mybaits执行查询的简化版 主要根据Mybatis中的重要的四大类，和SqlSession、TypeHandler进行简化描述，如下：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mybatis深入学习]]></title>
      <url>%2F2019%2F08%2F05%2Fmybatis%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[环境搭建 按照官方文档搭建即可 typeAliases（别名） 在使用mybatis标签的时候，需要指定类的全类名，比如resultType=xx.xxx.xx，但是我们可以为类指定别名，那么就可以直接使用别名，避免全类名冗余【不推荐使用】 别名的配置有两种方式，这里我们讲解简单的配置方式，步骤如下： 在mybatis的全局配置文件下指定别名的包扫描如下： 123&lt;typeAliases&gt; &lt;package name="cn.tedu.domain"/&gt; &lt;/typeAliases&gt; 在domain这个包下的所有类默认的别名是类名首字母小写，但是我们也可以使用注解指定，如下： 1234@Alias("author")public class Author &#123; ...&#125; 内建的别名【推荐使用】 mybatis对java中基本类型和基本的引用类型内嵌了别名，我们可以直接使用别名进行指定，这样利于开发，内建的别名如下： 别名 映射的类型 _byte byte _long long _short short _int int _integer int _double double _float float _boolean boolean string String byte Byte long Long short Short int Integer integer Integer double Double float Float boolean Boolean date Date decimal BigDecimal bigdecimal BigDecimal object Object map Map hashmap HashMap list List arraylist ArrayList collection Collection iterator Iterator 参数处理 mybatis内部会将我们传入的参数封装成一个Map，key就是以param1、param2.... 单个参数 单个参数在sql语句中可以任意指定，比如#{a}…，或者可以使用#{param1} 多个参数 使用@Param指定key，那么就可以在sql语句中直接使用这个key即可，如下： 12@Select("select * from patient_info where ipt_num=#&#123;iptNum&#125; and status=#&#123;status&#125;") Patient selectByIptNumAndInhos(@Param("iptNum") String iptNum, @Param("status") String status); 也可以直接使用mybatis中默认的key，即是param1….. 12@Select("select * from patient_info where ipt_num=#&#123;param1&#125; and status=#&#123;param2&#125;") Patient selectByIptNumAndInhos(String iptNum,String status); 参数是Map类型 mybatis默认的会将参数转换为map，那么我们直接传入一个map那是再好不过了，此时的key就可以直接使用，如下： 12345678910111213@Select("select * from patient_info where ipt_num=#&#123;iptNum&#125; and status=#&#123;status&#125;") Patient selectByIptAndInhosNumMap(Map ipts);@Test public void test3() throws IOException &#123; SqlSessionFactory sqlSessionFactory = XmlConfigInit.getSqlSessionFactory(); PatientMapper mapper = sqlSessionFactory.openSession().getMapper(PatientMapper.class); Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put("iptNum","15627656"); map.put("status","1"); Patient patient = mapper.selectByIptAndInhosNumMap(map); System.out.println(patient); &#125; POJO【推荐使用】 对于POJO可以直接使用成员属性的名称就可以取值，这个经常使用，不再演示 返回结果封装 mybatis对于返回结果如何封装有多种实现方式，可以返回List，POJO，Map等类型的数据 返回POJO 对于从数据库中查询单条数据库的时候，返回一个POJO只需要sql查询的字段和POJO类中的属性相同即可自动映射，当然我们也可以开启驼峰配置 resultType指定返回的POJO的全类名即可，或者指定别名 此处不演示 返回List 同POJO，此时的resultType指定的仍然是List泛型的全类名或者别名 返回Map mybatis还可以返回Map类型的数据，比如我们查询患者的信息，使用Map接收数据，key是患者的id，value就是POJO，如下： 1234567/** * 使用@MapKey注解指定返回Map中的key，这里设定的是Patient中的id属性作为key * @return */ @MapKey("id") @Select("select * from patient_info") Map&lt;Integer,Patient&gt; selectAllReturnMap(); 在返回的Map的时候需要指定POJO类的哪个字段作为Map的key，使用@MapKey这个注解指定 ResultMap mybatis还支持使用ResultMap自定义结果映射，此时的select语句中需要指定resultMap为当前的定义的id 经常使用，不再演示 分步查询 在mybatis中collection和association中都是可以使用分步查询 我们需要查询一个科室下的所有患者，那么实体类定义如下： 123456789101112131415@Data@ToStringpublic class Dept &#123; private Integer id; private String name; private List&lt;Patient&gt; patients;&#125;@Data@ToStringpublic class Patient &#123; private String userId; private Integer id; private String status;&#125; 不采用分布查询，此时我们的resultMap应该如下： 1234567891011121314151617181920212223&lt;resultMap id="baseResultMap" type="cn.tedu.domain.Dept"&gt; &lt;id column="id" property="id" /&gt; &lt;result column="name" property="name"/&gt; &lt;collection property="patients" ofType="cn.tedu.domain.Patient"&gt; &lt;id column="pid" property="id"/&gt; &lt;result column="userId" property="userId"/&gt; &lt;result column="pstatus" property="status"/&gt; &lt;/collection&gt; &lt;/resultMap&gt;//sql SELECT d.id AS id, d.NAME AS NAME, p.id AS pid, p.user_id AS userId, p.STATUS AS pstatus FROM dept_info d LEFT JOIN patient_info p ON p.dept_id = d.id WHERE d.id =#&#123;id,jdbcType=INTEGER&#125; 但是我们也可以采用分布查询的方式，先查询出科室的信息，再根据科室的id查询出对应患者的信息，实现步骤如下： 定义一个方法查找科室，此时的resultMap指定的是分步查询的id 12345678&lt;select id="selectById" resultMap="ByStepResultMap"&gt; SELECT * FROM dept_info WHERE id =#&#123;id,jdbcType=INTEGER&#125; &lt;/select&gt; 定义一个方法根据科室id查询患者信息 12@Select("SELECT * from patient_info where dept_id=#&#123;deptId&#125;") List&lt;Patient&gt; selectByDeptId(Integer deptId); 在resultMap中指定分步查询 12345678910111213141516&lt;!--分步查询科室信息和患者信息--&gt; &lt;resultMap id="ByStepResultMap" type="cn.tedu.domain.Dept"&gt; &lt;id column="id" property="id" /&gt; &lt;result column="name" property="name"/&gt; &lt;!--ofType：指定级联属性的类型--&gt; &lt;!--select：指定分步查询患者信息的方法，全类名+方法名--&gt; &lt;!--column：指定查询科室获取的结果的哪一个字段作为查询患者方法的参数，可以指定多个 如果指定多个，那么需要将参数封装成map，比如column="&#123;key1=column1,key2=column2&#125;" --&gt; &lt;!--fetchType：在开启全局延迟加载的时候设置是否延迟加载，默认是延迟加载，可以设置为eager表示不延迟加载--&gt; &lt;collection property="patients" ofType="cn.tedu.domain.Patient" select="cn.tedu.mapper.PatientMapper.selectByDeptId" column="id"&gt; &lt;/collection&gt; &lt;/resultMap&gt; 延迟加载 mybatis默认是不使用延迟加载的，因此当使用分步查询的时候即使没有用到分步查询的结果仍然会发出sql语句 我们可以在全局配置文件中设置开启延迟加载，如下： 123456&lt;settings&gt; &lt;!--延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。--&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;!--当开启时，任何方法的调用都会加载该对象的所有属性。 否则，每个属性会按需加载（参考 lazyLoadTriggerMethods)。--&gt; &lt;setting name="aggressiveLazyLoading" value="false"/&gt; &lt;/settings&gt; 内置参数 mybatis中内置了两个参数，在写sql的时候可以直接拿来使用，如下： _parameter：代表整个参数，如果是一个参数就表示这个参数，如果是多个参数，此时的参数会被封装成一个Map，那么_parameter此时就代表整个Map _databaseId：如果配置了databaseIdProvider标签，就代表当前数据库的别名 实例： 12@Select("SELECT * from patient_info where dept_id=#&#123;_parameter&#125;") List&lt;Patient&gt; selectByDeptId(Integer deptId); 如果是一个参数，并且是POJO对象，我们还可以使用_parameter判断是否为空，如下： 123&lt;if test="_parameter!=null"&gt; .....&lt;/if&gt; 如果是多个参数，那么就表示一个Map，此时可以直接使用_parameter.key1....直接获取值即可，当然如果没有指定@Param注解，此时还可以使用_parameter.param1,_parameter.param2...直接获取对应的值 批量处理 Mybatis针对批量操作有两种常用的方法，第一种就死通过动态sql在sql语句中使用for-each拼写，第二种就是使用Mybaits自带的批量执行器（BatchExecutor），这里主要介绍第二种的方式 如何配置？有如下两种方式 在全局配置文件的settings中配置一个属性defaultExecutorType =BATCH即可，不过这种方式将会导致所有的sql操作都会使用批量操作。 我们可以在获取SqlSession的时候指定执行类型，如下： SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH);，此时当前的SqlSession执行的就是批量操作。 Mybaits-Spring执行批量处理 Spring执行批量处理很简单，只需要在ioc容器中注入一个SqlSessionTemplate，并且设置批量处理的属性即可，如下： 这种改变是全局的，慎用 12345678910/** * 注入SqlSessionTemplate，替代SqlSessionFactory直接创建SqlSession，并且能够使用Spring的事务管理 * 如果需要使用批量处理，在构造方法中指定ExecutorType.BATCH即可，那么全部的操作的都会使用 * 【可以不配置，需要的时候使用】 */ @Bean public SqlSessionTemplate sqlSessionTemplate() throws Exception &#123; SqlSessionTemplate sqlSessionTemplate = new SqlSessionTemplate(sqlSessionFactory().getObject(),ExecutorType.BATCH); return sqlSessionTemplate; &#125; 类型处理器（TypeHandler） 用于处理Java类型和JDBC类型之前的映射关系，mybaits中内置了许多的类型处理器，一般我们在使用#{}中的jdbcType属性的时候，mybaits框架会为我们设置相应的处理器，比如jdbcType=DATE，那么mybatis默认对应的处理器就是DateOnlyTypeHandler（只有年月日），如果我们设置了jdbcType=TIMESTAMP，那么mybatis对Date类型的类型处理器就是DateTypeHandler，关于类型处理器和jdbcType的对应关系，看官方文档中typeHandler这一节 内置处理器执行的时间： 在StatementHandler创建Statement之后，会调用ParameterHandler设置参数，其中执行了类型处理器的setParametes的方法，设置对应的参数 在DefaultResultsetHandler处理执行结果的时候，会调用的TypeHandler中的getResult方法获取结果集 TypeHandler中的方法如下： 12345678910111213141516171819202122232425262728293031323334353637383940public interface TypeHandler&lt;T&gt; &#123; /** * 为预编译语句设置参数的时候执行，实际就是调用setxxx方法设置参数 * @param ps PreparedStatement 对象 * @param i * @param parameter 参数 * @param jdbcType #&#123;&#125;中自定义的jdbcType * @throws SQLException */ void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException; /** * 根据列名获取指定的值 * @param rs ResultSet结果集 * @param columnName 列名 * @return * @throws SQLException */ T getResult(ResultSet rs, String columnName) throws SQLException; /** * 根据下标获取指定列的值 * @param rs ResultSet结果集 * @param columnIndex 下标 * @return * @throws SQLException */ T getResult(ResultSet rs, int columnIndex) throws SQLException; /** * 调用存储过程的获取返回值的时候 * @param cs * @param columnIndex * @return * @throws SQLException */ T getResult(CallableStatement cs, int columnIndex) throws SQLException;&#125; 虽然mybatis中内置了许多的类型处理器，但是我们也可以自定义类型处理器，并且作用到指定需要处理的类型中，自定义的方式有两种，如下： 实现TypeHandler接口 继承BaseTypeHandler【推荐】 实例 实例：我们需要将一个List&lt;Auth&gt;对象存入数据库的时候是以json字符串的形式，获取的是以List集合的形式，此时我们可以自定义一个TypeHandler，如下： 12345678910111213141516171819202122232425262728293031323334/** * 自定义类型转换器，将List&lt;Auth&gt;数据存入数据库的时候是以json字符串存入的，获取返回的结果的时候是List集合 * @MappedJdbcTypes(value = &#123;JdbcType.VARCHAR&#125;)：指定了映射的jdbcType的类型是VARCHAR * @MappedTypes(value = &#123;Auth.class&#125;)：指定了映射的java类型是Auth */@MappedJdbcTypes(value = &#123;JdbcType.VARCHAR&#125;)@MappedTypes(value = &#123;Auth.class&#125;)public class AuthTypeHandler extends BaseTypeHandler &#123; /** * 将参数转换为json数据存入数据库 */ @Override public void setNonNullParameter(PreparedStatement ps, int i, Object parameter, JdbcType jdbcType) throws SQLException &#123; String json = new Gson().toJson(parameter); ps.setString(i,json); &#125; @Override public Object getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; String string = rs.getString(columnName); return new Gson().fromJson(string,new TypeToken&lt;List&lt;Auth&gt;&gt;()&#123;&#125;.getType()); &#125; @Override public Object getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; String string = rs.getString(columnIndex); return new Gson().fromJson(string,new TypeToken&lt;List&lt;Auth&gt;&gt;()&#123;&#125;.getType()); &#125; @Override public Object getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; return null; &#125;&#125; 需要在全局配置文件中设置TypeHandler的包扫描，如下： 1234&lt;!--设置自动扫描包下的typeHandler--&gt; &lt;typeHandlers&gt; &lt;package name="cn.tedu.typehandler"/&gt; &lt;/typeHandlers&gt; 此时的类型处理器还是不起作用的，需要在insert、update的#{}中设置一下typehandler属性，如下： #{}中有一个typeHandler属性，指定自定义的TypeHandler即可 123456&lt;insert id="insertAdmin" parameterType="cn.tedu.domain.Admin"&gt; insert into t_admin(name,birthday,account,password,point,status,auths) values (#&#123;name,jdbcType=VARCHAR&#125;,#&#123;birthday,jdbcType=DATE&#125;, #&#123;account,jdbcType=VARCHAR&#125;,#&#123;password,jdbcType=VARCHAR&#125;, #&#123;point,jdbcType=DOUBLE&#125;,#&#123;status,jdbcType=VARCHAR&#125;,#&#123;auths,jdbcType=VARCHAR,typeHandler=cn.tedu.typehandler.AuthTypeHandler&#125;) &lt;/insert&gt; 对select语句设置类型处理器，只能在resultMap中设置，如下： 在result中需要设置javaType，jdbcType，typeHandler三个属性，这里的auths就是需要映射的List&lt;AUth&gt; 123456&lt;resultMap id="BaseResultMap" type="cn.tedu.domain.Admin"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="name" property="name" /&gt; &lt;result column="auths" property="auths" javaType="cn.tedu.domain.Auth" jdbcType="VARCHAR" typeHandler="cn.tedu.typehandler.AuthTypeHandler"&gt;&lt;/result&gt; &lt;/resultMap&gt; 枚举类型处理器 枚举的类型处理器默认是EnumTypeHandler，存入和取出都是存储的枚举的名称，也有一个EnumOrdinalTypeHandler是按照枚举的索引存储和查询的。 我们也可以自定义类型处理器来处理枚举类型。 插件 插件的设计其实就是一个拦截器，在目标方法执行之前进行拦截，当然这里只是针对Mybatis中的四大对象进行拦截，四大对象如下： Executor StatementHandler ParameterHandler ResultSetHandler Interceptor能够做到对四大对象中的每一个方法进行拦截 实现一个插件很简单，只需要实现org.apache.ibatis.plugin.Interceptor接口即可 对应Interceptor这个接口的方法解释如下： 1234567891011121314151617181920212223242526272829public interface Interceptor &#123; /** * 拦截器真正执行的方法，其中的invocation.proceed()是用来执行目标方法的，只有执行了这个proceed方法，目标方法才会执行，否则不执行 * @param invocation * @return 返回目标方法执行的结果，return invocation.proceed(); * @throws Throwable */ Object intercept(Invocation invocation) throws Throwable; /** * 四大对象生成代理对象的方法，在四大对象创建的时候，都会调用一个pluginAll方法返回一个代理对象 * 这个方法不需要做修改，默认就行了 * @param target 目标对象 * @return 返回的代理对象（层层包装，表示只有一层） */ default Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; /** * 在全局配置文件中&lt;plugin&gt;标签中设置properties属性，会封装在此方法的properties中 * @param properties */ default void setProperties(Properties properties) &#123; // NOP &#125;&#125; 实现一个简单的插件 自定义一个插件，修改指定查询语句的入参。如下： 实现原理其实很简单，因为mybaits的增删改查标签所有的信息都封装在MappedStatement中，我们只需要获取这个对象，然后通过属性判断即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @Intercepts注解标记这是一个拦截器,其中可以指定多个@Signature * @Signature：指定该拦截器拦截的是四大对象中的哪个方法 * type：拦截器的四大对象的类型 * method：拦截器的方法，方法名 * args：入参的类型 */@Intercepts( &#123; @Signature(type = ParameterHandler.class,method ="setParameters",args = &#123;PreparedStatement.class&#125;) &#125;)public class FirstPlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; System.out.println("拦截器执行："+invocation.getTarget()); //目标对象 Object target = invocation.getTarget(); //获取目标对象中所有属性的值，因为ParameterHandler使用的是DefaultParameterHandler，因此里面的所有的属性都封装在其中 MetaObject metaObject = SystemMetaObject.forObject(target); //使用xxx.xxx.xx的方式可以层层获取属性值，这里获取的是mappedStatement中的id值 String value = (String) metaObject.getValue("mappedStatement.id"); //如果是指定的查询方法 if ("cn.tedu.mapper.AdminMapper.selectById".equals(value))&#123; //设置参数的值是2，即是设置id=2，因为这里只有一个参数，可以这么设置，如果有多个需要需要循环 metaObject.setValue("parameterObject", 2); &#125; //执行目标方法 return invocation.proceed(); &#125; //可以省略 @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; //可以省略 @Override public void setProperties(Properties properties) &#123; System.out.println(properties); &#125;&#125; 全局文件中配置： 123456&lt;!--配置插件，其中的property可以设置自己的属性，可以封装到setProperties中的properties中--&gt; &lt;plugins&gt; &lt;plugin interceptor="cn.tedu.plugin.FirstPlugin"&gt; &lt;property name="id" value="11"&gt;&lt;/property&gt; &lt;/plugin&gt; &lt;/plugins&gt; 重要的方法 SystemMetaObject.forObject(target)：可以获取目标类中所有的属性的值 metaObject.getValue(&quot;mappedStatement.id&quot;)：可以使用xxx.xxx层层的获取属性的值 metaObject.setValue(name, value)：设置属性的值 多个插件的执行顺序 全局配置文件中配置插件的顺序，决定插件的执行顺序，是相反的顺序。 如果有多个插件作用在同一个对象的同一个方法上，那么插件的执行顺序是怎样的？我们知道四大对象在创建的时候会调用拦截器中的plugin方法创建代理对象，这种代理实层层包装的，那么在后面的插件创建的代理是包裹在最外层的，因此肯定是先执行最外层的拦截器方法。 Spring整合Mybatis 官方文档 添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; 配置数据源、事务管理器、SqlSessionFactoryBean 这里使用了@MapperScan注解自动扫描Mapper接口 在SqlSessionFactoryBean中的配置中设置xml文件的位置和全局配置文件中的位置 SqlSessionTemplate的注入能够让我们很方便的获取一个SqlSession和Mapper，一旦注入之后，所有的获取Mapper的代理对象都会执行其中的getMapper方法获取，因此如果这里设置了批量处理，那么改变是全局的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 配置类 * @MapperScan：扫描所有的Mapper接口 */@Configuration@ComponentScan(basePackages = &#123;"cn.tedu.ssm"&#125;)@MapperScan(basePackages = &#123;"cn.tedu.ssm.mapper"&#125;)@EnableAspectJAutoProxy@EnableAsync@EnableTransactionManagementpublic class MainConfig &#123; /** * 注册数据源 */ @Bean public DruidDataSource dataSource()&#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(DataConfig.URL); dataSource.setUsername(DataConfig.USER); dataSource.setPassword(DataConfig.PWD); dataSource.setDriverClassName(DataConfig.DRIVER_NAME); return dataSource; &#125; /** * 配置SqlSessionFactoryBean，实际就是SqlSessionFactory */ @Bean public SqlSessionFactoryBean sqlSessionFactory() throws IOException &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); //设置数据源 sqlSessionFactoryBean.setDataSource(dataSource()); //配置扫描mapepr.xml文件 PathMatchingResourcePatternResolver classPathResource = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(classPathResource.getResources("classpath:mappers/*.xml")); //设置全局配置文件的位置 sqlSessionFactoryBean.setConfigLocation(classPathResource.getResource("classpath:mybatis-config.xml")); return sqlSessionFactoryBean; &#125; /** * 注入SqlSessionTemplate，替代SqlSessionFactory直接创建SqlSession，并且能够使用Spring的事务管理 * 如果需要使用批量处理，在构造方法中指定ExecutorType.BATCH即可，那么全部的操作的都会使用 * 【可以不配置，需要的时候使用】 */ @Bean public SqlSessionTemplate sqlSessionTemplate() throws Exception &#123; SqlSessionTemplate sqlSessionTemplate = new SqlSessionTemplate(sqlSessionFactory().getObject()); return sqlSessionTemplate; &#125; /** * 创建事务管理器 * @return */ @Bean public PlatformTransactionManager transactionManager()&#123; return new DataSourceTransactionManager(dataSource()); &#125;&#125; 注意 在和Spring整合的时候，原先全局配置中配置的数据源，事务管理器等都会被忽略，默认会加载Spring配置的事务管理器和数据源。 如果想要配置TypeHandler、Plugin、TypeAlias等设置，在SqlSessionFactoryBean中都是可以直接配置的，因此在和Spring整合之后，Mybaits的全局配置文件中需要配置的东西很少，几乎可以不用。 源码 全注解版的SSM整合，包括下面分页插件的整合：https://github.com/chenjiabing666/ssm-demo 分页插件 官方文档https://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md 使用环境：ssm环境下配置 添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; 配置拦截器，在和Spring整合下就只需要在SqlSessionFactoryBean中配置拦截器即可，如下： 1234567891011121314151617181920/** * 配置SqlSessionFactoryBean，实际就是SqlSessionFactory */ @Bean public SqlSessionFactoryBean sqlSessionFactory() throws IOException &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); //设置数据源 sqlSessionFactoryBean.setDataSource(dataSource()); //配置扫描mapepr.xml文件 PathMatchingResourcePatternResolver classPathResource = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(classPathResource.getResources("classpath:mappers/*.xml")); //设置全局配置文件的位置 sqlSessionFactoryBean.setConfigLocation(classPathResource.getResource("classpath:mybatis-config.xml")); //配置插件 PageInterceptor pageInterceptor = new PageInterceptor(); //可以配置PageHelper中的参数映射关系，这里使用默认的，不需配置// pageInterceptor.setProperties(); sqlSessionFactoryBean.setPlugins(pageInterceptor); return sqlSessionFactoryBean; &#125; 官方文档中有多种使用方式，我们使用面向接口的方式，如下： 只需要在doSelect中调用查询全部的sql即可 1234567891011@Test public void test3()&#123; SqlSessionTemplate sqlSessionTemplate = applicationContext.getBean(SqlSessionTemplate.class); final PatientMapper mapper = sqlSessionTemplate.getMapper(PatientMapper.class); PageInfo&lt;Object&gt; pageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(new ISelect() &#123; @Override public void doSelect() &#123; mapper.selectAllPatient(); &#125; &#125;); &#125; 自己整合工具类 在实际使用过程中上述的方式有点繁琐，本人自己整合一个工具类，能够很轻松的完成分页。 定义一个ParamReq类，如果有需要的分页的请求都继承这个类，如下： 12345678910111213141516171819202122232425262728293031323334353637383940import com.fasterxml.jackson.annotation.JsonIgnore;import lombok.Data;/** * 所有需要分页的请求要继承的类，其中提供了分页需要的参数 * 默认的映射关系是:pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero * 也可在设置拦截器的时候指定映射关系，具体看官方文档 * https://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md */@Datapublic class PageParam &#123; /** * 当前第几页 */ private Integer pageNum=1; /** * 每页查询的数量 */ private Integer pageSize=10; /** * 是否进行count查询，默认是true，查询 * 如果设置为false，那么总数total将会为-1，不进行count查询 */ @JsonIgnore private Boolean countSql=true; /** * 分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum&lt;=0 时会查询第一页， pageNum&gt;pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询。 */ @JsonIgnore private Boolean reasonable; /** * 默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 */ @JsonIgnore private Boolean pageSizeZero=true;&#125; 自定义执行接口，其实就是覆盖上面的doSelect方法，实现自己的执行查询的方法，如下： 12345678910111213141516/** * 分页需要实现的接口，在doExecute中只需调用查询全部数据的mapper即可 */@FunctionalInterfacepublic interface ExecutePageHelper extends ISelect &#123; /** * 实现类应该覆盖的方法 */ void doExecute(); @Override default void doSelect() &#123; doExecute(); &#125;&#125; 分页工具类，如下： 1234567891011121314151617/** * 执行分页插件的工具类 */public class PageHelperUtils &#123; /** * 执行PageHelper分页的方法 * @param req 请求对象，继承PageParam类 * @param executePageHelper ExecutePageHelper的接口实现类 * @param &lt;T&gt; 泛型，需要返回结果的类型 * @return */ public static &lt;T&gt; PageInfo&lt;T&gt; execute(PageParam req,ExecutePageHelper executePageHelper)&#123; //这里直接传入req，其实其中的值是有映射关系的，在PageParam中有讲到 return PageHelper.startPage(req).doSelectPageInfo(executePageHelper); &#125;&#125; 测试： 使用lambda表示可以方便的执行分页查询 123456789@Test public void test4()&#123; SqlSessionTemplate sqlSessionTemplate = applicationContext.getBean(SqlSessionTemplate.class); PatientMapper mapper = sqlSessionTemplate.getMapper(PatientMapper.class); //分页的请求类，继承ParamReq UserReq req=new UserReq(); PageInfo&lt;Patient&gt; pageInfo = PageHelperUtils.execute(req, mapper::selectAllPatient); System.out.println(pageInfo.getList()); &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc源码解读]]></title>
      <url>%2F2019%2F07%2F31%2FSpringmvc%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
      <content type="text"><![CDATA[实现Controller的方式 如何实现一个controller，在源码中其实将controller叫做handler，我们通常知道实现controller的方式就是在类上添加一个@Controller和@RequestMapping注解，但是还有其他的方式定义一个controller 实现Controller 使用Bean中的id指定路径，必须是以/开头 12345678@Component(value = "/user/test.do")public class UserController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; System.out.println("userController run....."); return null; &#125;&#125; 实现HttpRequestHandler 要求同上 1234567@Component(value = "/prod/test.do")public class ProductController implements HttpRequestHandler &#123; @Override public void handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws ServletException, IOException &#123; System.out.println("prodController run ....."); &#125;&#125; 使用注解 经常使用，不再细说 @EnableWebMvc 该注解使Spring MVC 开启高级功能的入口，主要的作用就是加载了一个配置类DelegatingWebMvcConfiguration，其中创建了MVC默认的一些组件，比如viewControllerHandlerMapping、RequestMappingHandlerMapping、BeanNameUrlHandlerMapping、RequestMappingHandlerAdapter 等等。 DispatcherServlet 一个用于分发请求的Servlet，一个请求进来之后，Servlet会根据HandlerMapping将请求转发给对应的Handler（controller）处理。 其中重要的方法如下： protected void doDispatch(HttpServletRequest request, HttpServletResponse response)：执行分发的流程 protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response)：渲染视图 HandlerMapping 顾名思义，就是保存Handler和Mapping之间的对应的关系，当然这种关系是多种的，有uri to beanName，有uri to HandlerMethod，不同的对应关系有不同的实现类处理，因此就衍生了后续的三种实现类。 BeanNameUrlHandlerMapping 见名思意，这种肯定是uri to beanName的实现，用于存储实现了Controller和HttpRequestHandler接口的Handler的映射关系 SimpleUrlHandlerMapping 这种也是uri to Handler的实现，不过这种用于存储View-controller、ResourceHttpRequestHandler的映射关系 RequestMappingHandlerMapping 这种用于实现uri to HandlerMethod的关系，从名称可以看出，这种是用于使用@RequestMapping注解的 HandlerExecutionChain 处理器执行链，其中存储了Handler和拦截器 HandlerAdapter 简单的说就是执行的Handler的适配类，定义了三个方法，如下： boolean supports(Object handler);：判断当前的HandlerAdapter是否支持这个Handler ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception;：执行Handler的方法 long getLastModified(HttpServletRequest request, Object handler);：获取请求都中的LastModified 该接口有多个实现类，如下： RequestMappingHandlerAdapter：匹配HandlerMethod HttpRequestHandlerAdapter：匹配实现了HttpRequestHandler接口的Handler SimpleControllerHandlerAdapter：匹配实现了Controller接口的Handler 执行流程分析]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc注解版开发]]></title>
      <url>%2F2019%2F07%2F31%2FSpringmvc%E6%B3%A8%E8%A7%A3%E7%89%88%E5%BC%80%E5%8F%91%2F</url>
      <content type="text"><![CDATA[项目搭建搭建原理 springMVC版本 此次使用的版本是Spring 5.1.8 配置内嵌tomcat 为了简化开发，使用tomcat插件实现web项目的运行，只需要在pom.xml中配置一个插件即可，如下： 123456789101112&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 之后在IDEA右侧的maven处可以看见tomcat7这个插件了，点击run即可运行 配置DispatcherServlet初始化器 配置的方式有多种，但是根据Spring文档推荐的方式如下： 1234567891011121314151617181920212223242526272829303132333435363738import cn.tedu.demo.config.AppConfig;import cn.tedu.demo.config.WebMvcConfig;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;/** * 配置DispatcherServlet初始化器，在容器启动的时候会加载初始化 * 入口就是/org/springframework/spring-web/5.1.8.RELEASE/spring-web-5.1.8.RELEASE.jar!/META-INF/services/javax.servlet.ServletContainerInitializer * web容器在启动的时候会加载META-INF/service下的文件 */public class StrartWebApplicationInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; /** * 配置主配置类，主配置类的作用就是配置业务所需要的各种Bean，比如dao，service * @return */ @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class[]&#123;AppConfig.class&#125;; &#125; /** * 配置MVC所需的配置类，该配置类的作用就是扫描controller，配置mvc的各种组件，比如视图解析器，拦截器等 * @return */ @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[]&#123;WebMvcConfig.class&#125;; &#125; /** * 配置servletMapping，相当于在DispatcherServlet中配置的url * @return */ @Override protected String[] getServletMappings() &#123; return new String[]&#123;"/"&#125;; &#125;&#125; 主配置文件 主配置文件主要的作用就是配置业务需求的Bean，比如dao，service层的 123456789101112import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.FilterType;import org.springframework.stereotype.Controller;/** * 业务逻辑的配置类，扫描所有的业务Bean，比如dao，service，排除所有的controller */@Configuration@ComponentScan(basePackages = &#123;"cn.tedu.demo"&#125;,excludeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,classes = &#123;Controller.class&#125;)&#125;)public class AppConfig &#123;&#125; MVC配置类 MVC配置类主要的作用就是扫描Controller，配置各种组件，比如视图解析器，拦截器等等 重要的两点如下： 使用@EnableWebMvc注解开启MVC功能，相当于xml文件中的&lt;mvc:annotation-driven/&gt; 配置类需要实现WebMvcConfigurer，该接口下有各种方法，开发者可以实现其中的方法完成相关组件的生成 1234567891011121314151617import cn.tedu.demo.interceptor.CustomInterceptor;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.FilterType;import org.springframework.stereotype.Controller;import org.springframework.web.servlet.config.annotation.*;/** * MVC的配置类，扫描所有的controller，排除所有的业务类 * @EnableWebMvc 注解开启mvc功能 * @ComponentScan 注解中的属性useDefaultFilters（默认是true，扫描全部的Bean），这里我们定义了只扫描controller，因此要设置该属性为false，否则不起作用，排除Bean则不需要 */@EnableWebMvc@Configuration@ComponentScan(basePackages = &#123;"cn.tedu.demo"&#125;,includeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,classes = &#123;Controller.class&#125;)&#125;,useDefaultFilters = false)public class WebMvcConfig implements WebMvcConfigurer &#123;&#125; 配置拦截器 自定义一个拦截器，如下： 12345678910111213141516171819/** * 自定义一个拦截器，实现HandlerInterceptor */@Componentpublic class CustomInterceptor implements HandlerInterceptor &#123; /** * 在拦截器方法之前执行 * @param request request * @param response response * @param handler 拦截的handler * @return 如果返回false，后续的拦截器和拦截的handler不执行 * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("在之前执行"); return true; &#125;&#125; 在配置类设置自定义的拦截器，使得起作用 1234567@Override public void addInterceptors(InterceptorRegistry registry) &#123; //创建 CustomInterceptor customInterceptor = new CustomInterceptor(); //添加自定义的拦截器 registry.addInterceptor(customInterceptor).addPathPatterns("/**"); &#125; 自定义的拦截器的真实实现类其实是MappedInterceptor，在源码中获取处理器执行链的时候会将其添加到执行链中。 配置过滤器 过滤器不属于SpringMVC，而是属于Servlet中的组件，因此配置过滤器使用的并不是MVC的配置，但是在Servlet3.0中也是提供了注解版的Servlet和Filter的生成方式，我们使用注解生成一个Filter，如下： 123456789101112131415161718192021/** * 自定义过滤器 */@WebFilter(filterName = "customFilter",urlPatterns = "/*")public class CustomFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println("过滤器初始化"); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println("过滤器执行"); chain.doFilter(request,response); &#125; @Override public void destroy() &#123; System.out.println("过滤器销毁"); &#125;&#125; 配置视图解析器1234@Override public void configureViewResolvers(ViewResolverRegistry registry) &#123; registry.jsp("/WEB_INF/",".jsp"); &#125; 配置ViewController12345@Override public void addViewControllers(ViewControllerRegistry registry) &#123; //定义一个controller，访问路径是/index.do，跳转的视图是index.jsp registry.addViewController("/index.do").setViewName("index"); &#125; 配置MessageConverters 消息转换器用于对Request和Response的消息进行处理，比如将Response中的消息转换为指定JSON字符串的形式 默认的消息转换器对于日期的类型的转换是时间戳，即是返回的JSON字符串的日期类型是时间戳，接收的日期类型参数也只能是时间戳 如何配置消息转换器，只需要重写springmvc配置类中的方法即可。 我们使用的是MappingJackson2HttpMessageConverter这类转换器，但是其中依赖的是ObjectMapper，因此我们比如引入依赖，如下： 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.9&lt;/version&gt; &lt;/dependency&gt; 在上述的MVC配置类中重写如下方法： 设置日期的格式化格式是yyyy-MM-dd，此时返回和接收的格式就是yyyy-MM-dd 在配置类中配置的消息转换器属于全局配置，所有的消息都会遵循这种配置。 12345678910@Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; Jackson2ObjectMapperBuilder builder = new Jackson2ObjectMapperBuilder() .indentOutput(true) //指定格式化的日期，这里只是举例，不建议在此处全局配置 .dateFormat(new SimpleDateFormat("yyyy-MM-dd")) //设置时区，默认是UTC，需要修改成北京时间 .timeZone("GMT+8"); converters.add(new MappingJackson2HttpMessageConverter(builder.build())); &#125; 注解版 在实际的项目中这种方式太鸡肋，实际的需求有实际的变化，因此我们最好能够寻找一种灵活的处理方式，类似注解的方式。 在jackson-databind中提供了许多的注解，可以供我们使用，可以覆盖全局配置，和全局配置形成一种互补的作用。 @JsonFormat：日期格式化注解，如下： 123//timeZone如果在全局配置过，可以不写 @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss",timezone = "GMT+8") private Date birthDay; @JsonIgnore：在返回的JSON字符串中不显示 12@JsonIgnore private String name; 其他的注解请参考https://blog.51cto.com/7308310/2310930?source=dra 异常处理器 springMvc处理异常有三种方式，分别为： ExceptionHandlerExceptionResolver：通过调用或 类中的@ExceptionHandler方法来解决异常，可以结合@ControllerAdvice DefaultHandlerExceptionResolver：对一些特殊的异常进行处理 ResponseStatusExceptionResolver：使用@ResponseStatus解析异常，并根据注解中的值将它们映射到HTTP状态代码 SimpleMappingExceptionResolver：异常和视图的映射，可以自定义指定的异常对应的视图 原理：主要的解析逻辑都是在doResolveException方法中完成的。 异常处理器执行的顺序 异常处理器的执行是有顺序的，优先级高的执行完之后，如果有对应的处理，那么后续的就不再执行。 异常处理器的执行顺序如下： ExceptionHandlerExceptionResolver DefaultHandlerExceptionResolver ResponseStatusExceptionResolver SimpleMappingExceptionResolver 四种异常处理器的顺序执行可以形成一种互补的配置。 SimpleMappingExceptionResolver 在配置中配置即可 12345678910111213@Bean public SimpleMappingExceptionResolver simpleMappingExceptionResolver()&#123; SimpleMappingExceptionResolver resolver = new SimpleMappingExceptionResolver(); //设置默认的视图，如果有的异常没有指定处理，那么使用默认的视图 resolver.setDefaultErrorView("index"); //设置排除的异常// resolver.setExcludedExceptions(); //指定异常视图映射 Properties properties=new Properties(); properties.put(RuntimeException.class.getName(),"error"); resolver.setExceptionMappings(properties); return resolver; &#125; DefaultHandlerExceptionResolver 此类异常解析器只能针对一些特殊的异常进行处理，如下： Exception HTTP Status Code HttpRequestMethodNotSupportedException 405 (SC_METHOD_NOT_ALLOWED) HttpMediaTypeNotSupportedException 415 (SC_UNSUPPORTED_MEDIA_TYPE) HttpMediaTypeNotAcceptableException 406 (SC_NOT_ACCEPTABLE) MissingPathVariableException 500 (SC_INTERNAL_SERVER_ERROR) MissingServletRequestParameterException 400 (SC_BAD_REQUEST) ServletRequestBindingException 400 (SC_BAD_REQUEST) ConversionNotSupportedException 500 (SC_INTERNAL_SERVER_ERROR) TypeMismatchException 400 (SC_BAD_REQUEST) HttpMessageNotReadableException 400 (SC_BAD_REQUEST) HttpMessageNotWritableException 500 (SC_INTERNAL_SERVER_ERROR) MethodArgumentNotValidException 400 (SC_BAD_REQUEST) MissingServletRequestPartException 400 (SC_BAD_REQUEST) BindException 400 (SC_BAD_REQUEST) NoHandlerFoundException 404 (SC_NOT_FOUND) AsyncRequestTimeoutException 503 (SC_SERVICE_UNAVAILABLE) 不需要声明，默认存在 ResponseStatusExceptionResolver 在自定义的异常类上标注@ResponseStatus注解，当抛出此种异常的时候，将会响应定义的状态码和提示语 1234@ResponseStatus(code = HttpStatus.FORBIDDEN,reason = "没有权限")public class CustomException extends RuntimeException &#123;&#125; ExceptionHandlerExceptionResolver 集合@ControllerAdvice和@RestControllerAdvice使用 方法中能够自动赋值的参数和返回值的类型都在Spring文档上有详细的记载，参考https://docs.spring.io/spring/docs/5.1.8.RELEASE/spring-framework-reference/web.html#mvc-ann-exceptionhandler-args 详细的使用如下： 123456789101112131415161718192021222324@ControllerAdvicepublic class ExceptionController &#123; /** * *处理FileNotFoundException，返回JSOn数据 */ @ExceptionHandler(value = ArrayIndexOutOfBoundsException.class) @ResponseBody public Object handleFileNotFoundException(Exception ex, HttpServletRequest request, HandlerMethod method)&#123; System.out.println(request.getRequestURI()); System.out.println(method); System.out.println(ex); return "index"; &#125; @ExceptionHandler(value = Exception.class) public Object handleException(Exception ex, HttpServletRequest request, HandlerMethod method)&#123; System.out.println(request.getRequestURI()); System.out.println(method); System.out.println(ex); return "index"; &#125;&#125; 配置跨域请求使用注解 使用注解@CrossOrigin，可以标注在Controller上，也可以标注在方法上，如下： 123456@CrossOrigin @PostMapping("/getObj") public Object getObject(@RequestBody AdminReq req)&#123; System.out.println(req); return new Admin("陈加兵",22,new Date(),new Date()); &#125; 该注解中可以配置各种属性，这里不再细讲，在下面的全局配置中会涉及到。 全局配置 全局配置就是在MVC的配置文件中重写方法即可，如下： 1234567891011121314@Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping("/api/**") //允许的源 .allowedOrigins("https://domain2.com") //允许请求跨域的请求类型 .allowedMethods("PUT", "DELETE") //允许的请求头 .allowedHeaders("header1", "header2", "header3") //暴露的请求头 .exposedHeaders("header1", "header2") //允许携带cookie等用户信息，这样才能实现登录 .allowCredentials(true).maxAge(3600); &#125; 配置静态资源解析 springmvc中的DispatcherServlet如果设置了拦截的请求是/，那么也会拦截静态资源，但是我们可以在配置文件中配置，如下： 123456789@Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; //拦截的请求 registry.addResourceHandler("/resources/**") //资源的位置 .addResourceLocations("/public", "classpath:/static/") //缓存的时间，单位秒 .setCachePeriod(31556926); &#125; 该配置会在ioc中注册一个ResourceHttpRequestHandler，封装在SimpleUrlHandlermapping中。 高级配置 @EnableMvc注解其实就是注入了一个配置类DelegatingWebMvcConfiguration，那么我们可以将自定义的配置类实现该类即可完成MVC的高级功能，此时就不需要使用该注解了，如下： 1234@Configuration@ComponentScan(basePackages = &#123;"cn.tedu.demo"&#125;,includeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,classes = &#123;Controller.class, Component.class&#125;)&#125;,useDefaultFilters = false)public class AdvanceConfig extends DelegatingWebMvcConfiguration &#123;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一文搞懂Spring-AOP原理]]></title>
      <url>%2F2019%2F07%2F19%2F%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82Spring-AOP%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[简介 面向切面编程，是面向对象编程的重要组成部分，在不改变业务逻辑功能的基础上，对横切逻辑进行扩展 添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.1.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; 通知 @Before（前置通知）：在业务方法执行之前调用 @After（后置通知）：在方法之后执行 @AfterReturning(正常返回通知)：在方法之后执行，只有在业务方法没有出现异常的时候才会执行 @AfterThrowing(异常通知) ： 在方法之后执行，只有在业务方法出现异常的时候才会执行 @Around （环绕通知）：在业务方法执行之前和之后执行 连接点 业务层的所有方法，叫做连接点 业务类中可以被增强的方法都叫做连接点 切点 能切入切面逻辑的方法，叫做切点 实际被增强的方法叫做切入点 ，其他的那些没有被增强的方法(连接点)不是切点 切面 定义了增强方法的类就叫做切面 实现 在配置类上开启切面，使用@EnableAspectJAutoProxy 12345@Configuration@ComponentScan(value = &#123;"cn.tedu.demo"&#125;)@EnableAsync@EnableAspectJAutoProxypublic class FirstConfig &#123;&#125; 使用五个不同的通知完成切入： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * 切面，使用@Aspect标注 */@Component@Aspectpublic class CustomAspect &#123; /** * 使用@PointCut定义切入点 */ @Pointcut(value = "execution(* cn.tedu.demo.aspect.AspectInvok.invok(..))") public void pointCut()&#123;&#125; /** * 前置通知，在指定方法之前执行 * @param point JoinPoint对象，可以获取切点的各种属性，比如入参的参数等 */ @Before(value = "pointCut()") public void before(JoinPoint point)&#123; //获取入参的参数的值 Object[] args = point.getArgs(); System.out.println(Arrays.asList(args)); //获取MethodSignature，其中可以获取切点的各种属性，比如方法返回类型，参数等等 MethodSignature signature = (MethodSignature) point.getSignature(); String[] parameterNames = signature.getParameterNames(); System.out.println(Arrays.asList(parameterNames)); System.out.println("在方法之前执行"); &#125; /** * 在切点之后执行 * @param point JoinPoint对象 */ @After(value = "pointCut()",argNames = "point") public void after(JoinPoint point)&#123; System.out.println("在方法之后执行"); &#125; /** * 在方法前后都会执行 * @param point */ @Around(value = "pointCut()") public void around(ProceedingJoinPoint point) throws Throwable &#123; System.out.println("前置执行"); //执行方法，可以获取返回值，否则方法将不会执行 Object result = point.proceed(point.getArgs()); System.out.println("后置执行，执行的结果=="+result); &#125; /** * 正常返回通知， * @param point Joinpoint对象 * @param result 方法执行返回的结果，需要和@AfterReturning注解中returning中的属性值相同，否则不能自动装配 */ @AfterReturning(value = "pointCut()",returning = "result") public void afterReturning(JoinPoint point,Object result)&#123; System.out.println("正常返回执行，执行的结果为："+result); &#125; /** * 异常返回执行，程序出现异常了才会执行 * @param point * @param ex 切入点执行抛出的异常，需要和@AfterThrowing注解的throwing值相同，否则不能完成自动装配 */ @AfterThrowing(value = "pointCut()",throwing = "ex") public void afterThrowing(JoinPoint point,Exception ex)&#123; System.out.println("异常返回执行，执行的异常为："+ex); &#125;&#125; 注解的实现 详细请看我的上一篇博客 定义一个注解，如下： 1234567@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface MyAnnotation &#123; String name() default "陈加兵"; int age() default 22;&#125; 定义一个切面，使用注解如下： 12345678910111213141516171819202122232425@Component@Aspectpublic class CustomAspect &#123; /** * 使用@PointCut定义切入点 */ @Pointcut(value = "@annotation(cn.tedu.demo.aspect.MyAnnotation)") public void pointCut()&#123;&#125; /** * 前置通知，在指定方法之前执行 * @param point JoinPoint对象，可以获取切点的各种属性，比如入参的参数等 */ @Before(value = "pointCut()") public void before(JoinPoint point)&#123; //获取MethodSignature，其中可以获取切点的各种属性，比如方法返回类型，参数等等 MethodSignature signature = (MethodSignature) point.getSignature(); Method method = signature.getMethod(); //获取方法上指定的注解 MyAnnotation myAnnotation = method.getAnnotation(MyAnnotation.class); System.out.println("name="+myAnnotation.name()); System.out.println("在方法之前执行"); &#125;&#125; 切入点表达式 两个或者三个切入点，可以使用切入点表达式，比如||、&amp;&amp;、! 如下我们定义两个切入点： 12345@Pointcut("execution(* cn.tedu.demo.service.UserService.addUser(..))") public void pointCut1()&#123;&#125; @Pointcut("execution(* cn.tedu.demo.service.UserService.deleteUserById(..))") public void pointCut2()&#123;&#125; 我们使用表达式来定义第三个切入点 @Pointcut(&quot;pointCut1()||pointCut2()&quot;)：两个切入点只要满足其中一个就能匹配 @Pointcut(&quot;pointCut1()&amp;&amp;pointCut2()&quot;)：两个切入点必须全部满足才能匹配 @Pointcut(&quot;!pointCut1()&amp;&amp;pointCut2()&quot;)：不满足PointCut1并且满足pointCut2才能匹配 切面执行顺序（Order） 如果有多个切面匹配了同一个目标方法，那么切面如何执行，我们可以使用@Order指定的切入点的执行顺序，注意：@Order中的值越小优先级越高 123456789@Aspect@Component@Order(Ordered.LOWEST_PRECEDENCE-1)public class LogAspect &#123; @Aspect@Component@Order(Ordered.HIGHEST_PRECEDENCE-2)public class LogAspect2 &#123; 注意点 事务也是的一个切面，那么事务的优先级和自定义的切面优先级有什么关系呢？ 如果自定义事务的优先级比事务的优先级高，那么在动态代理的时候，获取的拦截器链就在事务的拦截器（TransactionInterceptor）之前，此时切面执行的逻辑和目标方法就不在同一个事务中 默认的事务的优先级是最低的，因此切面使用默认的是能够保证在同一个事务中执行的。 事务的优先级可以在@EnableTransactionManagement这个注解中设置 如果切面指定了优先级，但是还要保证和目标方法在同一个事务中，那么必须调整事务的优先级比自定义切面的优先级高。 如何知道事务的优先级？ 在ProxyTransactionManagementConfiguration配置类中注入BeanFactoryTransactionAttributeSourceAdvisor会获取EnableTransactionManagement注解中的order值作为优先级 12345678910111213@Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() &#123; BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor(); advisor.setTransactionAttributeSource(transactionAttributeSource()); advisor.setAdvice(transactionInterceptor()); //如果注解中的属性不为空 if (this.enableTx != null) &#123; //直接设置order的值 advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber("order")); &#125; return advisor; &#125; 拦截器如果根据优先级排序？ 在创建代理对象的时候，会获取适用于当前Bean的所有Advisor，之后会根据优先级进行排序 在JDK获取拦截器链的时候实际就是循环便利ProxyFactory中存储的Advisor，将其中的Advice转换为MethodInterceptor，因此这个拦截器也是按照Advisor的顺序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475//org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator#findEligibleAdvisors//获取适用于当前bean的所有Advisorprotected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; //获取候选Advisor List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); //获取能够适用于的当前Bean的advisor List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; //对advisor排序 eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors; &#125;//org.springframework.aop.framework.DefaultAdvisorChainFactory#getInterceptorsAndDynamicInterceptionAdvice//直接获取ProxyFactory中的Advisor，循环遍历将其中的advice转换为MethodInterceptorpublic List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice( Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; // This is somewhat tricky... We have to process introductions first, // but we need to preserve order in the ultimate list. AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); Advisor[] advisors = config.getAdvisors(); List&lt;Object&gt; interceptorList = new ArrayList&lt;&gt;(advisors.length); Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); Boolean hasIntroductions = null; for (Advisor advisor : advisors) &#123; if (advisor instanceof PointcutAdvisor) &#123; // Add it conditionally. PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); boolean match; if (mm instanceof IntroductionAwareMethodMatcher) &#123; if (hasIntroductions == null) &#123; hasIntroductions = hasMatchingIntroductions(advisors, actualClass); &#125; match = ((IntroductionAwareMethodMatcher) mm).matches(method, actualClass, hasIntroductions); &#125; else &#123; match = mm.matches(method, actualClass); &#125; if (match) &#123; MethodInterceptor[] interceptors = registry.getInterceptors(advisor); if (mm.isRuntime()) &#123; // Creating a new object instance in the getInterceptors() method // isn't a problem as we normally cache created chains. for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125; Aspect实例化模型获取参数(args) 在这之前如果我们想要获取目标方法的参数，我们常用的手段就是通过JoinPoint的API直接获取的，如下： 12MethodSignature signature = (MethodSignature) point.getSignature();String[] parameters = signature.getParameterNames(); 但是我们也是可以通过args将入参绑定，如下： 此时的args中的user就和通知方法中的user绑定了，spring会自动获取目标方法中的参数user为其绑定值 注意：args中此时只指定了一个参数User，也就是意味着目标方法只能是带有User对象这一个参数的方法才能匹配，如果有其他的参数，那么这个通知将不起作用 12@Before(value = "pointCut1()&amp;&amp;args(user)") public void before(JoinPoint point,User user)&#123; 我们可以使用的args指定一个或者多个参数，如：args(user,..),此时匹配的目标方法中至少包含一个参数User对象才能匹配。 PointCut PointCut这个接口有两部分组成，分别是ClassFilter和MethodMatcher，其实可以很好的理解，如何定义一个切入点？我们在定义切入点的时候，就是想对某一个类的全部方法，或者对某一个类的部方法进行切入，因此在判断能否作用到方法上的时候，先判断是否类能够匹配（ClassFilter的活），之后再判断方法是否匹配（MethodMatcher的活）。 PointCut的实现类有很多，其中比较重要的是AOP使用的AspectJExpressionPointcut【这个类主要是解析execution表达式的，这个类同时实现了ClassFilter和MethodMatcher，具备了两者的功能，因此可以直接使用该类进行切入点的匹配】、AnnotationMatchingPointcut【注解的PointCut，主要用来匹配注解,底层使用就是AnnotationMethodMatcher和AnnotationMethodClassFilter，后续会讲到】 源码如下： 1234567891011public interface Pointcut &#123; //返回一个ClassFilter ClassFilter getClassFilter(); //返回一个MethodMatcher MethodMatcher getMethodMatcher(); //TruePointCut，对应任何的方法都是匹配(总是匹配) Pointcut TRUE = TruePointcut.INSTANCE;&#125; AspectJExpressionPointcut演示如下： 1234567891011@Test public void testAspectJExpressionPointCut() throws NoSuchMethodException &#123; AspectJExpressionPointcut expressionPointcut = new AspectJExpressionPointcut(); //设置aspectj表达式，这个比较常用的表达式 expressionPointcut.setExpression("execution(* cn.tedu.demo.service.UserService.addUser(..))"); //匹配类 boolean b = expressionPointcut.matches(UserService.class); //直接调用matches匹配方法 boolean a = expressionPointcut.matches(UserService.class.getDeclaredMethod("addUser", User.class), UserService.class); System.out.println(a+"---&gt;"+b); &#125; AnnotationMatchingPointcut的演示如下：12345678910@Testpublic void testAnnotationMatchingPointcut() throws NoSuchMethodException &#123; //第一个参数是注解，第二参数表示是否在接口和父类的查找该注解 AnnotationMatchingPointcut pointcut = new AnnotationMatchingPointcut(Transactional.class, false); //匹配方法上是否有@Transactional注解 boolean a = pointcut.getMethodMatcher().matches(UserService.class.getDeclaredMethod("addUser", User.class), UserService.class); //匹配类上是否有@Transactional注解 boolean b = pointcut.getClassFilter().matches(UserService.class); System.out.println(a+"---&gt;"+b);&#125; PointCuts 类似于MethodMatchers和ClassFilters，其中同样有union等，作用就是提供了一个matches方法，不需要自己写步骤先比较Class，再比较Method等操作，当然还有一些便捷的功能。12345678910@Testpublic void testPointcuts() throws NoSuchMethodException &#123; AnnotationMatchingPointcut annotationMatchingPointcut = new AnnotationMatchingPointcut(Transactional.class, false); Class cls=UserService.class; Method method = cls.getDeclaredMethod("addUser", User.class); //调用matches方法，判断UserService的addUser方法是否有@Transactional注解 boolean matches = Pointcuts.matches(annotationMatchingPointcut, method, cls); System.out.println(matches);&#125; ClassFilter 类过滤器，就是判断类是否匹配 12345678910@FunctionalInterfacepublic interface ClassFilter &#123; //判断方法 boolean matches(Class&lt;?&gt; clazz); //定义一个总是匹配的TrueClassFilter，其实就是matches方法总是返回true ClassFilter TRUE = TrueClassFilter.INSTANCE;&#125; ClassFilter在spring底层有许多实现的类，比如AnnotationClassFilter（匹配指定注解）、TrueClassFilter（全部匹配）、AspectJExpressionPointcut（Aspect表达式匹配，APO重要的组件） 实例：使用AnnotationClassFilter测试该类是否有@Transactional注解 该类有一个属性checkInherited，如果为false，那么只检查当前类是否有对应的注解，为true，那么会检查父类或者实现的接口存在，默认为false12345678 @Testpublic void testAnnotationClassFilter()&#123; //指定checkInherited为true，会同时检查该类和父类及其实现的接口是否存在Transactional注解 AnnotationClassFilter annotationClassFilter = new AnnotationClassFilter(Transactional.class, true); boolean matches = annotationClassFilter.matches(UserServiceImpl.class); System.out.println(matches); &#125; 我们也可以自定义自己的ClassFilter， 只需要实现其中的接口方法即可，如下： 1234567@Testpublic void testCustomClassFilter()&#123; //自定义一个classFilter，判断指定的类是否是UserServiceImpl的接口或者父类或者同类 ClassFilter customFilter =cls-&gt; cls.isAssignableFrom(UserServiceImpl.class); boolean matches = customFilter.matches(UserService.class); System.out.println(matches);&#125; ClassFilters 该抽象类中有两个ClassFilter，分别是UnionClassFilter【满足其中一个即返回true】、IntersectionClassFilter【必须满足所有的ClassFilter才返回true】 同样的对应有两个静态方法上面的两个Filter，如下： public static ClassFilter union(ClassFilter cf1, ClassFilter cf2) public static ClassFilter intersection(ClassFilter cf1, ClassFilter cf2) 实例123456789101112131415@Test public void testClassFilters()&#123; //类或者接口上必须有Transactional注解 AnnotationClassFilter annotationClassFilter = new AnnotationClassFilter(Transactional.class,false); //类或者接口必须是UserServiceImpl的父类或者接口或者同类 ClassFilter customFilter =cls-&gt; cls.isAssignableFrom(UserServiceImpl.class); //返回unionFilter，只要满足上面的一个ClassFilter即返回true ClassFilter unionFilter = ClassFilters.union(annotationClassFilter, customFilter); //返回intersectionFilter，必须满足上面两个ClassFilter才会返回true ClassFilter intersectionFilter = ClassFilters.intersection(annotationClassFilter, customFilter); boolean u = unionFilter.matches(UserService.class); boolean i = intersectionFilter.matches(UserService.class); System.out.println(u); System.out.println(i); &#125; MethodMatcher ClassFilter是匹配类，MethodMatcher是用来匹配方法 MethodMatcher有两个matches方法，分别是两个参数和三个参数的，两个参数用于静态匹配，只有两个参数的匹配返回true，isRuntime方法true，才应该调用三个参数的方法。如果isRuntime返回false，那么不应该调用三个参数的matches 接口的实现类有很多，如StaticMethodMatcher【只支持静态匹配，两个参数的matchs】、AspectJExpressionPointcut【AOP重要组件】、TrueMethodMatcher【总是匹配】、AnnotationMethodMatcher【注解匹配】 实例如下： 12345678910@Testpublic void testAnnotationMethodMatcher() throws NoSuchMethodException &#123; //检测方法上是否标注了Transactional注解，false指定了不检查当前类父类和接口 AnnotationMethodMatcher methodMatcher=new AnnotationMethodMatcher(Transactional.class,false); Class cls=UserService.class; Method method = cls.getDeclaredMethod("addUser", User.class); //两个参数的mathces，三个参数的不支持【继承了StaticMethodMatcher】 boolean matches = methodMatcher.matches(method, cls); System.out.println(matches);&#125; 当然也是可以自定义实现类，这里和上面的ClassFilter的差不多，就不再写了，自己发挥想象力 MethodMatchers 同ClassFilters功能一样，其中提供了UnionMethodMatcher类【只要匹配一个即返回true】，IntersectionMethodMatcher【】 此处不再演示 Advice 通知的接口，在aop中的每一个通知注解都有对应的接口，比如BeforeAdvice、AfterAdvice等 Advice的默认实现抽象类是AbstractAspectJAdvice，各种AspectJ的通知都会继承并拓展该类，其中封装了有关通知的全部信息，比如方法名称、方法Method对象、PointCut、Jpoint、pointCut表达式等等信息，其中最重要的一个方法就是protected Object invokeAdviceMethodWithGivenArgs(Object[] args)，该方法用于调用通知方法。 其中关于AspectJ的五种通知方法，类的命名方式是AspectJXxxAdvice，继承抽象类AbstractAspectJAdvice。 比如AspectAfterAdvice这个实现类，其中重要的方法就是invok，源码如下： 通过源码就可以看出在方法之后执行是怎样的过程，先调用被增强的方法【原方法】、再调用被@After标注的通知方法。 12345678910public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; //先执行被增强的方法 return mi.proceed(); &#125; finally &#123; //再执行通知方法 invokeAdviceMethod(getJoinPointMatch(), null, null); &#125; &#125; Advisor 顾问的意思，其中封装了Advice（通知）。 PointcutAdvisor 继承了Advisor，是对Advice和PointCut的封装 AspectJExpressionPointcutAdvisor：Aop中的一种Advisor，用于封装AspectJExpressionPointCut和Advice proxyFactory 代理工厂：其中保存了代理对象的一切属性，包括advisor，类的信息，接口的信息等。 创建代理对象，实际调用的是org.springframework.aop.framework.DefaultAopProxyFactory#createAopProxy 123456789101112131415161718public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException("TargetSource cannot determine target class: " + "Either an interface or a target is required for proxy creation."); &#125; //如果是接口，创建JDK的动态代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); &#125; else &#123; //创建Cglib动态代理 return new JdkDynamicAopProxy(config); &#125; &#125; 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class ProxyFactoryTest &#123; /** * 自定义一个BeforeAdvice */ public static class CustomBeforAdvice implements MethodBeforeAdvice&#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; String name = method.getName(); if (StringUtils.equals(name,"addUser"))&#123; System.out.println("在addUser之前执行"); &#125;else&#123; System.out.println("other"); &#125; &#125; &#125; public static class Log&#123; public void before()&#123; System.out.println("在之前执行"); &#125; &#125; @Test public void test1()&#123; UserService userService=new UserServiceImpl(); //创建proxyFactory ProxyFactory factory = new ProxyFactory(userService); //创建自定义的BeforeAdvice MethodBeforeAdvice advice=new CustomBeforAdvice(); //将Advice添加到proxyFactory中 factory.addAdvice(advice); //获取代理对象 UserService proxy = (UserService) factory.getProxy(); proxy.addUser(new User("")); &#125; @Test public void test2() throws NoSuchMethodException &#123; UserService userService=new UserServiceImpl(); //创建proxyFactory ProxyFactory factory = new ProxyFactory(userService); Class aspectCls=Log.class; Method aspectMethod = aspectCls.getMethod("before"); //构建aspectJ表达式切入点 AspectJExpressionPointcut aspectJExpressionPointcut = new AspectJExpressionPointcut(); aspectJExpressionPointcut.setExpression("execution(* cn.tedu.demo.service.UserService.addUser(..))"); //创建AspectInstanceFactory（切面实例工厂） AspectInstanceFactory aspectInstanceFactory=new SimpleAspectInstanceFactory(aspectCls); AspectJMethodBeforeAdvice advice=new AspectJMethodBeforeAdvice(aspectMethod,aspectJExpressionPointcut,aspectInstanceFactory); //创建Advisor，其中封装了Advice和Advisor Advisor advisor = new AspectJPointcutAdvisor(advice); ArrayList&lt;Advisor&gt; advisors = Lists.newArrayList(advisor); //添加ExposeInvocationInterceptor到advisor中，这个不是必须的，但是使用AspectJ expression pointcut是必须的 AspectJProxyUtils.makeAdvisorChainAspectJCapableIfNecessary(advisors); //将advisor添加到ProxyFactory中 factory.addAdvisors(advisors); UserService proxy= (UserService) factory.getProxy(); proxy.addUser(new User("chen")); &#125;&#125; @EnableAspectJAutoProxy 从@EnableAspectJAutoProxy该注解中可以看出使用了@Import(AspectJAutoProxyRegistrar.class)，因此实际作用的类就是AspectJAutoProxyRegistrar。 12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123; AspectJAutoProxyRegistrar 该类实现ImportBeanDefinitionRegistrar【向容器中注入Bean】。 该类的主要作用就是向ioc容器中注入AnnotationAutoProxyCreator。 1234567891011121314151617181920212223242526class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * 向容器中注入AnnotationAutoProxyCreator */ @Override public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //调用方法注册AnnotationAutoProxyCreator AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); //获取@EnableAspectJAutoProxy注解中两个属性的值 AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); //判断注解属性的值 if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean("proxyTargetClass")) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean("exposeProxy")) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; AnnotationAutoProxyCreator 注解版代理创建器，主要的作用就是利用SmartInstantiationAwareBeanPostProcessor后置处理器，在Bean实例化前后创建代理对象。有了后置处理器和BeanFactoryAware，可想而知，主要的实现都是从他们实现的方法进入的。 继承关系如下： 创建代理对象的代码如下： 真正的实现在org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#wrapIfNecessary advisedBeans：存放所有的Bean，value是Boolean类型的值，如果为false表示不需要代理，反之则需要代理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; //如果为false，直接返回，不需要代理 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; //判断是否是基础的切面类 if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 获取适用的Advisor Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); //创建代理对象 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125;//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#createProxyprotected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; //创建代理工厂 ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; else &#123; evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; return proxyFactory.getProxy(getProxyClassLoader()); &#125; BeanFactoryAspectJAdvisorsBuilder Advisor的构建器，主要的功能就是扫描的带有@Aspect注解的类，构造Advisor。 在AbstractAdvisorAutoProxyCreator的setFactory的方法中被创建。 其中最重要的方法就是buildAspectJAdvisors，用来构造Advisor AspectJAdvisorFactory Advisor工厂，主要是用来构造Advisor的，在BeanFactoryAspectJAdvisorsBuilder中被应用。 ReflectiveAspectJAdvisorFactory是其实现类，AOP中就是使用该类构造Advisor 其中最重要的两个方法如下： private List&lt;Method&gt; getAdvisorMethods(Class&lt;?&gt; aspectClass)：在切面类获取没有标注@PointCut的方法 public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory)：获取所有的Advisor JdkDynamicAopProxy JDK的动态调用的主要类，实现了AopProxy、InvocationHandler 重要的属性： private final AdvisedSupport advised：其中封装了代理类的属性，其实就是一个ProxyFactory，包括目标类，目标方法、advisor等信息。 重要方法： public Object invoke(Object proxy, Method method, Object[] args)：方法调用的类，实现了InvocationHandler的方法 MethodInterceptor 方法拦截器接口，继承了Advice，Interceptor。AspectJxxxAdvice等通知的类中都实现了这个方法，其中有一个invoke方法，是执行方法调用的逻辑，在Spring的代理执行的过程中和ReflectiveMethodInvocation结合使用，完美的诠释了责任链的模式。 Object invoke(MethodInvocation invocation) throws Throwable：执行方法的逻辑 AspectJAfterAdvice【示例】 该类实现了MethodInterceptor，其中的Invoke实现如下： 其中的mi.proceed()这个方法，是责任链模式的重要方法。 1234567891011@Override public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; //调用其他的拦截器【因为这个拦截器是在方法之后执行的】 return mi.proceed(); &#125; finally &#123; //最终调用通知方法 invokeAdviceMethod(getJoinPointMatch(), null, null); &#125; &#125; MethodInvocation 方法调用器，其中一个实现类是AOp中非常重要的组件（ReflectiveMethodInvocation）。 ReflectiveMethodInvocation 该类在spring中的大致描述就是通过反射调用目标方法，是spring中内部使用的类。 该类其中的重要的方法就是proceed，通过责任链的模式执行拦截器中的方法，和MethodInterceptor完美的诠释了责任链设计模式。源码如下： 其实最重要的就是在内部调用了拦截器的invoke方法，但是在拦截器的invoke方法中还会递归的执行的proceed方法，这样的配置就完成了责任链的模式。 1234567891011121314151617181920212223242526272829public Object proceed() throws Throwable &#123; // 标记拦截器链执行的位置，初始值是-1，递归的结束条件 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; //拦截器都执行完成了，那么通过反射执行目标方法 return invokeJoinpoint(); &#125; //获取拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); //判断拦截器的类型 if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; return proceed(); &#125; &#125; else &#123; //调用拦截器的invoke方法 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; 实例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Test public void test1() throws Throwable &#123; //目标对象 UserService userService=new UserServiceImpl(); //新建一个ProxyFactory，创建代理 ProxyFactory factory = new ProxyFactory(); factory.setTarget(userService); //设置接口，否则使用的是cglib代理 factory.setInterfaces(UserService.class); //获取代理对象 Object proxy = factory.getProxy(); //切面 Class aspectCls=LogAspect.class; //通知方法 Method aspectMethod=aspectCls.getDeclaredMethod("afterAdvice"); //切面对象 final Object aspectObj=new LogAspect(); //新建一个拦截器 MethodInterceptor afterInterceptor=new MethodInterceptor() &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; CustomeInvocation ref=(CustomeInvocation)invocation; try&#123; //执行其他的拦截器 return invocation.proceed(); &#125;finally &#123; //最后执行切面的方法 ref.getAspectMethod().invoke(ref.getAspectObj(), ref.getAspectArgs());// System.out.println("方法之后执行"); &#125; &#125; &#125;; //创建拦截器链 List&lt;Object&gt; interceptors=new ArrayList&lt;&gt;(); interceptors.add(afterInterceptor); Method targetMethod=UserService.class.getMethod("addUser", User.class); Object[] args=new Object[]&#123;new User("陈加兵")&#125;; CustomeInvocation invocation = new CustomeInvocation(proxy, userService, targetMethod, args, UserService.class,interceptors,aspectCls,aspectMethod,aspectObj,new Object[]&#123;&#125;); invocation.proceed(); &#125; /** * 自定义一个Invocation，因为ReflectiveMethodInvocation是spring内部使用的，构造方法protected */ public static class CustomeInvocation extends ReflectiveMethodInvocation&#123; private Method aspectMethod; private Class aspcetCls; private Object aspectObj; private Object[] aspectArgs; /** * @param proxy 代理 * @param target 目标对象 * @param method 目标方法 * @param arguments 参数 * @param targetClass 目标类 * @param aspectMethod 通知方法 * @param aspctCls 切面类 * @param aspectObj 切面对象 * @param interceptorsAndDynamicMethodMatchers 拦截器 */ public CustomeInvocation(Object proxy, Object target, Method method, Object[] arguments, Class&lt;?&gt; targetClass, List&lt;Object&gt; interceptorsAndDynamicMethodMatchers,Class aspctCls,Method aspectMethod,Object aspectObj,Object[] aspectArgs) &#123; super(proxy, target, method, arguments, targetClass, interceptorsAndDynamicMethodMatchers); this.aspectMethod=aspectMethod; this.aspcetCls=aspctCls; this.aspectObj=aspectObj; this.aspectArgs=aspectArgs; &#125; &#125; JDK动态代理示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class JDKDynamicProxy &#123; public static interface Subject&#123; int add(int a,int b); &#125; public static class CustomSubject implements Subject&#123; @Override public int add(int a, int b) &#123; System.out.println("执行加法计算"); return a+b; &#125; &#125; /** * 自定义的InvocationHandler */ public static class CustomInvocationHandler implements InvocationHandler&#123; /** * 目标对象 */ private Object targetObject; public CustomInvocationHandler(Object targetObject) &#123; this.targetObject = targetObject; &#125; /** * @param proxy 代理对象 * @param method 真正执行的方法 * @param args 方法参数 * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); if (methodName.equals("add"))&#123; System.out.println("invok调用"); Object invoke = method.invoke(targetObject, args); return invoke; &#125; return null; &#125; &#125; @Test public void test()&#123; Subject subject=new CustomSubject(); CustomInvocationHandler customInvocationHandler = new CustomInvocationHandler(subject); Subject proxy= (Subject) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(),new Class[]&#123;Subject.class&#125;, customInvocationHandler); int count = proxy.add(1, 2); System.out.println(count); &#125;&#125; AOP创建代理流程 AOP执行流程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring解决循环依赖]]></title>
      <url>%2F2019%2F07%2F17%2FSpring%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%2F</url>
      <content type="text"><![CDATA[什么是循环依赖 循环依赖分为两种，一种是构造器的相互依赖，另外一种是属性的相互依赖。 属性的相互依赖 属性的相互依赖就是A类的属性中有B，B类的属性中有A，如下： 这里仅仅是两个类的循环依赖，当然还有更多的类相互依赖 1234567public class A&#123; private B b;&#125;public class B&#123; private A a;&#125; 构造器的依赖 构造器的依赖就是A类的构造器需要传入B类对象，B的构造器需要传入A类对象，如下： 1234567public class A&#123; public A(B b)&#123;&#125;&#125;public class B&#123; private B(A a)&#123;&#125;&#125; 如何解决 Spring只能解决属性的循环依赖，构造器的循环依赖是不能解决的。 spring中解决循环依赖的核心思想就是利用三级缓存，先创建Bean，后为各个属性赋值具体什么是三级缓存呢？ 三级缓存 三级缓存的实现在org.springframework.beans.factory.support.DefaultSingletonBeanRegistry类中，如下： private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);：单例对象缓存池，beanName-&gt;Bean，其中存储的就是实例化，属性赋值成功之后的单例对象 private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);：早期的单例对象，beanName-&gt;Bean，其中存储的是实例化之后，属性未赋值的单例对象。 private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);：单例工厂的缓存，beanName-&gt;ObjectFactory 流程分析 在分析之前，先写个实例，制造循环依赖，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Componentpublic class Husband &#123; private String name; private Integer age; //丈夫依赖妻子 @Autowired private Wife wife; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public Wife getWife() &#123; return wife; &#125; public void setWife(Wife wife) &#123; this.wife = wife; &#125;&#125;@Componentpublic class Wife &#123; private String name; private Integer age; //妻子依赖丈夫 @Autowired private Husband husband; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public Husband getHusband() &#123; return husband; &#125; public void setHusband(Husband husband) &#123; this.husband = husband; &#125;&#125; 解决循环依赖是在容器启动的时候实现的，我们分析源码可以知道，容器启动初始化的大部分过程都是在refresh方法中实现的，因此我们从refresh入口即可，流程如下： 下面只分析与循环依赖有关的流程，其他的会省略 12345678910111213141516171819202122232425262728293031323334353637383940414243441、finishBeanFactoryInitialization(beanFactory)：实例化所有饿加载的单例Bean2、org.springframework.beans.factory.config.ConfigurableListableBeanFactory#preInstantiateSingletons：真正的实现的方法3、org.springframework.beans.factory.support.AbstractBeanFactory#getBean：调用方法获取Bean4、org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean：真正getBean的方法 4.1 Object sharedInstance = getSingleton(beanName)：先尝试从三级缓存中获取Bean，第一次执行缓存中肯定是没有 4.2 BeanFactory parentBeanFactory = getParentBeanFactory()：检查父工厂中是否存在当前Bean 4.3 markBeanAsCreated(beanName)：将Bean放入alreadyCreated中，表示当前Bean已经创建了 4.4 String[] dependsOn = mbd.getDependsOn()：检查dependOn 4.5 Object bean = resolveBeforeInstantiation(beanName, mbdToUse)：执行后置处理器，在初始化之前执行 4.6 sharedInstance = getSingleton(beanName, () -&gt; &#123;：调用getSingleton方法，尝试从单例缓存池中获取Bean 4.6.1 Object singletonObject = this.singletonObjects.get(beanName)：从单例缓存池中获取 4.6.2 if (singletonObject == null) &#123;：如果缓存池中没有，那么执行后续的逻辑，如果有直接返回即可 4.6.3 单例池中没有的逻辑：singletonObject = singletonFactory.getObject()：调用createBean方法创建Bean 4.6.4 addSingleton(beanName, singletonObject)：创建Bean成功之后将其添加到单例缓存池中，并且将其从二三级缓存中移除（singletonFactories，earlySingletonObjects） 4.7 return createBean(beanName, mbd, args)：三级缓存和父工厂中都没有当前的这个Bean，此时进入创建Bean的过程 5、org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean：真正执行创建Bean的逻辑 5.1 instanceWrapper = createBeanInstance(beanName, mbd, args)：调用构造器创建Bean，此时的Bean称为早期Bean，还未进行属性赋值 5.2 applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName)：执行MergedBeanDefinitionPostProcessor，也是一种后置处理器 5.3 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean))：将早期Bean放入三级缓存singletonFactories中，并且从早期对象缓存earlySingletonObjects中删除，用来解决循环依赖。 if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; 5.4 populateBean(beanName, mbd, instanceWrapper)：此时执行当前Bean的属性赋值 6、org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#populateBean：进行属性的赋值 6.1 if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) ：执行实例化之后的后置处理器 6.2 for (BeanPostProcessor bp : getBeanPostProcessors()) ：执行属性赋值之前的后置处理器，返回PropertyVlaue，我们知道@Autowired注解就是后置处理器实现的，主要的逻辑就是在postProcessProperties方法中，并且我们的例子中是自动注入Wife和Husband的，所以逻辑一定是在这里实现的，进入7、org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor#postProcessProperties：@Autowired注解解析，为标注该注解的属性赋值 7.1 org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.AutowiredFieldElement#inject：真正执行赋值的逻辑 7.1.1 value = beanFactory.resolveDependency(desc, beanName, autowiredBeanNames, typeConverter)：解析依赖8、org.springframework.beans.factory.support.DefaultListableBeanFactory#resolveDependency：解析标注@Autowired的依赖 8.1 org.springframework.beans.factory.support.DefaultListableBeanFactory#doResolveDependency：真正解析逻辑 8.2 instanceCandidate = descriptor.resolveCandidate(autowiredBeanName, type, this)：从容器中获取指定的Bean，内部调用的又是getBean方法9、org.springframework.beans.factory.config.DependencyDescriptor#resolveCandidate：至此，又回到了getBean这个方法，从ioc容器中获取指定的Bean 流程图如下： 红色是关于三级缓存的操作 蓝色是关于后置处理器的操作 唯一一个淡黄色是解决循环依赖的关键，重新调用doGetBean 结合上述例子分析1、Husband创建Bean，先判断缓存池中是否存在，存在直接返回，不存在进入createBean创建的流程，调用构造方法创建一个早期的Bean【未进行属性赋值】，创建成功将其放入二级缓存earlySingletonObjects中，之后又调用addSingletonFactory方法将其放入三级缓存中并且将二级缓存中的移除，之后调用populateBean为属性赋值，在@Autowired的后置处理器中查找需要注入的依赖，发现Husband中的一个属性Wife，因此调用getBean方法从容器中获取，但是此时的Wife还未创建，因此又进入了doGetBean的流程，但是此时Wife并没有创建，因此在一二三级缓存中不能获取，又执行createBean方法创建Wife，同样调用构造方法创建一个早期Bean放入二级缓存中，调用addSingletonFactory放入三级缓存并移除二级缓存，然后调用populateBean方法为Wife属性赋值，在@Autowired的后置处理器中查找需要注入的依赖，发现Wife类中有一个属性是Husband，因此调用getBean方法，再次调用doGetBean获取Husband，但是此时的Husband已经创建成功【未赋值】，存放在三级缓存中，因此直接从三级缓存中取出Husband赋值给Wife属性，至此Wife属性已经赋值成功，直接添加到一级缓存（singletonObjects）中并且移除三级缓存，直接返回给Husband赋值，因此Husband中的属性也持有了Wife的引用，都创建并且赋值成功了。 为什么不能解决构造器的循环依赖 Spring解决循环依赖主要是依赖三级缓存，但是的在调用构造方法之前还未将其放入三级缓存之中，因此后续的依赖调用构造方法的时候并不能从三级缓存中获取到依赖的Bean，因此不能解决。 Spring为什么不能解决多例的循环依赖 多实例Bean是每次调用一次getBean都会执行一次构造方法并且未属性赋值，根本没有三级缓存，因此解决循环依赖。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring事务源码解析]]></title>
      <url>%2F2019%2F07%2F07%2FSpring%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[配置注解版事务事务管理器 事务管理器的接口是PlatformTransactionManager，其中定义了三个接口方法如下： TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException：获取事务，如果当前没有事务，那么就根据传播级别创建一个事务。 TransactionDefinition：其中定义了事务的传播属性，比如默认的传播属性（当前没有事务就开启事务）等。 void commit(TransactionStatus status) throws TransactionException;：提交事务 TransactionStatus：其中定义了一些事务的状态和查询、判断事务状态的方法 void rollback(TransactionStatus status) throws TransactionException;：回滚事务 PlatformTransactionManager的实现类有很多，比如结合JDBC操作的DataSourceTransactionManager、配置JTA、Hibernate的事务管理器。 注入事务管理器【JDBC】 注入PlatformTransactionManager，步骤如下： 注入数据源，这里我们使用的是结合JDBC，因此需要注入对应的事务管理器DataSourceTransactionManager 1234567891011121314151617181920//注入数据源，这里使用的是阿里的Druid，这里只是简单的配置@Bean public DruidDataSource dataSource()&#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUsername("******"); dataSource.setPassword("*****"); dataSource.setUrl("******"); dataSource.setInitialSize(10); dataSource.setMaxActive(20); dataSource.setMaxIdle(100000); return dataSource; &#125;//注入事务管理器@Bean public PlatformTransactionManager transactionManager(DataSource dataSource) &#123; DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(dataSource); return dataSourceTransactionManager; &#125; 开启事务，使用@EnableTransactionManagement 1234@Configuration@ComponentScan(basePackages = &#123;"cn.tedu.demo.*"&#125;)@EnableTransactionManagementpublic class MainConfig &#123;&#125; 源码解析事务必知的知识和类PlatformTransactionManager 事务管理器的接口，其中定义一些事务的方法，有提交，回滚，获取事务的方法。 实现类如下： DataSourceTransactionManager：适用于JDBC事务的管理 JtaTransactionManager：适用于多数据源的事务管理，实现强一致性事务 TransactionDefinition 该接口主要定义了事务的一些属性，比如事务的传播行为，隔离级别等数据。 @EnableTransactionManagement 此注解的源码如下，其实真正起作用的就是@Import(TransactionManagementConfigurationSelector.class)，使用@Import这个注解向容器中注入了其他的Bean，详情请看我的Spring注解版开发，其中有@Import的使用 12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(TransactionManagementConfigurationSelector.class)public @interface EnableTransactionManagement &#123; TransactionManagementConfigurationSelector 这个实现了ImportSelector，结合@Import注解使用，是@Import注解的注入Bean的其中一种方式，有一个必须重载的方法，如下： 此方法返回的BeanName的数组的全部Bean将会被注入到容器中 1String[] selectImports(AnnotationMetadata importingClassMetadata); TransactionManagementConfigurationSelector对上面的这个方法重写了，如下： 主要流程就是根据@EnableTransactionManagement中mode属性返回对应的BeanName，如果值是PROXY【默认】，那么就会注入AutoProxyRegistrar、ProxyTransactionManagementConfiguration这两个Bean，那么这个方法的作用就是如此，因此我们需要看看注入的两个Bean到底是什么作用？ 123456789101112131415161718@Overrideprotected String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;determineTransactionAspectClass()&#125;; default: return null; &#125;&#125;private String determineTransactionAspectClass() &#123; return (ClassUtils.isPresent("javax.transaction.Transactional", getClass().getClassLoader()) ? TransactionManagementConfigUtils.JTA_TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME : TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME);&#125; AutoProxyRegistrar 该类实现了ImportBeanDefinitionRegistrar，主要的作用就是根据@EnableTransactionManagement属性中的mode和proxyTargetClass，注入对应的AutoProxyCreator【APC】，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445//importingClassMetadata：其中封装了配置类的所有注解//registry：用于注入BeanDefintion@Overridepublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //标记 boolean candidateFound = false; //获取所有的注解类型 Set&lt;String&gt; annoTypes = importingClassMetadata.getAnnotationTypes(); //遍历注解 for (String annoType : annoTypes) &#123; //获取指定注解的全部属性的值 AnnotationAttributes candidate = AnnotationConfigUtils.attributesFor(importingClassMetadata, annoType); if (candidate == null) &#123; continue; &#125; //获取对应的mode和proxyTargetClass属性的值 Object mode = candidate.get("mode"); Object proxyTargetClass = candidate.get("proxyTargetClass"); //如果这些值都存在，那么可以判定配置类上标注了`@EnableTransactionManagement`这个注解 if (mode != null &amp;&amp; proxyTargetClass != null &amp;&amp; AdviceMode.class == mode.getClass() &amp;&amp; Boolean.class == proxyTargetClass.getClass()) &#123; //标记设置为true candidateFound = true; //根据mode的值，注入不同的APC if (mode == AdviceMode.PROXY) &#123; AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); if ((Boolean) proxyTargetClass) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); return; &#125; &#125; &#125; &#125; if (!candidateFound &amp;&amp; logger.isInfoEnabled()) &#123; String name = getClass().getSimpleName(); logger.info(String.format("%s was imported but no annotations were found " + "having both 'mode' and 'proxyTargetClass' attributes of type " + "AdviceMode and boolean respectively. This means that auto proxy " + "creator registration and configuration may not have occurred as " + "intended, and components may not be proxied as expected. Check to " + "ensure that %s has been @Import'ed on the same class where these " + "annotations are declared; otherwise remove the import of %s " + "altogether.", name, name, name)); &#125;&#125; 其中核心的代码就是注入不同的APC的代码，如下： AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); 实际作用的源码如下： 123456789101112131415161718192021222324252627//cls是InfrastructureAdvisorAutoProxyCreator.class，APC的一种实现类//注入的BeanName是org.springframework.aop.config.internalAutoProxyCreatorprivate static BeanDefinition registerOrEscalateApcAsRequired( Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, "BeanDefinitionRegistry must not be null"); //判断对应的APC是否已经注入了 if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; //没有注入，直接使用RootBeanDefinition注入，BeanName是org.springframework.aop.config.internalAutoProxyCreator RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add("order", Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; &#125; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);：强制使用子类代理【cglib代理】，实际作用的源码如下： 实际的作用就是设置了proxyTargetClass为true 123456public static void forceAutoProxyCreatorToUseClassProxying(BeanDefinitionRegistry registry) &#123; if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition definition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); definition.getPropertyValues().add("proxyTargetClass", Boolean.TRUE); &#125; &#125; 总结 该类是TransactionManagementSlector选择器注入的类，主要作用就是根据@EnableTranactionMangement注解中的mode和proxyTarget的值注入（AutoProxyCreator）【简称APC】，实际的APC的类型是InfrastructureAdvisorAutoProxyCreator ProxyTransactionManagementConfiguration 该类是一个配置类，如下： 1234567//ProxyTransactionManagementConfiguration配置类@Configurationpublic class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration &#123;&#125;//AbstractTransactionManagementConfiguration@Configurationpublic abstract class AbstractTransactionManagementConfiguration implements ImportAware &#123;&#125; 从上面的源码可以知道抽象的AbstractTransactionManagementConfiguration类实现了ImportAware，那么其中的重载的方法一定是很重要的，代码如下： 1234567891011@Overridepublic void setImportMetadata(AnnotationMetadata importMetadata) &#123; //获取@EnableTransactionMangement的属性值赋值给enableTx this.enableTx = AnnotationAttributes.fromMap( importMetadata.getAnnotationAttributes(EnableTransactionManagement.class.getName(), false)); //如果为null，抛出异常 if (this.enableTx == null) &#123; throw new IllegalArgumentException( "@EnableTransactionManagement is not present on importing class " + importMetadata.getClassName()); &#125;&#125; 上述讲解了AbstractTransactionManagementConfiguration中的一个重要实现，其实就是将@EnableTransactionMangement的属性值赋值给enableTx 从ProxyTransactionManagementConfiguration的源码可以知道，其实就是向容器中注入了三个Bean，分别是org.springframework.transaction.interceptor.BeanFactoryTransactionAttributeSourceAdvisor、org.springframework.transaction.interceptor.TransactionAttributeSource、org.springframework.transaction.interceptor.TransactionInterceptor ImportAware 该类的作用是获取标注在实现了该接口的配置类上的所有注解的元数据，包括注解的属性，值，类型等信息。 ImportAware同样实现了Aware接口，但是这个和BeanFactoryAware、ResourceLoaderAware等不同的是，这个接口必须是由配置类【即是标注了@Configuration注解】实现，并且需要结合@Import注解使用才能生效，否则不能生效，如下的使用方式将会生效。 一定要结合@Import使用，可以直接导入配置类，也可以使用selector方式的注入，总之是要结合@Import注解使用，否则不能生效 1234567891011121314@Configuration@ComponentScan(basePackages = &#123;"cn.tedu.demo.*"&#125;)@EnableTransactionManagement@Import(value = &#123;DruidConfig.class&#125;)public class MainConfig &#123;&#125;@Configurationpublic class DruidConfig implements ImportAware &#123; @Override public void setImportMetadata(AnnotationMetadata importMetadata) &#123; System.out.println(importMetadata); &#125;&#125; InfrastructureAdvisorAutoProxyCreator【@EnableTransactionManagement导入】 该APC是在@EnableTransactionMangement注解作用下注入到ioc容器中的 代理创建器，继承了AbstractAutoProxyCreator，这个和注解版AOP的代理创建器（AnnotationAwareAspectJAutoProxyCreator）继承的是一个类，主要的作用就是创建代理对象，我们之前也是知道事务的底层其实就是使用AOP进行操作的，继承的关系图如下： 从上面的继承关系图可以很清晰的看到，这个类实现了不少的关于Bean生命周期的接口，因此我们只需要把实现的这些接口打上断点，即可清楚的分析出执行的流程了。这个和AOP讲解的类似，有些东西就不再一一讲述了 主要的功能就是为标注了@Transactional创建代理对象，其中最重要的逻辑就是找到候选的增强器【事务的实现注入的增强器就是BeanFactoryTransactionAttributeSourceAdvisor】，主要的逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960611）在org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#wrapIfNecessary方法中是创建代理对象的主要方法，不过在这之前需要获取所有适用当前Bean的所有增强器（Advisor），调用的是Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);这个方法 1.1) 进入org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator#getAdvicesAndAdvisorsForBean方法，调用的是List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName)这段代码，获取可用的增强器 1.2） 进入，实际调用的是List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName)这段代码，获取能够作用在beanClass的增强器 1.3）进入，实际调用的是AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass)这段代码 1.4）一路跟进，最终到了org.springframework.aop.support.AopUtils#canApply(org.springframework.aop.Pointcut, ava.lang.Class&lt;?&gt;, boolean)，主要的逻辑开始了 1.4.1） 最重要的代码便是循环获取的接口，获取其中的方法，调用methodMatcher.matches(method, targetClass)匹配，源码如下： for (Class&lt;?&gt; clazz : classes) &#123; Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); for (Method method : methods) &#123; if (introductionAwareMethodMatcher != null ? introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions) : methodMatcher.matches(method, targetClass)) &#123; return true; &#125; &#125; &#125; 1.4.2）跟进，进入了org.springframework.transaction.interceptor.AbstractFallbackTransactionAttributeSource#computeTransactionAttribute方法，主要的逻辑就是先判断当前Bean的所有方法是否有@Transactional注解，之后判断该类头上是否有@Transactional注解 1.4.3）最重要的解析是否存在@Transactional注解的方法就是org.springframework.transaction.annotation.SpringTransactionAnnotationParser#parseTransactionAnnotation(java.lang.reflect.AnnotatedElement)，其中的逻辑如下： public TransactionAttribute parseTransactionAnnotation(AnnotatedElement element) &#123; //获取注解@Transactional中的属性值 AnnotationAttributes attributes = AnnotatedElementUtils.findMergedAnnotationAttributes( element, Transactional.class, false, false); //如果属性值不为空，表示该类获取方法上标注了@Transactional注解 if (attributes != null) &#123; //解析注解的属性值，封装在TransactionAttribute中返回 return parseTransactionAnnotation(attributes); &#125; else &#123; return null; &#125; &#125; //解析注解的属性值，将其封装在TransactionAttribute中protected TransactionAttribute parseTransactionAnnotation(AnnotationAttributes attributes) &#123; RuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute(); Propagation propagation = attributes.getEnum("propagation"); rbta.setPropagationBehavior(propagation.value()); Isolation isolation = attributes.getEnum("isolation"); rbta.setIsolationLevel(isolation.value()); rbta.setTimeout(attributes.getNumber("timeout").intValue()); rbta.setReadOnly(attributes.getBoolean("readOnly")); rbta.setQualifier(attributes.getString("value")); List&lt;RollbackRuleAttribute&gt; rollbackRules = new ArrayList&lt;&gt;(); for (Class&lt;?&gt; rbRule : attributes.getClassArray("rollbackFor")) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); &#125; for (String rbRule : attributes.getStringArray("rollbackForClassName")) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); &#125; for (Class&lt;?&gt; rbRule : attributes.getClassArray("noRollbackFor")) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); &#125; for (String rbRule : attributes.getStringArray("noRollbackForClassName")) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); &#125; rbta.setRollbackRules(rollbackRules); return rbta; &#125; SpringTransactionAnnotationParser @Transactional注解解析器，主要的作用就是解析指定类或者方法【标注有@Transactional注解的】上的@Transactional注解中的属性值，将其封装在 TransactionAttribute中，主要的逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243public TransactionAttribute parseTransactionAnnotation(AnnotatedElement element) &#123; //获取注解中的所有属性值 AnnotationAttributes attributes = AnnotatedElementUtils.findMergedAnnotationAttributes( element, Transactional.class, false, false); if (attributes != null) &#123; //如果属性不为空，调用parseTransactionAnnotation方法封装 return parseTransactionAnnotation(attributes); &#125; else &#123; return null; &#125; &#125;protected TransactionAttribute parseTransactionAnnotation(AnnotationAttributes attributes) &#123; RuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute(); //封装传播行为和隔离级别 Propagation propagation = attributes.getEnum("propagation"); rbta.setPropagationBehavior(propagation.value()); Isolation isolation = attributes.getEnum("isolation"); rbta.setIsolationLevel(isolation.value()); rbta.setTimeout(attributes.getNumber("timeout").intValue()); rbta.setReadOnly(attributes.getBoolean("readOnly")); rbta.setQualifier(attributes.getString("value")); //封装回滚规则 List&lt;RollbackRuleAttribute&gt; rollbackRules = new ArrayList&lt;&gt;(); for (Class&lt;?&gt; rbRule : attributes.getClassArray("rollbackFor")) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); &#125; for (String rbRule : attributes.getStringArray("rollbackForClassName")) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); &#125; for (Class&lt;?&gt; rbRule : attributes.getClassArray("noRollbackFor")) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); &#125; for (String rbRule : attributes.getStringArray("noRollbackForClassName")) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); &#125; rbta.setRollbackRules(rollbackRules); return rbta; &#125; AnnotationTransactionAttributeSource【@EnableTransactionManagement导入】 该类的作用就是获取目标类和目标方法上的@Transactional注解的属性信息，封装在缓存中。 实现了TransactionAttributeSource，简单的说这个类中封装了所有类、方法上标注的@Transactional注解的属性值【以TransactionAttribute的属性保存在private final Map&lt;Object, TransactionAttribute&gt; attributeCache = new ConcurrentHashMap&lt;&gt;(1024)，key是通过类，方法生成的MethodClassKey对象，value是TransactionAttribute】 重要的属性： attributeCache中存储了所有类的方法的对应的@Transactional注解属性的值，后续在执行事务的时候，就是直接从这个缓存中直接获取的。 其中有几个重要的方法，如下： public TransactionAttribute getTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass)：根据类、方法获取指定的TransactionAttribute ，具体的实现在AbstractFallbackTransactionAttributeSource类中，源码如下： 其中findTransactionAttribute()方法没有继续跟进，因为其中的执行逻辑就是使用注解解析器（SpringTransactionalAnnotationParser）进行对@Transactional注解的解析，封装在TransactionAttribute返回。 attributeCache中存储了所有类的方法的对应的@Transactional注解属性的值，后续在执行事务的时候，就是直接从这个缓存中直接获取的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//method：指定的方法，targetClass指定的类public TransactionAttribute getTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; //如果是Object，直接返回null if (method.getDeclaringClass() == Object.class) &#123; return null; &#125; // 第一步先直接从缓存中取值，如果存在，直接返回即可 Object cacheKey = getCacheKey(method, targetClass); TransactionAttribute cached = this.attributeCache.get(cacheKey); if (cached != null) &#123; // Value will either be canonical value indicating there is no transaction attribute, // or an actual transaction attribute. if (cached == NULL_TRANSACTION_ATTRIBUTE) &#123; return null; &#125; else &#123; return cached; &#125; &#125; else &#123; //如果缓存中没有，那么需要调用computeTransactionAttribute方法去ioc中解析 TransactionAttribute txAttr = computeTransactionAttribute(method, targetClass); //将取出的值存入缓存中，下次再取就不需要解析了，直接取值即可 if (txAttr == null) &#123; this.attributeCache.put(cacheKey, NULL_TRANSACTION_ATTRIBUTE); &#125; else &#123; //获取方法的名称，全类名+方法名的形式 String methodIdentification = ClassUtils.getQualifiedMethodName(method, targetClass); if (txAttr instanceof DefaultTransactionAttribute) &#123; ((DefaultTransactionAttribute) txAttr).setDescriptor(methodIdentification); &#125; if (logger.isTraceEnabled()) &#123; logger.trace("Adding transactional method '" + methodIdentification + "' with attribute: " + txAttr); &#125; this.attributeCache.put(cacheKey, txAttr); &#125; return txAttr; &#125; &#125;/**********************************computeTransactionAttribute****************/protected TransactionAttribute computeTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; //如果方法不是public类型的，直接返回null if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null; &#125; //如果method方法是在接口中定义的方法，那么获取接口实现类的方法。 Method specificMethod = AopUtils.getMostSpecificMethod(method, targetClass); // 尝试获取目标方法上标注的@Transactional注解的属性【因为这个注解可以标注在方法和类上】 TransactionAttribute txAttr = findTransactionAttribute(specificMethod); if (txAttr != null) &#123; return txAttr; &#125; // 获取标注在类上的注解的属性 txAttr = findTransactionAttribute(specificMethod.getDeclaringClass()); if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; if (specificMethod != method) &#123; // Fallback is to look at the original method. txAttr = findTransactionAttribute(method); if (txAttr != null) &#123; return txAttr; &#125; // Last fallback is the class of the original method. txAttr = findTransactionAttribute(method.getDeclaringClass()); if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; &#125; return null; &#125; protected TransactionAttribute findTransactionAttribute(Class&lt;?&gt; clazz)：获取指定类上的@Transactional的属性值 protected TransactionAttribute findTransactionAttribute(Method method)：获取指定方法的上的@Transactional属性的值 protected TransactionAttribute determineTransactionAttribute(AnnotatedElement element)：获取@Transactional属性值的真正调用的方法，执行的逻辑就是使用前面讲过的SpringTransactionAnnotationParser进行注解的解析，代码如下： 123456789101112131415161718192021222324protected TransactionAttribute determineTransactionAttribute(AnnotatedElement element) &#123; //遍历可用的事务注解解析器-&gt;this.annotationParsers for (TransactionAnnotationParser annotationParser : this.annotationParsers) &#123; //调用解析的方法，进行解析 TransactionAttribute attr = annotationParser.parseTransactionAnnotation(element); if (attr != null) &#123; return attr; &#125; &#125; return null; &#125;/***org.springframework.transaction.annotation.SpringTransactionAnnotationParser#parseTransactionAnnotation(java.lang.reflect.AnnotatedElement)****/public TransactionAttribute parseTransactionAnnotation(AnnotatedElement element) &#123; //直接获取元素上@Transactional注解的属性，如果获取都了，将其解析成TransactionAttribute对象返回即可 AnnotationAttributes attributes = AnnotatedElementUtils.findMergedAnnotationAttributes( element, Transactional.class, false, false); if (attributes != null) &#123; return parseTransactionAnnotation(attributes); &#125; //不存在该注解，那么直接返回null else &#123; return null; &#125; BeanFactoryTransactionAttributeSourceAdvisor【@EnableTransactionManagement导入】 事务的增强器，其中封装了TransactionInterceptor、TransactionAttributeSource 、TransactionAttributeSourcePointcut TransactionInterceptor【重要】 事务拦截器，顾名思义，就是在方法执行之前进行一些操作，开启事务就是使用拦截器在调用方法之前开启的。 其中几个重要的方法，如下： public Object invoke(MethodInvocation invocation)：jdk动态代理执行拦截器链的时候会执行的方法，内部真正调用的是父类TransactionAspectSupport的invokeWithinTransaction方法 protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation)：以事务的方式调用，关于事务的周期，比如开启，提交，回滚等等都是从此方法进入的，源码如下： TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);：从此段代码进去是开启事务的逻辑 completeTransactionAfterThrowing(txInfo, ex);：从此段代码进入是出现异常回滚事务的逻辑 commitTransactionAfterReturning(txInfo);：从此段代码进入是提交事务的逻辑 1234567891011121314151617181920212223242526272829protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // target invocation exception completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; commitTransactionAfterReturning(txInfo); return retVal; &#125; TransactionAttributeSourcePointcut 事务的切入点，实现了MethodMatcher，主要用于方法的匹配 matches方法的源码如下： 判断依据就是获取目标方法的@Transactional注解的属性，如果为null，那么就没有事务，反之则表示有事务开启。 getTransactionAttribute方法调用的是AbstractFallbackTransactionAttributeSource类中的，主要逻辑是先从缓存中取，如果缓存中没有，通过SpringTransactionalAnnotationParser解析。 12345678910public boolean matches(Method method, Class&lt;?&gt; targetClass) &#123; if (TransactionalProxy.class.isAssignableFrom(targetClass) || PlatformTransactionManager.class.isAssignableFrom(targetClass) || PersistenceExceptionTranslator.class.isAssignableFrom(targetClass)) &#123; return false; &#125; TransactionAttributeSource tas = getTransactionAttributeSource(); //获取目标方法的@Transactional注解的属性 return (tas == null || tas.getTransactionAttribute(method, targetClass) != null); &#125; 调用标注@Transactional方法前提 事务默认使用的是JDK的动态代理，并不是cglib代理 方法或者类上标注了@Transactional注解 配置类标注了@EnableTransactionManagement，开启事务 解析 调用标注有@Transactional注解的方法，进入了org.springframework.aop.framework.JdkDynamicAopProxy#invoke方法，进行了JDK的动态代理，源码如下： this.advised：其实就是ProxyFactory（代理工厂），其中在创建代理对象的时候，封装了targetSource和事务增强器（BeanFactoryTransactionAttributeSourceAdvisor） 其中最重要的一段代码就是List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);，获取适用于该方法的拦截器链 retVal = invocation.proceed();：通过拦截器执行该方法，内部实现了事务的一些逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586//proxy 代理对象 method方法，args参数public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; //获取targetSource TargetSource targetSource = this.advised.targetSource; Object target = null; try &#123; //判断方法是否是equals、hashCode方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; //封装返回值 Object retVal; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; //获取目标对象和目标类 target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); //获取拦截器链【重要方法】 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); //拦截器链为空表示没有使用事务，直接调用即可 if (chain.isEmpty()) &#123; //获取能够适用的参数 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); //直接调用方法 retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; //拦截器链不为空，需要拦截执行，创建ReflectiveMethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); //通过拦截器链执行 retVal = invocation.proceed(); &#125; // 判断返回值类型 Class&lt;?&gt; returnType = method.getReturnType(); //如果返回值是对象本身，即是return this,那么返回的必须还是代理对象proxy，否则后续的方法不能使用代理对象了。 if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned "this" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( "Null return value from advice does not match primitive return type for: " + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; 继续上面的获取拦截器链的方法，如下： 第一次调用是需要执行this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice(this, method, targetClass);方法，后续是直接从缓存中获取即可 1234567891011121314public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; //获取key MethodCacheKey cacheKey = new MethodCacheKey(method); //获取缓存中的数据 List&lt;Object&gt; cached = this.methodCache.get(cacheKey); //缓存为空，调用this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice方法 if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this, method, targetClass); //存入缓存中 this.methodCache.put(cacheKey, cached); &#125; return cached; &#125; 进入org.springframework.aop.framework.DefaultAdvisorChainFactory#getInterceptorsAndDynamicInterceptionAdvice方法，如下： 该方法执行成功返回的List就是适用于方法上的拦截器链，事务的拦截器是TransactionIntercept 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice( Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; //获取GlobalAdvisorAdapterRegistry AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); //获取ProxyFacotry中的增强器 Advisor[] advisors = config.getAdvisors(); //存储可用的全部拦截器 List&lt;Object&gt; interceptorList = new ArrayList&lt;&gt;(advisors.length); //获取真正的目标类 Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); Boolean hasIntroductions = null; //遍历增强器，事务的增强器是BeanFactoryTransactionAttributeSourceAdvisor for (Advisor advisor : advisors) &#123; //判断是否是PointcutAdvisor类型的，事务的增强器就是这种类型的 if (advisor instanceof PointcutAdvisor) &#123; // 强转 PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; //判断增强器是否之前已经过滤或者此增强器匹配目标类 if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); //标记是否匹配 boolean match; //判断类型 if (mm instanceof IntroductionAwareMethodMatcher) &#123; if (hasIntroductions == null) &#123; hasIntroductions = hasMatchingIntroductions(advisors, actualClass); &#125; match = ((IntroductionAwareMethodMatcher) mm).matches(method, actualClass, hasIntroductions); &#125; else &#123; //匹配是否适用，其实内部就是判断TransactionAttributeSource中的attributeCache的value是否为null match = mm.matches(method, actualClass); &#125; //匹配了，添加 if (match) &#123; //判断增强器中的advice是否是MethodInterceptor等类型 MethodInterceptor[] interceptors = registry.getInterceptors(advisor); if (mm.isRuntime()) &#123; // Creating a new object instance in the getInterceptors() method // isn't a problem as we normally cache created chains. for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; //类型是IntroductionAdvisor else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125; 拦截器链正确返回后，此时代码就执行到了retVal = invocation.proceed();，进入，源码如下： 真正以事务执行的方法是在父类TransactionAspectSupport中的invokeWithinTransaction方法 12345678910111213141516171819202122232425262728293031323334353637//此方法是循环调用的，每一个拦截器调用都会执行一遍，因此currentInterceptorIndex是表示执行到的拦截器下标public Object proceed() throws Throwable &#123; //如果拦截器全部执行完成，那么就开始调用目标方法了 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; //获取当前的拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); //判断拦截器类型是InterceptorAndDynamicMethodMatcher，事务的拦截器显然不是，跳过执行 if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. return proceed(); &#125; &#125; else &#123; //执行拦截器的invoke方法 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125;//org.springframework.transaction.interceptor.TransactionInterceptor#invokepublic Object invoke(MethodInvocation invocation) throws Throwable &#123; Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); //执行父类的invokeWithinTransaction方法 return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); &#125; org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction final PlatformTransactionManager tm = determineTransactionManager(txAttr)：获取事务管理器 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification)：内部重要的逻辑就是调用doBegin开启事务。 commitTransactionAfterReturning(txInfo)：提交事务，调用是org.springframework.jdbc.datasource.DataSourceTransactionManager#doCommit方法 completeTransactionAfterThrowing(txInfo, ex)：对事务的异常处理，根据@Transactional中的定义的异常，做出不同的处理，内部做了事务的回滚，最终回滚的方法是org.springframework.jdbc.datasource.DataSourceTransactionManager#doRollback 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; //获取TransactionAttributeSource TransactionAttributeSource tas = getTransactionAttributeSource(); //获取TransactionAttribute，如果为null，那么是以非事务的方式执行 final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); //获取事务管理器，见下方的方法 final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); //判断 if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; //创建TransactionInfo，此处就会开启事务 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try &#123; //再次调用invoke方法，执行下一个拦截器 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; //对事务的异常处理，根据@Transactional中的定义的异常，做出不同的处理，内部做了事务的回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; //重新设置TransactionInfo信息 cleanupTransactionInfo(txInfo); &#125; //正确返回之后，提交事务，调用的是org.springframework.jdbc.datasource.DataSourceTransactionManager#doCommit commitTransactionAfterReturning(txInfo); //返回结果 return retVal; &#125; &#125;//determineTransactionManager：获取事务管理器，先获取自身的，后获取注入的事务管理器，放入缓存中，下次直接用protected PlatformTransactionManager determineTransactionManager(@Nullable TransactionAttribute txAttr) &#123; //如果TransactionAttribute为null，不以事务的形式执行 if (txAttr == null || this.beanFactory == null) &#123; return getTransactionManager(); &#125; //获取@Transactional中的qualifier属性的值，根据名称获取事务管理器 String qualifier = txAttr.getQualifier(); if (StringUtils.hasText(qualifier)) &#123; //根据BeanName获取事务管理器 return determineQualifiedTransactionManager(this.beanFactory, qualifier); &#125; //根据transactionManagerBeanName获取事务管理器 else if (StringUtils.hasText(this.transactionManagerBeanName)) &#123; return determineQualifiedTransactionManager(this.beanFactory, this.transactionManagerBeanName); &#125; else &#123; //获取默认的事务管理器 PlatformTransactionManager defaultTransactionManager = getTransactionManager(); if (defaultTransactionManager == null) &#123; //获取缓存中的事务管理器 defaultTransactionManager = this.transactionManagerCache.get(DEFAULT_TRANSACTION_MANAGER_KEY); if (defaultTransactionManager == null) &#123; //从ioc容器中获取事务管理器 defaultTransactionManager = this.beanFactory.getBean(PlatformTransactionManager.class); //放入缓存 this.transactionManagerCache.putIfAbsent( DEFAULT_TRANSACTION_MANAGER_KEY, defaultTransactionManager); &#125; &#125; return defaultTransactionManager; &#125; &#125;//createTransactionIfNecessaryprotected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // 如果TransactionAttribute中没有指定name，那么使用joinpointIdentification【方法的全类名+方法名】 if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; //TransactionStatus中存储的是事务运行的各个状态 TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123; //获取事务的当前状态，内部调用最重要的方法是doBegin，开启事务，设置自动提交为false status = tm.getTransaction(txAttr); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Skipping transactional joinpoint [" + joinpointIdentification + "] because no transaction manager has been configured"); &#125; &#125; &#125; return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); &#125;//org.springframework.jdbc.datasource.DataSourceTransactionManager#doBegin//主要的作用是开启事务con.setAutoCommit(false);protected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try &#123; if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; //获取数据库连接 Connection newCon = obtainDataSource().getConnection(); if (logger.isDebugEnabled()) &#123; logger.debug("Acquired Connection [" + newCon + "] for JDBC transaction"); &#125; txObject.setConnectionHolder(new ConnectionHolder(newCon), true); &#125; txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); //如果是自动提交的，那么设置不是自动提交 if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) &#123; logger.debug("Switching JDBC Connection [" + con + "] to manual commit"); &#125; con.setAutoCommit(false); &#125; //准备工作，如果标记了readOnly=true，那么设置事务事只读的。 prepareTransactionalConnection(con, definition); txObject.getConnectionHolder().setTransactionActive(true); //判断设置的超时时间 int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; // Bind the connection holder to the thread. if (txObject.isNewConnectionHolder()) &#123; TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); &#125; &#125; catch (Throwable ex) &#123; if (txObject.isNewConnectionHolder()) &#123; DataSourceUtils.releaseConnection(con, obtainDataSource()); txObject.setConnectionHolder(null, false); &#125; throw new CannotCreateTransactionException("Could not open JDBC Connection for transaction", ex); &#125; &#125;//org.springframework.jdbc.datasource.DataSourceTransactionManager#doCommit//提交事务protected void doCommit(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) &#123; logger.debug("Committing JDBC transaction on Connection [" + con + "]"); &#125; try &#123; //提交事务 con.commit(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException("Could not commit JDBC transaction", ex); &#125; &#125; 事务生成AOP代理流程 事务执行流程 总结 事务执行流程： 标注@EnableTransactionManagement，内部使用@Import注解导入了几个Bean，分别是InfrastructureAdvisorAutoProxyCreator、BeanFactoryTransactionAttributeSourceAdvisor、AnnotationTransactionAttributeSource、TransactionInterceptor 对类上或者方法上标注了@Transactional注解的类生成代理对象，调用AbstractAutoProxyCreator中的wrapIfNecessary生成 重要的逻辑就是使用SpringAnnotationTransactionParser解析每一个类每一个方法上标注的@Transactional注解的属性值，封装在TransactionalAttribute中，最终将这些TransactionalAttribut统一封装在TransactionalAttributeSource中【使用attributeCache进行缓存】 最终将增强器Advisor和拦截器封装在ProxyFactory中 执行的时候先调用org.springframework.aop.framework.JdkDynamicAopProxy#invoke方法 先获取适用的拦截器链，最终以循环调用的方式（类似）执行拦截器 调用TransactionInterceptor中的invoke方法，最终执行的TransactionAspect中的invokeWithTransactional方法，在这方法内部涉及了事务的生命周期，如开启事务，回滚事务，提交事务等等操作，都是从此方法进入的。最终执行的处理是调用事务管理器中的doXXX方法，比如doCommit方法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中的事件]]></title>
      <url>%2F2019%2F06%2F30%2FSpring%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[简介 学过编程语言的肯定知道事件，在JS中事件，Android中的事件，大多是鼠标点击，键盘事件，手指滑动事件等等。在Spring中也有一些事件，比如容器启动、容器关闭、容器刷新都是一个事件。 既然有了事件，自然少不了事件监听器，事件分发器等，后续会详细介绍 事件Spring中内置的事件 ContextStartedEvent：容器启动的时候触发(start方法) ContextRefreshedEvent：容器刷新的时候触发(onRefresh，在finisRefresh中调用) ContextStoppedEvent：容器停止的时候触发(stop方法) ContextClosedEvent：容器关闭的时候触发(close方法) 自定义事件 Spring中自定义事件只需要继承ApplicationEvent即可完成一个自定义的Spring事件1234567891011121314151617181920/** * 自定义事件，继承ApplicationEvent */@Datapublic class FirstEvent extends ApplicationEvent &#123; /** * 需要携带的消息，可以是任意类型的数据，相当于传递数据 */ private String message; /** * 构造方法 * @param source 事件发生的类 * @param message 携带的消息 */ public FirstEvent(Object source,String message) &#123; super(source); this.message=message; &#125;&#125; 监听器 监听器用来监听事件触发，一旦事件触发了，监听器会执行相应的操作。 监听器的实现有两种方式： 实现ApplicationListener接口 使用@EventListener注解 实现ApplicationListener接口 创建监听器需要两个条件： 实现ApplicationListener接口 将该自定义的监听器注入到ioc容器中1234567891011121314151617/** * 自定义一个监听器，实现ApplicationListener，指定的泛型就是需要监听的事件 * 监听ContextRefreshedEvent，当容器完成刷新的时候该监听器就会监听到并执行onApplicationEvent方法 */@Componentpublic class FirstListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; /** * 重载方法，被监听的事件触发了就会调用这个方法 * @param event 触发事件的对象 */ @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; System.out.println("容器刷新的监听器启动了........"); System.out.println(event.getSource()+"----&gt;"+event.getTimestamp()+"----"+event.getApplicationContext()); System.out.println("........................................."); &#125;&#125; 此时只要启动容器，自定义的监听器就会起作用，当然我们监听的是Spring内置的事件，在容器启动的时候Spring会使用事件发布器发布事件，此时才是真正的触发事件，我们自定义的事件并不能被监听，除非被事件发布器发布。 使用@EventListener注解 常见的属性： classes：Class数组，指定需要监听的事件 condition：指定条件，默认监听123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 注解方式实现事件监听器 */@Componentpublic class CustomEventListener &#123; /** * 使用@EventListener监听事件 * @param event 传入的事件源 */ @EventListener(classes = &#123;ApplicationEvent.class&#125;) public void handlerContextRefreshEvent(ApplicationEvent event)&#123; if (event instanceof ContextRefreshedEvent) &#123; ContextRefreshedEvent e=(ContextRefreshedEvent)event; System.out.println("ContextRefreshedEvent启动了........"); System.out.println(event.getSource() + "----&gt;" + event.getTimestamp() + "----" + e.getApplicationContext()); System.out.println("........................................."); &#125;else if(event instanceof ContextStartedEvent)&#123; ContextStartedEvent e=(ContextStartedEvent)event; System.out.println("ContextStartedEvent启动了........"); System.out.println(event.getSource() + "----&gt;" + event.getTimestamp() + "----" + e.getApplicationContext()); System.out.println("........................................."); &#125;else if(event instanceof ContextStoppedEvent)&#123; ContextStoppedEvent e=(ContextStoppedEvent)event; System.out.println("ContextStoppedEvent启动了........"); System.out.println(event.getSource() + "----&gt;" + event.getTimestamp() + "----" + e.getApplicationContext()); System.out.println("........................................."); &#125;else if(event instanceof ContextClosedEvent)&#123; ContextClosedEvent e=(ContextClosedEvent)event; System.out.println("ContextClosedEvent启动了........"); System.out.println(event.getSource() + "----&gt;" + event.getTimestamp() + "----" + e.getApplicationContext()); System.out.println("........................................."); &#125; &#125; /** * 可以不指定classes，默认监听的是方法参数中的事件 * @param event 事件源 */ @EventListener public void handleFirstEvent(FirstEvent event)&#123; System.out.println("firstEvent事件启动了，。。。。。。。。。"); System.out.println(event.getSource()+"----&gt;"+event.getMessage()); &#125;&#125; 事件发布 Spring中发布事件的接口是ApplicationEventPublisher，我们可以自定义自己的类，当然也可以使用spring现成的类 Spring的事件发布类 ApplicationContext AnnotationConfigApplicationContext 直接注入 在容器启动刷新的时候已经注入了ApplicationEventPublisher的实现，我们可以直接注入使用。如下： 12345678910111213141516171819/** * 自定义的事件发布器 */@Componentpublic class CustomPublisher &#123; /** * 直接注入ApplicationEventPublisher */ @Autowired private ApplicationEventPublisher applicationEventPublisher; /** * 发布事件 * @param event 指定的事件 */ public void publishEvent(ApplicationEvent event)&#123; applicationEventPublisher.publishEvent(event); &#125;&#125; 测试 12345@Testpublic void test1()&#123; CustomPublisher customPublisher = applicationContext.getBean(CustomPublisher.class); customPublisher.publishEvent(new FirstEvent(this,"启动自定义事件"));&#125; 使用ApplicationEventPublisherAware注入1234567891011121314151617181920/** * 自定义的事件发布器，实现ApplicationEventPublisherAware接口 */@Componentpublic class CustomPublisher implements ApplicationEventPublisherAware &#123; private ApplicationEventPublisher applicationEventPublisher; /** * 发布事件 * @param event 指定的事件 */ public void publishEvent(ApplicationEvent event)&#123; applicationEventPublisher.publishEvent(event); &#125; @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher=applicationEventPublisher; &#125;&#125; 事件多播器 何为事件多播器【ApplicationEventMulticaster】？ 简单的说事件多播器就是一个管理事件监听器并且广播事件【根据指定的事件调用指定的监听器而已】 spring中两个实现类分别为AbstractApplicationEventMulticaster、SimpleApplicationEventMulticaster 如何广播事件？【如何通过指定的事件调用指定的监听器】 真正的实现在org.springframework.context.event.SimpleApplicationEventMulticaster#multicastEvent(org.springframework.context.ApplicationEvent, org.springframework.core.ResolvableType)这个方法中，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Override public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); //遍历事件监听器 for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; //判断是否设置了Executor，如果存在，那么就异步执行 Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; //否则的话，同步执行，调用invokeListener invokeListener(listener, event); &#125; &#125; &#125;/****************************************invokeListener******************************/protected void invokeListener(ApplicationListener&lt;?&gt; listener, ApplicationEvent event) &#123; //如果有异常处理器，就try-catch执行 ErrorHandler errorHandler = getErrorHandler(); if (errorHandler != null) &#123; try &#123; doInvokeListener(listener, event); &#125; catch (Throwable err) &#123; //如果有异常了，执行异常处理器的handleError方法 errorHandler.handleError(err); &#125; &#125; else &#123; //没有异常处理器直接执行 doInvokeListener(listener, event); &#125; &#125;/*******************************doInvokeListener****************************/private void doInvokeListener(ApplicationListener listener, ApplicationEvent event) &#123; try &#123; //此时真正调用监听器中的方法 listener.onApplicationEvent(event); &#125; catch (ClassCastException ex) &#123; String msg = ex.getMessage(); if (msg == null || matchesClassCastMessage(msg, event.getClass())) &#123; // Possibly a lambda-defined listener which we could not resolve the generic event type for // -&gt; let's suppress the exception and just log a debug message. Log logger = LogFactory.getLog(getClass()); if (logger.isDebugEnabled()) &#123; logger.debug("Non-matching event type for listener: " + listener, ex); &#125; &#125; else &#123; throw ex; &#125; &#125; &#125; 异步事件 前面创建的事件和监听器都是同步进行，我们可以使用异步事件 使用@Async实现异步 Spring中可以使用@Async注解标注方法异步执行，不过需要在配置类上开启异步功能，使用@EnableAsync注解，如下： 123456@Configuration@ComponentScan(value = &#123;"cn.tedu.demo"&#125;)@EnableAsyncpublic class FirstConfig &#123; &#125; 此时可以在监听方法上标注@Async注解，使得事件异步执行 1234567891011121314151617/** * 注解方式实现事件监听器 */@Componentpublic class CustomEventListener &#123; /** * 可以不指定classes，默认监听的是方法参数中的事件 * @Async : 指定这个方法异步执行 * @param event 事件源 */ @EventListener @Async public void handleFirstEvent(FirstEvent event)&#123; System.out.println("firstEvent事件启动了，。。。。。。。。。"); System.out.println(event.getSource()+"----&gt;"+event.getMessage()); &#125;&#125; 自定义事件多播器 从源码我们可以知道，spring容器加载的时候先获取的是ioc容器中的，如果不存在，那么才会新建一个SimpleApplicationEventMulticaster，我们可以自己注入一个多播器直接使用即可。 源码如下： 123456789101112131415161718192021protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //判断ioc容器中是否存在id为applicationEventMulticaster事件多播器 if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; //直接使用ioc容器中的 this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isTraceEnabled()) &#123; logger.trace("Using ApplicationEventMulticaster [" + this.applicationEventMulticaster + "]"); &#125; &#125; else &#123; //新建一个，不过没有设置TaskExector this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isTraceEnabled()) &#123; logger.trace("No '" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + "' bean, using " + "[" + this.applicationEventMulticaster.getClass().getSimpleName() + "]"); &#125; &#125; &#125; 从源码中【org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(org.springframework.context.ApplicationEvent, org.springframework.core.ResolvableType)】我们可以看出监听器的执行是先判断多播器中是否存在Executor,如果存在，那么就单独开启一个线程执行，否则就同步执行，我们在初始化多播器的时候，可以为其设置一个Executor，那么就可以异步执行了。 12345678910111213@Override public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); &#125; &#125; &#125; 实现：在配置类注入一个多播器即可，bean的id一定要是applicationEventMulticaster，同时为其设置一个executor 12345678910111213141516171819/** * 自定义一个事件多播器，用来管理监听器和执行监听器 * @return */@Bean(name = "applicationEventMulticaster")public ApplicationEventMulticaster applicationEventMulticaster()&#123; //事件多播器 SimpleApplicationEventMulticaster simpleApplicationEventMulticaster=new SimpleApplicationEventMulticaster(); //设置executor SimpleAsyncTaskExecutor executor=new SimpleAsyncTaskExecutor(); simpleApplicationEventMulticaster.setTaskExecutor(executor); //设置一个事件异常处理器，当监听器执行出现错误了会进行补救 simpleApplicationEventMulticaster.setErrorHandler(t-&gt;&#123; //这里可以针对不同的异常进行处理，在监听器中trycatch，不同执行抛出不同异常即可分类处理 System.out.println("监听事件执行报错了"); System.out.println(t.getMessage()); &#125;); return simpleApplicationEventMulticaster;&#125; 源码解析 在spring源码中和事件涉及到的主要概念如下： 事件（ApplicationEvent） 监听器（ApplicationEventListener） 事件发布器（ApplicationEventPublisher） 事件多播器（ApplicationEventMulticaster） 具体源码层面的涉及如下： 容器刷新refresh方法中： initApplicationEventMulticaster()：初始化事件多播器 registerListeners();：注册事件监听器 finishRefresh()方法中调用publishEvent(new ContextRefreshedEvent(this))方法发布容器刷新事件。 ​]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BeanFactoryPostProcessor解析]]></title>
      <url>%2F2019%2F06%2F27%2FBeanFactoryPostProcessor%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[简介 Spring IoC容器允许BeanFactoryPostProcessor在容器实例化任何bean之前读取bean的定义(配置元数据)，并可以修改它。同时可以定义多个BeanFactoryPostProcessor，通过设置’order’属性来确定各个BeanFactoryPostProcessor执行顺序。 实例123456789101112131415@Componentpublic class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println("MyBeanFactoryPostProcessor开始执行"); String[] beanDefinitionNames = beanFactory.getBeanDefinitionNames(); for (String name : beanDefinitionNames) &#123; if (name.equals("user"))&#123; BeanDefinition beanDefinition = beanFactory.getBeanDefinition(name); MutablePropertyValues propertyValues = beanDefinition.getPropertyValues(); propertyValues.add("name","Jack"); &#125; &#125; &#125;&#125; 原理 在刷新ioc容器的方法org.springframework.context.support.AbstractApplicationContext.refresh中执行，如下图： BeanDefinitionRegistryPostProcessor 后续更新。。。。 MergedBeanDefinitionPostProcessor 后续更新]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BeanWrapper解析]]></title>
      <url>%2F2019%2F06%2F27%2FBeanWrapper%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[简介 BeanWrapper是Spring底层经常使用的一个接口，简单来说是对Bean的一种包装，包括对Bean的属性、方法，数据等。 唯一的一个实现类是BeanWrapperImpl，继承和实现关系图如下： 常用API public BeanWrapperImpl(Object object)：指定对象构造 public BeanWrapperImpl(Class&lt;?&gt; clazz)：指定Class构造，内部会通过反射调用clazz的默认无参构造方法进行实例化 public final Object getWrappedInstance()：获取对象实例 public PropertyDescriptor getPropertyDescriptor(String propertyName：获取指定属性的PropertyDescriptor public PropertyDescriptor[] getPropertyDescriptors()：获取所有属性的PropertyDescriptor【包括继承而来的】 public Object getPropertyValue(String propertyName)：获取指定属性的值 PropertyDescriptor 简称属性描述器，是对属性的封装，包括属性的类型，值，get和set方法，可以通过属性描述器可以很简单的获取和修改对应的值。 两个概念如下： ReadMethod：即是对应属性的get方法 WriteMethod：即是对应属性的set方法 实例 我们可以同BeanWrapper和PropertyDescriptor可以很轻松实现属性的复制，下面是本人手写的一个复制的工具类【当然这个是很粗糙的，和BeanUtils中的copyPropreties方法不能相提并论，不喜勿喷】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 对象复制【浅克隆】 */public class NewCopyUtils &#123; private static final String CLASS="class"; /** * 复制对象【只能复制基本数据类型，浅克隆】 * @param source 源对象 * @param target 目标对象 * @param ingoreAgrs 忽略的属性 * @throws Exception */ public static void copyProperties(Object source,Object target,String... ingoreAgrs) throws Exception &#123; if (source.getClass().isInterface()||target.getClass().isInterface())&#123; throw new Exception("source和target不能为接口"); &#125; BeanWrapper sourceWrap = createBeanWrap(source); BeanWrapper targetWrap = createBeanWrap(target); PropertyDescriptor[] targetPds = targetWrap.getPropertyDescriptors(); PropertyDescriptor[] sourcePds = sourceWrap.getPropertyDescriptors(); //根据名称分组，减少一层循环 Map&lt;String, List&lt;PropertyDescriptor&gt;&gt; map = Arrays.asList(sourcePds).parallelStream().filter(o -&gt; !StringUtils.equals(CLASS, o.getName())).collect(Collectors.groupingBy(o -&gt; o.getName())); for (int i = 0; i &lt; targetPds.length; i++) &#123; PropertyDescriptor tpd=targetPds[i]; //去掉class属性和不要的复制的属性 if (!StringUtils.equals(CLASS,tpd.getName())&amp;&amp; !Arrays.asList(ingoreAgrs).contains(tpd.getName()))&#123; List&lt;PropertyDescriptor&gt; list = map.getOrDefault(tpd.getName(), null); if (Objects.nonNull(list))&#123; Method writeMethod = tpd.getWriteMethod(); Method readMethod = list.get(0).getReadMethod(); if (Objects.isNull(writeMethod)&amp;&amp;Objects.isNull(readMethod))&#123; throw new Exception("属性必须有get和set方法"); &#125; Object o = readMethod.invoke(source); writeMethod.invoke(target,o); &#125; &#125; &#125; &#125; /** * 构造BeanWrapImpl * @param source 对象 * @return BeanWrapper */ private static BeanWrapper createBeanWrap(Object source)&#123; return new BeanWrapperImpl(source); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[InstantiationAwareBeanPostProcessor源码解析]]></title>
      <url>%2F2019%2F06%2F25%2FInstantiationAwareBeanPostProcessor%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[简介 继承BeanPostProcessor接口，在此基础上又定义了三个方法，分别在Bean实例化前后【不是初始化】执行。 从上面的介绍可以看到，这个接口相对于BeanPostProcessor功能更加强大，一个接口承担了Bean的实例化前后、初始化前后责任。 Bean加载顺序 ioc容器创建加载Bean的执行顺序如下： InstantiationAwareBeanPostProcessor接口中的postProcessBeforeInstantiation，在实例化之前调用 Bean的实例化，调用构造方法 InstantiationAwareBeanPostProcessor接口中的postProcessAfterInstantiation，在实例化之后调用 InstantiationAwareBeanPostProcessor接口中的postProcessPropertyValues【当postProcessAfterInstantiation返回true才执行】 BeanPostProcessor接口中的postProcessBeforeInitialization，在初始化之前调用 InitializingBean中的afterProperties方法，执行初始化 BeanPostProcessor接口中的postProcessAfterInitialization，在实例化之后调用 InstantiationAwareBeanPostProcessor接口方法的执行顺序 正常的执行顺序如下： postProcessBeforeInstantiation postProcessAfterInstantiation postProcessProperties postProcessBeforeInitialization postProcessAfterInitialization 方法解析 Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName)：在实例化之前执行【构造方法之前执行】 返回值：如果返回的不为null，那么后续的Bean的创建流程【实例化、初始化afterProperties】都不会执行，而是直接使用返回的快捷Bean，此时的正常执行顺序如下： InstantiationAwareBeanPostProcessor接口中的postProcessBeforeInstantiation，在实例化之前调用 BeanPostProcessor接口中的postProcessAfterInitialization，在实例化之后调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/*** org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.resolveBeforeInstantiation * 作用：在实例化之前解析是否有快捷创建的Bean，既是通过postProcessBeforeInstantiation返回的Bean* 内部调用两个重要的方法：* 1、applyBeanPostProcessorsBeforeInstantiation：内部遍历调用postProcessBeforeInstantiation方法【在实例化之前调用】* 2、applyBeanPostProcessorsAfterInitialization：如果postProcessBeforeInstantiation方法返回了快捷的Bean，内部遍历调用postProcessBeforeInstantiation方法【在初始化之后调用】*/protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // Make sure bean class is actually resolved at this point. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); if (targetType != null) &#123; //调用方法，内部遍历调用postProcessBeforeInstantiation方法【在实例化之前调用】 bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); //如果返回了快捷的Bean if (bean != null) &#123; //如果postProcessBeforeInstantiation方法返回了快捷的Bean，内部遍历调用postProcessBeforeInstantiation方法【在初始化之后调用】 bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean; &#125; /** * org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInstantiation * 作用：调用postProcessBeforeInstantiation方法 */ protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; //遍历所有的后置处理器 for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //判断是否是InstantiationAwareBeanPostProcessor类型的，如果是的，调用postProcessBeforeInstantiation方法获取快捷Bean if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null; &#125; /** * org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization * 作用：遍历调用postProcessAfterInitialization */ public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessAfterInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result; &#125; boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException：正常情况下在实例化之后在执行populateBean之前调用 返回值：如果有指定的bean的时候返回false，那么后续的属性填充和属性依赖注入【populateBean】将不会执行，同时后续的postProcessPropertyValues将不会执行,但是初始化和BeanPostProcessor的仍然会执行。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/*** org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean* 填充指定Bean的属性* 在该方法内部遍历所有的BeanPostPorcessor，调用postProcessAfterInstantiation方法*/protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; //获取属性 PropertyValues pvs = mbd.getPropertyValues(); if (bw == null) &#123; if (!pvs.isEmpty()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; //**********************逻辑开始执行******************** //标志，判断是否继续执行属性填充，默认为false boolean continueWithPropertyPopulation = true; //判断ioc容器中是否存在InstantiationAwareBeanPostProcessors( if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; //遍历所有的BeanPostProcessor for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //判断类型是InstantiationAwareBeanPostProcessor if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //执行postProcessAfterInstantiation方法 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; //返回结果为false，那么赋值continueWithPropertyPopulation=false，表示不继续执行属性填充 continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; //如果continueWithPropertyPopulation为false，直接返回，不执行下面的步骤 if (!continueWithPropertyPopulation) &#123; return; &#125; // if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; //同样是遍历BeanPostProcessor for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //执行postProcessPropertyValues方法 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; //重要的一步，设置属性 applyPropertyValues(beanName, mbd, bw, pvs); &#125; public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName)：实例化之后调用，在方法applyPropertyValues【属性填充】之前 返回值：如果返回null，那么将不会进行后续的属性填充，比如依赖注入等，如果返回的pvs额外的添加了属性，那么后续会填充到该类对应的属性中。 pvs：PropertyValues对象，用于封装指定类的对象，简单来说就是PropertyValue的集合，里面相当于以key-value形式存放类的属性和值 pds：PropertyDescriptor对象数组，PropertyDescriptor相当于存储类的属性，不过可以调用set，get方法设置和获取对应属性的值123456789101112131415161718192021222324/*** org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean的代码片段*/if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; //遍历调用postProcessPropertyValues方法 for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); //如果返回的pvs是null，直接返回 if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; //执行真正的属性填充 applyPropertyValues(beanName, mbd, bw, pvs); 实例 只是写了InstantiationAwareBeanPostProcessor定义的方法，另外的BeanPostProcessor的方法，请看上一篇文章1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Componentpublic class MyInstantiationAwareBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; /** * 在实例化之前调用，如果返回null，一切按照正常顺序执行，如果返回的是一个实例的对象，那么这个将会跳过实例化、初始化的过程 * @param beanClass * @param beanName * @return */ @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if (beanClass == User.class) &#123; System.out.println("postProcessBeforeInstantiation执行"); return null; &#125; return null; &#125; /** * 在实例化之后，postProcessBeforeInitialization之前执行 * @param bean * @param beanName * @return * @throws BeansException */ @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; if (bean instanceof User) &#123; System.out.println("postProcessAfterInstantiation执行"); return true; &#125; return true; &#125; /** * 实例化之后调用，属性填充之前 * @param pvs PropertyValues对象，用于封装指定类的对象，简单来说就是PropertyValue的集合，里面相当于以key-value形式存放类的属性和值 * @param pds PropertyDescriptor对象数组，PropertyDescriptor相当于存储类的属性，不过可以调用set，get方法设置和获取对应属性的值 * @param bean 当前的bean * @param beanName beanName * @return 如果返回null，那么将不会进行后续的属性填充，比如依赖注入等，如果返回的pvs额外的添加了属性，那么后续会填充到该类对应的属性中。 */ @Override public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; if (pvs instanceof MutablePropertyValues&amp;&amp;bean instanceof User)&#123; MutablePropertyValues mutablePropertyValues= (MutablePropertyValues) pvs; HashMap&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); map.put("name","陈加兵"); map.put("age",44); mutablePropertyValues.addPropertyValues(map); return mutablePropertyValues; &#125; /**使用pds设置值 if (bean instanceof User) &#123; for (PropertyDescriptor descriptor:pds) &#123; try &#123; if ("name".equals(descriptor.getName())) &#123; descriptor.getWriteMethod().invoke(bean, "陈加兵"); &#125;else if("age".equals(descriptor.getName()))&#123; descriptor.getWriteMethod().invoke(bean,40); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; return null; &#125;**/ return pvs; &#125; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof User) &#123; System.out.println("postProcessBeforeInitialization执行"); &#125; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof User) &#123; System.out.println("postProcessAfterInitialization执行"); &#125; return bean; &#125;&#125; 源码梳理 无论是BeanPostProcessor还是InstantiationAwareBeanPostProcessor都是在对象实例化和初始化前后执行的逻辑，因此我们主要的代码都在getBean，doGetBean，cerateBean方法中 BeanPostProcessor的两个方法的执行源码请看上一篇的文章 步骤如下： Autowired源码解析 从源码可以看出，Autowired的功能实现最重要的一个接口就是AutowiredAnnotationBeanPostProcessor，继承关系如下： 从继承关系图可以看出，实际上关键的实现了InstantiationAwareBeanPostProcessor这个接口。 源码实现如下图： 总结 源码： ioc容器创建Bean的方法是从createBean方法进入的，真正执行创建的Bean的是doCreateBean方法，我们从createBean开始往下走 调用resolveBeforeInstantiation方法【在doCreatBean之前执行，即是实例化之前】，在内部遍历BeanPostProcessor调用postProcessBeforeInstantiation方法 如果postProcessBeforeInstantiation方法返回null，那么需要执行实例化的过程，调用doCreatBean实例化Bean。 doCreateBean内部分为两步：①调用createBeanInstance实例化Bean；②调用populateBean设置Bean的属性 在populateBean内部分为如下的步骤： 调用postProcessAfterInstantiation【实例化之后调用】，分为两种情况：①返回false，后续的postProcessPropertyValues将不再执行，属性也不在进行设置；②返回true，程序照常进行，调用postProcessPropertyValues，属性设置的过程正常进行 执行完populateBean之后将会调用initializeBean【初始化Bean，调用afterPropertiesSet方法】，在内部就涉及到BeanPostProcessor定义的接口了，步骤如下： 执行applyBeanPostProcessorsBeforeInitialization方法调用postProcessBeforeInitialization【在初始化之前调用】方法 执行invokeInitMethods方法，内部其实是调用afterPropeertiesSet方法，进行初始化 执行applyBeanPostProcessorsAfterInitialization，内部调用postProcessAfterInitialization【在实例化之后调用】方法]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[FactoryBean解析]]></title>
      <url>%2F2019%2F06%2F23%2FFactoryBean%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[简介 简单的说FactoryBean实际上是一个Bean，并不是一个工厂，它能够为我们创建一个Bean，但是创建的这个Bean实际指向的并不是FactoryBean类型的，而是其中getObject方法返回类型的对象。 接口解析 FactoryBean中有三个需要实现的方法，如下： getObject() ：获取返回的对象，此处返回的对象会被注入到ioc容器中 public Class&lt;?&gt; getObjectType()：返回创建Bean类型 public boolean isSingleton()：返回是否创建单例，如果返回true，那么创建的对象将是单例的，返回false，创建的是多实例的对象。 自定义实现 自定义一个FactoryBean，实现Admin的注入，如下： 12345678910111213141516171819202122232425/** * 自定义FactoryBean，用来创建对象 * 1、@Component :将创建的MyFactoryBean注入到容器中 * 2、实现FactoryBean * 3、指定泛型&lt;T&gt; */@Componentpublic class MyFactoryBean implements FactoryBean&lt;Admin&gt; &#123; @Override public Admin getObject() throws Exception &#123; System.out.println("创建Admin"); return new Admin(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Admin.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125;&#125; 此时即可从容器中获取到对应的Bean了，如下： 123456@Testpublic void testFactoryBean()&#123; //根据id获取实例，这里实际获取的是getObject返回的对象 Admin admin1 = applicationContext.getBean("myFactoryBean", Admin.class); System.out.println(admin1);&#125; 以上是获取的实例Bean，现在我们就想获取MyBeanFactory本身这个对象，可以在id的前面加上&amp;即可，如下： 123456@Testpublic void testFactoryBean2()&#123; //根据&amp;id获取实例，实际获取的就是MyFactoryBean的对象 MyFactoryBean bean = applicationContext.getBean("&amp;myFactoryBean", MyFactoryBean.class); System.out.println(bean);&#125; 源码解析 指定的是FactoryBean的id，为什么获取的是getObject返回的对象？ 简单的逻辑：判断传入的类型是否是FactoryBean类型，如果是该类型的，调用getObject方法返回对象即可。 在源码中可以看到调用的是org.springframework.beans.factory.support.FactoryBeanRegistrySupport#doGetObjectFromFactoryBean方法]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Bean的后置处理器]]></title>
      <url>%2F2019%2F06%2F23%2FBean%E7%9A%84%E5%90%8E%E7%BD%AE%E5%A4%84%E7%90%86%E5%99%A8%2F</url>
      <content type="text"><![CDATA[简介 调用顺序：在Bean的初始化前后调用，分别对应了其中的两个方法 Bean的后置处理器对应的接口是BeanPostProcessor，其中定义了两个方法，如下：123456789101112public interface BeanPostProcessor &#123; /** * 在Bean初始化之前执行，即是在执行Bean的构造方法之后，在执行InitializingBean的afterPropertiesSet方法之前执行 */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * 在Bean的初始化之后执行，即是在InitializingBean的afterPropertiesSet方法之后执行 */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 使用场景 在Bean的初始化前后做一些自己的逻辑处理，比如为Bean设置一些额外的属性。 最典型的例子就是spring中的Aware接口的实现，都是利用BeanPostProcessor在Bean初始化之前进行调用set方法设置相应的属性【详情请看ApplicationContextAwareProcessor源码】 @Autowired的实现依赖注入也是使用的BeanPostProcessor的原理，详情请看AutowiredAnnotationBeanPostProcessor的源码 自定义后置处理器 必备条件： 自定义的后置处理器必须注入到容器中 必须实现BeanPostProcessor接口，实现其中的方法 自定义一个User类，如下： 123456789101112131415161718192021/** * 实现InitializingBean接口，定义初始化方法，在构造方法之后执行 */@Componentpublic class User implements Serializable, InitializingBean &#123; private String name; private Integer age; public User()&#123;&#125; public User(String name, Integer age) &#123; System.out.println("执行构造方法"); this.name = name; this.age = age; &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("执行初始化方法，在构造方法执行之后执行"); &#125;&#125; 自定义后置处理器，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 1、自定义的后置处理器,实现BeanPostProcessor * 2、必须注入到容器中才能执行 * 3、后置处理器是每一个Bean实例化前后都会调用的，并不能指定某一个 */@Componentpublic class FirstPostProcessor implements BeanPostProcessor &#123; /** * 在Bean初始化之前执行，即是在执行Bean的构造方法之后，在执行InitializingBean的afterPropertiesSet方法之前执行 * @param bean bean的对象 * @param beanName bean的名字，即是在ioc容器中的id * @return 一定不能null * @throws BeansException */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果这个Bean是User类型 if (bean instanceof User)&#123; System.out.println("在User的初始化方法【afterPropertiesSet】之前执行"); //改变属性的值 User user=(User)bean; user.setName("马云"); user.setAge(40); &#125; return bean; &#125; /** * 在Bean的初始化之后执行，即是在InitializingBean的afterPropertiesSet方法之后执行 * @param bean bean的对象 * @param beanName bean的名字，即是在ioc容器中的id * @return 一定不能null * @throws BeansException */ @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof User)&#123; System.out.println("在User的初始化方法【afterPropertiesSet】之后执行"); &#125; return bean; &#125;&#125; 源码解析 最重要的就是后置处理器两个方法的执行顺序： 为什么postProcessBeforeInitialization在构造方法之后，初始化之前调用？ 为什么postProcessAfterInitialization在初始化之后调用？ 我们分别在自定义的后置处理器上打上断点，通过debug模式跟踪代码，程序的入口测试类如下： 使用AnnotationConfigApplicationContext启动容器12345678public class FirstConfigTest &#123; public AnnotationConfigApplicationContext applicationContext; @Before public void initApplicationContext() &#123; applicationContext = new AnnotationConfigApplicationContext(FirstConfig.class); &#125;&#125; 步骤 执行AnnotationConfigApplicationContext的构造方法public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses)： register(annotatedClasses)：注入指定的配置类FirstConfig 【refresh()：刷新容器，在这个执行结束之后会完成Bean的加载，详情见第2步】 进入org.springframework.context.support.AbstractApplicationContext#refresh方法： prepareRefresh();：在刷新容器之前做一些准备工作，比如设置激活状态【activate】,设置启动时间【startupDate】 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); refreshBeanFactory()：刷新BeanFactory，如果之前存在了就删除创建新的，返回的是 返回ConfigurableListableBeanFactory类型的Bean工厂 prepareBeanFactory(beanFactory);：对新创建的Bean工厂设置一些属性配置 设置ClassLoader、表达式解析器、属性注入器 设置ApplicationContextAwareProcessor这个后置处理器到org.springframework.beans.factory.support.AbstractBeanFactory#beanPostProcessors该成员变量中、去除一些不能自动注入的类【ResourceLoaderAware、ApplicationEventPublisherAware、MessageSourceAware、ApplicationContextAware、EnvironmentAware】，因为这些Aware类型的类需要后续自定义实现的 向容器中注入一些能够自动注入的类【BeanFactory，ResourceLoader，ApplicationEventPublisher，ApplicationContext】，这些类能够直接通过@Autowired直接注入使用 向容器中注入一些运行环境的Bean【ConfigurableEnvironment、systemProperties(Map&lt;String,Object&gt;其中存放的是配置参数)】，这些Bean可以直接自动注入使用 invokeBeanFactoryPostProcessors(beanFactory)：调用已经注册在容器中的BeanFactory后置处理器 registerBeanPostProcessors(beanFactory)：向ioc容器中注册BeanFactoryProcessor initMessageSource()：初始化MessageSource initApplicationEventMulticaster()：初始化事件分发器 registerListeners()：注册事件监听器，用来监听事件 【finishBeanFactoryInitialization(beanFactory)：初始化单例、非懒加载的Bean】，详情见步骤3 finishRefresh()：发布事件 进入org.springframework.context.support.AbstractApplicationContext#finishBeanFactoryInitialization: 初始化类型转换类 初始化LoadTimeWeaverAware，用于方法织入 冻结BeanDefinition，表示后面的BeanDefinition不能再改变 【beanFactory.preInstantiateSingletons()：初始化Bean，详情请看第4步】 进入到org.springframework.beans.factory.support.DefaultListableBeanFactory#preInstantiateSingletons方法中，用于初始化Bean 遍历所有的BeanNames，判断当前Bean是否是FactoryBean，如果不是运行getBean方法 进入到org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#initializeBean，如下图所示，将是完整的逻辑，可以看出后置处理器为什么是在初始化之前和之后执行。 总结 从源码可以看出，最核心的执行就是在org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#initializeBean的方法中，主要的代码逻辑是在初始化之前调用对应的before方法，在之后调用after方法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring注解开发]]></title>
      <url>%2F2019%2F06%2F23%2FSpring%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91%2F</url>
      <content type="text"><![CDATA[@Configuration 标注在类上，表明该类是一个配置类，相当于之前写的spring的xml文件，通常与@Bean结合使用 该注解同时拥有了@Component的作用，将当前类注入ioc容器 其中有一个value属性，指定注入ioc容器的名称，默认是类名首字母小写 源码如下：12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Configuration &#123;&#125; @Bean 在配置类中使用该注解 标注在方法上，默认将方法的返回对象注入到ioc容器，名称默认使用的是方法名12345678910111213/** * 配置类 */@Configuration(value = "MyConfiguration")public class MyConfiguration &#123; /** * 注入一个User对象，ioc容器中的name是user，类型是User类型 */ @Bean public User user()&#123; return new User(1,"name"); &#125;&#125; 属性 name：指定注入ioc容器中的名称 value：同name autowireCandidate：是否能够自动注入，默认是true，如果指定了属性为false，那么不能使用@Autowired或者@Resource自动注入 initMethod：指定初始化方法，在构造方法之后执行 destroyMethod：指定销毁方法，在容器关闭的时候执行 实例1234567891011121314151617181920212223242526272829303132333435363738394041/** * 配置类 */@Configuration(value = "MyConfiguration")public class MyConfiguration &#123; /** * 注入一个User对象，ioc容器中的name是user，类型是User类型 * init是User类中的init方法，destory是User类中的destory方法 */ @Bean(initMethod = "init",destroyMethod = "destory") public User user1()&#123; return new User(1,"name"); &#125;&#125;/*** User类*/public class User implements Serializable &#123; private Integer id; private String name; public User(String name) &#123; this.name = name; &#125; public User(Integer id, String name) &#123; System.out.println("执行构造方法"); this.id = id; this.name = name; &#125; public void init()&#123; System.out.println("初始化方法"); &#125; public void destory()&#123; System.out.println("销毁方法"); &#125;&#125; @Scope 指定对象的作用域名，标注在类上或者方法上，默认是单实例 四大作用域 singleton：单例，默认值，当容器启动的时候会创建对象放入ioc容器中，后续获取只是从容器中创建，并不会再次调用构造方法new出来 prototype：多实例，容器启动的时候并不会创建该对象，而是当需要用到的才调用构造方法new出来（不放入ioc容器，每次用到就new一个） request：该属性仅对HTTP请求产生作用，使用该属性定义Bean时，每次HTTP请求都会创建一个新的Bean，适用于WebApplicationContext环境。 session：该属性仅用于HTTP Session，同一个Session共享一个Bean实例。不同Session使用不同的实例。 12345678/** * 指定多实例，每次用到都会调用 */ @Bean(initMethod = "init",destroyMethod = "destory") @Scope(value = "prototype") public User user1()&#123; return new User(1,"name"); &#125; @Conditional 标注在方法或者在类上，只有在满足其中的匹配条件才会将对象注入到ioc容器中。 只有一个属性value，是一个Condition数组，要向实现相应的功能，可以自定义一个类，实现Condition这个接口即可。 这个注解在SpringBoot中将会有很多的扩展，这里就不多说了。 123456789/** * 指定多实例，每次用到都会调用 * @Conditional 只有里面全部都匹配才会正常注入到容器中 */ @Bean(initMethod = "init",destroyMethod = "destory") @Conditional(value = &#123;FirstCondition.class&#125;) public User user1()&#123; return new User(1,"name"); &#125; 下面看看FirstCondition这个类具体实现 只需要实现接口中的matches方法即可，返回true表示符合条件，否则不满足条件，只有满足条件才会注入到ioc容器中1234567891011121314151617181920/** * 自定义的条件判断，实现Condition接口 */public class FirstCondition implements Condition &#123; /** * 如果返回true表示符合条件，反之不符合条件 * @param context ConditionContext对象，可以获取上下文的信息 * @param metadata AnnotatedTypeMetadata对象，可以获取标注在该方法上面的注解信息 * @return */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; //获取Environment，用来获取运行环境中的一些变量 Environment environment = context.getEnvironment(); //获取在properties文件中配置的参数，表示是否注入相关属性 Boolean isAutowired = environment.&lt;Boolean&gt;getProperty("isAutowired", Boolean.class); return isAutowired; &#125;&#125; ConditionContext 主要的功能是获取上下文的对象，比如BeanFactory1234567891011121314151617181920212223242526272829public interface ConditionContext &#123; /** * 获取 BeanDefinitionRegistry，可以自己手动注册对象到ioc容器中 */ BeanDefinitionRegistry getRegistry(); /** * 获取BeanFacotory，操作ioc容器，比如获取对应的Bean，判断ioc中是否已经注入 */ @Nullable ConfigurableListableBeanFactory getBeanFactory(); /** * 返回当前的运行环境，可以获取运行环境中的一下参数，或者一些配置文件中的数据 */ Environment getEnvironment(); /** * 获取资源加载器 */ ResourceLoader getResourceLoader(); /** * 获取类加载器 */ @Nullable ClassLoader getClassLoader();&#125; AnnotatedTypeMetadata 主要的作用就是获取标注了@Conditional这个注解的方法上的注解和对应的参数等信息123456789101112131415161718192021222324public interface AnnotatedTypeMetadata &#123; /** * 判断方法上是否有对应的注解 * @param annotationName 注解类的全类名，getName() */ boolean isAnnotated(String annotationName); /** * 获取对应注解的全部属性的值，key是属性，value是属性的值 * @param annotationName 注解类的全类名，getName() */ @Nullable Map&lt;String, Object&gt; getAnnotationAttributes(String annotationName); @Nullable Map&lt;String, Object&gt; getAnnotationAttributes(String annotationName, boolean classValuesAsString); @Nullable MultiValueMap&lt;String, Object&gt; getAllAnnotationAttributes(String annotationName); @Nullable MultiValueMap&lt;String, Object&gt; getAllAnnotationAttributes(String annotationName, boolean classValuesAsString);&#125; @PostConstruct 标注在方法上，用来在类加载并且属性赋值之后调用，通常用来初始化，和@Bean中的init-menthd指定的作用相同1234@PostConstruct public void init()&#123; System.out.println("初始化方法"); &#125; @PreDestroy 标注在方法上，容器销毁执行，相当于@Bean中的destroy-method属性1234@PreDestroy public void destory()&#123; System.out.println("销毁方法"); &#125; @Import 用来形式化的注入，主要形式有： 直接导入类 导入配置类 指定ImportSelector 使用ImportBeanDefinitionRegistrar手动注册 直接导入类 直接在 value属性中指定需要导入的类即可，如下：123@Configuration(value = "MyConfiguration")@Import(value = &#123;Person.class&#125;)public class MyConfiguration &#123;&#125; 导入配置类 新建一个配置类，但是不用@Configuration标注，使用@Import在另外一个配置类上引入即可 123456789/** * 这是一个配置，但是并没有使用@Configuration这个注解，因此不会生效 */public class SecondConfiguration &#123; @Bean public Person person()&#123; return new Person(); &#125;&#125; 在另外一个配置类使用@Import注解引入上面的配置类，如下： 123@Configuration(value = "MyConfiguration")@Import(value = &#123;SecondConfiguration.class&#125;)public class MyConfiguration &#123;&#125; 指定ImportSelector 使用ImportSelector需要自定义一个实现类，如下： 1234567891011121314151617181920/** * 自定义Selector，需要实现ImportSelector */public class FirstSelector implements ImportSelector &#123; /** * 筛选逻辑，返回的是String数组（需要注入到容器中的类的全类名） * @param importingClassMetadata AnnotationMetadata对象，对标注了@Import这个注解的类中的所有注解信息，比如获取标注指定注解的方法 * @return 返回的是需要注入的字符串数组（类的全类名） */ @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; //获取@Import标注的类中被@Bean标注的方法元数据 Set&lt;MethodMetadata&gt; annotatedMethods = importingClassMetadata.getAnnotatedMethods(Bean.class.getName()); annotatedMethods.forEach(o-&gt;&#123; System.out.println(o.getMethodName()); &#125;); //将Person类返回去，那么将会自动注入Person return new String[]&#123;Person.class.getName()&#125;; &#125;&#125; 在配置类上使用@Import注解引入即可，如下： 123@Configuration@Import(value = &#123;FirstSelector.class&#125;)public class MyConfiguration &#123;&#125; AnnotationMetadata12345678910111213141516171819public interface AnnotationMetadata extends ClassMetadata, AnnotatedTypeMetadata &#123; //拿到Class上标注的所有注解，依赖于Class#getAnnotations Set&lt;String&gt; getAnnotationTypes(); // 拿到所有的元注解信息AnnotatedElementUtils#getMetaAnnotationTypes //annotationName:注解类型的全类名 Set&lt;String&gt; getMetaAnnotationTypes(String annotationName); // 是否包含指定注解 （annotationName：全类名） boolean hasAnnotation(String annotationName); //这个厉害了，依赖于AnnotatedElementUtils#hasMetaAnnotationTypes boolean hasMetaAnnotation(String metaAnnotationName); // 类里面只有有一个方法标注有指定注解，就返回true //getDeclaredMethods获得所有方法， AnnotatedElementUtils.isAnnotated是否标注有指定注解 boolean hasAnnotatedMethods(String annotationName); // 注意返回的是MethodMetadata 原理基本同上 // .getDeclaredMethods和AnnotatedElementUtils.isAnnotated 最后吧Method转为MethodMetadata Set&lt;MethodMetadata&gt; getAnnotatedMethods(String annotationName);&#125; 使用ImportBeanDefinitionRegistrar手动注册 需要自定义一个类实现ImportBeanDefinitionRegistrar，如下： 1234567891011121314151617181920/** * 自定义的FirstBeanDefinitionRegistrar，需要实现ImportBeanDefinitionRegistrar */public class FirstBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * 自己手动注册Bean到ioc容器中 * @param importingClassMetadata 获取@Import标注的类上的注解信息，比如获取被指定注解标注的方法信息 * @param registry 注册中心，可以获取指定bean的信息和手动注册bean */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //如果容器中没有Person这个Bean，就创建一个 if (!registry.containsBeanDefinition(Person.class.getName()))&#123; GenericBeanDefinition beanDefinition=new GenericBeanDefinition(); beanDefinition.setBeanClass(Person.class); //手动注册 registry.registerBeanDefinition("person",beanDefinition); &#125; &#125;&#125; 在配置类上使用@Import注解引入即可，如下： 123@Configuration@Import(value = &#123;FirstBeanDefinitionRegistrar.class&#125;)public class MyConfiguration &#123;&#125; @Primary 在spring 中使用注解，常使用@Autowired， 默认是根据类型Type来自动注入的。但有些特殊情况，对同一个接口，可能会有几种不同的实现类，而默认只会采取其中一种的情况下 @Primary 的作用就出来了。 有两种使用方式，一种是结合@Bean，另外一种是结合@Service,@Component,@Controller.....12345678910111213@Bean@Primarypublic User user1()&#123; return new User(1,"user1");&#125;//第二种@Primary@Componentpublic class Person &#123; private String name; private Integer age;&#125; @Autowired 标注在方法和属性上，用来自动为成员变量赋值 默认先根据属性的类型从ioc容器中查找，如果ioc容器中存在多个类型相同的属性，将会根据变量名从ioc容器中查找。1234@Controllerpublic class UserController &#123; @Autowired private UserService userService; 属性 required：指定该属性是否是必须的，默认为true，表示一定要为属性赋值，如果ioc容器中没有对应的Bean，那个将会报错，如果为false，会先从ioc容器中查找对应的Bean，如果存在就进行赋值，不存在就不赋值，不会报错。 @Qualifier 和@Autowired结合使用，用来从容器中注入指定名字的Bean 使用场景：容器中存在多个类型相同的Bean,那么此时仅仅使用@Autowired就不太适用了，此时就要结合该注解，指定需要注入的name。（当然除了@Autowired还是可以根据成员变量的名称进行注入的）12345@Controllerpublic class UserController &#123; @Autowired @Qualifier(value = "userService") private UserService userService; @PropertySource 从配置文件中读取相关配置注入到指定的成员属性中123456789101112@Component@PropertySource(value = &#123;"classpath:user.properties"&#125;)public class User implements Serializable &#123; private String name; private Integer age; public User()&#123;&#125; public User(String name, Integer age) &#123; this.name = name; this.age = age; &#125; 属性 value：指定资源文件的位置 ignoreResourceNotFound：是否忽略资源文件不存在，默认为false，表示如果资源文件不存在，那么将会抛出异常，如果为true，资源文件不存在的话，程序正常运行 @Value() 有三个典型的使用场景： 获取配置文件中对应的值，为指定属性赋值 使用指定的值为属性赋值 通过表达式计算得到的值为属性赋值 获取配置文件中的值为属性赋值 使用${}的方式获取配置文件中设置的值12@Value("$&#123;name&#125;")private String name; 使用指定的值 其中的value属性可以是自己随便指定的值，如下：12@Value("陈加兵")private String name; 表达式赋值 表达式的计算需要使用#{}12@Value("#&#123;10+22&#125;")private Integer age; @Profile 未完待续。。。。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中的Aware解析]]></title>
      <url>%2F2019%2F06%2F12%2FSpring%E4%B8%AD%E7%9A%84Aware%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[简介 Spring框架中提供了许多实现了Aware接口的类，这些类主要是为了辅助Spring访问容器中的数据，比如BeanNameAware，这个类能够在Spring容器加载的过程中将Bean的名字（id）赋值给变量。 常用的Aware BeanNameAware：能够获取bean的名称，即是id BeanFactoryAware：获取BeanFactory实例 ApplicationContextAware：获取ApplicationContext MessageSourceAware：获取MessageSource ResourceLoaderAware：获取ResourceLoader EnvironmentAware：获取Environment ApplicationContextAware ApplicationContext可以获取容器中的bean，但是必须注入才能使用，当一些类不能注入的时候怎么才能获得bean呢？比如Utils中的类，通常不能直接通过注入直接使用ApplicationContext，此时就需要借助ApplicationContextAware这个接口了。 ApplicationContextAware的实现类如下 1234567891011121314151617/** * 自定义一个实现类，一定要注入到容器中 */@Componentpublic class ApplicationContextAwareImpl implements ApplicationContextAware &#123; /** * 容器启动的时候会调用这个方法，只需要将applicationContext设置即可 * @param applicationContext 容器启动会自动注入 * @throws BeansException */ @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; //将其设置到ApplicationContextUtil ApplicationContextUtil.setApplicationContext(applicationContext); &#125;&#125; ApplicationContextUtil如下： 123456789101112131415161718192021222324252627282930313233343536373839import org.springframework.context.ApplicationContext;/** * ApplicationContext的工具类 */public class ApplicationContextUtil &#123; /** * ApplicationContext对象，会ApplicationContextAwareImpl中的setApplicationContext方法中赋值 */ private static ApplicationContext applicationContext; public static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; public static void setApplicationContext(ApplicationContext applicationContext) &#123; ApplicationContextUtil.applicationContext = applicationContext; &#125; /** * 根据类型获取指定的bean * @param requiredType Class * @param &lt;T&gt; 泛型 * @return */ public static &lt;T&gt; T getBean(Class&lt;T&gt; requiredType )&#123; return applicationContext.getBean(requiredType); &#125; /** * 根据名称和类型获取Bean * @param name bean的id * @param requiredType class * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(String name,Class&lt;T&gt; requiredType)&#123; return applicationContext.getBean(name,requiredType); &#125;&#125; 配置了如上的工具类，那么就可以直接使用ApplicationContextUtil获取ApplicationContext对象了，而不需要注入了，如下： 1StringRedisTemplate redisTemplate=ApplicationContextUtil.getBean("stringRedisTemplate",StringRedisTemplate.class); 总结 spring底层的一些东西并不能通过自动注入直接从ioc容器中获取，但是spring提供了其他的一些方法获取相应的对象，比如一些Aware，要向成功获取指定的对象，必备的条件如下： 实现xxxAware接口 自定义的类注入到容器中 源码解析 Aware的装配使用的BeanPostProcessor原理，在初始化之前调用set方法设置对应的值，相应的实现都在org.springframework.context.support.ApplicationContextAwareProcessor#invokeAwareInterfaces，源码如下： 主要的逻辑就是判断相应bean的类型，调用相应的set方法1234567891011121314151617181920212223private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver( new EmbeddedValueResolver(this.applicationContext.getBeanFactory())); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125; &#125; 参考文章 https://blog.csdn.net/iechenyb/article/details/83788338]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8新特性]]></title>
      <url>%2F2019%2F06%2F12%2FJDK8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
      <content type="text"><![CDATA[JDk8新特性函数式编程集合的foreach List 这里的表示List中每一个元素，可以不指定类型，JDK会自动推测出类型，但是也是可以使用()加上类型 如果有一条语句可以直接在后面输出，如果有多行，那么可以在后面使用{}指定12Arrays.asList(1,2,4,1,76).forEach(e-&gt; System.out.println(e)); Arrays.asList(1,2,4,1,76).forEach((Integer e)-&gt; System.out.println(e)); Set 12Set&lt;Object&gt; set=new HashSet&lt;&gt;(Arrays.asList(1,2,4,1,76)); set.forEach(e-&gt; System.out.println(e)); Map 1234567Map&lt;Object,Object&gt; map=new HashMap&lt;&gt;(); map.put("2",2); map.put("4",5); //a,b两个元素分别是key和value map.forEach((a,b)-&gt;&#123; System.out.println(a+"---"+b); &#125;); lambda表达式轻松创建接口实例 条件：该接口只能有一个需要实现的方法（默认方法除外） ()-&gt;{}：无参数的实现 item-&gt;{}：单个参数的实现，jdk能够默认推断出参数的类型 (String item1,String item2)：指定参数的类型 FunctionalInterface：标记这个接口只能定义一个方法（除了默认的方法）123456789101112@FunctionalInterfacepublic interface UserService &#123; String display(String name);&#125;@Test public void test1()&#123; UserService userService=name -&gt; &#123; return name; &#125;; userService.display("che"); &#125; 接口的默认方法和静态方法 默认方法不需要实现，但是可以被覆盖12345678910111213141516public interface Demo1 &#123; /** * 接口的静态方法 */ static void display() &#123; System.out.println("cdc"); &#125; /** * 默认方法可以不实现，但是可以被覆盖 */ default void play() &#123; System.out.println("cdddd"); &#125;&#125; Stream Stream接口中包含许多对流操作的方法，这些方法分别为： filter()：对流的元素过滤 map()：将流的元素映射成另一个类型 distinct()：去除流中重复的元素 sorted()：对流的元素排序 forEach()：对流中的每个元素执行某个操作 peek()：与forEach()方法效果类似，不同的是，该方法会返回一个新的流，而forEach()无返回 limit()：截取流中前面几个元素 skip()：跳过流中前面几个元素 toArray()：将流转换为数组 reduce()：对流中的元素归约操作，将每个元素合起来形成一个新的值 collect()：对流的汇总操作，比如输出成List集合 anyMatch()：匹配流中的元素，类似的操作还有allMatch()和noneMatch()方法 findFirst()：查找第一个元素，类似的还有findAny()方法 max()：求最大值 min()：求最小值 count()：求总数 filter 过滤集合，实际是实现其中的test方法，返回的是一个Boolean类型的值，我们可以使用lambda表达式可以很轻松的实现集合的过滤1234567891011121314151617181920212223242526272829 @Test public void test2()&#123; User user1 = new User(); user1.setName("chen"); user1.setAge(22); User user3 = new User(); user3.setName("zheng"); user3.setAge(22); User user2 = new User(); user2.setName("zhou"); user2.setAge(30); List&lt;User&gt; users=new ArrayList&lt;&gt;(); users.add(user1); users.add(user2); users.add(user3);/* 下面的语句类似如下 * users.stream().filter(item-&gt;item.getAge()&gt;25).collect(Collectors.toList()); */ List&lt;User&gt; collect = users.stream().filter(user -&gt; &#123; if (user.getAge() &gt; 25) &#123; return true; &#125; else &#123; return false; &#125; &#125;).collect(Collectors.toList()); &#125; sorted 有两个实现的方法，如下： 12Stream&lt;T&gt; sorted(Comparator&lt;? super T&gt; comparator);Stream&lt;T&gt; sorted(); 例子如下： 1234567Stream.of(1, 8, 5, 2, 1, 0, 9, 2, 0, 4, 8) .filter(n -&gt; n &gt; 2) // 对元素过滤，保留大于2的元素 .distinct() // 去重，类似于SQL语句中的DISTINCT .skip(1) // 跳过前面1个元素 .limit(2) // 返回开头2个元素，类似于SQL语句中的SELECT TOP .sorted() // 对结果排序 .forEach(System.out::println); 1234//按照age排序，实际上就是实现Comparator的接口方法compareTo users.sort((item1,item2)-&gt;&#123; return item1.getAge()-item2.getAge(); &#125;); 查找和匹配 Stream中提供的查找方法有anyMatch()、allMatch()、noneMatch()、findFirst()、findAny()，这些方法被用来查找或匹配某些元素是否符合给定的条件：1234567891011121314151617// 检查流中的任意元素是否包含字符串"Java"boolean hasMatch = Stream.of("Java", "C#", "PHP", "C++", "Python") .anyMatch(s -&gt; s.equals("Java"));// 检查流中的所有元素是否都包含字符串"#"boolean hasAllMatch = Stream.of("Java", "C#", "PHP", "C++", "Python") .allMatch(s -&gt; s.contains("#"));// 检查流中的任意元素是否没有以"C"开头的字符串boolean hasNoneMatch = Stream.of("Java", "C#", "PHP", "C++", "Python") .noneMatch(s -&gt; s.startsWith("C"));// 查找元素Optional&lt;String&gt; element = Stream.of("Java", "C#", "PHP", "C++", "Python") .filter(s -&gt; s.contains("C")) // .findFirst() // 查找第一个元素 .findAny(); // 查找任意元素 归约map map 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数: 123List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);// 获取对应的平方数List&lt;Integer&gt; squaresList = numbers.stream().map( i -&gt; i*i).distinct().collect(Collectors.toList()); map使用lambda表达式返回的类型就是最后的类型,下面我们将用户的年龄设置成两倍 123456789101112131415161718192021222324@Test public void test2()&#123; User user1 = new User(); user1.setName("chen"); user1.setAge(22); User user3 = new User(); user3.setName("zheng"); user3.setAge(22); User user2 = new User(); user2.setName("zhou"); user2.setAge(40); List&lt;User&gt; users=new ArrayList&lt;&gt;(); users.add(user1); users.add(user2); users.add(user3); List&lt;User&gt; list = users.stream().map(item -&gt; &#123; item.setAge(item.getAge() * 2); return item; &#125;).collect(Collectors.toList()); &#125; reduce 将两个元素进行归约操作，比如两个元素相加，但是这个操作的返回值一定要和操作之前的类型相同12345//归约操作，返回的是一个Optional类型的 Optional&lt;Integer&gt; optional = users.stream().map(item -&gt; item.getAge()).reduce((item1, item2) -&gt; item1 + item2); if (optional.isPresent())&#123; System.out.println(optional.get()); &#125; 分组 和关系数据库一样，流也提供了类似于数据库中GROUP BY分组的特性，由Collectors.groupingBy()方法提供： 12345//根据age进行分组，返回的是Map集合，key就是分组后的age，value是user对象 Map&lt;Integer, List&lt;User&gt;&gt; listMap = users.parallelStream().collect(Collectors.groupingBy(item -&gt; item.getAge())); listMap.forEach((key,value)-&gt;&#123; System.out.println(key+"---&gt;"+value); &#125;); 但实际情况可能比这复杂，比如将价格在0-50之间的书籍分成一组，50-100之间的分成一组，超过100的分成一组，这时候，我们可以直接使用Lambda表达式来表示这个分组逻辑： 123456789101112//根据age进行分组，返回的是Map集合，key就是分组后的age，value是user对象 Map&lt;String, List&lt;User&gt;&gt; listMap = users.parallelStream().collect(Collectors.groupingBy(item -&gt; &#123; if (item.getAge() &gt; 20) &#123; return "A"; &#125; else &#123; return "B"; &#125; &#125;)); listMap.forEach((key,value)-&gt;&#123; System.out.println(key+"---&gt;"+value); &#125;); Optional 文档 https://zhuanlan.zhihu.com/p/40966718 创建方法： public static &lt;T&gt; Optional&lt;T&gt; of(T value)：value的值不能为null public static &lt;T&gt; Optional&lt;T&gt; ofNullable(T value)：value允许为空 常用方法 public Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate)：过滤其中的元素，如果返回true，那么保留，返回false去除该元素 public T orElse(T other)：如果该元素的值为null，那么指定该值为other 1234User user = new User(22, "chenjiabing");User user2 = Optional.ofNullable(user).filter(item-&gt;&#123; return item.getAge()&gt;30;&#125;).orElse(null); public T orElseGet(Supplier&lt;? extends T&gt; other)：如果该值为空，那么就调用other的get方法，其中返回一个同种类型的对象 123456Optional.ofNullable(user).filter(item-&gt;&#123; return item.getAge()&gt;30;&#125;).orElseGet(()-&gt;&#123; System.out.println("该值为空"); return new User(44, "zhengjiahe");&#125;); public boolean isPresent()：判断当前的元素是否为null，如果为null返回false，否则返回true public void ifPresent(Consumer&lt;? super T&gt; consumer)：如果不为空调用其中的方法 public &lt;U&gt; Optional&lt;U&gt; map(Function&lt;? super T,? extends U&gt; mapper)：如果为空直接返回一个空的Optional，不会调用map中的apply方法，如果不为空，那么调用apply方法12345Optional&lt;Integer&gt; map = Optional.ofNullable(null).map(item-&gt;&#123; System.out.println(item); //返回值也决定着你的类型 return Integer.MAX_VALUE;&#125;); Collectors 针对集合操作的封装类，结合Stream编程客可以很简单的实现 toMap List直接转换为Map，使用JDK1.8的Stream编程 Collector&lt;T, ?, Map&lt;K,U&gt;&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper,Function&lt;? super T, ? extends U&gt; valueMapper)：简单的将集合转换成Map，出现key重复的将直接抛出异常 keyMapper：指定的 valueMapper：指定的value 12 Map&lt;Integer, String&gt; map = users.stream().collect(Collectors.toMap(User::getAge, User::getName));` public static &lt;T, K, U&gt; Collector&lt;T, ?, Map&lt;K,U&gt;&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper,Function&lt;? super T, ? extends U&gt; valueMapper,BinaryOperator&lt;U&gt; mergeFunction)：用于解决key冲突的情况 mergeFunction：用于当出现key冲突的情况下解决方法，其中只需要实现apply方法即可，两个参数分别是重复的map的value值，返回值是指定的值 1Map&lt;Integer, String&gt; map = users.stream().collect(Collectors.toMap(User::getAge, User::getName,(v1,v2)-&gt;v1+","+v2)); toList 将结果转换成一个List集合1List&lt;Integer&gt; list = Stream.of(1, 2, 3, 4).collect(Collectors.toList()); toSet 将结果转换成一个Set集合1Set&lt;Integer&gt; set = Stream.of(1, 2, 3, 4).collect(Collectors.toSet()); groupingBy 将所得的结果根据指定的内容进行分组，所得结果是一个Map类型的数据 public static &lt;T, K&gt; Collector&lt;T, ?, Map&lt;K, List&lt;T&gt;&gt;&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier) 指定的key，value的默认类型为List12Map&lt;Integer, List&lt;Integer&gt;&gt; map = Stream.of(1, 1, 3, 10, 2, 3, 4).collect( Collectors.groupingBy(Integer::intValue)); `public static Collector]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springBoot制作docker镜像]]></title>
      <url>%2F2019%2F01%2F19%2FspringBoot%E5%88%B6%E4%BD%9Cdocker%E9%95%9C%E5%83%8F%2F</url>
      <content type="text"><![CDATA[SpringBoot制作docker镜像开启2375端口修改docker配置文件 vim /usr/lib/systemd/system/docker.service 在ExecStart=/usr/bin/dockerd配置加上如下内容 1-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock 添加完之后的完整内容如下： 12345678910111213141516171819202122232425Type=notifyNotifyAccess=mainEnvironmentFile=-/run/containers/registries.confEnvironmentFile=-/etc/sysconfig/dockerEnvironmentFile=-/etc/sysconfig/docker-storageEnvironmentFile=-/etc/sysconfig/docker-networkEnvironment=GOTRACEBACK=crashEnvironment=DOCKER_HTTP_HOST_COMPAT=1Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbinExecStart=/usr/bin/dockerd-current \ -H tcp://0.0.0.0:2375 \ -H unix:///var/run/docker.sock \ --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current \ --default-runtime=docker-runc \ --exec-opt native.cgroupdriver=systemd \ --userland-proxy-path=/usr/libexec/docker/docker-proxy-current \ --init-path=/usr/libexec/docker/docker-init-current \ --seccomp-profile=/etc/docker/seccomp.json \ $OPTIONS \ $DOCKER_STORAGE_OPTIONS \ $DOCKER_NETWORK_OPTIONS \ $ADD_REGISTRY \ $BLOCK_REGISTRY \ $INSECURE_REGISTRY \ $REGISTRIES 重启docker 配置环境变量 添加环境变量DOCKER_HOST的值为tcp://ip:2375 Dockerfile 将编写的Dockerfile文件放在/src/main/docker下，内容如下： 123456789101112131415FROM java:8MAINTAINER https://chenjiabing666.github.io# 指定虚拟卷，/tmp是tomcat运行时需要的，/usr/local/images是上传文件需要的，/usr/local/weblogs/demo是记录日志需要的VOLUME ["/tmp","/usr/local/images","/usr/local/weblogs/demo"]# 添加jarADD demo-server.jar demo.jar# 暴露8080端口EXPOSE 8080# 运行jarCMD ["java","-jar","demo.jar"] 配置maven插件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;build&gt; &lt;finalName&gt;demo-server&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- springBoot的maven打包插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;!-- 将docker:build这个动作绑定在package这个动作上，只要maven install 即可上传到远程服务器 --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 指定镜像的名称+版本，必须是满足[a-z,0-9]这个正则才行 --&gt; &lt;imageName&gt;$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;!-- 覆盖相同标签镜像 --&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;!-- 指定Dockerfile的文件位置 --&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt; &lt;!-- 指定Dockerfile的文件位置 --&gt; &lt;dockerHost&gt;http://39.105.123.197:2375&lt;/dockerHost&gt; &lt;!-- 指定jar包所在的位置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 运行 我们制作镜像运行的时候需要挂载自己的虚拟卷，否则诸如创建文件夹和上传文件之类的都是在容器内创建的，不会在本机创建，因此我们需要将其挂载在自己的宿主机上，运行命令如下： 使用-v挂载即可 1docker run --name demo -p 8080:8080 -v /usr/local:/usr/local -v /tmp:/tmp -d 8877edd71d5a 源码 https://gitee.com/chenjiabing666/docker-server.git 参考文章 https://blog.csdn.net/qq_35615618/article/details/81201646]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker搭建私有仓库]]></title>
      <url>%2F2018%2F12%2F30%2Fdocker%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%2F</url>
      <content type="text"><![CDATA[Docker私有仓库步骤 docker pull registry docker run --name registry -p 5000:5000 -d registry 启动完成后访问http:// 192.168.174.130:5000/v2/_catalog即可看到如下的内容说明启动成功： 123&#123; "repositories": []&#125; 添加信任（无论是下载还是上传都需要添加，这里的ip和端口指定的是私有仓库的宿主机的ip）： vim /etc/docker/daemon.json，添加如下的内容： 1"insecure-registries":["192.168.174.130:5000"] 重启docker ,systemctl restart docker 上传镜像到私有仓库 docker tag jdk8 192.168.174.130:5000/jdk8： 标记该镜像 指定仓库所在的ip和端口号 第一个jdk8是当前的镜像名称（或者填Id），后一个是上传到仓库中的名字，可以任意起 docker images：此时查看镜像，发现多了一个192.168.174.130:5000/jdk8的镜像 docker push 192.168.174.130:5000/jdk8 ：将标记的镜像上传到私有仓库中 此时再次访问http:// 192.168.174.130:5000/v2/_catalog，将会看到如下内容 12345&#123; "repositories": [ "jdk8" ]&#125; 下载镜像 添加信任 vim /etc/docker/daemon.json`，添加如下的内容： 1"insecure-registries":["192.168.174.130:5000"] 重启docker ,systemctl restart docker 下载，需要指定ip和端口：docker pull 192.168.174.130:5000/jdk8 Docker Maven插件自动上传镜像到私有仓库步骤仓库所在服务器的配置 添加信任，同上 修改 /etc/sysconfig/docker文件：vim /etc/sysconfig/docker 在最下面添加一行DOCKER_OPTS=&#39;-H unix:///var/run/docker.sock -H 0.0.0.0:2375&#39; vim /lib/systemd/system/docker.service添加如下内容 执行下面的命令刷新配置并且重启docker 12systemctl daemon-reloadsystemctl restart docker 开启防火墙的端口：firewall-cmd --zone=public --add-port=2375/tcp --permanent 重新载入配置firewall-cmd --reload 项目中的配置 在pom.xml文件中添加如下内容： 123456789101112131415161718192021222324252627282930313233343536&lt;build&gt; &lt;!-- 指定的最终打成jar包的名字 --&gt; &lt;finalName&gt;demo&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- SpringBoot的maven插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;!-- 注意imageName需要指定的`IP:端口/image_name`的格式--&gt; &lt;imageName&gt;192.168.174.130:5000/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;!-- 指定基础镜像，不需要运行，相当于 from hub.c.163.com/library/java:8-alpine --&gt; &lt;baseImage&gt;hub.c.163.com/library/java:8-alpine&lt;/baseImage&gt; &lt;!--覆盖相同标签镜像--&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;!-- 运行jar包 --&gt; &lt;entryPoint&gt;["java", "-jar", "/$&#123;project.build.finalName&#125;.jar"]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- 指定私有仓库所在服务器的2375端口，之前配置过可以远程访问的那个 --&gt; &lt;dockerHost&gt;http://192.168.174.130:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 在命令台运行如下的命令，即可完成生成镜像并且上传到私有仓库 mvn clean package docker:build -DpushImage 上述命令的解析如下： mvn clean package：maven打jar包 docker:build：docker构建镜像的命令 -DpushImage： 将生成的镜像上传到私有仓库中 执行并且运行成功之后访问http://192.168.174.130:5000/v2/_catalog，将会出现如下的内容 12345&#123; "repositories": [ "demo" ]&#125; 访问http://192.168.174.130:5000/v2/demo/tags/list，可以看到demo这个镜像的所有版本 上面的运行完成之后，查看项目中自动生成Dockerfile，如下： 123FROM hub.c.163.com/library/java:8-alpineADD /demo.jar //ENTRYPOINT ["java", "-jar", "/demo.jar"] 拉取上传的镜像并且运行 在拉取之前需要添加信任 使用 docker pull 192.168.174.130:5000/demo:0.0.1-SNAPSHOT下载仓库中的镜像 运行镜像：docker run --name demo -p 7001:7001 -d f7f36f3f3f06 其中生成的镜像端口为项目自己本身配置的端口，只需要映射出去即可 此时我们可以访问http://192.168.174.128:7001/，就能看到eureka注册中心的页面 源码 https://gitee.com/chenjiabing666/docker-maven.git 参考文章 https://blog.csdn.net/qq_39623859/article/details/80072545]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dockerfile]]></title>
      <url>%2F2018%2F12%2F30%2FDockerfile%2F</url>
      <content type="text"><![CDATA[DockerFile 镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 常用命令 命令 作用 FROM image:tag 指定基础镜像，有点继承的意思 MAINTAINER user_name 声明镜像的创建者 ENV key value 设置环境变量，可以设置多条,比如 ENV VERSION=1.0 RUN command 核心命令，多个命令用&amp;&amp;连接即可 ADD source_dir/file dest_dir/file 将宿主机的文件负复制到容器内，如果是一个压缩文件，将会自动解压缩 COPY source_dir/file dest_dir/file 和ADD命令类似，但是不能自动解压缩 WORKDIR path_dir 指定当前的工作目录，由于分层的概念，每一个命令的工作目录都不同，因此需要使用该命令显示指定工作目录 CMD args 在构建容器的时候使用，会docker run 后的args覆盖 ENTRYPOINT args 和CMD相似，但是不会被docker run后的args覆盖 VOLUME 将本地文件夹挂载到容器中 配置镜像加速 我们使用阿里云的镜像加速 vim /etc/docker/daemon.json,设置如下内容即可： 123&#123; "registry-mirrors":["https://rxx4pnmv.mirror.aliyuncs.com"]&#125; 构建简单的JDK镜像 新建一个Dockerfile 1234567891011121314# 初始镜像,默认拉去lastest的FROM centos# 指定镜像的构建者MAINTAINER chenjiabing666# 切换工作目到usr，这个是容器中的目录WORKDIR /usr# 新建 /usr/local/java目录RUN mkdir /usr/local/java# 添加本地的jdk到容器中并且解压ADD jdk-8u172-linux-x64.tar.gz /usr/local/java/# 设置环境变量ENV JAVA_HOME /usr/local/java/jdk1.8.0_181ENV CLASSPATH $JAVA_HOME/lib;$JAVA_HOME/jre/libENV PATH $PATH:$JAVA_HOME/bin docker build -t jdk8 .：构建镜像 docker run --name jdk -di jdk8：运行镜像 参考文章 https://blog.csdn.net/wo18237095579/article/details/80540571]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot实现BCrypt密码加密]]></title>
      <url>%2F2018%2F12%2F25%2FSpringBoot%E5%AE%9E%E7%8E%B0BCrypt%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%2F</url>
      <content type="text"><![CDATA[SpringBoot 实现 BCrypt密码加密前言 出于安全的考虑，一些敏感的信息是绝对不能以明文的方式存储在数据库中的，比如密码通常是通过哈希算法进行加密的。有很多标准的算法比如SHA和MD5，结合salt（盐）是一种不错的选择，但是如果知道其加密的规则还是相对不安全。 Spring security提供了BCryptPasswordEncoder类，使用Bcrypt强哈希方法来加密密码 Bcrypt强哈希算法每次加密的结果都是不一样的。 API public String encode(CharSequence rawPassword)： 对给定的内容进行加密，返回加密后的字符串 public boolean matches(CharSequence rawPassword, String encodedPassword)： 比较给定的字符串和加密后的字符串是否是同一个 rawPassword：未加密的字符串 encodedPassword： 加密后的字符串 使用 引入spring security的依赖 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 添加security的配置类，如下: 在其中注入BCryptPasswordEncoder 12345678910111213141516171819202122232425/** * Spring security的配置类 */@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .antMatchers("/**") .permitAll() .anyRequest() .authenticated() .and().csrf().disable(); super.configure(http); &#125; /* * 注入BCryptPasswordEncoder */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() &#123; return new BCryptPasswordEncoder(); &#125; &#125; 主配置类添加@EnableWebSecurity 123@SpringBootApplication@EnableWebSecurity //开启securitypublic class AuthServerApplication &#123; 在业务层实现登录和注册的功能 ，对密码进行加密和校验 12345678910111213141516171819202122232425262728293031323334353637@Service@Transactionalpublic class UserServiceImpl implements UserService &#123; @Resource private UserRepository userRepository; @Resource private BCryptPasswordEncoder bCryptPasswordEncoder; //注入bcryct加密 @Override public User add(User user) &#123; user.setPassword(bCryptPasswordEncoder.encode(user.getPassword())); //对密码进行加密 User user2 = userRepository.save(user); return user2; &#125; @Override public ResultInfo login(User user) &#123; ResultInfo resultInfo=new ResultInfo(); User user2 = userRepository.findByName(user.getName()); if (user2==null) &#123; resultInfo.setCode("-1"); resultInfo.setMessage("用户名不存在"); return resultInfo; &#125; //判断密码是否正确 if (!bCryptPasswordEncoder.matches(user.getPassword(),user2.getPassword())) &#123; resultInfo.setCode("-1"); resultInfo.setMessage("密码不正确"); return resultInfo; &#125; resultInfo.setMessage("登录成功"); return resultInfo; &#125; &#125; 源码 https://gitee.com/chenjiabing666/auth-server.git]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[zuul服务网关]]></title>
      <url>%2F2018%2F12%2F25%2Fzuul%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3%2F</url>
      <content type="text"><![CDATA[Zuul简介 Zuul包含了对请求的路由和过滤两个主要的功能，其中路由功能负责将外部的请求转发到具体的微服务实例上，是实现外部访问统一入口的基础上，而过滤功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。 Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获取其他微服务的信息，也即以后访问微服务都是通过Zuul跳转后获得 代理+路由+过滤三大功能 使用 需要和Eureka客户端结合使用，依赖如下： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--zuul的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置，将其注册到eureka中，如下： 123456789101112server: port: 9001eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册 instance: instance-id: zuul.com prefer-ip-address: truespring: application: name: zuul #应用的名称，在同一个eureka中必须不重复 在主启动类上添加@EnableZuulProxy这个注解，如下: 1234@SpringBootApplication@EnableEurekaClient //开启eurkea客户端@EnableZuulProxy //开启zuulpublic class DeptGetWayZuul9001Application &#123; 启动即可，在eureka中看到注册进入即可 之后只需要通过zuul访问其他的微服务提供者即可，比如服务提供者的实例名称为dept-provider，那么通过zuul访问的路径为http://localhost:9001/dept-provider/dept/1 路由映射规则代理名称 之前的配置访问的还是需要带上微服务的实例名称，但是我们不想微服务的实例名称暴露，那么此时就需要使用代理名称替代，配置如下: 使用ignored-services忽略真实的服务名称访问，可以同时指定多个，其中服务名称必须和服务配置文件中一样。 在routes下指定多个路由映射规则 123456789101112zuul: # 忽略真实的服务名称实例访问，是一个Set集合，可以指定多个，取消全部使用 "*"即可 ignored-services: - order-provider #routes下面指定代理规则，可以同时指定多个 routes: #指定第一个规则，这里的名称任意 api-order: #指定的实例名称 serviceId: order-provider #指定可以访问的路由 path: /api-order/** 按照上面的配置完成之后就可以直接使用映射的路由访问即可，如：http://zuul.com:9001/api-order/order/1 设置统一前缀 我们可以在所有的访问uri前面加上统一的前缀，配置如下: 使用zuul.prefix加上统一的前缀即可 1234567891011121314zuul: #加上统一的前缀，那么访问的时候一定要加上这个前缀才可以访问到 prefix: /chenjiabing # 忽略真实的服务名称实例访问，是一个Set集合，可以指定多个，取消全部使用 "*"即可 ignored-services: - order-provider #routes下面指定代理规则，可以同时指定多个 routes: #指定第一个规则，这里的名称任意 api-dept: #指定的实例名称 serviceId: order-provider #指定可以访问的路由 path: /api-order/** 通过上面的配置，此时的访问路径变成http://zuul.com:9001/chenjiabing/api-order/order/1 某个uri取消路由 使用zuul.ignored-services是忽略一个或者多个微服务的全部接口，但是如果我们可以更细化 如果我们需要隐藏一些敏感的接口不给访问，我们可以在yml文件中配置，如下: 1234zuul: ignored-patterns: - /api-order/order/list # 取消指定的一个 - /api-order/order/** # 使用通配符去掉order下的全部接口 传递敏感头信息 默认zuul是不能传递头信息的，比如cookie，默认的设置了三个字段，如下: 12private Set&lt;String&gt; sensitiveHeaders = new LinkedHashSet&lt;&gt;( Arrays.asList("Cookie", "Set-Cookie", "Authorization")); 如果我们想让它不过滤，只需要将其设置为空，或者不配置其他的，如下： 将sensitive-headers这个值设置为空即可 这个配置只是针对order-provider这个微服务起作用 123456789zuul: routes: #指定第一个规则，这里的名称任意 api-order: #指定的实例名称 serviceId: order-provider #指定可以访问的路由 path: /api-order/** sensitive-headers: # 设置为空即可，那么就可以传递敏感头信息了 上面的配置是针对单个服务的设置，我们也可以配置针对所有的服务，如下： 12zuul: sensitive-headers: # 设置所有的服务都取消敏感头信息 过滤器生命周期 Filter 的生命周期有 4 个，分别是 “PRE”、“ROUTING”、“POST” 和“ERROR”，整个生命周期可以用下图来表示 生命周期解释如下： PRE：这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、鉴权、限流、参数校验、请求转发，在集群中选择请求的微服务、记录调试信息等。 ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用 Apache HttpClient 或 Netfilx Ribbon 请求微服务。 POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的 HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 ERROR：在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul 还允许我们创建自定义的过滤器类型。例如，我们可以定制一种 STATIC 类型的过滤器，直接在 Zuul 中生成响应，而不将请求转发到后端的微服务。 前置过滤器的使用 利用前置过滤器实现检测token是否正确，如果不正确，那么直接返回权限不足401状态码，不路由微服务 继承ZuulFilter 注入到ioc容器中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 自定义过滤器，用于实现鉴权，前置过滤器 * 继承ZuulFilter */@Component //一定要注入到ioc容器中public class TokenFilter extends ZuulFilter &#123; /** * 判断过滤器是否被执行，返回true表示被会被执 * 在这里我们可以限制过滤器的执行范围，可以根据指定的条件判断这个请求是否被过滤 */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 过滤器的具体实现逻辑 * @return * @throws ZuulException */ @Override public Object run() throws ZuulException &#123; RequestContext requestContext = RequestContext.getCurrentContext(); //获取请求上下文 HttpServletRequest request = requestContext.getRequest(); //获取HttpServletRequest String token = request.getParameter("token"); //获取传递过来的请求参数 //如果token是空的，返回权限不足，一般返回的状态码是401 if (StringUtils.isEmpty(token)) &#123; requestContext.setSendZuulResponse(false); //设置false，此时的zuul不对此路由 requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); //设置401// requestContext.setResponseBody("no power"); //设置响应的消息 &#125; return null; &#125; /** * 指定过滤器的类型，前置，后置................. * 1、其中FilterConstants这个常量类中定义了过滤器常用的变量 * public static final String ERROR_TYPE = "error"; public static final String POST_TYPE = "post"; public static final String PRE_TYPE = "pre"; public static final String ROUTE_TYPE = "route"; * @return */ @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; //前置过滤器 pre &#125; /** * 过滤器执行的顺序，数字越小优先级越高 * @return */ @Override public int filterOrder() &#123; //一般前置过滤器放在org.springframework.cloud.netflix.zuul.filters.pre.PreDecorationFilter这个过滤器之前即可，只需要将其对应的顺序-1 return FilterConstants.PRE_DECORATION_FILTER_ORDER-1; &#125;&#125; 后置过滤器的使用 利用后置过滤器在响应头中添加内容，和前置过滤器的使用一样，只是使用的过滤器的类型不用，如下： 123456789101112131415161718192021222324252627282930/** * 后置过滤器，在响应头中添加一些内容 */@Component //注入public class AddResponseHeaderFilter extends ZuulFilter &#123; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; RequestContext requestContext = RequestContext.getCurrentContext(); //获取请求上下文 HttpServletResponse response = requestContext.getResponse(); //获取HttpServletResponse response.addHeader("X-Foo", "add header"); //添加头信息 return null; &#125; @Override public String filterType() &#123; return FilterConstants.POST_TYPE; //后置过滤器 &#125; @Override public int filterOrder() &#123; //在org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter#filterOrder()这个过滤一起之前执行即可 return FilterConstants.SEND_RESPONSE_FILTER_ORDER-1; &#125;&#125; 禁用某种过滤器 如果我们想要禁用某种过滤器（自定义或者zuul自身的），我们可以在配置中设置，格式：zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable=true，比如禁用我们TokenFilter，如下： 1234zuul: TokenFilter: # 类的名字 pre: # 类型 disable: true 限流令牌桶算法 https://blog.csdn.net/tianyaleixiaowu/article/details/74942405 https://baike.baidu.com/item/%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95/6597000?fr=aladdin 系统按照恒定的速率往指定大小的桶里添加令牌，每来一个请求就消耗一个令牌，如果桶内没有令牌表示此事的请求流量已经超过设置的大小了，应该做出相应的响应或者直接抛出异常 实现 使用前置过滤器，在请求被转发之前调用，限流的过滤器应该是所有过滤器中优先级最大的 使用google开源的组件Guava 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import com.google.common.util.concurrent.RateLimiter;import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.context.RequestContext;import com.netflix.zuul.exception.ZuulException;/** * 限流 ，前置过滤器 * 限流的过滤器的优先级应该是最高，数字最小 */@Componentpublic class RateFilter extends ZuulFilter &#123; private static final RateLimiter RATE_LIMITER=RateLimiter.create(100); //程每秒钟往桶里放置100个令牌 @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; /** * tryAcquire()：如果获取不到一个令牌,表示流量超时了，没有等待时间 * tryAcquire(int permits, long timeout, TimeUnit unit)：获取permits个令牌，如果在指定的时间timeout内，还是没有获取到指定的permits个令牌，那么就返回false */ if (!RATE_LIMITER.tryAcquire()) &#123; RequestContext requestContext = RequestContext.getCurrentContext(); requestContext.setSendZuulResponse(false); //不路由 requestContext.setResponseStatusCode(HttpStatus.FORBIDDEN.value()); //403拒绝访问 &#125; //也可以直接抛出异常// if (!RATE_LIMITER.tryAcquire()) &#123;// throw new RuntimeException(); //抛出异常// &#125; return null; &#125; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; //前置 &#125; @Override public int filterOrder() &#123; //org.springframework.cloud.netflix.zuul.filters.pre.ServletDetectionFilter#filterOrder()这个过滤器的优先级是最高的，只需要-1即可 return FilterConstants.SERVLET_DETECTION_FILTER_ORDER-1; &#125;&#125; 多维度限流 https://segmentfault.com/a/1190000012252677 鉴权 https://www.jianshu.com/p/f89f5557990f 一些api只有具有某些权限的时候才可以被调用，比如用户的一些相关信息，只有在用户登录之后才可以调用，否则将会提示没有权限 实现 我们在用户登录成功之后会在返回头中添加cookie的值为openId=random(随机数)，并且将其保存在redis中（key=openId_userId，value=random） 123456789101112131415161718/** * 登录的方法，登录成功响应头返回添加cookie * @param response * @return */@GetMapping("/user/login")public String login(HttpServletResponse response) &#123; //登录的逻辑。。。。。 //设置cookie的值 Cookie cookie=new Cookie("openId", UUID.randomUUID().toString()); cookie.setMaxAge(60*60); response.addCookie(cookie); //添加到响应头中 //添加到redis中，key=openId_userId,value=uuid的值 return "登录成功";&#125; 我们事先将指定权限的接口uri存放在数据库中，在zuul中定义一个鉴权的过滤器，如果请求过来了，判断这个uri是否需要某种权限才能调用，如果不需要直接路由即可，如果需要那么判断cookie中是否有openId，如果没有表示没有登录，权限不够，如果有，需要判断和redis中的值是否相同，如果相同，表示有权限，直接路由到服务即可 这里将部分逻辑写在shouldFilter()方法中，限制范围（判断请求的uri是否需要鉴权），run()方法中只需要判断是否具有权限即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 自定义过滤器，用于实现鉴权，前置过滤器 * 继承ZuulFilter */@Component //一定要注入到ioc容器中public class TokenFilter extends ZuulFilter &#123; @Resource private UriService uriservice; //注入 @Resource private RedisTemplate redisTemplate; //redis /** * 判断过滤器是否被执行，返回true表示被会被执行（经过run方法） * 只需要判断请求的uri是存在数据库中即可 */ @Override public boolean shouldFilter() &#123; RequestContext context=RequestContext.getCurrentContext(); //获取上下文 HttpServletRequest request = context.getRequest(); //获取request String uri=request.getRequestURI(); //获取请求的uri /** * 伪代码如下： * 1、List&lt;URL&gt; uriList=uriservice.getUrlList(); //获取需要权限访问的uri列表 * 2、判断请求的uri是否在uriList中 * 1、如果不存在，return false，表示不用执行过滤的逻辑（run方法）直接路由到指定的服务即可 * 2、如果不存在返回true，表示执行过滤的逻辑（run方法） */ return true; &#125; /** * 过滤器的具体实现逻辑，经过shouldFilter方法之后，能够执行到这里的表示这个请求的uri需要验证权限 * @return * @throws ZuulException */ @Override public Object run() throws ZuulException &#123; RequestContext requestContext = RequestContext.getCurrentContext(); //获取请求上下文 HttpServletRequest request = requestContext.getRequest(); //获取HttpServletRequest Cookie[] cookies = request.getCookies(); //获取cookie /** * 伪代码如下： * 1、判断cookie中是否存在openId * 1、如果不存在，返回权限不足的提示信息 * 2、如果存在，需要判断redis中存储的openId的值是否和携带过来的cookie值相同 * 1、如果不相同，返回权限不足的提示信息 * 2、如果相同，表示这个请求具有相应的权限 */ return null; &#125; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; //前置过滤器 pre &#125; @Override public int filterOrder() &#123; //一般前置过滤器放在org.springframework.cloud.netflix.zuul.filters.pre.PreDecorationFilter这个过滤器之前即可，只需要将其对应的顺序-1 return FilterConstants.PRE_DECORATION_FILTER_ORDER-1; &#125;&#125; 跨域12345678910111213141516171819202122232425import java.util.Arrays;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;/** * 跨域的配置类 */@Configuration //配置类public class CorsConfig &#123; @Bean public CorsFilter corsFilter() &#123; final UrlBasedCorsConfigurationSource source=new UrlBasedCorsConfigurationSource(); final CorsConfiguration config=new CorsConfiguration(); config.setAllowCredentials(true); //支持cookie跨域 config.setAllowedOrigins(Arrays.asList("*")); //配置允许跨域访问的域名，这里*表示全部 config.setAllowedHeaders(Arrays.asList("*")); //设置允许的头 config.setAllowedMethods(Arrays.asList("*")); //设置允许跨域的方法，GET,POST....,这里表示允许全部 config.setMaxAge(300l); //缓存时间，在指定的时间内，对于相同的请求就不需要再次检查了 source.registerCorsConfiguration("/**", config); return new CorsFilter(source); &#125;&#125; 超时时间设置 我们在使用zuul访问服务的时候，一旦服务超过很短的时间没有响应，那么zuul就会自动熔断，默认的时间是2秒，但是可以通过配置修改，如下： 由于zuul使用ribbon实现负载均衡，因此这里还需要配置ribbon的超时时间，否则配置将不会生效 12345678zuul: host: # 配置zuul的超时时间 connect-timeout-millis: 60000 # 默认2秒， socket-timeout-millis: 60000 ribbon: # zuul使用服务发现的时候，要想让上面的配置生效，必须配置ribbon的超时时间 ReadTimeout: 60000 # 请求处理时间。 ConnectTimeout: 60000 # 请求连接时间。 服务熔断 当请求的服务响应时间超时或者服务不可用的时候zuul会直接响应异常，我们可以设置熔断，只需要在zuul的服务中配置即可，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package cn.tedu.zuul.hystrix;import java.io.ByteArrayInputStream;import java.io.IOException;import java.io.InputStream;import org.springframework.cloud.netflix.zuul.filters.route.FallbackProvider;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.client.ClientHttpResponse;import org.springframework.stereotype.Component;/** * 设置zuul的熔断 * 实现FallbackProvider接口 * 出现熔断的情况如下： * 1、当请求的服务响应超时 * 2、当请求的服务不能正常提供服务 */@Component //注入到IOC容器public class OrderFallback implements FallbackProvider &#123; /** * 这个方法返回的是serviceId，如果返回的单个服务，那么只针对一个服务熔断 * 如果想要针对所有的服务进行配置熔断，只需要返回*即可 */ @Override public String getRoute() &#123; return "order-provider"; &#125; /** * 发生熔断的响应方法 */ @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.OK; &#125; @Override public int getRawStatusCode() throws IOException &#123; return 200; &#125; @Override public String getStatusText() throws IOException &#123; return "OK"; &#125; @Override public void close() &#123; &#125; //设置响应的内容 @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream("fallback".getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125; zuul的重试 有时候因为网络或者其它原因，服务可能会暂时的不可用，这个时候我们希望可以再次对服务进行重试，Zuul也帮我们实现了此功能，需要结合Spring Retry 一起来实现 依赖： 12345&lt;!-- 超时重试 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt; 在配置文件中配置如下： 在zuul中开启重试机制 配置ribbon的重试次数 默认请求超时时间很短，还可以配置ribbon的超时时间 123456zuul: retryable: true # 开启重试机制ribbon: # zuul内部使用的是ribbon实现负载均衡的，因此配置ribbon的重试次数 MaxAutoRetries: 2 # 同一个服务的最大重试次数 MaxAutoRetriesNextServer: 2 # 对于切换的下一个实例的重试次数 Zuul的高可用 将多个zuul的微服务注册到Eureka中的（集群） Nginx和Zuul混搭的方式，可以将Nginx的请求转发到多个zuul中，zuul再路由给指定的微服务 完整的配置12345678910111213141516171819zuul:# TokenFilter:# pre:# disable: true # 忽略真实的服务名称实例访问，是一个Set集合，可以指定多个，取消全部使用 "*"即可 sensitive-headers: # 设置所有的服务都取消敏感头信息 ignored-services: - order-provider# ignored-patterns:# - /api-order/order/list # 取消指定的一个# - /api-order/order/** # 使用通配符去掉order下的全部接口 #routes下面指定代理规则，可以同时指定多个 routes: #指定第一个规则，这里的名称任意 api-order: #指定的实例名称 serviceId: order-provider #指定可以访问的路由 path: /api-order/** 消费端的使用 前提： zuul微服务（zuul-server）注册到eureka注册中心 微服务提供者注册到Eureka注册中心，zuul-server配置的路由是api-order 服务消费者注册到Eureka中 那么如果消费者想用通过zuul-server访问到服务提供者，那么可以直接写http://zuul-server/api-order/order/{id} 123456789101112@RestControllerpublic class OrderController &#123; private final static String URI_PRFIX="http://zuul-server/api-order"; //直接使用zuul网管连接订单的服务提供者 @Resource private RestTemplate restTemplate; @GetMapping("/order/&#123;id&#125;") public Order getOrder(@PathVariable("id")Integer id) &#123; return restTemplate.getForObject(URI_PRFIX+"/order/"+id, Order.class); &#125;&#125; 源码 https://gitee.com/chenjiabing666/zuul-server.git 参考文章 https://mp.weixin.qq.com/s/FsvZgkvpI0S6rposacGiiQ https://windmt.com/2018/04/23/spring-cloud-11-zuul-filter/ https://cloud.spring.io/spring-cloud-netflix/2.0.x/single/spring-cloud-netflix.html#_router_and_filter_zuul]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Config统一配置中心]]></title>
      <url>%2F2018%2F12%2F25%2FConfig(%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83)%2F</url>
      <content type="text"><![CDATA[Config 统一配置中心为什么使用？ 方便维护：微服务可能成百个，如果一个个配置都是在项目中配置的话，会给运维造成不必要的麻烦 安全：配置统一是由运维来操作，如果涉及到数据库的账户和密码，肯定是不能让开发知道的 服务端 添加依赖: 1234567891011&lt;!-- config server的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka客户端的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 配置如下： 这里使用的是git仓库，当然也是可以使用svn 1234567891011121314151617server: port: 3344eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册spring: application: name: config-server #应用的名称，在同一个eureka中必须不重复 cloud: config: server: git: uri: https://github.com/chenjiabing666/dept-config.git # git仓库的地址，如果是ssh方式的不需要指定用户名和密码，但是需要在github上添加秘钥 username: ****** # 用户名 password: ****** # 密码 basedir: C:/images/config-server # 本地的路径，将会自动在这个路径创建一个git仓库 在主启动类上添加@EnableConfigServer这个注解，如下: 1234@SpringBootApplication@EnableEurekaClient //开启eureka@EnableConfigServer //开启config severpublic class ConfigServerApplication &#123; 此时需要在远程的github仓库创建如下内容： 此时访问如下的路径：http://localhost:3344/orderClient9002-{profile}.yml，就会输出orderClient9002的内容 如果后缀写的是.json就会以json格式输出，是.properties就会以properties的格式输出 如果输出报错说明配置的内容有错误 访问方式 /name-{profile}.yml name是github仓库中的文档名称 {profile}是springBoot的profile，可以指定任意的环境 这里默认是master分支的内容 /label/name-{profile}.yml lable是仓库的分支名称 源码 https://github.com/chenjiabing666/cloud-config-server.git 客户端思路 启动配置中心的服务端，将其注入到eureka的注册中心 客户端相通过注册中心找到服务端的实例，然后读取到github仓库中对应的配置 使用 添加依赖： 1234567891011&lt;!-- 统一配置中心的客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- eureka注册中心的客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 在配置文件中（bootstrap.xml）中配置： bootstrap.xml是最高级的，其中的配置项不会被application.yml或者application.properties覆盖 其中一定要配置eureka的客户端，否则将不能找到统一配置中心的配置 123456789101112131415eureka: # 配置eureka客户端，一定要bootstrap文件中配置，因为需要到注册中心获取配置中心的服务端的地址，如果配置在github上面的配置，那么将会找不到配置中心的服务端 client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册 register-with-eureka: falsespring: application: name: orderClient9002 # 配置项目的名称，也是github中对应配置文件的名称（去掉后缀） cloud: config: discovery: enabled: true # 开启config的客户端 service-id: config-server # 指定eureka中的配置中心服务端的实例名称 profile: dev # 指定配置文件的环境 label: master # 指定需要访问github上的分支，这里不填默认是master分支 在主启动类上不需要对应的注解，只需要添加eureka客户端的注解即可，如下: 123@SpringBootApplication@EnableEurekaClient //开启eurekapublic class OrderClient9001Application &#123; 源码 https://github.com/chenjiabing666/config-client.git 配置中心服务端的高可用 只需要同时开启多个服务端即可，相当于配置了一个集群 spring cloud bus git仓库的配置改变了，但是统一配置中心并不能及时更新，因此我们需要一种机制能够保证git仓库中的配置改变了就会及时通知配置中心，bus就是这种机制 使用（bus + rabbitmq）配置中心的服务端 添加依赖 12345&lt;!-- spring cloud bus 消息总线的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 在配置文件中配置eureka和rabbitmq 123456789101112131415161718192021222324server: port: 3344eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册spring: application: name: config-server # 应用的名称，在同一个eureka中必须不重复 rabbitmq: # rabbitmq配置的 host: 39.105.123.197 # 主机的地址 port: 5672 # 端口 username: guest # 用户名 password: guest # 密码 virtual-host: / # 虚拟主机 cloud: config: server: git: uri: https://github.com/chenjiabing666/dept-config.git # git仓库的地址，如果是ssh方式的不需要指定用户名和密码，但是需要在github上添加秘钥 username: ****** # 用户名 password: ****** # 密码 basedir: C:/images/config-server # 本地的路径，将会自动在这个路径创建一个git仓库 开启刷新配置的uri： 123456management: # 开启刷新配置的地址 /bus-refresh endpoints: web: exposure: include: - bus-refresh 主启动类上添加eureka和config的server 1234@SpringBootApplication@EnableEurekaClient //开启eureka@EnableConfigServer //开启config severpublic class ConfigServerApplication &#123; 启动之后将会发现在rabbitmq中新增了一个队列，如下: 在github仓库中新增一个配置文件orderClient9001.yml: 123456server: port: 9001 person: name: chenjaibing age: 20 完整的配置12345678910111213141516171819202122232425262728293031server: port: 3344eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册spring: application: name: config-server # 应用的名称，在同一个eureka中必须不重复 rabbitmq: # rabbitmq配置的 host: 39.105.123.197 # 主机的地址 port: 5672 # 端口 username: guest # 用户名 password: guest # 密码 virtual-host: / # 虚拟主机 cloud: config: server: git: uri: https://github.com/chenjiabing666/dept-config.git # git仓库的地址，如果是ssh方式的不需要指定用户名和密码，但是需要在github上添加秘钥 username: chenjiabing666 # 用户名 password: ********** # 密码 basedir: C:/images/config-server # 本地的路径，将会自动在这个路径创建一个git仓库 management: # 开启刷新配置的地址 /bus-refresh endpoints: web: exposure: include: - bus-refresh 配置中心的客户端 添加依赖 12345&lt;!-- spring cloud bus 消息总线的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 添加eureka、rabbitmq、config client的配置（bootstrap.xml） 123456789101112131415161718192021eureka: # 配置eureka客户端，一定要bootstrap文件中配置，因为需要到注册中心获取配置中心的服务端的地址，如果配置在github上面的配置，那么将会找不到配置中心的服务端 client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册 register-with-eureka: falsespring: application: name: orderClient9001 # 配置项目的名称，也是github中对应配置文件的名称（去掉后缀） rabbitmq: # rabbitmq配置的 host: 39.105.123.197 # 主机的地址 port: 5672 # 端口 username: guest # 用户名 password: guest # 密码 virtual-host: / # 虚拟主机 cloud: config: discovery: enabled: true # 开启config的客户端 service-id: config-server # 指定eureka中的配置中心服务端的实例名称 profile: dev # 指定配置文件的环境 label: master # 指定需要访问github上的分支，这里不填默认是master分支 新增一个Person类，其中的属性来自配置文件，并且通过controller读取其中的值，用作测试 1234567891011121314151617181920212223@Component@ConfigurationProperties(prefix="person") //读取配置文件中前缀为person的值，并且赋值给其中的变量@Datapublic class Person &#123; private String name; private String age;&#125;@RestControllerpublic class PersonController &#123; @Resource private Person person; /** * 获取配置文件中的值 * @return */ @GetMapping("/person") public Person getPerson() &#123; return person; &#125;&#125; 在主启动类上只需要开启eureka客户端即可 123@SpringBootApplication@EnableEurekaClient //开启eurekapublic class OrderClient9001Application &#123; 测试 启动eurkea，config server，config client 访问http://localhost:9001/person，返回一个person的信息 此时我们修改github仓库中的person的配置，再次访问http://localhost:9001/person,但是值并没有改变 我们通过post请求访问http://localhost:3344/actuator/bus-refresh（config server端的接口，自动生成的），再次获取person的信息之后，发现改变了，此时说明我们的配置成功了 在github中配置提交代码自动更新 之前我们更新配置之后都是需要手动的post一个请求才会自动更新，现在我们可以在github中配置自动更新。 在github仓库中的webhooks中配置一个post请求，地址写外网访问到bus-refresh即可。 源码 https://github.com/chenjiabing666/cloud-bus]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring sleuth 服务追踪]]></title>
      <url>%2F2018%2F12%2F25%2Fspring-sleuth-%E6%9C%8D%E5%8A%A1%E8%BF%BD%E8%B8%AA%2F</url>
      <content type="text"><![CDATA[spring sleuth- 服务追踪Zipkin Zipkin 是一个开放源代码分布式的跟踪系统，由Twitter公司开源，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。 每个服务向zipkin报告计时数据，zipkin会根据调用关系通过Zipkin UI生成依赖关系图，显示了多少跟踪请求通过每个服务，该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。 Zipkin提供了可插拔数据存储方式：In-Memory、MySql、Cassandra以及Elasticsearch。接下来的测试为方便直接采用In-Memory方式进行存储，生产推荐Elasticsearch。 服务端的安装 使用docker安装：docker run --name zipkin -d -p 9411:9411 openzipkin/zipkin 访问http://localhost:9411/zipkin/即可看到可视化的界面 客户端使用 需要在每一个项目中（包括提供者，消费者，网关等），依赖如下: 1234567891011&lt;!-- zipkin的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- sleuth的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; 在上面所有的项目中添加如下的配置： 在开发环境中可以指定抽样的比例为1，在生产环境中可以使用默认的即可 123456789spring: zipkin: base-url: http://192.168.174.128:9411 # 指定zipkin的服务端的地址 sleuth: web: client: enabled: true sampler: probability: 1.0 # 将采样比例设置为 1.0，也就是全部都需要。默认是 0.1 参考文章 http://www.ityouknow.com/springcloud/2018/02/02/spring-cloud-sleuth-zipkin.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hystrix断路器、熔断器]]></title>
      <url>%2F2018%2F12%2F25%2FHystrix%E6%96%AD%E8%B7%AF%E5%99%A8%E3%80%81%E7%86%94%E6%96%AD%E5%99%A8%2F</url>
      <content type="text"><![CDATA[Hystrix 断路器、熔断器服务雪崩 在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。 如果下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。 是什么 Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，Hystrix能够保证在一个依赖出现问题的情况下，不会导致整个服务失败，避免级联故障，以提高分布式系统的弹性。 断路器本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期，可处理的备选响应（FallBack），而不是长时间等待或者抛出调用方法无法处理的异常，这样就保证了调用方线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩 作用 简单的说就是当程序出现异常的时候返回一个错误的状态告知其他的服务，而不是任由异常发展下去导致整个系统的瘫痪 对象 服务提供者 服务降级简介 什么是服务降级？当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。 如果还是不理解，那么可以举个例子：假如目前有很多人想要给我付钱，但我的服务器除了正在运行支付的服务之外，还有一些其它的服务在运行，比如搜索、定时任务和详情等等。然而这些不重要的服务就占用了JVM的不少内存与CPU资源，为了能把钱都收下来（钱才是目标），我设计了一个动态开关，把这些不重要的服务直接在最外层拒掉，这样处理后的后端处理收钱的服务就有更多的资源来收钱了（收钱速度更快了），这就是一个简单的服务降级的使用场景。 使用场景 服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，我们可以将一些 不重要或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。 使用效果 在客户端结合Feign配置熔断处理，当没有服务提供者或者服务出现异常的时候就会调用熔断Hystrix定制的接口，返回特定的错误信息 使用Feign达到服务降级 服务降级是在客户端配置，与服务提供者无关 添加依赖如下： 1234567891011121314151617181920212223&lt;!-- feign的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Hystrix的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- eureka的客户端依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; &lt;!-- ribbon的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 使用@FeignClient在公共模块上创建一个接口实现负载均衡，如下： @FeignClient(name=&quot;DEPT-PROVIDER&quot;,fallbackFactory=DeptFallBack.class) name：指定服务提供者的实例名称 fallbackFactory：熔断处理的接口，在下面会定义 123456789101112131415161718192021222324252627282930import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import cn.tedu.provider.domain.Dept;/** * Hystrix和Feign结合实现服务的降级 * @FeignClient 标注这个接口使用Feign实现负载均衡 * 1、name指定了微服务提供者的实例名称 * 2、fallbackFactory指定了熔断的接口，一旦出现异常就会调用这个接口的方法返回指定的熔断信息 */@FeignClient(name="DEPT-PROVIDER",fallbackFactory=DeptFallBack.class)public interface DeptFeign &#123; /** * 获取部门，使用Get方式请求 * @param id * @return */ @RequestMapping(value="/dept/&#123;id&#125;",method=RequestMethod.GET) Dept get(@PathVariable("id")Integer id); /** * 添加部门，使用POST请求的方式 * @param dept * @return */ @RequestMapping(value="/dept",method=RequestMethod.POST) Dept addDept(Dept dept);&#125; 在公共模块创建熔断处理的接口，如下： 这个类需要使用FallbackFactory，其中的泛型是Feign定义的接口 一定要使用@Component这个注解将其注入到IOC容器中 123456789101112131415161718192021222324252627282930313233343536import org.springframework.stereotype.Component;import cn.tedu.provider.domain.Dept;import feign.hystrix.FallbackFactory;/** * 针对DeptFiegn接口的服务熔断的公共类，在其中可以对各个接口进行服务熔断响应进行定制 * 1、这个接口必须实现`feign.hystrix.FallbackFactory` * 2、这个FallbackFactory中的泛型必须是`@FeignClient`标注的接口（实现负载均衡） */@Component //一定要将其注入到容器中public class DeptFallBack implements FallbackFactory&lt;DeptFeign&gt; &#123; /** * 实现其中的方法 */ @Override public DeptFeign create(Throwable cause) &#123; //直接return这个接口的对象，并且实现其中的所有接口方法，下面的每一个接口返回的信息就将是服务熔断返回的消息 return new DeptFeign() &#123; @Override public Dept get(Integer id) &#123; //根据Id获取异常之后就会返回其中的信息 Dept dept=new Dept(); dept.setDeptId(-1); dept.setDeptName("服务熔断......"); return dept; &#125; @Override public Dept addDept(Dept dept) &#123; //添加异常返回这个信息 dept.setDeptId(-1); dept.setDeptName("服务熔断......"); return dept; &#125;&#125;; &#125;&#125; 在消费者端controller中调用Feign的接口即可，如果程序抛出异常或者没有服务提供者，那么将会调用定义好的熔断方法，返回对应的信息，如下： 12345678910111213141516171819202122232425@RestControllerpublic class DeptController &#123; @Resource private DeptFeign deptFeign; //直接注入Feign接口，不过需要在主启动类上扫描该类所在的包或者父包 /** * 根据部门Id获取部门 * @param id * @return */ @GetMapping("/dept/&#123;id&#125;") public Dept getDept(@PathVariable("id") Integer id) &#123; return deptFeign.get(id); &#125; /** * 添加部门，json方式提交 * @param dept * @return */ @PostMapping("/dept") public Dept addDept(@RequestBody Dept dept) &#123; return deptFeign.addDept(dept); &#125;&#125; 在消费者端开启feign对Hystrix的支持，如下： 123feign: hystrix: enabled: true 在消费者的启动类上添加注解，如下： 123456@SpringBootApplication@EnableEurekaClient //开启eureka@EnableCircuitBreaker //开启熔断器@EnableFeignClients(basePackages= &#123;"cn.tedu.api.*"&#125;) //由于是分模块开发，feignclient是定义在公共模块的，因此必须指定basePackages扫描@FeignClient所在的包@ComponentScan(basePackages= &#123;"cn.tedu.api.*","cn.tedu.client.*"&#125;) //由于分模块开发，因此必须扫描Hystrix定义的fallbackFactory所在的包，同时也要扫描本模块所在的包，当然可以直接扫描cn.tedu.*这个包public class OrderClient9002Application &#123; 源码 order-api order-client 使用RestTemplate服务降级 添加依赖，如下: 12345&lt;!-- Hystrix的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 启动类上开启熔断 1234@SpringBootApplication@EnableEurekaClient //开启eureka@EnableCircuitBreaker //开启服务熔断public class OrderClient9001Application &#123; 一对一 第一种的实现方式就是每一个方法都对应一个熔断的方法（复杂，很难拓展和管理） 12345678910111213141516171819202122232425262728@RestControllerpublic class OrderController &#123; private final static String URI_PRFIX="http://zuul-server/api-order"; //直接使用zuul网管连接订单的服务提供者 @Resource private RestTemplate restTemplate; //使用@HystrixCommand这个注解，其中指定熔断后调用的方法 @HystrixCommand(fallbackMethod="getOrderFallback") @GetMapping("/order/&#123;id&#125;") public Order getOrder(@PathVariable("id")Integer id) &#123; System.out.println(1/0); //特意出异常 return restTemplate.getForObject(URI_PRFIX+"/order/"+id, Order.class); &#125; /** * 服务的熔断方法，只有当没有服务提供者提供服务或者程序出现异常的时候才会执行这个方法 * 注意： * 1、返回的类型一定要相同或者是其子类 * 2、入参的参数和类型一定要相同 */ public Order getOrderFallback(@PathVariable("id")Integer id) &#123; Order order=new Order(); order.setOrderId(-1); order.setOrderNum("太拥挤了，请稍后再试......"); return order; &#125;&#125; 默认的熔断 上面是针对一对一的熔断，每个接口都要写一个熔断方法，但是我们也可以针对一个类写一个默认的熔断方法即可 12345678910111213141516171819202122232425262728293031323334/** * 使用@DefaultProperties指定默认的熔断方法 * 1、需要熔断机制的接口上只需要添加@HystrixCommand注解即可 * @author Administrator * */@RestController@DefaultProperties(defaultFallback="defaultFallBack") public class OrderController &#123; private final static String URI_PRFIX="http://zuul-server/api-order"; //直接使用zuul网管连接订单的服务提供者 @Resource private RestTemplate restTemplate; @HystrixCommand //使用这个注解，其中指定熔断后调用的方法 @GetMapping("/order/&#123;id&#125;") public Order getOrder(@PathVariable("id")Integer id) &#123; System.out.println(1/0); return restTemplate.getForObject(URI_PRFIX+"/order/"+id, Order.class); &#125; /** * 默认的熔断方法 * 1、参数必须为空 * 2、返回的类型有特殊要求 * 1、必须和出现熔断的方法的返回类型相同或者是其子类 * @return */ public Order defaultFallBack() &#123; Order order=new Order(); order.setOrderId(-1); order.setOrderNum("太拥挤了，请稍后再试......"); return order; &#125;&#125; 超时设置ribbon+ Hystrix 熔断超时时间默认是1秒，即是当请求的服务在一秒之内没有执行完成，那么将会直接熔断，调用熔断方法，返回熔断信息，如下： 请求这个接口将会直接熔断，因为这里等待的时间超过了设置的时间 1234567891011@HystrixCommand //使用这个注解，其中指定熔断后调用的方法@GetMapping("/order/&#123;id&#125;")public Order getOrder(@PathVariable("id")Integer id) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return restTemplate.getForObject(URI_PRFIX+"/order/"+id, Order.class);&#125; 直接在@HystrixCommand注解中配置 我们可以通过配置改变这个默认的时间，如下： 直接在@HystrixCommand的注解中配置 一些常用的常量配置都可以在com.netflix.hystrix.HystrixCommandProperties这个类中找到 单位毫秒 1234567891011121314@HystrixCommand(commandProperties=&#123; @HystrixProperty(name="execution.isolation.thread.timeoutInMilliseconds",value="3000") &#125;) //使用这个注解，其中指定熔断后调用的方法 @GetMapping("/order/&#123;id&#125;") public Order getOrder(@PathVariable("id")Integer id) &#123;// System.out.println(1/0); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return restTemplate.getForObject(URI_PRFIX+"/order/"+id, Order.class); &#125; 配置文件中配置 直接在配置文件中配置，但是在需要熔断的方法上面一定要加上@HystrixCommand这个注解 针对所有的方法设置超时时间，如下： 1234567hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 3000 针对指定的方法设置超时时间，如下： 也可以对指定的方法指定commandKey,只需要在@HystrixCommand这个注解中指定这个属性即可，默认是方法的名称 1234567hystrix: command: getOrder: # 方法名称 execution: isolation: thread: timeoutInMilliseconds: 3000 Feign+Hystrix 在使用Feign+Hystrix实现服务熔断的时候，虽然我们在配置文件中改变了hystrix的默认的熔断超时时间，但是并不作用，如下: 1234567hystrix: command: default: # 方法名称 execution: isolation: thread: timeoutInMilliseconds: 7000 上面的配置并不起作用，因为Feign也是使用ribbon的，ribbon也是有超时时间的，默认也是一秒，因此我们要想上面的配置生效，必须指定ribbon的超时时间，并且Hystrix的超时时间应该比ribbon的时间长，因为ribbon还有重试机制，只有当重试也失效之后才应该熔断，完整的配置如下: 1234567891011121314ribbon: # 设置ribbon的超时时间，这里使用Feign会和Hystrix的超时间相互干扰 ReadTimeout: 5000 ConnectTimeout: 3000 OkToRetryOnAllOperations: true #对所有操作都进行重试。 MaxAutoRetriesNextServer: 2 # 切换实例的重试次数。 MaxAutoRetries: 1 # 对当前实例的重试次数。hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 7000 https://blog.csdn.net/east123321/article/details/82385816 服务熔断熔断器的状态机 Closed：熔断器关闭状态，调用失败次数积累，到了阈值（或一定比例）则启动熔断机制； Open：熔断器打开状态，此时对下游的调用都内部直接返回错误，不走网络，但设计了一个时钟选项，默认的时钟达到了一定时间（这个时间一般设置成平均故障处理时间，也就是MTTR），到了这个时间，进入半熔断状态； Half-Open：半熔断状态，允许定量的服务请求，如果调用都成功（或一定比例）则认为恢复了，关闭熔断器，否则认为还没好，又回到熔断器打开状态； 配置参数 参数 作用 备注 circuitBreaker.enabled 是否开启熔断器 默认true circuitBreaker.sleepWindowInMilliseconds 熔断多少秒后去尝试请求 当熔断器处于open的时候，并且达到了这个阈值，熔断器处于half-open状态，当再次有请求过来的时候就会尝试再次请求服务，而不是直接熔断服务，当此时访问服务正常的话，那么熔断器就会关闭。默认值5000毫秒 circuitBreaker.requestVolumeThreshold 在使用统计信息做出打开/关闭决策之前，必须在统计窗口中进行的请求数量 默认20 circuitBreaker.errorThresholdPercentage 失败率达到多少百分比后熔断 默认值50，即是请求失败率达到50%熔断器处于open状态 commandKey 默认值：当前执行方法名 直接在@HystrixCommand注解中配置熔断 添加依赖 12345&lt;!-- Hystrix的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 直接在消费者端使用即可，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 使用@DefaultProperties指定默认的熔断方法 * 1、需要熔断机制的接口上只需要添加@HystrixCommand注解即可 * @author Administrator * */@RestController@DefaultProperties(defaultFallback="defaultFallBack") public class OrderController &#123; private final static String URI_PRFIX="http://zuul-server/api-order"; //直接使用zuul网管连接订单的服务提供者 @Resource private RestTemplate restTemplate; @HystrixCommand(commandProperties=&#123; @HystrixProperty(name="execution.isolation.thread.timeoutInMilliseconds",value="3000"), //设置超时时间 @HystrixProperty(name="circuitBreaker.enabled",value="true"), // 开启熔断 @HystrixProperty(name="circuitBreaker.requestVolumeThreshold",value="10"), //最小请求数 @HystrixProperty(name="circuitBreaker.sleepWindowInMilliseconds",value="10000"), //请求重试时间，单位毫秒 @HystrixProperty(name="circuitBreaker.errorThresholdPercentage",value="60"), //失败率 &#125;) //使用这个注解，其中指定熔断后调用的方法 @GetMapping("/order/&#123;id&#125;") public Order getOrder(@PathVariable("id")Integer id) &#123; if (id==1) &#123; //模拟异常 throw new RuntimeException(); &#125; return restTemplate.getForObject(URI_PRFIX+"/order/"+id, Order.class); &#125; /** * 默认的熔断方法 * 1、参数必须为空 * 2、返回的类型有特殊要求 * 1、必须和出现熔断的方法的返回类型相同或者是其子类 * @return */ public Order defaultFallBack() &#123; Order order=new Order(); order.setOrderId(-1); order.setOrderNum("太拥挤了，请稍后再试......"); return order; &#125;&#125; 上面的配置完成之后，先请求传入id=1，达到失败率50%，那么熔断器就会开启，此时再传入id=1，那么本应该正常访问的，但是此时会被熔断，经过10000毫秒之后，再次访问传入id=2，请求成功之后，表示熔断机制关闭了 使用配置文件实现 在需要熔断的方法上面添加@HystrixCommand这个注解 123456789101112hystrix: command: default: # 这里使用default，但是如果针对单个方法，可以使用方法名称 execution: isolation: thread: timeoutInMilliseconds: 3000 circuitBreaker: enabled: true requestVolumeThreshold: 10 sleepWindowInMilliseconds: 10000 errorThresholdPercentage: 60 源码 https://gitee.com/chenjiabing666/order-client.git Hystrix Dashboard 图形化监控 主要是用来监控服务提供者的情况（服务提供者必须实现了Hystrix的熔断机制才能被监控） Hystrix-dashboard 服务端配置 添加依赖： 123456789 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 添加eureka客户端的依赖，并且将其注册到eureka中 在主启动类上添加对应的注解@EnableHystrixDashboard 1234@SpringBootApplication@EnableHystrixDashboard //开启Hystrix-dashboard@EnableEurekaClient //eureka的客户端public class HystrixDashboardApplication &#123; 配置如下： 123456789server: port: 3366eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册spring: application: name: hystrix-dashborad #应用的名称，在同一个eureka中必须不重复 启动服务访问地址：http://localhost:3366/hystrix，将会出现如下界面: 源码：https://gitee.com/chenjiabing666/hystrix-dashboard.git 被监控服务的创建 添加依赖： 12345678910&lt;!-- Hystrix的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 配置如下： 必须配置endpoints，否则将会连接补上 12345678910111213141516171819202122232425hystrix: command: default: # 这里使用default，但是如果针对单个方法，可以使用方法名称 execution: isolation: thread: timeoutInMilliseconds: 3000 circuitBreaker: enabled: true requestVolumeThreshold: 10 sleepWindowInMilliseconds: 10000 errorThresholdPercentage: 60 ribbon: # 设置ribbon的超时时间，这里使用Feign会和Hystrix的超时间相互干扰 ReadTimeout: 5000 ConnectTimeout: 3000 OkToRetryOnAllOperations: true #对所有操作都进行重试。 MaxAutoRetriesNextServer: 2 # 切换实例的重试次数。 MaxAutoRetries: 1 # 对当前实例的重试次数。 management: # 配置节点，一定要配置，否则将不能连接上 endpoints: web: exposure: include: hystrix.stream 在主启动类上必须添加注解`@EnableCircuitBreaker` 123456@SpringBootApplication@EnableEurekaClient //开启eureka@EnableCircuitBreaker //开启熔断@EnableFeignClients(basePackages= &#123;"cn.tedu.api.feign"&#125;) //扫描FeignClient@ComponentScan(basePackages= &#123;"cn.tedu.*"&#125;) //扫描Hystrix的fallbackFactorypublic class OrderClient9002Application &#123; 启动成功后在hystrix-dashboard添加如下地址即可被监控: http://localhost:9002/actuator/hystrix.stream 源码（order-client9002）：https://github.com/chenjiabing666/order-parent.git 详细指标 总结熔断发生的场景 达到配置的超时时间 没有服务提供者提供服务 服务提供者程序发生异常 注意点 Feign+Hystrix的方式配置Hystrix的超时时间一定还要配置Ribbon的超时时间 Feign+Hystrix的熔断配置和Ribbon+Hystrix的配置方式基本相同 参考文章 https://www.cnblogs.com/yawen/p/6655352.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Feign（负载均衡）]]></title>
      <url>%2F2018%2F12%2F25%2FFeign%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
      <content type="text"><![CDATA[Feign 负载均衡简介 Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果。 声明式的接口+注解 使用的是轮询的算法 使用 添加依赖（消费者端和公共模块端） 1234567891011121314151617 &lt;!--feign的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--eureka客户端的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--ribbon的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 创建两个服务提供者，实例名称为DEPT-PROVIDER 123456789101112131415161718192021222324@RestControllerpublic class DeptController &#123; /** * 根据Id获取部门 * @param id * @return */ @GetMapping("/dept/&#123;id&#125;") public Dept getDept(@PathVariable("id") Integer id) &#123; Dept dept=new Dept(); dept.setDeptId(id); dept.setDeptName("8081"); return dept; &#125; /** * 添加部门 * @param dept */ @PostMapping("/dept") public Dept addDept(@RequestBody Dept dept) &#123; return dept; &#125;&#125; 一般我们需要将feign接口写在公共的项目中，因为接口不止一个项目使用，可以提供给多个项目使用，在dept-api这个项目中添加如下的feign接口,其中@FeignClient这个注解的value属性必须和对应的服务提供者的实例名称相同 123456789101112131415161718192021222324252627282930313233package cn.tedu.api.feign;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import cn.tedu.api.doamin.Dept;/** * 1、配置一个Feign的客户端，使用@FeignClient()，其中的name是微服务提供者的实例名称 * 2、其中的restful风格的api只能使用RequestMapping，不能使用GetMapping等，有些版本可能会报错 * 3、怎样和提供者的api对应呢？ * 1、并不是方法名称一致，根据uri来区分的，只要uri访问一致，那么就会匹配对应的服务提供者的api * 2、虽然不是根据方法名称来匹配，但是我们最好保持一致 */@FeignClient("DEPT-PROVIDER")public interface DeptFeign &#123; /** * 获取部门，使用Get方式请求 * @param id * @return */ @RequestMapping(value="/dept/&#123;id&#125;",method=RequestMethod.GET) Dept get(@PathVariable("id")Integer id); /** * 添加部门，使用POST请求的方式 * @param dept * @return */ @RequestMapping(value="/dept",method=RequestMethod.POST) Dept addDept(Dept dept);&#125; 创建消费者，添加上面的dept-api这个坐标，直接注入DeptFeign这个接口实例即可使用，如下： 12345678910111213141516171819202122232425@RestControllerpublic class DeptController &#123; @Resource private DeptFeign deptFeign; //直接注入Feign接口，不过需要在主启动类上扫描该类所在的包或者父包 /** * 根据部门Id获取部门 * @param id * @return */ @GetMapping("/dept/&#123;id&#125;") public Dept getDept(@PathVariable("id") Integer id) &#123; return deptFeign.get(id); &#125; /** * 添加部门，json方式提交 * @param dept * @return */ @PostMapping("/dept") public Dept addDept(@RequestBody Dept dept) &#123; return deptFeign.addDept(dept); &#125;&#125; 在消费者的主启动类上添加@EnableFeignClients这个注解，注意一定要扫描带有@FeignClient这个注解的接口的包或者父包，将其注入到ioc容器中 12345678@SpringBootApplication@EnableEurekaClient //eureka客户端@EnableFeignClients(basePackages= &#123;"cn.tedu.api"&#125;) //开启Feign，其中basePackages扫描的包一定要是@FeignClient这个注解的所在包或者父包public class DeptConsumer8003Application &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer8003Application.class, args); &#125;&#125; 注意 消费者端的主启动类上需要使用@EnableFeignClients并且扫描带有@FeignClient这个注解的包或者父包 Feign是和Eureka结合使用的，因此需要添加Eureka的依赖，并且在主启动类上添加对应的注解@EnableEurekaClient Feign的接口怎样和提供者的api对应呢？ 并不是方法名称一致，根据uri来区分的，只要uri访问一致，那么就会匹配对应的服务提供者的api 虽然不是根据方法名称来匹配，但是我们最好保持一致 其中的restful风格的api只能使用RequestMapping，不能使用GetMapping等，有些版本可能会报错 一般使用Feign定义接口都需要放在公共模块中，因为这些接口可能是公用的 负载均衡算法 Feign是结合Ribbon使用的，负载均衡算法和Ribbon是一样的，默认采用的是轮询算法，如果需要改变，只需要注入Ribbon的已经有的算法即可，具体操作和Ribbon一样，只需要新建一个配置类类，直接注入接，如下： 1234567891011121314151617181920import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.netflix.loadbalancer.IRule;import com.netflix.loadbalancer.RandomRule;/** * Feign的负载均衡算法的配置类，和Ribbon一样 */@Configurationpublic class FeignRule &#123; /** * 注入随机算法 * @return */ @Bean public IRule myRule() &#123; return new RandomRule(); //直接创建一个随机算法返回即可 &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ribbon（客户端负载均衡）]]></title>
      <url>%2F2018%2F12%2F25%2FRibbon%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
      <content type="text"><![CDATA[Ribbon - 客户端负载均衡简介 Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。它是一个基于HTTP和TCP的客户端负载均衡器。它可以通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。 使用（消费端） 导入依赖 12345678910 &lt;!--eureka客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--ribbon--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 在消费端添加如下配置，用来从eureka集群中轮询请求可访问的微服务，不用注册到eureka中，配置如下： 123456789server: port: 8003 servlet: context-path: /dept-consumereureka: # 配置eureka客户端，不用注册到eureka中 client: serviceUrl: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/,http://eureka7001.com:7001/eureka/ # eureka的暴露地址，指向集群中每一个eureka，多个用都好分隔 register-with-eureka: false # 只是消费者，因此不用将自己注册到eureka中 在restTemplate的配置类中添加一个注解@LoadBalanced，配置如下： 123456789101112131415161718192021222324252627import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.client.ClientHttpRequestFactory;import org.springframework.http.client.SimpleClientHttpRequestFactory;import org.springframework.web.client.RestTemplate;/** * RestTemplate的配置类 * @author 陈加兵 * @since 2018年12月6日 下午6:10:58 */@Configurationpublic class RestConfig &#123; @Bean @LoadBalanced //ribbon实现客户端的负载均衡，默认使用的是轮询的算法 public RestTemplate restTemplate(ClientHttpRequestFactory factory) &#123; return new RestTemplate(factory); &#125; @Bean public ClientHttpRequestFactory simpleClientHttpRequestFactory() &#123; SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory(); factory.setReadTimeout(5000);//单位为ms factory.setConnectTimeout(5000);//单位为ms return factory; &#125;&#125; 在主启动类上添加@EnableEurekaClient注解 12345678@SpringBootApplication@EnableEurekaClientpublic class EurekaClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientApplication.class, args); &#125;&#125; 消费者的controller端直接使用微服务的名称访问即可，ribbon会自动根据名称在eureka中查询指定的微服务，不需要写明微服务的ip了，如下： 123456789101112131415161718@RestControllerpublic class DeptController &#123; @Resource private RestTemplate restTemplate; //请求路径直接使用微服务的名称即可EUREKA-PROVIDER，eureka-provider是微服务的项目名称(servlet.context-path) private final static String URI_PREFIX="http://EUREKA-PROVIDER/eureka-provider"; /** * 使用RestTemplate发出get请求 */ @GetMapping("/dept/&#123;id&#125;") public Dept getDept(@PathVariable("id")Integer id) throws RestClientException, URISyntaxException&#123; Map&lt;String, Object&gt; params=new HashMap&lt;String, Object&gt;(); params.put("id", id); Dept dept = restTemplate.getForObject(URI_PREFIX+"/dept/&#123;id&#125;", Dept.class, params); return dept; &#125;&#125; 创建两个提供者，提供相同的服务，使用同一个微服务的名称（EUREKA-PROVIDER），这个就相当于是一个集群了，需要改变的就是端口和instance-id，配置如下： 第一个服务提供者 1234567891011121314server: port: 8001 servlet: context-path: /eureka-provider # 访问的项目名称在配置“集群”的时候也是必须一样的，否则不好调用eureka: client: serviceUrl: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/,http://eureka7001.com:7001/eureka/ # eureka的暴露地址，直接注册，使用的是eureka的集群 instance: instance-id: eureka-provider:8001 ## instance-id区别服务 prefer-ip-address: true ## 访问路径可以显示服务主机的IP地址spring: application: name: eureka-provider #微服务的名称，配置集群的时候必须相同 第二个服务提供者 1234567891011121314server: port: 8002 servlet: context-path: /eureka-provider # 访问的项目名称在配置“集群”的时候也是必须一样的，否则不好调用eureka: client: serviceUrl: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/,http://eureka7001.com:7001/eureka/ # eureka的暴露地址，直接注册，使用的是eureka的集群 instance: instance-id: eureka-provider:8002 ## instance-id区别服务 prefer-ip-address: true ## 访问路径可以显示服务主机的IP地址spring: application: name: eureka-provider #微服务的名称，配置集群的时候必须相同 微服务启动，如下图： 此时访问http://localhost:8003/dept/-consumer/dept/1可以发现此时的负载均衡的策略默认使用的是轮询算法 注意 负载均衡是在同一个功能的微服务中根据不同的策略选择不同的微服务，因此这些微服务对外暴露的实例名称要相同（spring.application.name） ribbon是一个客户端的负载均衡，必须要连接eureka，才能在指定的微服务实例中按照策略选择 负载均衡算法 RoundRobinRule：轮询，默认的算法 RandomRule ： 随机算法 AvailabilityFilteringRule：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，还有并发的连接数量超过阈值的服务，然后对剩余的服务列表按照轮询策略进行访问 WeightedResponseTimeRule：根据平均响应时间计算所有的权重，响应时间越快服务权重越大被选中的概率越高，刚启动时统计信息不足，则使用轮询策略，等统计信息足够，会自动切换到WeightedResponseTimeRule RetryRule：先按照轮询策略获取服务，如果服务获取失败则在指定时间内会进行重试，获取可用的服务 BestAvailableRule：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务 ZoneAvoidanceRule：复合判断server所在区域的性能和server的可用性选择服务器 配置负载均衡策略 直接创建一个配置类，注入想要使用的负载均衡算法即可 1234567891011121314151617181920import com.netflix.loadbalancer.IRule;import com.netflix.loadbalancer.RandomRule;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Ribbon负载均衡算法的配置类 * 1、原理：如果用户没有注入自己的算法，那么ribbon默认使用的是轮询算法，如果注入了，那么将会使用注入的 */ @Configuration //表明这是一个配置类，相当于配置文件xmlpublic class RibbonRule &#123; /** * 配置随机算法，改变默认的轮询算法 * @return */ @Bean public IRule rule()&#123; return new RandomRule(); //直接返回随机算法 &#125;&#125; 自定义负载均衡算法 未完，待续…… 超时时间设置 默认超时时间为1000毫秒，如果需要修改超时时间，配置如下: 由于是http请求，因此这里代表的socket的连接时间和读取时间 123ribbon: ReadTimeout: 5000 # 请求处理时间。 ConnectTimeout: 9000 # 请求连接时间。 重试机制 https://blog.csdn.net/akaks0/article/details/80039590 全局配置如下： 1234ribbon: OkToRetryOnAllOperations: true #对所有操作都进行重试。 MaxAutoRetriesNextServer: 2 # 切换实例的重试次数。 MaxAutoRetries: 1 # 对当前实例的重试次数。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring cloud的资源]]></title>
      <url>%2F2018%2F12%2F25%2FSpring%20cloud%E7%9A%84%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90%2F</url>
      <content type="text"><![CDATA[spring cloud的资源 Springcloud中文网 中文文档 中国社区 优质学习资源 SpringBoot学习资源 官方文档 http://www.itmuch.com/spring-cloud-sum-eureka/ 指南 https://www.cnblogs.com/huangjuncong/tag/SpringCloud/ https://blog.csdn.net/u012702547/article/details/78547925 https://www.cnblogs.com/leeSmall/category/1185489.html https://windmt.com/tags/Spring-Cloud/ http://www.ityouknow.com http://www.itmuch.com/categories/Spring-Cloud]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Eureka服务发现和注册]]></title>
      <url>%2F2018%2F12%2F25%2FEureka%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E5%92%8C%E6%B3%A8%E5%86%8C%2F</url>
      <content type="text"><![CDATA[Eureka - 服务发现和注册服务端 新建springBoot项目，选择模块cloud Discovery====&gt;Eureka Server 此时的依赖如下： 12345678910111213141516171819&lt;dependencies&gt; &lt;!-- eureka的服务端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 在配置文件中配置基本的信息，如下： 1234567891011server: port: 7001eureka: instance: hostname: localhost ## 实例名称 client: fetch-registry: false # 注册中心不向自己注册自己 register-with-eureka: false # 表示是否将自己注册到Eureka Server,不去检索服务 service-url: # 设置与Eureka Server的地址,查询服务和注册服务都需要依赖这个地址.默认是http://localhost:7001/eureka/;多个地址可使用','风格. defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 在启动类上添加@EnableEurekaServer这个注解即可启动 启动在本地访问：http://localhost:7001/，如果出现下图，那么表示启动成功： 客户端 新建springBoot项目，选择cloud Discovery==&gt;Eureka Discovery 新建完成之后，pom文件中的依赖如下： 123456789101112131415161718&lt;dependencies&gt; &lt;!--eureka客户端的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 配置文件需要配置将该项目注册到之前的服务端中 123456789server: port: 8003eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka # eureka的暴露地址，直接注册spring: application: name: eureka-client #应用的名称，在同一个eureka中必须不重复 此时访问http://localhost:7001将会看到如下界面： 通过上图能够看到自己项目已经注册到了eureka中了 细节的完善微服务名称的改变 通过上面的图形可以看到默认的名称是192.168.1.1:eureka-client:8003，现在我们需要改变名称，让开发者能够一目了然的知道这个服务是干什么的，配置如下: 1eureka.instance.instance-id=eureka-client:8003 #改变微服务的名称 访问信息显示IP信息提示1eureka.instance.prefer-ip-address=true ## 显示IP地址 微服务info内容的说明（客户端） 之前点击微服务名称之后跳转到之后是一个错误页面，现在我们需要返回这个info信息 添加依赖，如下： 12345&lt;!--actuator依赖，不需要填写version，由springBoot父类控制 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 在pom文件中添加build信息，如下： 123456789101112131415161718192021&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 读取以$符号开头的和$符号结尾的，都能够读取 --&gt; &lt;delimiters&gt; &lt;delimiter&gt;$&lt;/delimiter&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 之后只需要在src/main/resuorces/application.yml文件中添加信息即可，格式是键值对的形式，如下： 1234567# 说明info的信息，key-value的形式info: app.name: eureka-client company.name: http://chenjiabing666.github.io groupId: $project.groupId$ artifactId: $project.artifactId$ version: $project.version$ 自我保护机制 在eureka中出现如下内容表示自我保护机制起作用了，如下： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY&#39;RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 默认情况下,如果Eureka Server在一定时间内没有收到某个微服务实例的心跳,Eureka Server就会注销这个实例(默认是90秒).但是当网路分区发生故障时,微服务与Eureka Server之间无法正常通信,以上行为就可能非常危险,因为微服务本身是健康的,此时本不应该注销这个服务的. Eureka 通过自我保护模式来解决这个问题,当Eureka Server节点在短时间内丢失过多客户端时(可能发生了网络分区故障),那么这个节点就会进入自我保护模式。一旦进入这个模式,Eureka Server就会保护服务注册表中的信息,不再删除服务注册表中的数据(也就是不注销任何微服务).当网络故障恢复后,这个Eureka Server节点会自动退出自我保护模式. 禁用自我保护机制（生产环境中不推荐） 123eureka: server: enable-self-preservation: false # 禁用自我保护模式 服务发现（不重要） 为了让别人能够了解这个微服务是干什么的，需要对外暴露一个链接，让别人能够了解到这个微服务是干什么的 在eureka的客户端添加如下controller 1234567891011121314151617181920@RestControllerpublic class DeptController &#123; @Resource private DiscoveryClient discoveryClient; //服务发现的client /** * 服务发现 * @return */ @GetMapping("/dept/discovery") public Object discovery()&#123; List&lt;String&gt; list=discoveryClient.getServices(); //获取所有的微服务实例 System.out.println(list); //根据为微服务的名称获取实例 List&lt;ServiceInstance&gt; serviceList=discoveryClient.getInstances("EUREKA-PROVIDER"); for (ServiceInstance element : serviceList) &#123; System.out.println(element.getServiceId()+"\t"+element.getHost()+"\t"+element.getUri()); &#125; return this.discoveryClient; &#125;&#125; 在主启动类上添加注解开启服务发现：@EnableDiscoveryClient 12345678@SpringBootApplication@EnableEurekaClient //eureka服务客户端@EnableDiscoveryClient //eureka服务发现public class EurekaProvider8001Application &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaProvider8001Application.class, args); &#125;&#125; 此时访问http://localhost:8001/eureka-provider/dept/discovery控制台就会打印如下信息： 1EUREKA-PROVIDER 192.168.1.102 http://192.168.1.102:8001 此时在消费端就可以通过restTemplate调用这个服务发现的uri获取服务的信息，此处省略 eureka3.png 集群配置 在本地模拟开启三个注册中心server，在hosts文件中添加如下的地址： 123127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com127.0.0.1 eureka7003.com 服务端的配置 分别创建三个eureka服务端，如下： 其中每一个eureka服务端的service-url都必须指向其他的服务端，由此形成一个手拉手的模式 eureka7001的配置如下： 1234567891011server: port: 7001eureka: instance: hostname: eureka7001.com # 配置主机的名称，之前是需要在hosts文件中做映射的 client: fetch-registry: false # 注册中心不向自己注册自己 register-with-eureka: false # 表示是否将自己注册到Eureka Server,默认为true.由于当前应用就是Eureka Server,故而设置为false. service-url: # 设置与Eureka Server的地址,查询服务和注册服务都需要依赖这个地址,多个地址可使用','风格，配置集群必须指向除自己之外的其他的eureka服务的地址 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ eureka7001的配置如下： 1234567891011server: port: 7002eureka: instance: hostname: eureka7002.com # 配置主机的名称，之前是需要在hosts文件中做映射的 client: fetch-registry: false # 注册中心不向自己注册自己 register-with-eureka: false # 表示是否将自己注册到Eureka Server,默认为true.由于当前应用就是Eureka Server,故而设置为false. service-url: # 设置与Eureka Server的地址,查询服务和注册服务都需要依赖这个地址,多个地址可使用','风格，配置集群必须指向除自己之外的其他的eureka服务的地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7003.com:7003/eureka/ eureka7001的配置如下： 1234567891011server: port: 7003eureka: instance: hostname: eureka7003.com client: fetch-registry: false # 注册中心不向自己注册自己 register-with-eureka: false # 表示是否将自己注册到Eureka Server,默认为true.由于当前应用就是Eureka Server,故而设置为false. service-url: # 设置与Eureka Server的地址 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7001.com:7001/eureka/ 以上三个服务端配置完成之后，就可以分别访问以下链接： 123http://eureka7001.com:7001/http://eureka7002.com:7002/http://eureka7003.com:7003/ 客户端 只需要将客户端注册到上面的集群中即可，只需要改变eureka.client.serviceUrl.defaultZone的值为eureka集群中的值，配置如下： 1234567891011121314151617server: port: 8003eureka: client: serviceUrl: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/,http://eureka7001.com:7001/eureka/ # eureka的暴露地址，指向集群中每一个eureka，多个用都好分隔 instance: instance-id: eureka-client:8003 ## 改变eureka中显示微服务的名称 prefer-ip-address: true ## 访问路径可以显示服务主机的IP地址spring: application: name: eureka-client #应用的名称，在同一个eureka中必须不重复# 说明info的信息，key-value的形式info: app.name: eureka-client company.name: http://chenjiabing666.github.io 完整的配置信息服务端12345678910111213server: port: 7001eureka:# server:# enable-self-preservation: false ##禁用自我保护机制，但是生产环境中不推荐 instance: hostname: localhost client: fetch-registry: false # 注册中心不向自己注册自己 register-with-eureka: false # 表示是否将自己注册到Eureka Server,默认为true.由于当前应用就是Eureka Server,故而设置为false. service-url: # 设置与Eureka Server的地址,查询服务和注册服务都需要依赖这个地址.默认是http://localhost:8761/eureka/;多个地址可使用','风格. defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 客户端123456789101112server: port: 8003eureka: client: serviceUrl: defaultZone: http://localhost:7001/eureka/ # eureka的暴露地址，直接注册 instance: instance-id: eureka-client:8003 ## 改变eureka中显示微服务的名称 prefer-ip-address: true ## 访问路径可以显示服务主机的IP地址spring: application: name: eureka-client #应用的名称，在同一个eureka中必须不重复 Eureka设置用户名和密码访问Eureka和zookepper的区别 未完，待续…… https://blog.csdn.net/pml18710973036/article/details/64121522 https://blog.csdn.net/qq_32521313/article/details/79032155 参考文章 Springcloud中文网 中文文档 中国社区 优质学习资源 SpringBoot学习资源 官方文档 http://www.itmuch.com/spring-cloud-sum-eureka/ 指南]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot整合Spring Data Mongodb]]></title>
      <url>%2F2018%2F12%2F25%2FSpringBoot%E6%95%B4%E5%90%88Spring-Data-Mongodb%2F</url>
      <content type="text"><![CDATA[SpringBoot整合Spring Data Mongodb简介 MongoDB是一款面向文档的数据库，类似json（Bson）的数据存储格式 何时使用 数据量大 数据价值较低 安装 docker pull mongo docker run --name mymongo -p 27017:27017 -d mongo 概念解析 SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table joins 表连接,MongoDB不支持 primary key primary key 主键,MongoDB自动将_id字段设置为主键 使用 添加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 配置如下: 12345678910spring: application: name: mongodb-server data: mongodb: host: ****** # 主机地址 port: 27017 # 端口 database: test # 数据库server: port: 9003 新建User实体类，存储在MongonDB中，如下: 12345678910@Data@Accessors(chain=true) //链式调用@Document(collection="user") //指定集合public class User implements Serializable &#123; @Id private Integer _id; private String name; private String mobile; private Date birthday;&#125; 定义一个UserRepository继承MongoRepository 123456/** * 用户的dao层的接口，实现MongoRepository * 第一个泛型指定的是实体类，第二个指定的是主键Id的类型 */public interface UserRepository extends MongoRepository&lt;User, Integer&gt;&#123;&#125; 在service使用如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Service@Transactional //开启事务public class UserServiceImpl &#123; @Resource private UserRepository userRepository; //注入 /** * 添加用户 * @return */ public User addUser(User user)&#123; User user2 = userRepository.save(user); System.out.println(1/0); return user2; &#125; /** * 批量添加 * @param users * @return */ public List&lt;User&gt; addUserBatch(List&lt;User&gt; users)&#123; List&lt;User&gt; user2 = userRepository.saveAll(users); return user2; &#125; /** * 根据Id删除 * @param id */ public void deleteById(Integer id) &#123; userRepository.deleteById(id); &#125; /** * 更新数据，使用的还是save方法，相当于覆盖 * @param user * @return */ public User update(User user) &#123; User user2 = userRepository.save(user); return user2; &#125; /** * 根据Id获取信息 * @param id * @return */ public User findById(Integer id) &#123; return userRepository.findById(id).get(); &#125; /** * 查询全部 * @return */ public List&lt;User&gt; findAll()&#123; return userRepository.findAll(); &#125; /** * 分页查询信息 * @param pageSize * @param pageNum * @return */ public List&lt;User&gt; findUserList(Integer pageNum,Integer pageSize)&#123; Pageable pageable=new PageRequest(pageNum-1,pageSize); Page&lt;User&gt; pages = userRepository.findAll(pageable); if (pages.hasContent()) &#123; return pages.getContent(); &#125; return null; &#125;&#125; 分页查询 dao层 1234567891011121314import java.util.List;import org.springframework.data.domain.Pageable;import org.springframework.data.mongodb.repository.MongoRepository;import com.techwells.study.domain.DynamicComment;public interface DynamicCommentRepository extends MongoRepository&lt;DynamicComment, Integer&gt;&#123; /** * 分页查询，先根据nickName筛选出结果，之后分页 * @param nickName 昵称 * @param pageable 分页 * @return */ List&lt;DynamicComment&gt; findByNickName(String nickName,Pageable pageable);&#125; 测试如下： 123456789101112@Test public void test4() &#123; //构建分页信息 Pageable pageable=new PageRequest(0, 2, Sort.Direction.DESC,"id"); List&lt;DynamicComment&gt; comments = dynamicRepository.findByNickName("爱撒谎的男孩",pageable); for (DynamicComment dynamicComment : comments) &#123; System.out.println(dynamicComment); &#125; &#125; 常用的查询关键字 https://docs.spring.io/spring-data/jpa/docs/2.1.3.RELEASE/reference/html/#jpa.query-methods 事务 未完待续……………….. 源码 https://gitee.com/chenjiabing666/mongo-server.git]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Token认证]]></title>
      <url>%2F2018%2F12%2F25%2FToken%E8%AE%A4%E8%AF%81%2F</url>
      <content type="text"><![CDATA[认证机制常见的几种认证机制HTTP Basic Auth 在HTTP中，HTTP基本认证是一种允许Web浏览器或者其他客户端在请求时提供用户名和口令形式的身份凭证的一种登录验证方式。 简单而言，HTTP基本认证就是我们平时在网站中最常用的通过用户名和密码登录来认证的机制。 就是每次请求都会带上用户名和密码 优点 HTTP 基本认证是基本上所有流行的网页浏览器都支持。但是基本认证很少在可公开访问的互联网网站上使用，有时候会在小的私有系统中使用。 适用于各种平台，包括app和web 缺点 HTTP 基本认证虽然足够简单，但是前提是在客户端和服务器主机之间的连接足够安全。如果没有使用SSL/TLS这样的传输层安全的协议，那么以明文传输的密钥和口令很容易被拦截。 由于现存的浏览器保存认证信息直到标签页或浏览器关闭，或者用户清除历史记录。导致了服务器端无法主动来当前用户登出或者认证失效。 OAuth（开放授权） OAuth 是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表等），而无需将用户名和密码提供给第三方应用。 OAuth 允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的网站（例如，视频编辑网站）在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容。 最常见的就是qq和微信授权登录 Cookie/Session 认证机制 Cookie 是由客户端保存的小型文本文件，其内容为一系列的键值对。Cookie 是由 HTTP 服务器设置的，保存在浏览器中。Cookie会随着 HTTP请求一起发送。 Session 是存储在服务器端的，避免在客户端 Cookie 中存储敏感数据。Session 可以存储在 HTTP 服务器的内存中，也可以存在内存数据库（如redis）中。 Cookie/Session认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端的浏览器端创建了一个Cookie对象；通过客户端带上来Cookie对象来与服务器端的session对象匹配来实现状态管理的。默认的，当我们关闭浏览器的时候，cookie会被删除。但可以通过修改cookie 的expire time使cookie在一定时间内有效 缺点： 平台有限，不适合App端 数据量过大的话，对服务器会造成负担 基于 Token 的认证机制 Token机制相对于Cookie机制又有什么好处呢？ 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输. 无状态(也称：服务端可扩展行):Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息. 更适用CDN: 可以通过内容分发网络请求你服务端的所有资料（如：javascript，HTML,图片等），而你的服务端只要提供API即可. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可. 更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。 CSRF:因为不再依赖于Cookie，所以你就不需要考虑对CSRF（跨站请求伪造）的防范。 性能: 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算 的Token验证和解析要费时得多. 不需要为登录页面做特殊处理: 如果你使用Protractor 做功能测试的时候，不再需要为登录页面做特殊处理. 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT). 这个标准已经存在多个后端库（.NET, Ruby, Java,Python, PHP）和多家公司的支持（如：Firebase,Google, Microsoft）. 有状态服务和无状态服务 无状态服务:就是没有特殊状态的服务,各个请求对于服务器来说统一无差别处理,请求自身携带了所有服务端所需要的所有参数(服务端自身不存储跟请求相关的任何数据,不包括数据库存储信息) 有状态服务:与之相反,有状态服务在服务端保留之前请求的信息,用以处理当前请求,比如session等 基于JWT（JSON WEB TOKEN）的Token认证机制实现 一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名。 头部（Header） JWT还需要一个头部，头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象。 1234&#123; "typ": "JWT", "alg": "HS256"&#125; 载荷（Payload） iss: 该JWT的签发者，是否使用是可选的； sub: 该JWT所面向的用户,一般是用户名，是否使用是可选的； aud: 接收该JWT的一方，是否使用是可选的； exp(expires): 什么时候过期，这里是一个Unix时间戳，是否使用是可选的； iat(issued at): 在什么时候签发的(UNIX时间)，一般是登录时间，是否使用是可选的；其他还有： nbf (Not Before)：如果当前时间在nbf里的时间之前，则Token不被接受；一般都会留一些余地，比如几分钟；，是否使用是可选的； 12345678910&#123; "iss": "Online JWT Builder", "iat": 1416797419, "exp": 1448333419, "aud": "www.example.com", "sub": "jrocket@example.com", "GivenName": "Johnny", "Surname": "Rocket", "Email": "jrocket@example.com", "Role": [ "Manager", "Project Administrator" ] &#125; 将上面的JSON对象进行[base64编码]可以得到编码后的字符串。这个字符串我们将它称作JWT的Payload（载荷）。 签名（Signature） 将头部和载荷编码后的字符串用.分隔（头部在前）,最后将拼接后的字符串和秘钥（secret）用头部指定的算法进行加密得到一个字符串。那么此时完整的JWT的内容就是头部+载荷+最后加密得到的字符串，中间用.分割 JJWT Java实现JWT的token生成 添加依赖123456&lt;!-- jjwt --&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt;&lt;/dependency&gt; 生成token1234567891011121314/** * 生成token */@Testpublic void test1() &#123; //eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiIxIiwiaWF0IjoxNTQ1NTc0ODE1LCJzdWIiOiLpmYjliqDlhbUifQ.WF0VoGSP5oH0XRsCraJ9lRjtVFRs6I0KJpkhFngpwgk JwtBuilder builder = Jwts.builder() .setId("1") //用户Id .setIssuedAt(new Date()) //用户登录的日期 .setSubject("陈加兵")//用户名 .signWith(SignatureAlgorithm.HS256, "sercet"); //指定签名的算法和秘钥（盐） String token = builder.compact(); //获取生成的token System.out.println(token);&#125; 解析token 解析token需要知道秘钥 12345678910111213141516/* * 解析token */ @Test public void test2() &#123; Claims claims = Jwts.parser() .setSigningKey("sercet") //设置解析的秘钥 .parseClaimsJws("eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiIxIiwiaWF0IjoxNTQ1NTc0ODE1LCJzdWIiOiLpmYjliqDlhbUifQ.WF0VoGSP5oH0XRsCraJ9lRjtVFRs6I0KJpkhFngpwgk") .getBody(); System.out.println("用户Id："+claims.getId()); System.out.println("用户名："+claims.getSubject()); System.out.println("登录时间："+claims.getIssuedAt()); &#125; 设置过期时间 不设置过期时间默认是无时间限制的 JwtBuilder setExpiration(Date exp); 123456JwtBuilder builder = Jwts.builder() .setId("1") //用户Id .setIssuedAt(new Date()) //用户登录的日期 .setSubject("陈加兵")//用户名 .setExpiration(new Date(new Date().getTime()+1000*60*60)) //设置过期时间为1小时 .signWith(SignatureAlgorithm.HS256, "sercet"); //指定签名的算法和秘钥（盐） 添加自定义属性 JwtBuilder claim(String name, Object value);： 直接添加自定义的属性，key-value形式 JwtBuilder addClaims(Map&lt;String, Object&gt; claims);： 直接添加一个Map作为自定义的属性 12345678910111213141516171819202122232425262728293031323334/** * 生成token */ @Test public void test1() &#123; JwtBuilder builder = Jwts.builder() .setId("1") //用户Id .setIssuedAt(new Date()) //用户登录的日期 .setSubject("陈加兵")//用户名 .setExpiration(new Date(new Date().getTime()+1000*60*60)) //设置过期时间为1小时 .signWith(SignatureAlgorithm.HS256, "sercet") //指定签名的算法和秘钥（盐） .claim("age", 22) //自定义内容 .claim("address", "江苏省"); //自定义内容 String token = builder.compact(); //获取生成的token System.out.println(token); &#125; /* * 解析token */ @Test public void test2() &#123; Claims claims = Jwts.parser() .setSigningKey("sercet") //设置解析的秘钥 .parseClaimsJws("eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiIxIiwiaWF0IjoxNTQ1NTc1ODQzLCJzdWIiOiLpmYjliqDlhbUiLCJleHAiOjE1NDU1Nzk0NDMsImFnZSI6MjIsImFkZHJlc3MiOiLmsZ_oi4_nnIEifQ.uRhzSnsWl5IO-K6SA3zHsqGacZzkOOsFlD8lvqYDleY") .getBody(); System.out.println("用户Id："+claims.getId()); System.out.println("用户名："+claims.getSubject()); System.out.println("登录时间："+claims.getIssuedAt()); System.out.println("过期时间："+claims.getExpiration()); System.out.println("address："+claims.get("address")); &#125; 在拦截器中配置JWT工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.Date;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import io.jsonwebtoken.Claims;import io.jsonwebtoken.JwtBuilder;import io.jsonwebtoken.Jwts;import io.jsonwebtoken.SignatureAlgorithm;import lombok.Data;/** * JWT的工具类 */@Component@ConfigurationProperties(prefix="jwt.config") //读取配置文件中的配置@Datapublic class JwtUtil &#123; private String secret; //秘钥 private long expire; //过期时间 /** * 生成token * @param id 用户的Id * @param subject 用户名 * @param role 角色，分为用户和后台管理员 * @return */ public String encoder(String id,String subject,String role) throws Exception&#123; JwtBuilder builder = Jwts.builder() .setId(id) //用户Id .setIssuedAt(new Date()) //用户登录的日期 .setSubject(subject)//用户名 .setExpiration(new Date(new Date().getTime()+expire)) //设置过期时间为1小时 .claim("role",role) //自定义属性，指定角色 .signWith(SignatureAlgorithm.HS256, secret); //指定签名的算法和秘钥（盐） return builder.compact(); &#125; /** * 对token进行解码 * @param token * @return 解码后的结果集，相当于Map * @throws Exception 如果解码失败会抛出异常 */ public Claims decoder(String token) throws Exception&#123; return Jwts.parser() .setSigningKey(secret) //设置解析的秘钥 .parseClaimsJws(token) //解析的token .getBody(); &#125;&#125; 配置文件1234jwt: # JWT的配置 config: secret: secret ## 秘钥 expire: 3600000 ## 过期时间1个小时 拦截器12345678910111213141516171819202122232425262728293031323334353637383940414243444546import javax.annotation.Resource;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.http.HttpStatus;import org.springframework.util.StringUtils;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import cn.tedu.auth.util.JwtUtil;import io.jsonwebtoken.Claims;/** * JWT验证token的拦截器 * 改进： 如果没有权限，那么可以跳转到一个指定的错误页面护....... */public class JwtInterceptor extends HandlerInterceptorAdapter &#123; @Resource private JwtUtil jwtUtil; //注入JwtUtil @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //获取请求头中的token String token=request.getHeader("token"); if (StringUtils.isEmpty(token)) &#123; response.setStatus(HttpStatus.UNAUTHORIZED.value()); //设置401响应信息，没有权限 System.err.println("没有权限"); return false; //直接拦截，不继续进行 &#125; //如果有token，需要解码 Claims claims=null; try &#123; System.err.println(token); claims = jwtUtil.decoder(token); if (claims!=null) &#123; request.setAttribute("claims", claims); //放置在request中，后续的接口可能还需使用 &#125; &#125; catch (Exception e) &#123; response.setStatus(HttpStatus.UNAUTHORIZED.value()); //设置401响应信息，没有权限 return false; &#125; return true; &#125;&#125; 配置拦截器 一定要先注入拦截器类，否则拦截器内的其他对象将不能注入 1234567891011121314151617181920@Configurationpublic class webConfig extends WebMvcConfigurerAdapter &#123; /** * 注入拦截器，这里一定需要提前注入，否则拦截器中注入的对象将无法注入 * * @return */ @Bean public JwtInterceptor jwtInterceptor() &#123; return new JwtInterceptor(); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 注册自定义拦截器，添加拦截路径和排除拦截路径 ，这里直接使用上面的方法直接获取注入的拦截器即可，否则将会造成拦截器中无法注入其他的对象 registry.addInterceptor(jwtInterceptor()).addPathPatterns("/**").excludePathPatterns("/user/test") .excludePathPatterns("/user/login"); &#125;&#125; 使用 登录成功返回token 123456789101112131415161718192021222324252627public ResultInfo login(User user)throws Exception&#123; ResultInfo resultInfo=new ResultInfo(); User user2 = userRepository.findByName(user.getName()); if (user2==null) &#123; resultInfo.setCode("-1"); resultInfo.setMessage("用户名不存在"); return resultInfo; &#125; //判断密码是否正确 if (!bCryptPasswordEncoder.matches(user.getPassword(),user2.getPassword())) &#123; resultInfo.setCode("-1"); resultInfo.setMessage("密码不正确"); return resultInfo; &#125; //生成token String token=JwtUtil.encoder(user2.getId()+"", user2.getName(),"user"); System.err.println(token); Map&lt;String, Object&gt; map=new HashMap&lt;&gt;(); map.put("token", token); //返回token map.put("user", user); resultInfo.setData(map); resultInfo.setMessage("登录成功"); return resultInfo; &#125; 删除操作需要验证token是否具有指定的权限 拦截器验证 controller中的角色验证码（后期可以使用切面将其提取出来） 123456789101112131415161718192021222324252627/** * 删除用户 * @param id * @return */@DeleteMapping("/&#123;id&#125;")public ResultInfo deleteById(@PathVariable("id")Integer id,HttpServletRequest request) &#123; ResultInfo resultInfo=new ResultInfo(); //验证角色，之后该段可以直接用切面完成 Claims claims = (Claims) request.getAttribute("claims"); //获取token解析的map String role=(String) claims.get("role"); //获取角色 if (!"user".equals(role)) &#123; resultInfo.setCode("-1"); resultInfo.setMessage("权限不足！"); return resultInfo; &#125; try &#123; resultInfo=userService.deleteById(id); return resultInfo; &#125; catch (Exception e) &#123; resultInfo.setCode("-1"); resultInfo.setMessage("异常"); return resultInfo; &#125;&#125; 相关问题 为什么用JWT？ JWT只通过算法实现对Token合法性的验证，不依赖数据库，Memcached的等存储系统，因此可以做到跨服务器验证，只要密钥和算法相同，不同服务器程序生成的Token可以互相验证。 JWT Token不需要持久化在任何NoSQL中，不然背离其算法验证的初心 在退出登录时怎样实现JWT Token失效呢？ 退出登录， 只要客户端端把Token丢弃就可以了，服务器端不需要废弃Token。 怎样保持客户端长时间保持登录状态？ 服务器端提供刷新Token的接口， 客户端负责按一定的逻辑刷新服务器Token。 服务器端是否应该从JWT中取出userid用于业务查询？ REST API是无状态的，意味着服务器端每次请求都是独立的，即不依赖以前请求的结果，因此也不应该依赖JWT token做业务查询， 应该在请求报文中单独加个userid 字段。 为了做用户水平越权的检查，可以在业务层判断传入的userid和从JWT token中解析出的userid是否一致， 有些业务可能会允许查不同用户的数据。 开发流程 常见验证流程: 用户提交用户名、密码到服务器后台 后台验证用户信息的正确性 若用户验证通过，服务器端生成Token，返回到客户端 客户端保存Token，再下一次请求资源时，附带上Token信息 服务器端（一般在拦截器中进行拦截）验证Token是否由服务器签发的 若Token验证通过，则返回需要的资源 源码 https://gitee.com/chenjiabing666/auth-server.git 参考文章 https://blog.csdn.net/qq_36838191/article/details/79926196 https://www.cnblogs.com/howhy/p/7063247.html https://blog.csdn.net/swl979623074/article/details/81150184]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springBoot整合spring-data-redis]]></title>
      <url>%2F2018%2F12%2F22%2FspringBoot%E6%95%B4%E5%90%88spring-data-redis%2F</url>
      <content type="text"><![CDATA[SpringBoot整合Spring data redis依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 连接配置1234spring: redis: host: ****** ## redis的主机地址 port: 6379 序列化方式的配置 默认采用的是jdk的序列化 我们可以改变成json序列化方式，如下: 123456789101112131415161718192021222324252627282930313233343536373839404142import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * Redis的配置类 * @author Administrator * */@Configurationpublic class RedisConfig &#123; /** * 重写Redis序列化方式，使用Json方式: * 当我们的数据存储到Redis的时候，我们的键（key）和值（value）都是通过Spring提供的Serializer序列化到数据库的。RedisTemplate默认使用的是JdkSerializationRedisSerializer，StringRedisTemplate默认使用的是StringRedisSerializer。 * Spring Data JPA为我们提供了下面的Serializer： * GenericToStringSerializer、Jackson2JsonRedisSerializer、JacksonJsonRedisSerializer、JdkSerializationRedisSerializer、OxmSerializer、StringRedisSerializer。 * 在此我们将自己配置RedisTemplate并定义Serializer。 * @param redisConnectionFactory * @return */ @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory);// JdkSerializationRedisSerializer jdkSerializationRedisSerializer = new JdkSerializationRedisSerializer(); GenericJackson2JsonRedisSerializer jackson2JsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); // 设置值（value）的序列化采用FastJsonRedisSerializer。 redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);// redisTemplate.setHashValueSerializer(fastJsonRedisSerializer); // 设置键（key）的序列化采用StringRedisSerializer。 redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125; &#125; StringRedisTemplate 这个只能存放字符串，如果需要存放对象，那么需要将其转换成json存储即可 RedisTemplate 配置好序列化方式之后，即可注入，如下： 1234567891011121314151617181920@RunWith(SpringRunner.class)@SpringBootTest //springBoot测试类，可以自定义测试类，不过需要引用这两个注解public class BlueApplicationTests &#123; @Resource private RedisTemplate&lt;String, Object&gt; redisTemplate; @Test public void test2()&#123; Person person=new Person(); person.setAge(22); person.setName("陈加兵"); redisTemplate.opsForHash().put("p", "3", person); &#125; @Test public void test3()&#123; Person person= (Person) redisTemplate.opsForHash().get("p", "3"); System.out.println(person); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot整合Spring-data-jpa]]></title>
      <url>%2F2018%2F12%2F20%2FSpringBoot%E6%95%B4%E5%90%88Spring-data-jpa%2F</url>
      <content type="text"><![CDATA[SpringBoot整合Spring data jpa依赖1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--mysql驱动--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 添加数据库连接池 druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt;&lt;/dependency&gt; 主键生成策略 @GeneratedValue(strategy=GenerationType.xxx)指定主键的生成策略 IDENTITY：根据数据库的主键自增长策略 GenerationType.TABLE：使用一个特定的数据库表格来保存主键 GenerationType.SEQUENCE：在某些数据库中,不支持主键自增长,比如Oracle,其提供了一种叫做”序列(sequence)”的机制生成主键。此时,GenerationType.SEQUENCE就可以作为主键生成策略。该策略的不足之处正好与TABLE相反,由于只有部分数据库(Oracle,PostgreSQL,DB2)支持序列对象,所以该策略一般不应用于其他数据库。类似的,该策略一般与另外一个注解一起使用@SequenceGenerator,@SequenceGenerator注解指定了生成主键的序列.然后JPA会根据注解内容创建一个序列(或使用一个现有的序列)。如果不指定序列,则会自动生成一个序列SEQ_GEN_SEQUENCE GenerationType.AUTO：把主键生成策略交给持久化引擎(persistence engine),持久化引擎会根据数据库在以上三种主键生成策略中选择其中一种。此种主键生成策略比较常用,由于JPA默认的生成策略就是GenerationType.AUTO,所以使用此种策略时.可以显式的指定@GeneratedValue(strategy = GenerationType.AUTO)也可以直接@GeneratedValue 实例如下： 123@Id@GeneratedValue(strategy=GenerationType.IDENTITY) //数据库自增private Integer id; 配置1234567891011121314151617181920212223242526spring: datasource: ## 配置数据源 type: com.alibaba.druid.pool.DruidDataSource url: jdbc:mysql://118.31.15.108:3306/jpa?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false driver-class-name: com.mysql.jdbc.Driver username: root password: **** initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 6000 timeBetweenEvictionRunsMillis: 6000 minEvictableIdleTimeMillis: 25200000 testWhileIdle: true testOnBorrow: false testOnReturn: false validationQuery: SELECT 1 FROM DUAL RemoveAbandanded: true removeAbandonedTimeout: 1800 logAbandoned: true jpa: show-sql: true #控制台打印sql语句 database: MYSQL # 指定数据库的类型，不填会默认检测 generate-ddl: false ## 是否自动生成表,默认是false# hibernate:# ddl-auto: update 创建一个实体类12345678910111213141516171819/** * 用户的实体类，其中的变量和数据库默认是以驼峰形式对应的，比如industryId,那么在表中的字段一定要是industry_id，否则将会报错 */@Table(name="t_user") //指定对应数据库对应的表名@Entity //标记这是一个实体类@Data //lombook的自动生成set，getpublic class User &#123; @Id //标记主键 @GeneratedValue(strategy=GenerationType.IDENTITY) private Integer id; private String name; private Integer age; private String address; private Integer industryId; //在数据库中的对应字段一定要是industry_id&#125; 基本的查询 定义一个UserRepository，相当于Mybatis中的Mapper，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.util.List;import org.springframework.data.jpa.repository.JpaRepository;import cn.tedu.jpa.domain.User;import java.lang.String;/** * JpaRepository的接口，相当于mapper * 泛型：JpaRepository&lt;User, Integer&gt; ：第一个是实体类的类型，第二个是主键的类型 */public interface UserRepository extends JpaRepository&lt;User, Integer&gt;&#123; /** * 根据指定条件查询 Byxxx(where xxx=xxx)，除了根据主键查询，否则返回的都是List * 其中查询的条件对应的类型必须相同 */ List&lt;User&gt; findByName(String name); /** * 并列条件查询 ，相当于where name=xxx and age=xxx */ List&lt;User&gt; findByNameAndAge(String name,Integer age); /* * 三个条件的并列查询 where xxx and xxx and xxx */ List&lt;User&gt; findByNameAndAgeAndIndustryId(String name,Integer age,Integer industryId); /* * Top或者First指定返回结果数量,默认返回第一个，相当于limit 1 */ User findTopByNameAndAge(String name,Integer age); /* * Topn或者Firstn指定返回结果数量,这里的n表示返回的数量，相当于limit n */ List&lt;User&gt; findTop2ByNameAndAge(String name,Integer age); /* * In 相当于where age in(....) 其中的变量类型可以数组、List、Set只要是Collection即可，泛型必须和查询条件的类型一致 */ List&lt;User&gt; findByAgeIn(Integer[] ages); /* * 统计数据 相当于select count(*) where age=xxx */ Long countByAge(Integer age); &#125; 测试类如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@RunWith(SpringRunner.class)@SpringBootTestpublic class JpaServerApplicationTests &#123; @Resource private UserRepository userRepository; /** * 新增数据（单个） */ @Test public void addUser() &#123; User user=new User(); user.setAge(22); user.setName("陈加兵"); User user2 = userRepository.save(user); //自增主键的返回 System.out.println(user); &#125; /** * 批量插入 */ @Test public void saveAll() &#123; User user1=new User(); user1.setAge(22); user1.setName("陈加兵"); User user2=new User(); user2.setAge(22); user2.setName("陈加兵"); List&lt;User&gt; users=new ArrayList&lt;&gt;(); users.add(user1); users.add(user2); List&lt;User&gt; usersResturn=userRepository.saveAll(users); //返回列表，自增主键的返回 for (User user : usersResturn) &#123; System.out.println(user); &#125; &#125; /** * 更新数据，使用的仍然是save方法，如果其中包含id，那么就是更新数据，否则就是添加 * 1、如果有数据不更新，那么就出入null即可 */ @Test public void update() &#123; User user1=new User(); user1.setId(1); user1.setAge(22); user1.setName("郑元梅"); User user = userRepository.save(user1); System.out.println(user); &#125; /** * 统计数据 */ @Test public void count() &#123; System.out.println(userRepository.count()); &#125; /** * 统计数据 */ @Test public void countByAge() &#123; System.out.println(userRepository.countByAge(23)); &#125; @Test public void findByName() &#123; List&lt;User&gt; users=userRepository.findTop2ByNameAndAge("陈加兵", 22); for (User user : users) &#123; System.out.println(user); &#125; &#125; @Test public void findByAgeIn() &#123; Integer[] ages= &#123;22,23&#125;; List&lt;User&gt; users=userRepository.findByAgeIn(ages); for (User user : users) &#123; System.out.println(user); &#125; &#125; &#125;&#125; 自定义查询@Query使用HQL语句查询 默认使用的就是HQL语句查询的，如下： 12345/** * 使用hql表达式查询，其中?1表示对应第一个参数，不能直接使用?作为占位符 */@Query(value="select u from User u where u.age=?1 and u.name=?2")List&lt;User&gt; findUserList(Integer age,String name); 使用sql语句查询 需要指定nativeQuery=true 12345/** * 使用sql语句查询，其中nativeQuery表示使用本地查询，即是sql语句查询 */@Query(value="select * from t_user where age=?1 order by industry_id desc",nativeQuery=true)List&lt;User&gt; findUserListByAge(Integer age); 删除和修改 使用自定义sql的时候，如果涉及到删除和修改的sql需要满足两个条件才能执行，如下： 使用@Modifying标注 在事务中执行 123456/** * 删除和修改信息，必须同时使用@Modifying注解标注 */ @Modifying @Query(value="delete from t_user where industry_id=?1",nativeQuery=true) void deleteByIndustryId(Integer industryId); 复杂条件查询 Repository接口需要继承JpaSpecificationExecutor，如下： 1public interface UserRepository extends JpaRepository&lt;User, Integer&gt;,JpaSpecificationExecutor&lt;User&gt;&#123; 查询如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 结果筛选 * @param user 封装了查询的条件 * @return */ public List&lt;User&gt; findAll_2(User user) &#123; List&lt;User&gt; users = userRepository.findAll(new Specification&lt;User&gt;() &#123; /** * @param root 根对象，用于封装查询的条件，比如name,jack、age 10等 * @param query 封装查询关键字 比如group by order by * @param criteriaBuilder 封装对象条件 * @return 返回null表示没有查询条件 */ @Override public Predicate toPredicate(Root&lt;User&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder criteriaBuilder) &#123; //new 一个集合，存放所有的查询条件 List&lt;Predicate&gt; predicates=new ArrayList&lt;&gt;(); if (!StringUtils.isEmpty(user.getName())) &#123; //如果name不是null，就填入到筛选条件中 //第一个参数是表达式，第二个参数是值,相当于where name=%name% Predicate predicate = criteriaBuilder.like(root.get("name").as(String.class),"%"+user.getName()+"%"); predicates.add(predicate); //加入到条件集合中 &#125; if (!StringUtils.isEmpty(user.getAddress())) &#123; //如果地址不为空，填入筛选条件 //where address=xxx Predicate predicate = criteriaBuilder.equal(root.get("address").as(String.class), user.getAddress()); predicates.add(predicate); &#125; if (user.getAge()!=null) &#123; //如果年龄不为空 //where age&lt;=xxx Predicate predicate = criteriaBuilder.le(root.get("age").as(Integer.class), user.getAge()); predicates.add(predicate); &#125; Predicate[] parray=new Predicate[predicates.size()]; //返回，这里的使用的and条件，将上面所有的条件用and连接 return criteriaBuilder.and(predicates.toArray(parray)); &#125; &#125;); return users;&#125; /** * 测试 */ @Test public void test1() &#123; User user=new User(); user.setName("a"); //封装name List&lt;User&gt; users = findAll_2(user); for (User user2 : users) &#123; System.out.println(user2); &#125; &#125; 分页查询PageRequest 构造方法如下： public PageRequest(int page, int size) size：每页查询的大小 page：从第几页开始，从0开始，0 表示第一页 public PageRequest(int page, int size, Direction direction, String... properties) direction： 排序的方式，枚举类，其中有ASC，DESC properties： 进行排序的字段，可以指定多个 Page int getTotalPages()：返回共有多少页数 long getTotalElements()：获取总数 boolean hasContent();： 当前分页是否有数据 List&lt;T&gt; getContent();： 返回当前页所有的数据 boolean isFirst();：判断当前的页数是否是第一页 boolean isLast();： 是否是最后页 boolean hasNext();： 是否还有下一页 boolean hasPrevious();： 是否还有前一页 Pageable nextPageable();： 获取下一页 Pageable previousPageable();：获取前一页 简单查询 以相同的排序方式查询 12345678910@Testpublic void findAll() &#123; //构造分页数据，查找第二页，每页2条记录，order by age,industryId desc Pageable pageable=new PageRequest(1, 2,Direction.DESC,"age","industryId"); Page&lt;User&gt; pages = userRepository.findAll(pageable); //执行分页查询的方法 if (pages.hasContent()) &#123; //如果查询到了内容 List&lt;User&gt; users = pages.getContent(); //获取查询到的结果 long total = pages.getTotalElements(); //获取总数 &#125;&#125; 不同的排序方式查询 123456789101112131415161718192021@Testpublic void findAll() &#123; Order order1=new Order(Direction.DESC, "age"); //创建排序方式 Order order2=new Order(Direction.ASC, "industryId"); List&lt;Order&gt; orders=new ArrayList&lt;&gt;(); //放入集合 orders.add(order1); orders.add(order2); Sort sort=new Sort(orders); //创建Sort //构造分页数据，查找第二页，每页2条记录，order by age desc,industryId asc Pageable pageable=new PageRequest(0, 2,sort); Page&lt;User&gt; pages = userRepository.findAll(pageable); //执行分页查询的方法 if (pages.hasContent()) &#123; //如果查询到了内容 List&lt;User&gt; users = pages.getContent(); //获取查询到的结果 long total = pages.getTotalElements(); //获取总数 for (User user : users) &#123; System.out.println(user); &#125; &#125;&#125; 简单条件分页查询 方法如下： 1234/* * 根据条件查询的结果分页，相当于select * from user where name=xxx limit #,# */List&lt;User&gt; findByName(String name,Pageable pageable); 复杂条件分页查询 Repository接口需要继承JpaSpecificationExecutor，如下： 1public interface UserRepository extends JpaRepository&lt;User, Integer&gt;,JpaSpecificationExecutor&lt;User&gt;&#123; 和复杂条件查询一样，只是多了一个分页 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 结果筛选 * @param user 封装了查询的条件 * @return */ public List&lt;User&gt; findAll_3(User user,Integer pageNum,Integer pageSize) &#123; Pageable pageable=new PageRequest(pageNum-1, pageSize); //分页的查询 Page&lt;User&gt; pages = userRepository.findAll(new Specification&lt;User&gt;() &#123; /** * @param root 根对象，用于封装查询的条件，比如name,jack、age 10等 * @param query 封装查询关键字 比如group by order by * @param criteriaBuilder 封装对象条件 * @return 返回null表示没有查询条件 */ @Override public Predicate toPredicate(Root&lt;User&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder criteriaBuilder) &#123; //new 一个集合，存放所有的查询条件 List&lt;Predicate&gt; predicates=new ArrayList&lt;&gt;(); if (!StringUtils.isEmpty(user.getName())) &#123; //如果name不是null，就填入到筛选条件中 //第一个参数是表达式，第二个参数是值,相当于where name=%name% Predicate predicate = criteriaBuilder.like(root.get("name").as(String.class),"%"+user.getName()+"%"); predicates.add(predicate); //加入到条件集合中 &#125; if (!StringUtils.isEmpty(user.getAddress())) &#123; //如果地址不为空，填入筛选条件 //where address=xxx Predicate predicate = criteriaBuilder.equal(root.get("address").as(String.class), user.getAddress()); predicates.add(predicate); &#125; if (user.getAge()!=null) &#123; //如果年龄不为空 //where age&lt;=xxx Predicate predicate = criteriaBuilder.le(root.get("age").as(Integer.class), user.getAge()); predicates.add(predicate); &#125; Predicate[] parray=new Predicate[predicates.size()]; //返回，这里的使用的and条件，将上面所有的条件用and连接 return criteriaBuilder.and(predicates.toArray(parray)); &#125; &#125;,pageable); return pages.getContent(); //返回结果&#125; /** * 测试 */ @Test public void test2() &#123; User user=new User(); user.setName("a"); //封装name List&lt;User&gt; users = findAll_3(user,1,10); for (User user2 : users) &#123; System.out.println(user2); &#125; &#125; 查找关键字 关键词 样品 JPQL代码段 And findByLastnameAndFirstname … where x.lastname = ?1 and x.firstname = ?2 Or findByLastnameOrFirstname … where x.lastname = ?1 or x.firstname = ?2 Is,Equals findByFirstname，findByFirstnameIs，findByFirstnameEquals … where x.firstname = ?1 Between findByStartDateBetween … where x.startDate between ?1 and ?2 LessThan findByAgeLessThan … where x.age &lt; ?1 LessThanEqual findByAgeLessThanEqual … where x.age &lt;= ?1 GreaterThan findByAgeGreaterThan … where x.age &gt; ?1 GreaterThanEqual findByAgeGreaterThanEqual … where x.age &gt;= ?1 After findByStartDateAfter … where x.startDate &gt; ?1 Before findByStartDateBefore … where x.startDate &lt; ?1 IsNull findByAgeIsNull … where x.age is null IsNotNull,NotNull findByAge(Is)NotNull … where x.age not null Like findByFirstnameLike … where x.firstname like ?1 NotLike findByFirstnameNotLike … where x.firstname not like ?1 StartingWith findByFirstnameStartingWith … where x.firstname like ?1（附加参数绑定%） EndingWith findByFirstnameEndingWith … where x.firstname like ?1（与前置绑定的参数%） Containing findByFirstnameContaining … where x.firstname like ?1（参数绑定包装%） OrderBy findByAgeOrderByLastnameDesc … where x.age = ?1 order by x.lastname desc Not findByLastnameNot … where x.lastname &lt;&gt; ?1 In findByAgeIn(Collection&lt;Age&gt; ages) … where x.age in ?1 NotIn findByAgeNotIn(Collection&lt;Age&gt; ages) … where x.age not in ?1 True findByActiveTrue() … where x.active = true False findByActiveFalse() … where x.active = false IgnoreCase findByFirstnameIgnoreCase … where UPPER(x.firstame) = UPPER(?1) Top或者First findTopByNameAndAge，findFirstByNameAndAge where … limit 1 Topn或者Firstn findTop2ByNameAndAge，findFirst2ByNameAndAge where … limit 2 Distinct findDistinctPeopleByLastnameOrFirstname select distinct …. count countByAge，count select count(*) 参考文章 https://docs.spring.io/spring-data/jpa/docs/2.1.3.RELEASE/reference/html/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot集成lombok]]></title>
      <url>%2F2018%2F12%2F20%2FSpringBoot%E9%9B%86%E6%88%90lombok%2F</url>
      <content type="text"><![CDATA[SpringBoot集成lombokSTS安装 https://blog.csdn.net/blueheart20/article/details/52909775 常用的注解 @Getter: 自动生成Getter方法 @NonNull： 标识对象是否为空，为空则抛出异常 @Setter: 自动生成Setter @ToString： 覆盖tostring方法 @Slf4j: 默认使用slf4j的日志对象 @EqualsAndHashCode: 覆盖equal和hashCode方法 @Data: @Getter/@Setter, @ToString, @EqualAndHashCode等组合 @AllArgsConstructor：自动生成全参构造方法 @NoArgsConstructor：自动生成无参构造方法 @Accessors(chain = true)：实现链式编程 使用 添加依赖 1234567&lt;!-- lombok的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.2&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 创建实体类，如下: 12345678910111213@Data // 自动生成get、set、toString、equals方法@AllArgsConstructor // 全参构造方法@NoArgsConstructor // 无参构造方法@Accessors(chain = true) // 链式编程public class Order &#123; private Integer orderId; // 订单Id private String orderNum; // 订单编号 public static void main(String[] args) &#123; Order order = new Order(); order.setOrderId(1).setOrderNum("156416516"); // 链式调用 &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot集成JSR303校验]]></title>
      <url>%2F2018%2F12%2F08%2FSpringBoot%E9%9B%86%E6%88%90JSR303%E6%A0%A1%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[SpringBoot集成JSR303使用 添加依赖： 12345&lt;!--JSR303校验的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt; &lt;/dependency&gt; 实体类添加校验 123456789101112public class Person &#123; @NotEmpty(message="姓名不能为空") private String name; private int userId; @Length(min=6,max=10,message="密码必须在6-10位之间") private String password; @Email(message="邮箱不符合格式") private String email;&#125; controller层传参的校验，必须对参数用@Valid，并且后面必须紧跟着BindingResult，否则将会抛出全局异常 12345678910111213141516171819/** * 校验Person * 必须对参数用@Valid，并且后面必须紧跟着BindingResult，否则将会抛出全局异常 * @param person * @param result * @return */@PostMapping("/person")public Object addPerson(@RequestBody @Valid Person person, BindingResult result) &#123; if (result.hasErrors()) &#123; // 如果有异常的话，就会返回 List&lt;ObjectError&gt; allErrors = result.getAllErrors(); //获取所有的异常信息 for (ObjectError error : allErrors) &#123; System.out.println(error.getCode() + "\t" + error.getDefaultMessage()); &#125; &#125; return person;&#125; 常用的校验注解12345678910111213141516171819202122232425262728293031323334353637383940空检查@Null 验证对象是否为null@NotNull 验证对象是否不为null, 无法查检长度为0的字符串@NotBlank 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格.@NotEmpty 检查约束元素是否为NULL或者是EMPTY. Booelan检查@AssertTrue 验证 Boolean 对象是否为 true @AssertFalse 验证 Boolean 对象是否为 false 长度检查@Size(min=, max=) 验证对象（Array,Collection,Map,String）长度是否在给定的范围之内 @Length(min=, max=) Validates that the annotated string is between min and max included. 日期检查@Past 验证 Date 和 Calendar 对象是否在当前时间之前 @Future 验证 Date 和 Calendar 对象是否在当前时间之后 @Pattern 验证 String 对象是否符合正则表达式的规则 数值检查，建议使用在Stirng,Integer类型，不建议使用在int类型上，因为表单值为“”时无法转换为int，但可以转换为Stirng为"",Integer为null@Min 验证 Number 和 String 对象是否大等于指定的值 @Max 验证 Number 和 String 对象是否小等于指定的值 @DecimalMax 被标注的值必须不大于约束中指定的最大值. 这个约束的参数是一个通过BigDecimal定义的最大值的字符串表示.小数存在精度@DecimalMin 被标注的值必须不小于约束中指定的最小值. 这个约束的参数是一个通过BigDecimal定义的最小值的字符串表示.小数存在精度@Digits 验证 Number 和 String 的构成是否合法 @Digits(integer=,fraction=) 验证字符串是否是符合指定格式的数字，interger指定整数精度，fraction指定小数精度。 @Range(min=, max=) 检查数字是否介于min和max之间.@Range(min=10000,max=50000,message="range.bean.wage")private BigDecimal wage; @Valid 递归的对关联对象进行校验, 如果关联对象是个集合或者数组,那么对其中的元素进行递归校验,如果是一个map,则对其中的值部分进行校验.(是否进行递归验证) @CreditCardNumber 信用卡验证@Email 验证是否是邮件地址，如果为null,不进行验证，算通过验证。@ScriptAssert(lang= ,script=, alias=) @URL(protocol=,host=, port=,regexp=, flags=)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springBoot集成RestTemplate]]></title>
      <url>%2F2018%2F12%2F03%2FspringBoot%E9%9B%86%E6%88%90RestTemplate%2F</url>
      <content type="text"><![CDATA[SpringBoot集成RestTemplate构造restful风格的api1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@RestControllerpublic class DepetController &#123; @Resource private DeptService deptService; /** * 根据Id查找 * @param id * @return */ @GetMapping("/dept/&#123;id&#125;") public Dept getDept(@PathVariable("id") Integer id)&#123; Dept dept = deptService.getDeptById(id); return dept; &#125; /** * 分页获取列表 * @param pageNum * @param pageSize * @return */ @GetMapping("/dept") public List&lt;Dept&gt; getDeptList(Integer pageNum,Integer pageSize)&#123; return deptService.getDeptList(pageNum,pageSize); &#125; /** * 添加dept * @param dept * @return */ @PostMapping("/dept") public Dept addDepet(@RequestBody Dept dept)&#123; Dept dept1=deptService.addDept(dept); return dept1; &#125; /** * 修改dept * @param dept * @return */ @PutMapping("/dept") public boolean modifyDept(@RequestBody Dept dept)&#123; return deptService.modifyDept(dept); &#125; /** * 根据Id删除 * @param id * @return */ @DeleteMapping("/dept/&#123;id&#125;") public boolean deleteDept(@PathVariable("id") Integer id)&#123; return deptService.deleteDept(id); &#125;&#125; 注入 在使用之前需要在配置文件中注入，如下： 123456789101112131415@Configurationpublic class RestConfig &#123; @Bean public RestTemplate restTemplate(ClientHttpRequestFactory factory) &#123; return new RestTemplate(factory); &#125; @Bean public ClientHttpRequestFactory simpleClientHttpRequestFactory() &#123; SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory(); factory.setReadTimeout(5000);//单位为ms factory.setConnectTimeout(5000);//单位为ms return factory; &#125;&#125; 注入之后即可直接使用了 详解GET（获取数据）生产 安全幂等操作 先创建一个GET请求的controller，如下： 12345678910111213/** * 通过get请求方式 * @param id * @param name * @return */@GetMapping("/dept/&#123;id&#125;/&#123;name&#125;")public Dept getDept(@PathVariable("id") Integer id,@PathVariable("name")String name)&#123; Dept dept=new Dept(); dept.setDepetId(id); dept.setDepetName(name); return dept;&#125; 消费 public &lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) 123456789101112/** * 使用RestTemplate的getForObject()发出get请求 */@GetMapping("/consumer/&#123;id&#125;/&#123;name&#125;")public Dept getDept(@PathVariable("id")Integer id,@PathVariable("name") String name) throws RestClientException, URISyntaxException&#123; //使用一个Map封装Get请求的参数，其中key一定要和uri中的占位符一致 Map&lt;String, Object&gt; params=new HashMap&lt;String, Object&gt;(); params.put("id", id); params.put("name", name); Dept dept = restTemplate.getForObject(URL_PRFIX+"&#123;id&#125;/&#123;name&#125;", Dept.class,params); return dept;&#125; public &lt;T&gt; T getForObject(URI url, Class&lt;T&gt; responseType) 123456789/** * 使用RestTemplate的getForObject()发出get请求 */@GetMapping("/consumer/&#123;id&#125;/&#123;name&#125;")public Dept getDept(@PathVariable("id")Integer id,@PathVariable("name") String name) throws RestClientException, URISyntaxException&#123; //直接在uri中拼接参数 Dept dept = restTemplate.getForObject(URL_PRFIX+id+"/"+name, Dept.class); return dept;&#125; public &lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Object... uriVariables) 123456789/** * 使用RestTemplate的getForObject()发出get请求 */@GetMapping("/consumer/&#123;id&#125;/&#123;name&#125;")public Dept getDept(@PathVariable("id")Integer id,@PathVariable("name") String name) throws RestClientException, URISyntaxException&#123; //使用&#123;id&#125;作为一个占位符，第三个参数是用来设置这个占位符的值，当然可以有多个占位符 Dept dept = restTemplate.getForObject(URL_PRFIX+"&#123;id&#125;/&#123;name&#125;", Dept.class, id,name); return dept;&#125; 以上三种形式的请求都是大同小异的，只是入参的方式不同罢了 POST（新建、添加） 不安全 public &lt;T&gt; T postForObject(URI url, @Nullable Object request, Class&lt;T&gt; responseType) 第一个参数是请求的uri 第二个参数是添加的数据 第三个是返回的数据类型 public &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType,Map&lt;String, ?&gt; uriVariables) 前三个参数同上 第四个参数是用来封装过滤参数的（?后面的） public &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType,Object... uriVariables) 同上 12345678/** * 新建数据 */@PostMapping("/dept")public Dept addDept(@RequestBody Dept dept) throws RestClientException, URISyntaxException&#123; Dept dept2 = restTemplate.postForObject(new URI(URL_PRFIX), dept, Dept.class); return dept2;&#125; PUT（更新） public void put(URI url, @Nullable Object request) 第一个参数是地址 第二个参数是更新需要提交的数据 public void put(String url, @Nullable Object request, Object... uriVariables) 前两个参数同上 第二个参数是封装需要过滤的数据（？后面的数据） 12345678910/** * 更新数据 * @param dept * @throws RestClientException * @throws URISyntaxException */@PutMapping("/dept")public void modifyDept(@RequestBody Dept dept) throws RestClientException, URISyntaxException&#123; restTemplate.put(new URI(URL_PRFIX), dept);&#125; DELETE（删除） public void delete(URI url) 第一个参数是地址 public void delete(String url, Object... uriVariables) 第一个参数是地址 第二个参数是过滤参数（？后面的） public void delete(String url, Map&lt;String, ?&gt; uriVariables) 第二个参数是过滤参数（？后面的） 12345678/** * 删除数据 * @param id */@DeleteMapping("/dept/&#123;id&#125;")public void delete(@PathVariable("id")Integer id)&#123; restTemplate.delete(URL_PRFIX+"/&#123;id&#125;", id);&#125; 参考文章 RESTful API 最佳实践 https://www.cnblogs.com/softidea/p/5977375.html https://blog.csdn.net/itguangit/article/details/80198895]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java nio]]></title>
      <url>%2F2018%2F12%2F01%2Fjava-nio%2F</url>
      <content type="text"><![CDATA[缓冲区（Buffer） 负责数据的存取，实际上就是一个数组，用于存储不同的数据 除了布尔类型之后，其他类型都有，最常用的就是ByteBuffer 常用的方法 allocate(int capacity)： 分配指定大小的缓冲区（非直接缓冲区） allocateDirect(int capacity)： 分配指定大小的缓冲区（直接缓冲区） put()：向缓冲区中存储数据 get(byte[] dst)：从缓冲区获取数据，这里的dst的容量必须和缓冲区的大小一致 get(byte[] dst,int offest,int length) ：读取指定长度的内容到dst中，这里的dst容量没有要求 flip()： 缓冲区从写模式切换到读模式 clear()：清空缓冲区，数据依然存在，只是处于一个“被遗忘”状态，改变的只是limit和position array() ：返回实现此缓冲区的 byte 数组 mark()： 标记当前位置（position） reset()：恢复到mark的位置 核心属性 capacity：容量，表示缓冲区的最大容量，一旦声明不能改变 limit： 界限，缓冲区中可以操作的数据的大小，实际存储数据的大小，limit之后的数据不能进行读写 position：位置，表示缓冲区中正在操作数据的位置 position&lt;=limit&lt;=capacity 12345678910111213141516@Testpublic void test1()&#123; String str="abcd"; ByteBuffer buffer=ByteBuffer.allocate(1024);//分配1024个字节大小的缓冲区 buffer.put(str.getBytes()); //写入数据 System.out.println(buffer.capacity()); //容量 1024 System.out.println(buffer.limit()); //界限，1024 System.out.println(buffer.position()); //正在操作数据的位置 0 buffer.flip(); //切换到读模式，读取数据的时候一定要切换，否则将会没有界限 System.out.println(buffer.capacity()); //容量 1024 System.out.println(buffer.limit()); //界限，4，允许读取的位置只能到4，因为就存储了这么多的数据 System.out.println(buffer.position()); //正在操作数据的位置 0 System.err.println(buffer.get(4)); //超出界限了，下标记从0开始，0&lt;=index&lt;limit&#125; 实例 12345678910111213141516171819202122232425262728/** * 读取缓冲区中的数据到指定的字节数组中 * 1、字节数组的大小一定要和buffer.limit()一样大小，否则会报错 */@Testpublic void test2()&#123; String str="abcdefg"; ByteBuffer buffer=ByteBuffer.allocate(1024); //申请空间大小 buffer.put(str.getBytes()); //存入数据 buffer.flip(); //切换到读模式 //申请一个字节数组和实际数据一样大,这里必须和缓冲区的实际数据大小一样，否则将会报错 byte[] dst=new byte[buffer.limit()]; buffer.get(dst); //读取缓冲区的数据到dst字节数组中 System.out.println(new String(dst));&#125;/** * 读取一个字节 */@Testpublic void test3()&#123; String str="abcdefg"; ByteBuffer buffer=ByteBuffer.allocate(10); //申请空间大小 buffer.put(str.getBytes()); //存入数据 buffer.flip(); //切换到读模式 System.out.println((char)buffer.get());&#125; 测试remark和reset 123456789101112131415161718192021222324/** * 测试remark和rest */ @Test public void test1()&#123; ByteBuffer buffer=ByteBuffer.allocate(1024); String str="abcdcdscdscds"; buffer.put(str.getBytes()); //向缓冲区中写入数据 buffer.flip(); //切换到读的模式 byte[] dst=new byte[1024]; //创建byte数组 System.out.println("---------------------读取两个字节的数据----------------------------"); buffer.get(dst,0,2); //读取两个字节长度的数据到dst中，此时的position的位置位2 System.out.println(new String(dst)); System.out.println("----------------------标记此时的位置------------------------------"); buffer.mark(); //标记位置，此时的position的位置位2 System.out.println("---------------------继续读取两个字节的数据----------------------------"); buffer.get(dst,buffer.position(),2); //继续从当前位置读取两个字节到dst中 System.out.println(new String(dst)); System.out.println(buffer.position()); //此时的position的位置为4 System.out.println("---------------------重置缓冲区到remark的位置----------------------------"); buffer.reset(); //重置缓冲区到rmark的位置 System.out.println(buffer.position()); //此时的position为2 &#125; 直接缓冲区 直接字节缓冲区可以通过调用此类的 allocateDirect()工厂方法 来创建。此方法返回的 缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区 。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的机 本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。 非直接缓冲区 在JVM中内存中创建，在每次调用基础操作系统的一个本机IO之前或者之后，虚拟机都会将缓冲区的内容复制到中间缓冲区（或者从中间缓冲区复制内容），缓冲区的内容驻留在JVM内，因此销毁容易，但是占用JVM内存开销，处理过程中有复制操作。 写入步骤如下： 创建一个临时的直接ByteBuffer对象。 将非直接缓冲区的内容复制到临时缓冲中。 使用临时缓冲区执行低层次I/O操作。 临时缓冲区对象离开作用域，并最终成为被回收的无用数据。 通道（Channel） 通道是双向的，流是单向的 通道相当于输出和输入流 主要的实现类如下： FileChannel：文件的操作 SocketChannel：TCP ServerSocketChannel：TCP DatagramChannel：UDP 获取通道 本地IO，提供了getChannel()方法获取通道 FileInputStream FileOutputStram RandomAccessFile 在JDK1.7中的NIO，针对各个通道提供了静态方法open() 在JDK1.7中的NIO的Files工具类的newByteChannel() 实例 利用通道实现文件的复制（非直接缓冲区） 123456789101112131415161718192021222324252627/** * 使用getChannel获取通道,实现文件的复制 * @throws IOException */@Testpublic void test1() throws IOException&#123; FileInputStream inputStream=new FileInputStream(new File("C:/images/lifecrystal.png")); FileOutputStream outputStream=new FileOutputStream(new File("C:/images/2.png")); FileChannel inchannel = inputStream.getChannel(); //获取通道，用于读取 FileChannel outchannel=outputStream.getChannel(); //获取通道，用于写入 ByteBuffer buffer=ByteBuffer.allocate(1024); //申请缓冲区 //将通道中的数据写入缓冲区 while (inchannel.read(buffer)!=-1) &#123; buffer.flip(); //切换到读模式 //将缓冲区中的数据写入通道 outchannel.write(buffer); buffer.clear(); //清空缓冲区，继续读取数据 &#125; //关闭通道 inchannel.close(); outchannel.close(); inputStream.close(); outchannel.close();&#125; 使用直接缓冲区完成文件的复制，使用open()的方法获取通道 1234567891011121314151617181920212223242526272829/** * 使用直接缓冲区完成文件的复制 * 使用open()的方法获取通道 * @throws IOException */ @Test public void test2() throws IOException&#123; //获取一个读取数据的通道，使用的读模式 FileChannel inchannel=FileChannel.open(Paths.get("C:/images/2.png"), StandardOpenOption.READ); /** * StandardOpenOption.CREATE : 如果文件不存在，那么就创建，如果存在将会覆盖，不报错 * StandardOpenOption.CREATE_NEW ： 如果不存在就创建，如果存在，将会报错 */ FileChannel outchannel=FileChannel.open(Paths.get("C:/images/3.png"), StandardOpenOption.CREATE,StandardOpenOption.WRITE,StandardOpenOption.READ); //创建一个内存映射文件，操作直接缓冲区，和allocatDirect()一样，MapMode.READ_ONLY表示只读的模式，用于读取 MappedByteBuffer inMappedBuff = inchannel.map(MapMode.READ_ONLY, 0, inchannel.size()); //创建一个内容映射文件，MapMode.READ_WRITE表示读写模式，可以读写 MappedByteBuffer outMappedBuffer = outchannel.map(MapMode.READ_WRITE, 0, inchannel.size()); byte[] dst=new byte[inMappedBuff.limit()]; //将数据读入到dst中 inMappedBuff.get(dst); //将数据从dst中读取到outMappedBuffer outMappedBuffer.put(dst); &#125; 通道之间指定进行数据传输 transferTo(long position,long count,WritableByteChannel target):将数据从通道写入可写的通道target中 transferFrom(ReadableByteChannel from,long position,long count)：将数据从通道from中读取到通道中 123456789101112131415161718192021222324252627 /** * 通道之间直接进行传输 * 1、transferTo(long position,long count,WritableByteChannel target):将数据从通道写入可写的通道target中 * 2、transferFrom(ReadableByteChannel from,long position,long count)：将数据从通道from中读取到通道中 * @throws IOException */ @Test public void test3() throws IOException&#123; //获取一个读取数据的通道，使用的读模式 FileChannel inchannel = FileChannel.open(Paths.get("C:/images/2.png"), StandardOpenOption.READ); /** * StandardOpenOption.CREATE : 如果文件不存在，那么就创建，如果存在将会覆盖，不报错 * StandardOpenOption.CREATE_NEW ： 如果不存在就创建，如果存在，将会报错 */ FileChannel outchannel=FileChannel.open(Paths.get("C:/images/4.png"), StandardOpenOption.CREATE,StandardOpenOption.WRITE,StandardOpenOption.READ); //将通道inchannel中的数据直接写入outchannel中 inchannel.transferTo(0, inchannel.size(), outchannel); //和上面一样的效果// outchannel.transferFrom(inchannel, 0, inchannel.size()); inchannel.close(); outchannel.close(); &#125; 分散读取 将通道中的数据分散到各个缓冲区中 12345678910111213141516171819202122232425262728/** * 分散读取：将通道中的数据写入各个缓冲区中，是按照顺序写入的，第一个缓冲区写满才会写入第二个缓冲区 * @throws IOException */@Testpublic void test4() throws IOException&#123; //创建读写模式的RandomAccessFile RandomAccessFile accessFile=new RandomAccessFile(new File("C:/images/2.png"), "rw"); FileChannel inchannel=accessFile.getChannel(); //读取 ByteBuffer buffer1=ByteBuffer.allocate(10); //第一个缓冲区，10个字节大小 ByteBuffer buffer2=ByteBuffer.allocate(1024);//第二个缓冲区 ByteBuffer[] dst=&#123;buffer1,buffer2&#125;; //分散读取 inchannel.read(dst); for (ByteBuffer byteBuffer : dst) &#123; byteBuffer.flip(); //切换到读的模式 &#125; //输出第一个缓冲区的数据 System.out.println(new String(buffer1.array())); //输出第二个缓冲区中的数据 System.out.println(new String(buffer2.array()));&#125; 聚集写入 将各个缓冲区的数据读入到通道中 1234567891011121314151617181920212223242526272829303132333435@Testpublic void test4() throws IOException&#123; //创建读写模式的RandomAccessFile RandomAccessFile accessFile=new RandomAccessFile(new File("C:/images/2.png"), "rw"); FileChannel inchannel=accessFile.getChannel(); //读取 ByteBuffer buffer1=ByteBuffer.allocate(10); //第一个缓冲区，10个字节大小 ByteBuffer buffer2=ByteBuffer.allocate(1024);//第二个缓冲区 ByteBuffer[] dst=&#123;buffer1,buffer2&#125;; //分散读取 inchannel.read(dst); for (ByteBuffer byteBuffer : dst) &#123; byteBuffer.flip(); //切换到读的模式 &#125; //输出第一个缓冲区的数据 System.out.println(new String(buffer1.array())); //输出第二个缓冲区中的数据 System.out.println(new String(buffer2.array())); System.out.println("---------------------聚集写入-------------------"); RandomAccessFile accessFile2=new RandomAccessFile(new File("C:/images/6.png"), "rw"); FileChannel outChannel=accessFile2.getChannel(); //写入数据的通道 //聚集写入，将数据从各个缓冲区中写入到通道中 outChannel.write(dst); inchannel.close(); outChannel.close(); &#125; NIO阻塞式 阻塞或者不阻塞是针对SocketChannel，ServerSocketChannel NIO中的套接字可以轻松在阻塞和非阻塞之间切换，这里我们使用NIO实现阻塞式的TCP数据传输 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * 客户端使用SocketChannel * 客户端使用SocketChannel中的write()方法向服务端发送数据，使用read()读取服务端返回的反馈 * 在数据发送完成之后如果不调用shutdownOutput告知服务端数据已传送完成，那么将会一直阻塞下去 * @throws Exception */ @Test public void testClient()throws Exception&#123; //获取通道 SocketChannel clientChannel = SocketChannel.open(new InetSocketAddress("127.0.0.1",9898)); FileChannel inchannel = FileChannel.open(Paths.get("C:/images/2.png"), StandardOpenOption.READ); ByteBuffer buffer=ByteBuffer.allocate(1024); //循环读取本地图片，并且发送到服务端 //1、先使用FileChannel将数据读取到缓冲区中 //2、再使用SocketChannel的write方法将缓冲区的数据发送到服务端 while(inchannel.read(buffer)!=-1)&#123; buffer.flip(); //切换读模式 clientChannel.write(buffer); //发送数据 buffer.clear(); //清空缓冲区 &#125; //告诉服务端数据已经传送完成，否则将会一直阻塞 clientChannel.shutdownOutput(); //接收服务端的反馈 //使用read()方法接收服务端的反馈，将其读入到缓冲区中 while(clientChannel.read(buffer)&gt;0)&#123; buffer.flip(); //切换读模式 System.out.println("服务端："+new String(buffer.array())); buffer.clear(); &#125; //关闭通道 inchannel.close(); clientChannel.close(); &#125; /** * 服务端使用ServerSocketChannel * 服务端使用SocketChannel的read()方法读取客户端发送的数据，使用write()方法向客户端返回数据 * @throws Exception */ @Test public void testServer()throws Exception&#123; //获取服务端的通道 ServerSocketChannel serverChannel = ServerSocketChannel.open(); //绑定连接 serverChannel.bind(new InetSocketAddress(9898)); //获取客户端的连接通道 SocketChannel clientChannel = serverChannel.accept(); //申请缓冲区 ByteBuffer byteBuffer=ByteBuffer.allocate(1024); FileChannel outChannel = FileChannel.open(Paths.get("C:/images/12.png"), StandardOpenOption.WRITE,StandardOpenOption.CREATE); //循环接收客户端发送过来的数据，并且将其保存在本地 while(clientChannel.read(byteBuffer)&gt;0)&#123; byteBuffer.flip(); //切换读模式 outChannel.write(byteBuffer); //写入到本地 byteBuffer.clear(); //清空缓冲区 &#125; //服务端发送反馈信息给客户端，使用的还是SocketChannel的write方法 byteBuffer.put("服务端接收数据成功".getBytes()); byteBuffer.flip(); //切换模式 clientChannel.write(byteBuffer); clientChannel.shutdownOutput(); //告知客户端传输完成 //关闭通道 outChannel.close(); clientChannel.close(); serverChannel.close(); &#125; Selector（选择器） 总的来说，选择器是对通道进行监听，这样就会避免阻塞的发生，实现了多路复用 SelectionKey 某个Channel成功连接到另一个服务器称为“ 连接就绪 ”。一个Server Socket Channel准备好接收新进入的连接称为“ 接收就绪 ”。一个有数据可读的通道可以说是“ 读就绪 ”。等待写数据的通道可以说是“ 写就绪 ”。 选择器是用来轮询监听通道的状态，其中有四种状态如下： SelectionKey.OP_CONNECT：连接就绪 SelectionKey.OP_ACCEPT：接收就绪 SelectionKey.OP_READ：读就绪 SelectionKey.OP_WRITE：写就绪 NIO非阻塞式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 客户端需要使用configureBlocking(false)设置成非阻塞模式的 * @throws Exception */@Testpublic void testClient()throws Exception&#123; //获取通道 SocketChannel client = SocketChannel.open(new InetSocketAddress("127.0.0.1",9898)); //切换成非阻塞模式 client.configureBlocking(false); ByteBuffer buf=ByteBuffer.allocate(1024); //申请缓冲区 Scanner scanner=new Scanner(System.in); while(scanner.hasNext())&#123; String line=scanner.next(); //读取控制台输入的内容 buf.put((new Date().toString()+"\n"+line).getBytes()); //向缓冲区写入数据 buf.flip(); //切换到读模式 client.write(buf); //向服务端发送数据 buf.clear(); //清空缓存区 &#125; scanner.close(); client.close();&#125;/** * 服务端 * 1、将通道注册到选择器中，并且指定监听的事件 * 2、程序每次都会轮询的从选择器中选择事件，可以选择不同状态的通道进行操作 * @throws Exception */@Testpublic void testServer()throws Exception&#123; //获取通道 ServerSocketChannel server = ServerSocketChannel.open(); //绑定端口 server.bind(new InetSocketAddress(9898)); //配置非阻塞 server.configureBlocking(false); //获取选择器 Selector selector = Selector.open(); //将通道注册到选择器上，并且知道指定监听的事件为"接收就绪" server.register(selector, SelectionKey.OP_ACCEPT); //轮询式获取选择器上已经准备就绪的事件 while(selector.select()&gt;0)&#123; //获取当前选择器中所有的选择键(已经准备就绪的) Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); //获取迭代器 Iterator&lt;SelectionKey&gt; iterator = keys.iterator(); //迭代器遍历所有的选择键 while(iterator.hasNext())&#123; //获取当前选择键 SelectionKey key = iterator.next(); iterator.remove(); //删除选择键 if (key.isAcceptable()) &#123; //如果接收就绪了 SocketChannel client = server.accept(); //获取SocketChannel client.configureBlocking(false); //设置非阻塞模式 client.register(selector, SelectionKey.OP_READ); //将此通道注册到选择器中，指定监听的事件是读就绪 &#125;else if(key.isReadable())&#123; //如果读就绪 SocketChannel client = (SocketChannel) key.channel(); //读就绪了，那么可以获取通道直接读取数据 ByteBuffer buf=ByteBuffer.allocate(1024); //声明一个缓冲区 //循环接收客户端的到缓冲区中 int len=0; while((len=client.read(buf))&gt;0)&#123; buf.flip(); System.out.println(new String(buf.array(),0,len)); buf.clear(); &#125; &#125;else if (key.isWritable()) &#123; //如果写就绪 &#125;else if (key.isConnectable()) &#123; //如果连接就绪 &#125; &#125; &#125; server.close();&#125; 参考文章 https://www.cnblogs.com/tengpan-cn/p/5809273.html 并发编程网 http://www.cnblogs.com/snailclimb/p/9086334.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[消息中间件之Rabbitmq]]></title>
      <url>%2F2018%2F11%2F15%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E4%B9%8BRabbitmq%2F</url>
      <content type="text"><![CDATA[RabbitMQ【消息中间件】介绍 RabbitMQ是实现AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。RabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。 AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 安装 docker pull rabbitmq:3.7-management docker run --name rabbitmq -p 15672:15672 -p 5672:5672 -d df80af9ca0c9 安装运行成功之后访问：http://[ip]:15672即可登录 四种类型的交换器（exchange） https://baijiahao.baidu.com/s?id=1577456875919174629&amp;wfr=spider&amp;for=pc direct（点对点、单播，直连） 直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的 fanout（扇形，广播模式，订阅模式） 扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列。不同于直连交换机，路由键在此类型上不启任务作用。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的发送给这所有的N个队列 路由键对这个交换机 不起作用，只要发送给扇形交换机的消息，那么都会发送给和其绑定的所有队列 topic（主题） 直连交换机的routing_key方案非常简单，如果我们希望一条消息发送给多个队列，那么这个交换机需要绑定上非常多的routing_key，假设每个交换机上都绑定一堆的routing_key连接到各个队列上。那么消息的管理就会异常地困难。 所以RabbitMQ提供了一种主题交换机，发送到主题交换机上的消息需要携带指定规则的routing_key，主题交换机会根据这个规则将数据发送到对应的(多个)队列上。 主题交换机的routing_key需要有一定的规则，交换机和队列的binding_key需要采用*.#.*.....的格式，每个部分用.分开，其中： *表示一个单词 rabbit.*能够匹配到rabbit.new rabbit.*不能够匹配到rabbit.new.old #表示任意数量（零个或多个）单词。 rabbit.#能够匹配到rabbit.new rabbit.#能够匹配到rabbit.new.old 假设有一条消息的routing_key为fast.rabbit.white,那么带有这样binding_key的几个队列都会接收这条消息 header（头，首部） 类似主题交换机，但是头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。 此交换机有个重要参数：”x-match” 当”x-match”为“any”时，消息头的任意一个值被匹配就可以满足条件 交换机属性 除交换机类型外，在声明交换机时还可以附带许多其他的属性，其中最重要的几个分别是： Name：交换机名称 Durability：是否持久化。如果持久性，则RabbitMQ重启后，交换机还存在 Auto-delete：当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它 Queue【队列】 基本的属性如下： name：名称 durable：是否持久化，如果不持久化，那么重启后将会不存在 exclusive：独享（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） autoDelete：自动删除，当最后一个消费者退订后即被删除 arguments：其他 springBoot整合RabbitMQ入门 添加依赖 12345&lt;!-- rabbitmq启动器 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 配置连接信息 12345spring.rabbitmq.host=192.168.0.86 ## 主机地址spring.rabbitmq.port=5672 ## 端口spring.rabbitmq.username=admin ## 用户名spring.rabbitmq.password=123456 ## 密码spring.rabbitmq.virtual-host=/ ## 虚拟主机，这里的用户名和密码一定要对这个虚拟主机有权限 配置一个Topic交换机和对应的队列，配置类如下，会自动创建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Topic交换机的配置类 * 1、配置完成之后，当使用到的时候会自动创建，不需要手动的创建，当然使用rabbitAdmin也是可以手动创建的 */@Configuration //指定这是一个配置类public class TopicConfig &#123; /** * 创建队列 queue1 * @return */ @Bean public Queue queue1()&#123; return new Queue("queue_1",true); &#125; /** * 创建队列 queue2 * @return */ @Bean public Queue queue2()&#123; //指定名称和持久化 return new Queue("queue_2",true); &#125; /** * 创建topic交换机 */ @Bean public TopicExchange topic1()&#123; return new TopicExchange("topic_1"); &#125; /** * 将交换机topic1和队列queue1通过路邮键message_1绑定在一起 * @param topic1 交换机1 ，这里通过名称匹配，因为是通过@Bean自动注入的 * @param queue1 队列1 这里通过名称匹配，因为是通过@Bean自动注入的 * @return */ @Bean public Binding bindTopic1AndQueu1(TopicExchange topic1,Queue queue1 )&#123; return BindingBuilder.bind(queue1).to(topic1).with("message_1"); &#125; /** * 将交换机topic1和队列queue2通过路邮键message_2绑定在一起 * @param topic1 * @param queue1 * @return */ @Bean public Binding bindTopic1AndQueu2(TopicExchange topic1,Queue queue2 )&#123; return BindingBuilder.bind(queue2).to(topic1).with("message_2"); &#125; &#125; 启动类添加注解@EnableRabbit 1234567891011121314@EnableRabbit //开启rabbitmq@SpringBootApplicationpublic class DemoApplication extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125; //继承SpringBootServletInitializer实现war包的发布 @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(DemoApplication.class); &#125;&#125; 发送消息和接受消息 1234567891011121314151617181920@Servicepublic class RabbitServiceImpl implements RabbitServie &#123; @Resource private RabbitTemplate rabbitTemplate发送消息; //使用rabbitTemplate发送消息 @Override public void send() &#123; Map&lt;String, Object&gt; map=new HashedMap(); map.put("name", "陈加兵"); rabbitTemplate.convertAndSend("topic_1", "message_1", map); &#125; //使用rabbitTemplate接收消息 @Override public void get() &#123; Map&lt;String, Object&gt; map=(Map&lt;String, Object&gt;) rabbitTemplate.receiveAndConvert("queue_1"); System.out.println(map); &#125; &#125; RabbitTemplate springBoot自动注入，直接使用即可 实体类发送消息之前一定需要序列化 用于发送和接收消息 方法 void convertAndSend(String exchange, String routingKey, final Object object) ：发送消息 exchange：交换机 routingKey：路由键 object ：需要发送的对象 Object receiveAndConvert(String queueName)：接收指定队列的消息 queueName：消息队列的名字 RabbitAdmin springBoot已经为我们自动注入了AmqpAdmin，用于创建交换机、队列、绑定 123456789 @Bean @ConditionalOnSingleCandidate(ConnectionFactory.class) @ConditionalOnProperty(prefix = "spring.rabbitmq", name = "dynamic", matchIfMissing = true) @ConditionalOnMissingBean public AmqpAdmin amqpAdmin(ConnectionFactory connectionFactory) &#123; return new RabbitAdmin(connectionFactory); &#125;&#125; 测试类如下： 12345678910111213141516171819202122@RunWith(SpringRunner.class)@SpringBootTest // springBoot测试类，可以自定义测试类，不过需要引用这两个注解public class RabbitMqTest &#123; @Resource private AmqpAdmin amqpAdmin; //自动注入即可 @Test public void test4() &#123; DirectExchange directExchange = new DirectExchange("test_direct"); Queue queue = new Queue("direct_1", true); // 创建一个直连的交换机 amqpAdmin.declareExchange(directExchange); // 创建一个队列 amqpAdmin.declareQueue(queue); //创建绑定关系 amqpAdmin.declareBinding(BindingBuilder.bind(queue) .to(directExchange).with("direct_message")); &#125;&#125; 消息监听 消息监听使用的注解是@RabbitListener，可以监听指定的队列，一旦这个队列中有消息了，那么就会执行 在启动类上添加@EnableRabbit开启基于注解的rabbit的消息监听 @RabbitListener 消息监听的注解，可以监听一个或者多个队列，一旦队列中有了信息，那么就会执行，一旦被执行就意味着这条消息被消费了（不一定，后面会讲到消息确认机制，这里是默认会被消费的） 123456789101112131415161718192021222324252627282930/** * rabbitmq的消息处理类 * @author 陈加兵 */@Component //注入public class MessageHandler &#123; /** * 使用@RabbitListener这个注解监听指定的队列，一旦这个队列有了消息，那么将会执行 * @param log 消息的内容，如果接收的消息内容是log对象，那么将会被反序列化，存入这个log中 * 消息一旦被监听到了并且被执行了，那么这条队列的消息将会被删除了 */ @RabbitListener(queues=&#123;"direct_1"&#125;) public void received(Log log)&#123; System.out.println("------接收到消息----"); System.out.println("消息内容为："+log); &#125; /** * 使用org.springframework.amqp.core.Message对象来接收消息，可以显示消息头一些信息 * @param message */ @RabbitListener(queues=&#123;"direct_1"&#125;) public void received1(Message message)&#123; System.out.println("------接收到消息1----"); byte[] body=message.getBody(); System.out.println(message.getMessageProperties()); &#125;&#125; @RabbitHandler @RabbitListener 可以标注在类上面，需配合 @RabbitHandler 注解一起使用 @RabbitListener标注在类上面表示当有收到消息的时候，就交给 @RabbitHandler 的方法处理，具体使用哪个方法处理，根据 MessageConverter 转换后的参数类型 1234567891011121314151617181920212223242526272829/** * 处理消息的类，使用@RabbitListener监听队列，结合@RabbitHandler处理不同内容类型的消息 * @author Administrator * */@RabbitListener(queues=&#123;"direct_1"&#125;) //监听direct_1这个队列的消息@Component //注入public class RabbitMessage &#123; /** * 定义处理的方法是接收内容的类型为Log类型 * @param log */ @RabbitHandler public void receivedLog(Log log)&#123; System.out.println("接收了log对象"); System.out.println(log); &#125; /** * 定义接收内容为User类型的消息 * @param user */ @RabbitHandler public void receivedMap(User user)&#123; System.out.println("接收了user对象"); System.out.println(user); &#125;&#125; 消息确认（SpringBoot整合） 消息确认可以分为事务模式（类似jdbc的操作），confirm模式（可以使用异步回调模式，更加高效） rabbitmq默认是自动确认的，即是一条消息被发送了或者被消费了，无论你生产者或者消费者有没有发送或者消费成功，那么都是自动确认为已发送或者已接收了，但是在业务中接收了一条消息不一定就是成功消费了，如果这个业务没有正常完成，我们希望的是能够消息回滚，就像是mysql的事务机制，因此此时我们就需要手动确认这条消息被消费了，而不是自动确认 消息确认可以分为事务模式（类似jdbc的操作），confirm模式，具体的可以参考https://blog.csdn.net/u013256816/article/details/55515234 confirm模式 confirm不同于事务模式的地方是可以使用异步的确认模式 在配置文件中配置，如下： 1234567# 开启发送确认spring.rabbitmq.publisher-confirms=true# 开启发送失败退回spring.rabbitmq.publisher-returns=true# 开启ACK，开启之后只有手动提交才会消费消息spring.rabbitmq.listener.direct.acknowledge-mode=manualspring.rabbitmq.listener.simple.acknowledge-mode=manual 发送消息的确认 ConfirmCallback ： 这个是rabbitmq的确认的回调接口，当消息发送之后，会异步调用实现这个接口的方法 ReturnCallback ：这个是rabbitmq的失败回调接口，当消息发送失败之后，会异步调用实现这个接口的方法 一个消息的发送的业务类如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 消息发送的业务层 * SendMessageService ： 发送消息的接口 * ConfirmCallback ： 消息发送成功的回调接口 * ReturnCallback ： 消息发送失败的回调接口（找不到对应的路由或者因为各种原因消息没有成功投递到rabbitmq中都会出发回调） * @author 陈加兵 * @since 2018年11月15日 下午4:45:37 */@Servicepublic class SendMessageServiceImpl implements SendMessageService,ConfirmCallback,ReturnCallback &#123; @Resource private RabbitTemplate rabbitTemplate; //注入rabbitMq的template，用于发送和消费消息 private Logger logger=LoggerFactory.getLogger(SendMessageServiceImpl.class); //日志 /** * 消息发送失败的回调方法,实现ReturnCallback接口的方法 * 1、消息没有投递成功,包括没有找到对应的队列或者路由键 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; logger.info("返回的失败代码="+replyCode+" 返回的失败信息="+replyText); logger.info("交换机="+exchange+" 绑定的路由键="+routingKey); &#125; /** * 消息发送确认的回调方法 * 如果消息没有到exchange,则confirm回调,ack=false * 如果消息到达exchange,则confirm回调,ack=true * 判断消息有没有成功发送，只需要判断ack的值，correlationData是发送消息的时候传递过来的值（String） */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; //如果ack==true，表示消息发送成功 if (ack) &#123; logger.info("消息发送成功,下面开始处理业务。。。。。。。。。。。。。。。"); logger.info("correlationData="+correlationData); &#125;else &#123; logger.info("消息发送失败。。。。。。。。。。。。。。。。"); logger.info("cause="+cause); &#125; &#125; /** * 发送消息的方法 */ @Override public void sendMessage(Log log) throws Exception &#123; rabbitTemplate.setConfirmCallback(this); //设置 rabbitTemplate.setReturnCallback(this); CorrelationData data=new CorrelationData(); data.setId("success"); //定义内容，在消息发送成功的回调方法中可以获取这个值 rabbitTemplate.convertAndSend("amq.direct", "message", log,data); //发送消息 &#125;&#125; 消费消息的确认 开启ack之后，默认是不会自动消费的，只有手动ack才会被消费 手动ack和nack使用的类是com.rabbitmq.client.Channel channel.basicAck() ：手动ack deliveryTag：该消息的index multiple：是否批量，如果为true将一次性ack所有小于deliveryTag的消息，如果为false，那么将ack当前的消息 channel.basicNack(deliveryTag, multiple, requeue) deliveryTag：该消息的index multiple：是否批量，如果为true将一次性ack所有小于deliveryTag的消息，如果为false，那么将ack当前的消息 requeue：被丢弃消息是否重新进入队列，如果是true将会重新进入队列 实例如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.io.IOException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import com.rabbitmq.client.Channel;import com.techwells.demo.domain.Log;/** * 监听队列direct_1 * @author 陈加兵 * @since 2018年11月15日 下午6:55:56 */@Component@RabbitListener(queues=&#123;"direct_1"&#125;)public class ReceivedMessageHandler &#123; private Logger logger=LoggerFactory.getLogger(ReceivedMessageHandler.class); /** * 接收消息类型为Log的消息 * 如果不手动提交的话，默认是不会被自动确认消费的，只有手动提交了，才会被真正的消费 * @param log 消息的实体类 * @param channel * @param message rabbitmq的Message类 * @throws IOException */ @RabbitHandler //处理消息 public void handleMessage(Log log,Channel channel,Message message) throws IOException&#123; logger.info("成功接收到消息........"+log); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); //手动提交ack，消费消息// channel.basicNack(message.getMessageProperties().getDeliveryTag(), true, true); logger.info("成功被消费。。。。。。。。。。"); &#125; /** * 处理消息类型为String类型的消息 * @param str * @param channel * @param message * @throws IOException */ @RabbitHandler //处理消息 public void handleStringMessage(String str,Channel channel,Message message) throws IOException&#123; logger.info("成功接收到消息........"+str); channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true); //nack，不消费这条消息，一般是业务失败才会不消费 &#125;&#125; 参考文章1、https://www.kancloud.cn/yunxifd/rabbitmq/96997 2、中文文档 3、https://www.cnblogs.com/ityouknow/p/6120544.html 4、事务 5、ACK]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java自定义注解]]></title>
      <url>%2F2018%2F11%2F03%2Fjava%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[自定义注解【Annotation】元注解@Retention 表示需要在什么级别保存该注解信息 。分为如下三类： @Retention(RetentionPolicy.SOURCE)：注解仅存在于源码中，在class字节码文件中不包含 @Retention(RetentionPolicy.CLASS)：默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得 @Retention(RetentionPolicy.RUNTIME)： 注解会在class字节码文件中存在，在运行时可以通过反射获取到 @Target 注解的作用目标 取值 作用域 @Target(ElementType.TYPE) 接口、类、枚举、注解 @Target(ElementType.FIELD) 字段、枚举的常量 @Target(ElementType.METHOD) 方法 @Target(ElementType.PARAMETER) 方法参数 @Target(ElementType.CONSTRUCTOR) 构造函数 @Target(ElementType.LOCAL_VARIABLE) 局部变量 @Target(ElementType.ANNOTATION_TYPE) 注解 @Target(ElementType.PACKAGE) 包 @Document 注解包含在javadoc中 @Inherited 注解可以被继承 关于注解的反射方法1234567891011121314151617// 获取某个类型的注解public &lt;A extends Annotation&gt; A getAnnotation(Class&lt;A&gt; annotationClass);// 获取所有注解(包括父类中被Inherited修饰的注解)public Annotation[] getAnnotations(); // 获取声明的注解(但是不包括父类中被Inherited修饰的注解)public Annotation[] getDeclaredAnnotations();// 判断某个对象上是否被某个注解进行标注public boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass)// 获取某个类声明的所有字段public Field[] getDeclaredFields() throws SecurityException;// 获取某个方法public Method getMethod(String name, Class&lt;?&gt;... parameterTypes); 五种通知 @Before：前置通知，在调用目标方法之前执行通知定义的任务 @After：后置通知，在目标方法执行结束后，无论执行结果如何（异常或者正常执行）都执行通知定义的任务 @After-returning：后置通知，在目标方法执行结束后，如果执行成功（没有异常），则执行通知定义的任务 @After-throwing：异常通知，如果目标方法执行过程中抛出异常，则执行通知定义的任务 @Around：环绕通知，在目标方法执行前和执行后，都需要执行通知定义的任务 JoinPoint 对象 方法名 功能 Signature getSignature(); 获取封装了署名信息的对象,在该对象中可以获取到目标方法名,所属类的Class等信息 Object[] getArgs(); 获取传入目标方法的参数对象 Object getTarget(); 获取被代理的对象 Object getThis(); 获取代理对象 实战 使用springBoot，需要 添加aop相关的依赖，如下： 12345&lt;!-- springBoot的aop功能启动器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 日志 实际的生产环境中会对每个都记录日志，比如xxx用户执行了xxx操作，这些日志如果都使用一个方法的话，未免太不雅，此时我们可以定义一个注解，使用spring中的aop，在方法执行成功之后记录日志信息，步骤如下： 定义一个注解，使用@Interface 12345678910111213import java.lang.annotation.*;/** * 定义日志的注解，作用在方法上 * @author 陈加兵 * @since 2018年11月3日 上午11:53:59 */@Target(&#123;ElementType.PARAMETER, ElementType.METHOD&#125;) //作用在方法上面@Retention(RetentionPolicy.RUNTIME) //程序运行 @Documented public @interface InsertLog &#123; String name() default ""; //用户名 String operation() default ""; //操作&#125; 定义一个注解的实现类，使用aop实现该注解 123456789101112131415161718192021222324252627282930313233343536@Component //注入@Aspect //切面public class InsertLogAnnotation &#123; @Resource private LogService logService; //日志的service，用来记录日志 /** * 1、@pointCut：定义切入点，其中支持多种表达式来匹配切入点，这里的annotation是用来匹配注解的 * 2、@annotation的参数必须和这个方法的参数字段相同，因为这里表示的扫描的哪个注解 * 3、这个切入点的 意思：只要被`@InsertLog`这个注解标注的都会被扫描到成为切入点 * @param log 注解的对象 */ @Pointcut("@annotation(log)") public void insertLog(InsertLog log)&#123;&#125; /** * `@AfterReturning`:定义后置通知，只有程序执行成功才会调用该注解，用来添加操作的日志 * `insertLog(log)`: 这里的log一定要和上面定义切入点(@Pointcut)中的参数字段一样 * @param point JoinPoint对象，可以获取一些切面信息，比如调用的类，调用的方法名称 * @param log 该注解的对象，可以获取注解中参数的内容 * @throws Exception */ @AfterReturning("insertLog(log)") public void SystemLog(JoinPoint point,InsertLog log) throws Exception&#123; //获取注解中的参数内容 String name=log.name(); //姓名 String operation=log.operation(); //操作 Log log2=new Log(); log2.setName(name); log2.setOperation(operation); logService.addLog(log2); //添加到日志中 &#125; 此时就已经完成了，我们只需要将该注解添加到需要记录日志的方法上即可，如下： 12345@InsertLog(name="陈加兵",operation="删除用户") //使用日志注解，在程序执行成功之后记录日志public Object deleteUserById(Integer userId) &#123; System.out.println("删除成功"); return null;&#125; 完整的项目截图如下： 性能监控 可以定义一个注解实现性能监控，设置一个环绕通知即可，在程序执行开始和结束之后统计时间即可 定义一个注解，如下： 123456789101112import java.lang.annotation.*;/** * 性能监控的注解 * @author 陈加兵 * @since 2018年11月3日 下午1:08:30 */@Target(&#123;ElementType.PARAMETER, ElementType.METHOD&#125;) //作用在方法上面@Retention(RetentionPolicy.RUNTIME) //程序运行 @Documentedpublic @interface CapabilityMonitor &#123;&#125; 定义注解的实现类，使用切面的环绕通知 123456789101112131415161718192021222324252627282930313233/** * 性能监控注解的实现类 * @author 陈加兵 * @since 2018年11月3日 下午1:09:40 */@Aspect //切面@Component //注入public class CapabilityMonitorAnnotationImpl &#123; private Logger logger=LoggerFactory.getLogger(CapabilityMonitorAnnotationImpl.class); //selfj的日志信息 /** * 定义切入点，只要方法体上有这个注解 * @param capabilityMonitor 注解的对象 */ @Pointcut("@annotation(capabilityMonitor)") public void capabilityMonitor(CapabilityMonitor capabilityMonitor)&#123;&#125; /** * 环绕通知，在方法执行之前和之后都执行 * capabilityMonitor(capabilityMonitor)：这里的参数一定要和切入点（`@Pointcut("@annotation(capabilityMonitor)")`）的参数相同 * @param point * @param capabilityMonitor 注解的对象 * @throws Throwable */ @Around("capabilityMonitor(capabilityMonitor)") public void execute(ProceedingJoinPoint point,CapabilityMonitor capabilityMonitor) throws Throwable&#123; Long startTime=System.currentTimeMillis(); //开始时间 Object[] args=point.getArgs(); //获取目标方法执行的参数数组 Object returnValues=point.proceed(args); //执行目标方法 Long endTime=System.currentTimeMillis(); //结束时间 logger.info("程序执行的时间："+((endTime-startTime)/1000.0)); //输出程序执行的时间，秒位单位 &#125;&#125; 输出错误日志到文件中 定义日志注解，如下： 12345678910/** * 输出日志信息到日志文件的注解 * @author 陈加兵 * @since 2018年11月7日 下午5:52:55 */@Target(&#123;ElementType.PARAMETER, ElementType.METHOD&#125;) //作用在方法上面@Retention(RetentionPolicy.RUNTIME) //程序运行 @Documentedpublic @interface PrintLog &#123;&#125; 注解的实现类，结合aop实现 123456789101112131415161718192021222324@Component@Aspectpublic class PrintLogAnnotationImpl &#123; /** * 定义切入点，凡是方法体上标注@PrintLog这个注解都会被增强 * @param printLog */ @Pointcut("@annotation(printLog)") public void printLog(PrintLog printLog)&#123;&#125; /** * 在程序之后执行并且在出现异常的时候才会执行 * @param point JoinPoint对象，用于获取切入点的信息，比如被增加的类，被增强的方法名称、方法传入的参数等信息 * @param printLog 注解的接口信息，可以获取接口的信息 * @param message 异常信息 */ @AfterThrowing(value="printLog(printLog)",throwing="message") public void excute(JoinPoint point,PrintLog printLog,Throwable message)&#123; Class targetCls=point.getTarget().getClass(); //获取目标类 Logger logger = LoggerFactory.getLogger(targetCls); logger.error("异常信息：",message); &#125;&#125; 只需要在方法上标注这个注解，只要是遇到异常信息，就会自动写入日志文件中 参考文章 aop的相关知识点 spring aop]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot整合Swagger]]></title>
      <url>%2F2018%2F10%2F22%2FSpringBoot%E6%95%B4%E5%90%88Swagger%2F</url>
      <content type="text"><![CDATA[SpringBoot整合Swagger依赖12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Contact;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;/** * Swagger的配置类 * @author 陈加兵 * */@Configurationpublic class SwaggerConfig &#123; /** * 创建用户API文档 * @return */ @Bean public Docket createRestUserApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .groupName("user") .apiInfo(apiInfo()) //api的信息 .select() .apis(RequestHandlerSelectors .basePackage("cn.tedu.mycat.controller")) //添加包扫描 .paths(PathSelectors.any()).build(); &#125; /** * 创建API信息 */ private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("api文档的标题") //标题 .description("api文档的描述") //描述 .contact( //添加开发者的一些信息 new Contact("爱撒谎的男孩", "https://chenjiabing666.github.io", "18796327106@163.com")).version("1.0").build(); &#125;&#125; 启动类 在springBoot的启动类上添加一个注解即可配置成功：@EnableSwagger2 访问api的路径 http://ip/projectName/swagger-ui.html ：html的页面 http://localhost:8080/demo/v2/api-docs：这个是json数据的页面 注解说明@Api 标注在类上，用来对这个类进行说明的 如果想要生成文档，必须在类或者接口上标注 属性如下： 属性名称 备注 默认值 value url的路径值 tags 如果设置这个值、value的值会被覆盖 description 对api资源的描述 basePath 基本路径可以不配置 position 如果配置多个Api 想改变显示的顺序位置 produces For example, “application/json, application/xml” consumes For example, “application/json, application/xml” protocols Possible values: http, https, ws, wss. authorizations 高级特性认证时配置 hidden 配置为true 将在文档中隐藏 @ApiOperation 用在API方法上，对该API做注释，说明API的作用 不需要多讲，看源码，使用默认的value属性即可，说明该方法的作用 属性如下： value url的路径值 tags 如果设置这个值、value的值会被覆盖 notes 对api资源的描述 response 返回的对象，在文档中点击Model可以获取该配置的内容 responseContainer 这些对象是有效的 “List”, “Set” or “Map”.，其他无效 responseReference 可以不配置 httpMethod 可以接受 “GET”, “HEAD”, “POST”, “PUT”, “DELETE”, “OPTIONS” and “PATCH” position 如果配置多个Api 想改变显示的顺序位置 produces 同 Api中的定义 consumes 同 Api中的定义 protocols 同 Api中的定义 authorizations 同 Api中的定义 hidden 是否隐藏，true 或者false ，这个可以隐藏后台接口 code http的状态码 默认 200 extensions 扩展属性 @ApiImplicitParams 用来包含API的一组参数注解，可以简单的理解为参数注解的集合声明 很重要，这个注解其中包含接口入参的详细说明 内容是集合 @ApiImplicitParam 用在@ApiImplicitParams注解中，也可以单独使用，说明一个请求参数的各个方面 详细的属性使用说明如下： name：属性的字段名称，相当于form表单中的name，这个就是入参的字段 dataType：参数的类型，标识，字符串 value：该参数的描述 required：是否必填，布尔值 defaultValue：缺省值，会在文档中缺省填入，这样更方面造数据，不需要调用接口的去填值了 paramType：指定参数的入参数方式（也就是请求参数的位置），其中有四种常用的，如下： query path body form paramType属性的详细说明 query：必须要和入参的字段一样，也可以使用@RequestParam()指定 path：用于Restful的风格的url，请求的参数写在路径上，如下： 12345678@ApiOperation(value="根据用户Id获取用户信息",response=User.class,hidden=false) @ApiImplicitParams(&#123; @ApiImplicitParam(paramType = "path", name = "id", dataType="Integer", required = false, value = "用户的id", defaultValue = "1") &#125;) @GetMapping("/user/get/&#123;id&#125;") public Object getUser(@PathVariable("id")Integer id) &#123; return new User(id, "陈加兵"); &#125; body：以流的形式提交 仅支持POST form：以表单的形式提交 导出到markdown文件添加依赖1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- swagger自动生成文档依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger-version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--导出到markdown文件的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.swagger2markup&lt;/groupId&gt; &lt;artifactId&gt;swagger2markup&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.netzwerg&lt;/groupId&gt; &lt;artifactId&gt;paleo-core&lt;/artifactId&gt; &lt;version&gt;0.11.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/paleo-core-0.11.0.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;nl.jworks.markdown_to_asciidoc&lt;/groupId&gt; &lt;artifactId&gt;markdown_to_asciidoc&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/markdown_to_asciidoc-1.0.jar&lt;/systemPath&gt; &lt;/dependency&gt; 由于需要paleo-core和markdown_to_asciidoc，但是这两个依赖使用maven不能自动导入，只能使用本地jar的方式了 添加一个测试类1234567891011121314151617181920212223242526272829import java.net.URL;import java.nio.file.Path;import java.nio.file.Paths;import io.github.swagger2markup.GroupBy;import io.github.swagger2markup.Language;import io.github.swagger2markup.Swagger2MarkupConfig;import io.github.swagger2markup.Swagger2MarkupConverter;import io.github.swagger2markup.builder.Swagger2MarkupConfigBuilder;import io.github.swagger2markup.markup.builder.MarkupLanguage;/*** 生成Markdown文件的类*/public class SwaggerTest &#123; public static void main(String[] args) throws Exception &#123; Path outputFile = Paths.get("build/swagger"); //指定生成的目录和文件的名称swagger.md Swagger2MarkupConfig config = new Swagger2MarkupConfigBuilder() .withMarkupLanguage(MarkupLanguage.MARKDOWN) .withOutputLanguage(Language.ZH) .withPathsGroupedBy(GroupBy.TAGS) .withGeneratedExamples() .withoutInlineSchema() .build(); Swagger2MarkupConverter converter = Swagger2MarkupConverter.from(new URL("http://localhost:8080/demo/v2/api-docs")) //url是可以访问的在线json数据的url .withConfig(config) .build(); converter.toFile(outputFile); &#125;&#125; 一定要保证这里的链接可以访问，因此可以把项目启动起来之后再执行这个测试类，将会在项目的build目录下生成对应的文档 如果需要生成其他的文档，可以使用Typora导出到pdf或者doc文件 参考文章 https://my.oschina.net/zzuqiang/blog/793606 https://blog.csdn.net/qq_37512634/article/details/78984397]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Shell编程]]></title>
      <url>%2F2018%2F10%2F21%2FShell%E7%BC%96%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[Shell编程变量 定义变量：name=&quot;陈加兵&quot; 撤销变量：unset name 声明静态变量：readonly name=&quot;陈加兵&quot; 静态变量不能unset，否则报错 使用变量：${}或者$变量 echo &quot;姓名：${name}&quot;或者echo &quot;姓名：$name&quot; 系统环境变量：export A=&quot;陈加兵&quot; vim /etc/profile，在末尾添加即可 source /etc/profile ，让环境配置立即生效，否则只能重启系统才能生效 shell中使用环境变量：$name 位置参数变量 基本语法： $n（功能描述： n 为数字， $0 代表命令本身， $1-$9 代表第一到第九个参数，十以上 的参数，十以上的参数需要用大括号包含，如${10}） $*功能描述：这个变量代表命令行中所有的参数， $*把所有的参数看成一个整体，不包含命令本身 $@ 功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待 ，不包含命令本身 $#功能描述：这个变量代表命令行中所有参数的个数，不包含命令的本身 $*与$@的区别 $*和$@都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以$1 $2 …$n的形式输出所有参数 当它们被双引号“”包含时， $*会将所有的参数作为一个整体，以“$1 $2 …$n”的形 式输出所有参数； “$@”会将各个参数分开，以“$1” “$2”…”$n”的形式输出所有参数 12345678910111213#!/bin/bashfor i in &quot;$*&quot;#$*中的所有参数看成是一个整体，所以这个 for 循环只会循环一次doecho &quot;The parameters is: $i&quot;donex=1for y in &quot;$@&quot;#$@中的每个参数都看成是独立的，所以“$@”中有几个参数，就会循环几次doecho &quot;The parameter$x is: $y&quot;x=$(( $x +1 ))done 实例 输出输入的的参数 1，参数 2，所有参数，参数个数，其中的脚本first.shell如下 123456789#!/bin/bash# 输出命令本身和前两个参数echo &quot;$0 $1 $2&quot;# 输出所有的参数，不包含命令本身echo &quot;$*&quot;# 输出所有的参数，不包含命令本身echo &quot;$@&quot;#输出参数的个数，不包含命令本身echo &quot;$#&quot; 执行该脚本./first.shell 1 2 预定义变量 $?：最后一次执行命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行，如果这个变量的值为非0（具体哪个值是由命令自己决定），则证明上一个命令执行不正确了. 这样如果需要判断上一个执行的状态才能进行下一步的操作，那么只需要判断这个是是否为0即可 $$：输出当前进行的进程Id（PID） $!：后台运行的最后一个进程的PID 12345#!/bin/bashecho &quot;$$&quot;./helloworld.sh &amp;echo &quot;$!&quot;echo &quot;$? 运算符基本语法 &quot;$((运算式))&quot;或&quot;$[运算式]&quot; echo &quot;$((1+2))&quot; echo &quot;$[1+2]&quot; expr m + n ：其中这个表达式需要用单引号括起来才能执行 注意 expr 运算符间要有空格 ，即是m，n和运算符+要有空格 expr \*, /, % 乘，除，取余，注意其中的乘需要转义，否则不能参与运算 实例123A=$[(1+2)*4*4]echo &quot;$&#123;A&#125;&quot;unset A 判断语句基本语法 [ condition ] ：注意 condition 前后要有空格 常用判断条件 两个整数之间比较 =字符串比较 -lt 小于 -le小于等于 -eq 等于 -gt 大于 -ge 大于等于 -ne 不等于 按照文件权限比较 -r有读的权限 -w 有写的权限 -x 有执行的权限 按照文件类型进行判断 -f 文件存在并且是一个常规的文件 -e 文件存在 -d 文件存在并是一个目录 实例 23 是否大于等于 22：[ 23 -ge 22 ] student.txt 是否具有写权限 ：[ -w student.txt ] /root/install.log 目录中的文件是否存在 ：[ -e /root/install.log ] 流程控制if基本语法123456789if [ 条件判断式 ];then程序fi# 或者if [ 条件判断式 ]then程序fi 实例 if-else 1234if [ -e /usr/local/shell/five.shell ] then echo &quot;陈加兵&quot; fi if-elseif-els 12345678910111213#!/bin/bashA=$[(1+2)*4]if [ $&#123;A&#125; -gt 10 ]then echo &quot;$&#123;A&#125;大于10&quot;elif [ $&#123;A&#125; -lt 10 ]then echo &quot;$&#123;A&#125;小于10&quot;else echo &quot;$&#123;A&#125;等于10&quot;fi case基本语法123456789101112case $变量名 in&quot;值 1&quot;）如果变量的值等于值 1，则执行程序 1;;&quot;值 2&quot;）如果变量的值等于值 2，则执行程序 2;;…省略其他分支…*）如果变量的值都不是以上的值，则执行此程序;;esac 实例123456789101112131415161718192021#!/bin/bash# 获取控制台输入的第一个参数，不是命令本身A=$1case $&#123;A&#125; in&quot;1&quot;) echo &quot;1&quot;;;&quot;2&quot;) echo &quot;2&quot;;;&quot;3&quot;) echo &quot;3&quot;;;##结束标记esac for循环基本语法 语法一 1234for 变量 in 值 1 值 2 值 3…do程序done 语法二 双括号 1234for (( 初始值;循环控制条件;变量变化 ))do程序done 实例123456789101112#!/bin/bash# 接受控制台输入的值并且循环输出for i in &quot;$*&quot; do echo &quot;The num is $&#123;i&#125;&quot; donefor j in &quot;$@&quot; do echo &quot;The num is $j&quot; done 1234567sum=0;# 这里的for循环一定要加双括号for((i=1;i&lt;=100;i++)) do sum=$[$i+$sum] doneecho &quot;从1加到100的和为：$sum&quot; while循环基本语法1234while [ 条件判断式 ]do程序done 实例12345678910#!/bin/bashi=1sum=0while [ $i -le 100 ] do sum=$[$i+$sum] i=$[$i+1] doneecho &quot;从1加到100的值为：$sum&quot; read读取控制台输入基本语法 read [选项][参数] -p：指定读取值时的提示符； -t：指定读取值时等待的时间（秒）。 实例12345#!/bin/bashread -t 7 -p &quot;请在控制台输入数字，等待时间7秒：&quot; NUMecho &quot;用户输入的数字为：$NUM&quot; 函数系统函数 系统函数是系统自带的一些函数，只需要直接调用即可，不需要自己调用 basename ：去掉文件的路径，直接输出文件的名称 basename /usr/local/shell/first.shell ：直接输出first.shell basename /usr/local/shell/first.shell .shell ：直接输出first，去掉了文件的后缀.shell dirname：去掉文件的名称，直接输出文件的路径 dirname /usr/local/first.shell ：直接输出 /usr/local/ 自定义函数 格式： 12345678[ function ] funname[()]&#123;Action;[return int;]&#125;# d调用funname 实例 1234567891011121314#!/bin/bashfunction sum()&#123; sum=0; sum=$[$1+$2] echo &quot;两数之和为：$sum&quot;&#125;## 读取控制台输入的数字read -p &quot;输入第一个数：&quot; n1read -p &quot;输入第二个数&quot; n2## 调用函数sum $n1 $n2 定时任务调度 crond自动安装Nginx 本人写了一个自动安装Nginx的脚本，适合Centos的安装，亲测有用，点击下载 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/bin/bash## NGINX安装的路径NGINX_PATH=/usr/local/myNginx/## 自动安装Nginx的函数function install_nginx()&#123; ## 创建目录，如果文件夹不存在，那么需要新建文件夹 if [ -d $NGINX_PATH ] then echo &quot;文件件已经存在，开始安装&quot; else mkdir -p $NGINX_PATH fi ## 切换到安装目录 cd $NGINX_PATH ## 下载Nginx的压缩包,因为网络不稳定，因此需要开启无限循环下载 while [ true ] do wget http://nginx.org/download/nginx-1.12.2.tar.gz ## 判断下载命令是否执行成功,下载失败之后直接中断脚本的运行 if [ $? -eq 0 ] then echo &quot;=======================文件下载成功，现在开始解压文件了===========================&quot; tar -zvxf nginx-1.12.2.tar.gz ## 解压缩成功，那么需要删除这个压缩包了 rm -f nginx-1.12.2.tar.gz #文件下载成功当然可以跳出循环了，执行下面的步骤 break fi done ## 安装依赖 yum -y install pcre* yum -y install openssl* ## 进入解压缩的文件目录 cd nginx-1.12.2 ## 执行安装的命令 ./configure ## 判断上面的命令执行是否成功,如果执行失败需要安装对应的依赖才能编译 if [ !$? -eq 0 ] then echo &quot;==========================执行./configure这个命令失败,开始安装对应的依赖了========================================&quot; yum -y install gcc make gcc-c++ openssl-devel fi ## 此时到了这里，肯定是可以编译了 make install # 检测上面的编译是否成功，如果编译成功，那么就安装成功了 if [ $? -eq 0 ] then echo &quot;=========================安装成功==========================&quot; else echo &quot;======================================安装失败==============================&quot; fi &#125;##安装wgetyum install -y wgetif [ !$? -eq 0] then exitfi#调用函数install_nginx 自动安装JDK wget下载jdk的时候有点问题，需要动态验证，因此这里使用的链接是wget --no-cookies --no-check-certificate --header &quot;Cookie:gpw_e24=http%3a%2f%2fwww.oracle.com%2ftechnetwork%2fjava%2fjavase%2fdownloads%2fjdk8-downloads-2133151.html;oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz 可以直接替换后面的链接为对应的jdk版本即可 点击下载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#!/bin/bash## 文件夹的路径JDK_PATH=/usr/local/java/jdk# 解压缩之后的jdk的路径，jdk就在这个文件夹下面JDK_INSTALL_PATH=/usr/local/java/jdk/jdk-8u181-linux-x64## 自动安装jdk的函数function install_jdk()&#123; if [ -d $JDK_PATH ] then echo &quot;==============================jdk的安装目录已经存在，现在开始安装======================================&quot; else mkdir -p $JDK_PATH echo &quot;==============================新建JDK的安装目录成功========================================================&quot; fi ## 切换到安装目录 cd $JDK_PATH ## 安装目录创建成功，开始下载文件了，这里下载的是jdk的1.8版本 while [ true ] do wget --no-cookies --no-check-certificate --header &quot;Cookie:gpw_e24=http%3a%2f%2fwww.oracle.com%2ftechnetwork%2fjava%2fjavase%2fdownloads%2fjdk8-downloads-2133151.html;oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz # 检查是否下载成功，如果下载成功，那么可以跳出这个循环,下载失败继续下载 if [ $? -eq 0 ] then ## 下载成功之后，需要解压缩文件 tar -xzvf jdk-8u181-linux-x64.tar.gz ## 删除压缩包 rm -f jdk-8u181-linux-x64.tar.gz break fi done ## 下载成功之后需要为其中的所有文件赋予可执行的权限 cd $JDK_INSTALL_PATH for file in $JDK_INSTALL_PATH/* do ## 如果是文件夹，那么需要为这个文件夹下的所有文件都赋予权限 if [ -d $file ] then chmod a+x $file/* else chmod a+x $file fi done&#125; ## 安装tomcat## Tomcat的安装路径TOMCAT_PATH=/usr/local/java/tomcat8/TOMCAT_INSTALL_PATH=/usr/local/java/tomcat8/apache-tomcat-8.5.34function install_tomcat8()&#123; if [ -d $TOMCAT_PATH ] then echo &quot;=================TOMCAT的安装路径已经存在=========================&quot; else echo &quot;==========================TOMCAT的安装路径不存在==========================&quot; mkdir -p $TOMCAT_PATH fi cd $TOMCAT_PATH while [ true ] do wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.34/bin/apache-tomcat-8.5.34.tar.gz if [ $? -eq 0 ] then tar -xzvf apache-tomcat-8.5.34.tar.gz rm -f apache-tomcat-8.5.34.tar.gz break fi done for file in $TOMCAT_INSTALL_PATH/* do if [ -d $file ] then cd $file num=`ls | wc -l` if [ $num -eq 0 ] then continue fi chmod a+x * else chmod a+x $file fi done&#125;install_jdkinstall_tomcat8]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker安装服务]]></title>
      <url>%2F2018%2F10%2F09%2Fdocker%E5%AE%89%E8%A3%85%E6%9C%8D%E5%8A%A1%2F</url>
      <content type="text"><![CDATA[docker安装Nginx1、docker pull nginx ：下载nginx 2、docker run --name mynginx -d nginx： 运行nginx实例 3、新建nginx目录在本地 12cd /usr/local/mkdir nginx 3、复制nginx的目录到本地，命令如下 12345678//复制配置文件到本地docker cp mynginx:/etc/nginx /usr/share/nginx/conf///复制html目录到本地docker cp mynginx:/usr/share/nginx/html /usr/share/nginx/html//复制日志到到本地docker cp mynginx:/var/log/nginx /usr/share/nginx/logs 4、挂载目录并且启动nginx，如下： 1docker run --name mynginx -p 80:80 -v /usr/share/nginx/html:/usr/share/nginx/html -v /usr/share/nginx/conf:/etc/nginx -v /usr/share/nginx/logs:/var/log/nginx/ -d nginx 5、安装完成，此时的docker容器中的nginx的html路径就和本地的/usr/share/nginx/html对应了，如果需要建立目录，只需要在本地目录下建立就会自动更新到容器中 安装tomcat docker pull tomcat:8-jre8 ： 现在镜像（tomcat8，jdk的版本8） 运行实例：docker run --name tom -d -p 8081:8080 41a54fe1f79d 复制配置到本地（建立/usr/local/tomcat文件夹） 1234567docker cp tom:/usr/local/tomcat/conf /usr/local/tomcat/confdocker cp tom:/usr/local/tomcat/lib /usr/local/tomcat/libdocker cp tom:/usr/local/tomcat/webapps /usr/local/tomcat/webappsdocker cp tom:/usr/local/tomcat/bin /usr/local/tomcat/bindocker cp tom:/usr/local/tomcat/work /usr/local/tomcat/workdocker cp tom:/usr/local/tomcat/temp /usr/local/tomcat/tempdocker cp tom:/usr/local/tomcat/logs /usr/local/tomcat/logs 挂载目录 1docker run --name tom -p 8081:8080 -v /usr/local/tomcat/conf:/usr/local/tomcat/conf -v /usr/local/tomcat/lib:/usr/local/tomcat/lib -v /usr/local/tomcat/webapps:/usr/local/tomcat/webapps -v /usr/local/tomcat/bin:/usr/local/tomcat/bin -v /usr/local/tomcat/work:/usr/local/tomcat/work -v /usr/local/tomcat/temp:/usr/local/tomcat/temp -v /usr/local/tomcat/logs:/usr/local/tomcat/logs -d 41a54fe1f79d 完成，此时目录已经挂载完成，能够同步更新了 安装mysql 下载：docker pull mysql:5.7.24 启动：docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=12345 -d 702fb0b7837f 复制文件夹 123docker cp mysql:/sbin /usr/local/mysql/bindocker cp mysql:/var/lib/mysql /usr/local/mysql/datadocker cp mysql:/etc/mysql /usr/local/mysql/conf 挂载运行 1docker run --name mysql -p 3306:3306 -v /usr/local/mysql/bin:/sbin -v /usr/local/mysql/data:/var/lib/mysql -v /usr/local/mysql/conf:/etc/mysql -e MYSQL_ROOT_PASSWORD=12345 -d 702fb0b7837f 配置参数详解 https://www.cnblogs.com/wyy123/p/6092976.html http://www.cnblogs.com/Ray-xujianguo/p/3322455.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156[mysql]default-character-set=utf8# SERVER SECTION# ----------------------------------------------------------------------## The following options will be read by the MySQL Server. Make sure that# you have installed the server correctly (see above) so it reads this # file.#[mysqld]# The TCP/IP Port the MySQL Server will listen onport=3306#Path to installation directory. All paths are usually resolved relative to this.#basedir=&quot;E:/Java/Mysql/&quot;#Path to the database rootdatadir=&quot;/usr/local/mysql/data&quot;# The default character set that will be used when a new schema or table is# created and no character set is definedcharacter-set-server=utf8# The default storage engine that will be used when create new tables whendefault-storage-engine=INNODB# Set the SQL mode to strictsql-mode=&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&quot;# The maximum amount of concurrent sessions the MySQL server will# allow. One of these connections will be reserved for a user with# SUPER privileges to allow the administrator to login even if the# connection limit has been reached.max_connections=1000# Query cache is used to cache SELECT results and later return them# without actual executing the same query once again. Having the query# cache enabled may result in significant speed improvements, if your# have a lot of identical queries and rarely changing tables. See the# &quot;Qcache_lowmem_prunes&quot; status variable to check if the current value# is high enough for your load.# Note: In case your tables change very often or if your queries are# textually different every time, the query cache may result in a# slowdown instead of a performance improvement.query_cache_size=0# The number of open tables for all threads. Increasing this value# increases the number of file descriptors that mysqld requires.# Therefore you have to make sure to set the amount of open files# allowed to at least 4096 in the variable &quot;open-files-limit&quot; in# section [mysqld_safe]#table_cache=256# Maximum size for internal (in-memory) temporary tables. If a table# grows larger than this value, it is automatically converted to disk# based table This limitation is for a single table. There can be many# of them.tmp_table_size=35M# How many threads we should keep in a cache for reuse. When a client# disconnects, the client&apos;s threads are put in the cache if there aren&apos;t# more than thread_cache_size threads from before. This greatly reduces# the amount of thread creations needed if you have a lot of new# connections. (Normally this doesn&apos;t give a notable performance# improvement if you have a good thread implementation.)thread_cache_size=8#*** MyISAM Specific options# The maximum size of the temporary file MySQL is allowed to use while# recreating the index (during REPAIR, ALTER TABLE or LOAD DATA INFILE.# If the file-size would be bigger than this, the index will be created# through the key cache (which is slower).myisam_max_sort_file_size=100G# If the temporary file used for fast index creation would be bigger# than using the key cache by the amount specified here, then prefer the# key cache method. This is mainly used to force long character keys in# large tables to use the slower key cache method to create the index.myisam_sort_buffer_size=69M# Size of the Key Buffer, used to cache index blocks for MyISAM tables.# Do not set it larger than 30% of your available memory, as some memory# is also required by the OS to cache rows. Even if you&apos;re not using# MyISAM tables, you should still set it to 8-64M as it will also be# used for internal temporary disk tables.key_buffer_size=55M# Size of the buffer used for doing full table scans of MyISAM tables.# Allocated per thread, if a full scan is needed.read_buffer_size=64Kread_rnd_buffer_size=256K# This buffer is allocated when MySQL needs to rebuild the index in# REPAIR, OPTIMZE, ALTER table statements as well as in LOAD DATA INFILE# into an empty table. It is allocated per thread so be careful with# large settings.sort_buffer_size=256K#*** INNODB Specific options ***# Use this option if you have a MySQL server with InnoDB support enabled# but you do not plan to use it. This will save memory and disk space# and speed up some things.#skip-innodb# Additional memory pool that is used by InnoDB to store metadata# information. If InnoDB requires more memory for this purpose it will# start to allocate it from the OS. As this is fast enough on most# recent operating systems, you normally do not need to change this# value. SHOW INNODB STATUS will display the current amount used.#innodb_additional_mem_pool_size=3M# If set to 1, InnoDB will flush (fsync) the transaction logs to the# disk at each commit, which offers full ACID behavior. If you are# willing to compromise this safety, and you are running small# transactions, you may set this to 0 or 2 to reduce disk I/O to the# logs. Value 0 means that the log is only written to the log file and# the log file flushed to disk approximately once per second. Value 2# means the log is written to the log file at each commit, but the log# file is only flushed to disk approximately once per second.#innodb_flush_log_at_trx_commit=1# The size of the buffer InnoDB uses for buffering log data. As soon as# it is full, InnoDB will have to flush it to disk. As it is flushed# once per second anyway, it does not make sense to have it very large# (even with long transactions).#innodb_log_buffer_size=2M# InnoDB, unlike MyISAM, uses a buffer pool to cache both indexes and# row data. The bigger you set this the less disk I/O is needed to# access data in tables. On a dedicated database server you may set this# parameter up to 80% of the machine physical memory size. Do not set it# too large, though, because competition of the physical memory may# cause paging in the operating system. Note that on 32bit systems you# might be limited to 2-3.5G of user level memory per process, so do not# set it too high.#innodb_buffer_pool_size=107M# Size of each log file in a log group. You should set the combined size# of log files to about 25%-100% of your buffer pool size to avoid# unneeded buffer pool flush activity on log file overwrite. However,# note that a larger logfile size will increase the time needed for the# recovery process.#innodb_log_file_size=54M# Number of threads allowed inside the InnoDB kernel. The optimal value# depends highly on the application, hardware as well as the OS# scheduler properties. A too high value may lead to thread thrashing.#innodb_thread_concurrency=18]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库中间件之Mycat]]></title>
      <url>%2F2018%2F10%2F07%2FMycat%2F</url>
      <content type="text"><![CDATA[Mycat入门安装 点击下载 配置java环境 配置mysql数据库 打开conf/wrapper.conf文件，将其中的wrapper.java.command的值改成服务器上的jdk地址，如wrapper.java.command=/usr/local/jdk/jdk1.8.0_172/bin/java 为bin文件夹中的所有内容赋予执行的权限:chmod a+x * 修改schemal.xml文件中的内容，填上对应的表，数据节点，数据主机的内容 启动 ：./mycat start (后台启动)、./mycat console（前台启动） 开启服务器的8086端口 使用navicat连接mycat，端口是8086 常用的命令123456789101112131415./mycat start 启动./mycat stop 停止./mycat console 前台运行./mycat install 添加到系统自动启动（暂未实现）./mycat remove 取消随系统自动启动（暂未实现）./mycat restart 重启服务./mycat pause 暂停./mycat status 查看启动状态 数据库切分 数据库切分分为垂直切分，水平切分 垂直切分 一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同 的数据库上面，这样也就将数据或者说压力分担到不同的库上面 。 比如商城项目可以根据不同的业务将表分成用户表、订单表等，这些表分布在不同的数据库中，从而实现了垂直切分 优点： 拆分后业务清晰，拆分规则明确。 系统之间整合或扩展容易 数据维护简单。 缺点： 部分业务表无法 join，只能通过接口方式解决，提高了系统复杂度。 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。 事务处理复杂。 由于垂直切分是按照业务的分类将表分散到不同的库，所以有些业务表会过于庞大，存在单库读写与存储瓶 颈，所以就需要水平拆分来做解决。 水平切分 水平拆分不是将表做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中 包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中的某些行切分 到一个数据库，而另外的某些行又切分到其他的数据库中 拆分规则： 按照用户 ID 求模，将数据分散到不同的数据库，具有相同数据用户的数据都被分散到一个库中。 按照日期，将不同月甚至日的数据分散到不同的库中。 按照某个特定的字段求摸，或者根据特定范围段分散到不同的库中。 优点： 拆分规则抽象好，join 操作基本可以数据库做。 不存在单库大数据，高并发的性能瓶颈。 应用端改造较少。 提高了系统的稳定性跟负载能力。 缺点： 拆分规则难以抽象。 分片事务一致性难以解决。 数据多次扩展难度跟维护量极大。 跨库 join 性能较差。 垂直拆分和水平拆分的共同缺点 引入分布式事务的问题。 跨节点 Join 的问题。 跨节点合并排序分页问题。 多数据源管理问题。 日志分析sql防火墙配置 在server.xml中配置 Mycat配置schema（逻辑库） 一个标签，定义一个逻辑数据库。可以同时指定多个标签来指定不同的逻辑库 标签体的属性如下： dataNode：字符串，该属性用于绑定逻辑库到某个具体的 database 上 ，多个值用逗号分隔 checkSQLschema：布尔值，当该值设置为 true 时，如果我们执行语句select * from TESTDB.travelrecord;则 MyCat 会把语句修改 为select * from travelrecord; ，设置这个属性为true，可以在navicat中直接查看逻辑表中的所有数据，否则将会报异常（Table ‘testdb.travelrecord’ doesn’ t exist） sqlMaxLimit：当该值设置为某个数值时。每条执行的 SQL 语句，如果没有加上 limit 语句，MyCat 也会自动的加上所对应 的值。例如设置值为 100，执行select * from TESTDB.travelrecord;的效果为和执行select * from TESTDB.travelrecord limit 100;相同。 设置该值的话，MyCat 默认会把查询到的信息全部都展示出来，造成过多的输出。所以，在正常使用中，还 是建议加上一个值，用于减少过多的数据返回.当然 SQL 语句中也显式的指定 limit 的大小，不受该属性的约束。 需要注意的是，如果运行的 schema 为非拆分库的，那么该属性不会生效。需要手动添加 limit 语句。 table (逻辑表) 属性如下： name String 定义逻辑表的表名，这个名字就如同我在数据库中执行 create table 命令指定的名字一样，同个 schema 标 签中定义的名字必须唯一 dataNode String 定义这个逻辑表所属的 dataNode, 该属性的值需要和 dataNode 标签中 name 属性的值相互对应。多个值用逗号分隔 rule String 该属性用于指定逻辑表要使用的规则名字，规则名字在 rule.xml 中定义，必须与 tableRule 标签中 name 属 性属性值一一对应 ruleRequired boolean 该属性用于指定表是否绑定分片规则，如果配置为 true，但没有配置具体 rule 的话 ，程序会报错。 primaryKey String 该逻辑表对应真实表的主键，例如：分片的规则是使用非主键进行分片的，那么在使用主键查询的时候，就 会发送查询语句到所有配置的 DN 上，如果使用该属性配置真实表的主键。难么 MyCat 会缓存主键与具体 DN 的 信息，那么再次使用非主键进行查询的时候就不会进行广播式的查询，就会直接发送语句给具体的 DN，但是尽管 配置该属性，如果缓存并没有命中的话，还是会发送语句给具体的 DN，来获得数据。如果没有指定，那么默认使用的是主键字段是id type String 该属性定义了逻辑表的类型，目前逻辑表只有“全局表”和”普通表”两种类型。对应的配置： 1、全局表：global。 2、 普通表：不指定该值为 globla 的所有表 autoIncrement boolean mysql 对非自增长主键，使用 last_insert_id()是不会返回结果的，只会返回 0。所以，只有定义了自增长主 键的表才可以用 last_insert_id()返回主键值。 mycat 目前提供了自增长主键功能，但是如果对应的 mysql 节点上数据表，没有定义 auto_increment，那 么在 mycat 层调用 last_insert_id()也是不会返回结果的。 由于 insert 操作的时候没有带入分片键，mycat 会先取下这个表对应的全局序列，然后赋值给分片键。这样 才能正常的插入到数据库中，最后使用 last_insert_id()才会返回插入的分片键值。 如果要使用这个功能最好配合使用数据库模式的全局序列。 75 使用 autoIncrement=“true” 指定这个表有使用自增长主键，这样 mycat 才会不抛出分片键找不到的异 常。 使用 autoIncrement=“false” 来禁用这个功能，当然你也可以直接删除掉这个属性。默认就是禁用的。 subTables String needAddLimit boolean 指定表是否需要自动的在每个语句后面加上 limit 限制。由于使用了分库分表，数据量有时会特别巨大。这时 候执行查询语句，如果恰巧又忘记了加上数量限制的话。那么查询所有的数据出来，也够等上一小会儿的。 所以，mycat 就自动的为我们加上 LIMIT 100。当然，如果语句中有 limit，就不会在次添加了。 这个属性默认为 true,你也可以设置成 false`禁用掉默认行为。 dataNode 数据节点，用来设置 name String 定义数据节点的名字，这个名字需要是唯一的，我们需要在 table 标签上应用这个名字，来建立表与分片对 应的关系 dataHost String 该属性用于定义该分片属于哪个数据库实例的，属性值是引用 dataHost 标签上定义的 name 属性。 database String 该属性用于定义该分片属性哪个具体数据库实例上的具体库，因为这里使用两个纬度来定义分片，就是：实 例+具体的库。因为每个库上建立的表和表结构是一样的。所以这样做就可以轻松的对表进行水平拆分 dataHost 作为 Schema.xml 中最后的一个标签，该标签在 mycat 逻辑库中也是作为最底层的标签存在，直接定义了具 体的数据库实例、读写分离配置和心跳语句。现在我们就解析下这个标签。 配置如下： name String 唯一标识 dataHost 标签，供上层的标签使用。 maxCon Integer 指定每个读写实例连接池的最大连接。也就是说，标签内嵌套的 writeHost、 readHost 标签都会使用这个属 性的值来实例化出连接池的最大连接数 minCon Integer 指定每个读写实例连接池的最小连接，初始化连接池的大小 balance Integer 负载均衡类型，目前的取值有 3 种： 1. balance=”0”, 不开启读写分离机制，所有读操作都发送到当前可用的 writeHost 上。 2. balance=”1”，全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡，简单的说，当双 主双从模式(M1-&gt;S1，M2-&gt;S2，并且 M1 与 M2 互为主备)，正常情况下，M2,S1,S2 都参与 select 语句的负载 均衡。 3. balance=”2”，所有读操作都随机的在 writeHost、 readhost 上分发。 4. balance=”3”，所有读请求随机的分发到 wiriterHost 对应的 readhost 执行，writerHost 不负担读压 力，注意 balance=3 只在 1.4 及其以后版本有，1.3 没有。 writeType Integer 负载均衡类型，目前的取值有 3 种： 1. writeType=”0”, 所有写操作发送到配置的第一个 writeHost，第一个挂了切到还生存的第二个 writeHost，重新启动后已切换后的为准，切换记录在配置文件中:dnindex.properties . 2. writeType=”1”，所有写操作都随机的发送到配置的 writeHost，1.5 以后废弃不推荐。 dbType String 指定后端连接的数据库类型，目前支持二进制的 mysql 协议，还有其他使用 JDBC 连接的数据库。例如： mongodb、 oracle、 spark 等。 dbDriver String 指定连接后端数据库使用的 Driver，目前可选的值有 native 和 JDBC。使用 native 的话，因为这个值执行的 是二进制的 mysql 协议，所以可以使用 mysql 和 maridb。其他类型的数据库则需要使用 JDBC 驱动来支持。 从 1.6 版本开始支持 postgresql 的 native 原始协议。 如果使用 JDBC 的话需要将符合 JDBC 4 标准的驱动 JAR 包放到 MYCAT\lib 目录下，并检查驱动 JAR 包中 包括如下目录结构的文件：META-INF\services\java.sql.Driver。在这个文件内写上具体的 Driver 类名，例如： com.mysql.jdbc.Driver。 switchType Integer -1 表示不自动切换 1 默认值，自动切换 2 基于 MySQL 主从同步的状态决定是否切换 心跳语句为 show slave status 3 基于 MySQL galary cluster 的切换机制（适合集群）（1.4.1） 心跳语句为 show status like ‘wsrep%’. 这个和writeType结合使用 heartbeat 这个标签内指明用于和后端数据库进行心跳检查的语句。例如,MYSQL 可以使用select user()，Oracle 可以 使用 select 1 from dual等。 这个标签还有一个 connectionInitSql属性，主要是当使用 Oracla 数据库时，需要执行的初始化 SQL 语句就 这个放到这里面来。例如：alter session set nls_date_format=’yyyy-mm-dd hh24:mi:ss’ 1.4 主从切换的语句必须是：show slave status writeHost 、 readHost 这两个标签都指定后端数据库的相关配置给 mycat，用于实例化后端连接池。唯一不同的是，writeHost 指 定写实例、 readHost 指定读实例，组着这些读写实例来满足系统的要求 在一个 dataHost 内可以定义多个 writeHost 和 readHost。但是，如果 writeHost 指定的后端数据库宕机， 那么这个 writeHost 绑定的所有 readHost 都将不可用。另一方面，由于这个 writeHost 宕机系统会自动的检测 到，并切换到备用的 writeHost 上去 这两个标签的属性相同，这里就一起介绍。 host String 用于标识不同实例，一般 writeHost 我们使用M1，readHost 我们用S1。 url String 后端实例连接地址，如果是使用 native 的 dbDriver，则一般为 address:port 这种形式。用 JDBC 或其他的 dbDriver，则需要特殊指定。当使用 JDBC 时则可以这么写：jdbc:mysql://localhost:3306/。 password String 后端存储实例需要的用户名字 ,即是指向mysql的密码 user String 后端存储实例需要的密码 ，即是指向mysql的用户 weight String 权重 配置在 readhost 中作为读节点的权重（1.4 以后） usingDecrypt String 是否对密码加密默认 0 否 如需要开启配置 1，同时使用加密程序对密码加密 childTable childTable 标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。 name String 定义子表的表名。 joinKey String 插入子表的时候会使用这个列的值查找父表存储的数据节点 parentKey String 属性指定的值一般为与父表建立关联关系的列名。程序首先获取 joinkey 的值，再通过 parentKey 属性指定 的列名产生查询语句，通过执行该语句得到父表存储在哪个分片上。从而确定子表存储的位置。 primaryKey String 同 table 标签所描述的 needAddLimit boolean 同 table 标签所描述的 autoIncrement boolean 设置是否主键自增 server.xml中的标签设置用户12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- user标签可以设置登录的用户，可以指定多个 &lt;property name="password"&gt;： 设置该用户登录的密码 &lt;property name="schemas"&gt; ：设置该用户可以访问的逻辑库，如果有多个，那么需要使用逗号分隔 &lt;property name="readOnly"&gt;true&lt;/property&gt; ： 设置该用户是否对逻辑库为只读权限 &lt;property name="benchmark"&gt;11111&lt;/property&gt;： mycat 连接服务降级处理：benchmark 基准, 当前端的整体 connection 数达到基准值是, 对来自该账户的请求开始拒绝连接， 0 或不设表示不限制 &lt;property name="usingDecrypt"&gt;1&lt;/property&gt;：是否对密码加密默认 0 否 如需要开启配置 1，同时使用加密程序对密码加密 privileges 子节点：对用户的 schema 及 下级的 table 进行精细化的 DML 权限控制，privileges 节点中的 check 属性是用于标识是否开启 DML 权限检查， 默认 false 标识不检查，当然 privileges 节点不配置，等同 check=false,由于 Mycat 一个用户的 schemas 属性可配置多个 schema ，所以 privileges 的下级节点 schema 节点同样可配置多个，对多库多表进行细粒度的 DML 权限控制 schema 标签： 指定逻辑库的名称，用来选择对应的表，可以有多个 dml：设置对指定表的crud操作，分别是insert,update,select,delete，对应的如果是0表示禁止，1表示不禁止 --&gt; &lt;user name="root"&gt; &lt;property name="password"&gt;123456&lt;/property&gt; &lt;property name="schemas"&gt;Test&lt;/property&gt; &lt;!-- 表级 DML 权限设置 --&gt; &lt;!-- &lt;privileges check="false"&gt; &lt;schema name="TESTDB" dml="0110" &gt; &lt;table name="tb01" dml="0000"&gt;&lt;/table&gt; &lt;table name="tb02" dml="1111"&gt;&lt;/table&gt; &lt;/schema&gt; &lt;schema name="TESTDB" dml="0110" &gt; &lt;table name="tb01" dml="0000"&gt;&lt;/table&gt; &lt;table name="tb02" dml="1111"&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt; &lt;/user&gt; system标签 这个标签内嵌套的所有 property 标签都与系统配置有关，请注意，下面我会省去标签 property 直接使用这 个标签的 name 属性内的值来介绍这个属性的作用。 属性 作用 概要 charset 字符集设置。 配置字符集的时候一定要坚持 mycat 的字符集与数据库端的字符集是一致的，可以通过变量来查询。比如&lt;property name=&quot;charset&quot;&gt;utf8&lt;/property&gt; defaultSqlParser 1.3 解析器默认为 fdbparser，1.4 默认为 druidparser，1.4 以后 fdbparser 作废。 由于 mycat 最初是时候 Foundation DB 的 sql 解析器，而后才添加的 Druid 的解析器。所以这个属性用来 指定默认的解析器。目前的可用的取值有：druidparser 和 fdbparser。使用的时候可以选择其中的一种，目前一 般都使用 druidparser processors 这个属性主要用于指定系统可用的线程数，默认值为机器 CPU 核心线程数。 主要影响 processorBufferPool、 processorBufferLocalPercent、 processorExecutor 属性。 NIOProcessor 的个数也是由这个属性定义的，所以调优的时候可以适当的调高这个属性。 processorBufferChunk 这个属性指定每次分配 Socket Direct Buffer 的大小，默认是 4096 个字节。这个属性也影响 buffer pool 的 长度。如果一次性获取的数过大 buffer 不够用 经常出现警告，则可以适当调大。 processorBufferPool 这个属性指定 bufferPool 计算 比例值。由于每次执行 NIO 读、写操作都需要使用到 buffer，系统初始化的 时候会建立一定长度的 buffer 池来加快读、写的效率，减少建立 buffer 的时间。 Mycat 中有两个主要的 buffer 池: - BufferPool - ThreadLocalPool BufferPool 由 ThreadLocalPool 组合而成，每次从 BufferPool 中获取 buffer 都会优先获取 ThreadLocalPool 中的 buffer，未命中之后才会去获取 BufferPool 中的 buffer。也就是说 ThreadLocalPool 是 作为 BufferPool 的二级缓存，每个线程内部自己使用的。当然，这其中还有一些限制条件需要线程的名字是由$_ 开头。然而，BufferPool 上的 buffer 则是每个 NIOProcessor 都共享的。 默认这个属性的值为： 默认 bufferChunkSize(4096) processors 属性 1000 BufferPool 的总长度 = bufferPool / bufferChunk。 若 bufferPool 不是 bufferChunk 的整数倍，则总长度为前面计算得出的商 + 1 假设系统线程数为 4，其他都为属性的默认值，则： bufferPool ＝ 4096 4 1000 BufferPool 的总长度 : 4000 = 16384000 / 4096 processorBufferLocalPercent 前面提到了 ThreadLocalPool。这个属性就是用来控制分配这个 pool 的大小用的，但其也并不是一个准确 的值，也是一个比例值。这个属性默认值为 100。 线程缓存百分比 = bufferLocalPercent / processors 属性。 例如，系统可以同时运行 4 个线程，使用默认值，则根据公式每个线程的百分比为 25。最后根据这个百分比 来计算出具体的 ThreadLocalPool 的长度公式如下： ThreadLocalPool 的长度 = 线程缓存百分比 BufferPool 长度 / 100 假设 BufferPool 的长度为 4000，其他保持默认值。 那么最后每个线程建立上的 ThreadLocalPool 的长度为： 1000 = 25 4000 / 100 processorExecutor 这个属性主要用于指定 NIOProcessor 上共享的 businessExecutor 固定线程池大小。 mycat 在需要处理一 些异步逻辑的时候会把任务提交到这个线程池中。新版本中这个连接池的使用频率不是很大了，可以设置一个较 小的值 sequnceHandlerType 指定使用 Mycat 全局序列的类型。 0 为本地文件方式，1 为数据库方式，2 为时间戳序列方式，3 为分布式 ZK ID 生成器，4 为 zk 递增 id 生成。 handleDistributedTransactions 分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志 全局表 mycat中使用type定义全局表和普通表(type=global)，没有定义type的类型的都是普通表，是需要分片的 全局表适合那些数据量比较少的，变动不是很频繁的 全局表的插入，更新操作会实时在所有节点上执行，保持各个分片的数据一致性。没有太激烈的update操作。 全局表查询只从一个节点获取 全局表可以和任何一个表进行JOIN操作 需要注意的是，全局表每个分片节点上都要有运行创建表的 DDL 语句。 Mycat的跨分片join 同一个分片的数据可以任意的join，join的数量也没有限制，但是不同分片的数据跨分片join的话，是查询不到结果的 全局表 全局表在每一个分片上都保持着相同的数据，因此全局表可以和任意的表跨分片join ER join 我们可以根据ER关系设置每张表的关系，比如订单表依赖于用户表，我们可以设置ER join方式的，那么会根据外键（joinKey）的值和相关依赖的表分配在同一个分片上，那么就可以join了 支持多表join 配置如下（其中childTable中也可以嵌套childTable）： 123456789&lt;table name="t_user" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" primaryKey="id" autoIncrement="true"&gt; &lt;!--订单表， joinKey是t_order和t_user关联的外键关系， parentKey指定的是t_user表中的主键 primaryKey：指定的是t_order的主键 autoIncrement：设置是否主键自增--&gt; &lt;childTable name="t_order" joinKey="user_id" parentKey="id" primaryKey="id" autoIncrement="true"/&gt;&lt;/table&gt; Share Joinmycat自增主键的配置（数据库方式） 在mycat中并没有实现mysql的自增主键的配置，如果需要实现的话，需要自己配置。 自增主键的方式配置有多种方式，比如本地方式，数据库方式，ZK方式，时间戳的方式，这里我们测试的是数据库的方式。 测试步骤1、修改server.xml中生成方式为数据库生成的方式 12&lt;!--将sequnceHandlerType设置为1--&gt;&lt;property name="sequnceHandlerType"&gt;1&lt;/property&gt; 2、在schema.xml中，table中增加属性autoIncrement值为true，添加mycat_sequence表 1234567891011121314&lt;schema name="Test" checkSQLschema="true"&gt; &lt;!-- auto sharding by id (long) rule:指定分片的规则为根据Id自动分片 primaryKey： 指定主键 autoIncrement： 指定自增长，一定要为true --&gt; &lt;table name="t_item" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" primaryKey="id" autoIncrement="true" /&gt; &lt;!--指定自增长的表，数据节点为dn1--&gt; &lt;table name="mycat_sequence" primaryKey="name" dataNode="dn1" /&gt; &lt;/schema&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="db1" /&gt; &lt;dataNode name="dn2" dataHost="localhost1" database="db2" /&gt; &lt;dataNode name="dn3" dataHost="localhost1" database="db3" /&gt; 3、在数据节点dn1的数据库db1中新建mycat_sequence的表，如下： 123451、name：sequence：名称2、currenct_value：当前value3、increment：增长步长 1234567DROP TABLE IF EXISTS MYCAT_SEQUENCE; CREATE TABLE MYCAT_SEQUENCE( name VARCHAR(50) NOT NULL, current_value INT NOT NULL, increment INT NOT NULL DEFAULT 100, PRIMARY KEY(name) ) ENGINE=InnoDB; 4、在db1数据中创建存储函数，用来维持自增长 12345678910111213141516171819202122232425262728293031323334353637-- 获取当前sequence的值 (返回当前值,增量) DROP FUNCTION IF EXISTS mycat_seq_currval; DELIMITER $ CREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf8 DETERMINISTIC BEGIN DECLARE retval VARCHAR(64); SET retval="-999999999,null"; SELECT concat(CAST(current_value AS CHAR),",",CAST(increment AS CHAR)) INTO retval FROM MYCAT_SEQUENCE WHERE name = seq_name; RETURN retval; END $ DELIMITER ; -- 设置sequence值 DROP FUNCTION IF EXISTS mycat_seq_setval; DELIMITER $ CREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),value INTEGER) RETURNS varchar(64) CHARSET utf8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = value WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END $ DELIMITER ; -- 获取下一个sequence值 DROP FUNCTION IF EXISTS mycat_seq_nextval; DELIMITER $ CREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = current_value + increment WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END $ DELIMITER ; 5、在mycat_sequence表中插入数据，用来记录t_item表的自增长数据，名称必须全部大写 ​ 1、当然这里一条数据就代表一张表自增长，如果想要其他的表也能自增长，那么直接添加即可 1INSERT INTO MYCAT_SEQUENCE(name, current_value, increment) VALUES ('T_TIEM', 0,1); 6、在conf/sequence_db_conf.properties的文件中添加依赖全局序列，增加序列，与table名称相同全大写 12# T_ITEM是自增长的表，dn1是mycat_sequence所在的数据节点，之后每添加一张自增长的表，只需要在其中添加即可T_ITEM=dn1 7、测试，向t_item表中添加数据 1INSERT INTO t_item(name) values("chenjiabing"); 8、测试使用mybatis添加数据 123@Insert("INSERT into t_item(name) values(#&#123;name&#125;)")@Options(useGeneratedKeys = true,keyProperty = "id") //自增长主键返回void insert(Item item); 参考文章 http://deweing.github.io/2016/06/28/mycat-auto-increment/ Java操作Mycat 只需要将连接mysql的端口改成8066即可，其他的就像是操作mysql一样 Mycat的事务处理 Mycat 目前没有出来跨分片的事务强一致性支持，目前单库内部可以保证事务的完整性，如果跨库事务， 在执行的时候任何分片出错，可以保证所有分片回滚，但是一旦应用发起 commit 指令，无法保证所有分片都成 功，考虑到某个分片挂的可能性不大所以称为弱 XA。 也就是说，我们在单体应用中可以正常使用spring提供的事务管理器进行事务的管理，在处理出现异常的时候也是可以回滚的。 Mycat查询非分片字段查询 如果查询条件中有分片字段的话，那么mycat就可以轻松的根据分片规则找到对应的数据节点，然后在对应节点中查询，比如使用的是id取模分片规则，那么此时的id就是分片字段，一旦查询条件中有id这个字段的，就可以根据id的值定位到指定的节点中查询，否则将会在每个节点中执行sql语句，然后将每个节点的返回结果汇总返回 分页查询 mycat针对分页查询的执行逻辑如下： 根据sql语句的过滤条件到每个数据节点筛选数据，筛选完成之后返回各个节点的分页数据 mycat会判断哪个节点先返回数据，真正返回给客户端的就是先返回数据的那个节点上的数据库中 根据上面的分析，我们可以判断分页查询的数据每次都是不同的，不同数据节点的返回速度决定着分页查询的数据显示。 解决办法：在分页查询的时候必要的时候进行排序，这样返回的结果才是正确的，不然每次返回的结果可能不同，比如select * from t_item order by id desc limit 1,29 排序查询 mycat 的排序查询的执行逻辑如下： 将sql语句发送到各个节点进行筛选数据，返回数据给mycat mycat获取到各个节点的数据的时候会根据 不同的排序规则（升序，降序）对全部节点的数据重新排序，最后所有数据排序完成的结果就是正确的结果 分页排序查询参考文章 https://www.cnblogs.com/jpfss/p/8194111.html Mycat权威指南]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springBoot整合dubbo]]></title>
      <url>%2F2018%2F10%2F03%2FspringBoot%E6%95%B4%E5%90%88dubbo%2F</url>
      <content type="text"><![CDATA[SpringBoot整合dubbo搭建项目 创建springBoot项目，导入dubbo依赖 123456&lt;!-- 添加dubbo的启动器, 其中已经添加了zookepper的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt;&lt;/dependency&gt; 配置dubbo的连接和zookeeper的连接，在application.properties中添加如下配置 1234567# 启动的端口号server.port=8001server.servlet.context-path=/provider# 暴露的服务名称dubbo.application.name=user-service# zookeeper注册中心的地址dubbo.registry.address=zookeeper://39.105.123.197:2181 在主配置类上添加@EnableDubbo注解，开启dubbo 暴露服务 在spring中使用的&lt;dubbo:service&gt;暴露服务，但是在springBoot中只需要使用dubbo的注解@Service（com.alibaba.dubbo.config.annotation.Service）即可自动暴露。如下： 1234567891011121314151617import org.springframework.stereotype.Component;import com.alibaba.dubbo.config.annotation.Service;import cn.tedu.demo.beans.User;import cn.tedu.demo.service.UserService;@Service //暴露服务,只需要在对应的服务类上添加这个注解即可@Component //注入到IOC容器中public class UserServiceImpl implements UserService&#123; @Override public User getUser(Integer userId) &#123; User user=new User(); user.setAge(22); user.setUserId(userId); user.setUserName("陈加兵"); return user; &#125;&#125; 引用服务 在spring的配置文件中使用&lt;dubbo:reference&gt;引用服务，但是在springBoot中只需要使用dubbo的注解@Reference即可引用对应的服务 12345678910@RestControllerpublic class UserController &#123; @Reference //消费者引用提供者提供的服务，相当于&lt;dubbo:reference&gt; private UserService userService; @GetMapping("/user/get/&#123;id&#125;") public User get(@PathVariable("id")Integer userId)&#123; return userService.getUser(userId); &#125;&#125; maven聚合springBoot项目 项目地址-点击下载 创建demo-parent父项目管理版本，但是在springBoot项目中也是使用父项目管理的，因此我们需要在父项目中使用springBoot的依赖管理的starter来替代之前的parent 1234567891011121314151617181920212223242526&lt;!--之前的parent，在springBoot创建的时候将会添加，但是这里不需要&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;/parent&gt;--&gt; &lt;properties&gt; &lt;springBoot-version&gt;2.0.5.RELEASE&lt;/springBoot-version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 直接使用这个依赖管理springBoot的版本即可 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;springBoot-version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 在demo-parent新建module 在新的module的pom.xml直接添加springBoot的启动器即可，不用指定版本 maven创建springBoot工程1、新建一个module，打包方式为jar 2、添加依赖，如下（直接添加依赖，因为父工程demo-parent已经管理了版本）： 12345678910 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 3、在src/main/resources包的下新建springBoot的配置文件application.properties 4、新建一个启动类 123456@SpringBootApplication //标记为springBoot的启动类public class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; maven打包springBoot注意1、在pom文件中添加如下依赖（如果不添加如下依赖，可能打出的jar包运行将会报错找不到主程序清单）： 12345678910111213141516&lt;build&gt; &lt;!-- &lt;finalName&gt;batman-web&lt;/finalName&gt; --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql索引优化详解]]></title>
      <url>%2F2018%2F09%2F07%2Fmysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[Explain 使用explain能够知道自己写的sql语句在mysql中到底是怎样运行的，到底扫描了多少行，是否使用了索引，返回的结果如下： 12345+------+-------------+-----------+------+---------------+------+---------+------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+------+-------------+-----------+------+---------------+------+---------+------+------+-------+| 1 | SIMPLE | t_blogger | ALL | NULL | NULL | NULL | NULL | 2 | |+------+-------------+-----------+------+---------------+------+---------+------+------+-------+ 下面将会针对上面的值详细讲解 id sql执行查询的序列号，决定了查询中select子句的查询顺序，分为三种情况，如下： id相同 查询的select子句从上到到下执行，如下： 12345678MariaDB [db_blog3]&gt; explain select * from t_blog ,t_blogger;+------+-------------+-----------+------+---------------+------+---------+------+------+------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+------+-------------+-----------+------+---------------+------+---------+------+------+------------------------------------+| 1 | SIMPLE | t_blogger | ALL | NULL | NULL | NULL | NULL | 2 | || 1 | SIMPLE | t_blog | ALL | NULL | NULL | NULL | NULL | 16 | Using join buffer (flat, BNL join) |+------+-------------+-----------+------+---------------+------+---------+------+------+------------------------------------+ 那么执行的孙顺序就是先查询t_blogger，之后查询t_blog id不同 id的值越大优先级越高，就先执行，剩下相同的id的值，按照顺序从上到下执行 table select语句执行查询的表，如果是使用联合查询的，那么会使用这个值可能是虚拟的表 索引优化全值匹配 全部使用了索引，并且如果是复合索引，一定要按照复合索引的顺序查询，这样才能达到最高效的查询，如下： 1234-- 为user表创建组合索引 index_nameAgePos-- 全值匹配的实例 ,查询的条件的顺序必须和创建索引的顺序一致select * from t_user where name="Tom" and age=22 and pos="1" 最佳左前缀法则 如果使用了组合索引（索引了多列） ，那么一定查询要从最左前列开始并且不能跳过索引中的列 比如index_nameAgePos这个索引，实例如下： 1234567891011121314-- 全值匹配，最为高效explain select * from t_user where name="Tom" and age=22 and pos="1" -- 去掉最后一个，使用前两个，那么前两个索引会有效，使用了部分索引 explain select * from t_user where name="Tom" and age=22-- 去掉后面两个，只是用第一个，索引依然有效，使用了第一个索引的类，部分索引explain select * from t_user where name="Tom"-- 去掉第一个，使用后面两个索引查询，没有使用做前缀，索引失效，explain select * from t_user where and age=22 and pos="1" -- 去掉中间的一个，只使用第一个和第三个,中间断了，不能查找到索引，索引失效，即使有了做前缀依然会失效explain select * from t_user where name="Tom" and pos="1" 通过上面的例子得出：使用组合索引的时候，一定要带上左前缀，并且不能跳过中间的索引，否则将会索引失效 不在索引上列上做任何操作 不要在索引列上做任何的操作，包括计算、函数、自动或者手动类型的转换，这样都会导致索引失效 123select * from user where name=2000 ---- 我们知道name是一个varchar类型的，但是用name=2000虽然能够查到，但是在内部其实是将name转换成了数值类型，因此不能使用索引select * from user where left(name,4)="TOm" -- 这里将对name使用了left这个函数，索引失效 不能使用索引中范围条件右边的列（范围之后的索引全失效） 在使用组合索引的时候，一旦索引中有列使用了范围查询（&gt;=…in….like,between子句），那么在其右边的索引将会失效 假设创建了组合索引，顺序为name，age，address 12-- age使用了范围查询，那么在其右边的address将不会使用索引查询，但是name和age使用了索引explain select age from user where name="JOhn" and age&gt;22 and address="江苏"； 使用覆盖索引，少使用select* 需要用到什么数据就查询什么数据，这样可以减少网络的传输和mysql的全表扫描 尽量使用覆盖索引，比如索引为name，age，address的组合索引，那么尽量覆盖这三个字段之中的值，mysql将会直接在索引上取值（using index）。并且返回值不包含不是索引的字段 mysql在使用不等于(!=或者&lt;&gt;)的时候无法使用导致全表扫描 在查询的时候，如果对索引使用不等于的操作将会导致索引失效，进行全表扫描 在使用or的时候，前后两个都是索引的时候才会生效 比如我们创建组合索引name，age，address 123select * from user where name="John" or age=22; -- name和age都是索引，生效select * from user where name="John" or pos=22; -- pos不是索引，因此导致全表扫描，索引失效 is null和is not null 导致索引失效 索引条件一旦是is null或者is not null 将会导致索引失效 like使用%开头的将会导致索引失效 如果使用模糊查找的时候，使用%a%的时候将会导致索引失效 12345explain select * from user where name like "%a%"; -- 索引失效explain select * from user where name like "a%"; -- 索引生效、explain select * from user where name like "%a"; --- 索引失效 解决方法 需求就需要使用%$%查询，那么我们如何解决索引失效？我们可以使用覆盖索引避免索引失效 假设我们的索引为name，age 1234567select * from user where name like "%aa%"; -- 索引失效，没有使用覆盖索引而是select*select name from user where name like "%a%" ; -- 索引生效，使用了覆盖索引，返回索引列nameselect name,age from user where name like "%aa%" -- 索引生效，name和age都是索引select naem，pos from user where name like "%a" -- 索引失效，pos不是索引 字符串不加单引号导致索引失效 select * from user where pos=2000，将会导致name这个索引失效，因为mysql在底层会自动为name这个字段进行类型转换 单表查询优化 在经常查询或者排序的字段建立索引 两表查询优化 我们一般会使用联合查询，比如left Join，right Join 我们在不建立索引的情况下，如下： 12-- 没有索引，全表扫描explain select * from user left join image on user.url=image.url 那么我们这个索引应该建在哪张表上呢？我们验证之后知道，应该在image表中对url建立索引 总结：左连接在右边的表上加索引，右连接在左表添加索引 三表查询优化 三表建立索引，依然按照左连接在右表上建立索引，右连接在左表上建立索引。 12-- 没有建立索引，全表扫描select * from t1 left jon t2 t1.name=t2.name left join t3 t2.url=t3.url 我们可以在t2的表上为name字段建立索引，在t3表上为url字段建立索引，那么将会使用索引查询 小表驱动大表 在链接查询的时候，比如left Join，这种查询是左边的表驱动右边的表，那么我们应该小表驱动大表的策略，对于左连接的时候，左边的表应该是小表，右连接反之 order by 排序的索引生效 假设组合索引为name，age，address 对于order by排序问题，只有满足以下两种情况才会使用索引排序（using index) 对于组合索引，order by 语句使用最左前缀查询 select * from user order by name： 使用索引 select * from user order by age： 不使用索引 select * from user order by name,age： 使用索引，因为排序规则一样并且是左前缀查询 select * from user order by name asc,age desc：不使用索引，因为排序规则不同，即使使用了最佳左前缀 使用where子句与order by子句条件列组合满足索引最左前缀查询 select * from user where name=&quot;John&quot; order by age ： 使用索引，因为where中的name和order by中的age组合在一起符合最佳左前缀原则 select * from user where age=22 order by address：不使用索引 总结：order by排序应该遵循最佳左前缀查询，如果是使用多个索引字段进行排序，那么排序的规则必须相同（同是升序或者降序） 总结 使用最佳左前缀 提高sort_buffer_size的值：不管是使用单路排序还是双路排序，提高这个参数都会提高查询效率 提高max_length_for_sort_data的值：提高这个参数的值，会增加使用单路排序算法的概率，但是如果设置的太高，数据总容量超出sort_buffer_size的概率增大，明显症状是磁盘I/O活动和低的处理器使用率 ###]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring的Bean加载过程]]></title>
      <url>%2F2018%2F09%2F02%2FBean%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[spring Bean加载过程1、找准入口 ,使用ClassPathXmlApplicationContext加载配置文件，用于加载classPath下的配置文件 12345//第一行，执行完成之后就完成了spring配置文件的加载，刷新spring上下文ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext( "classpath:spring-mvc.xml");//获取实例BeanPerson person=context.getBean("person",Person.class); ClassPathXmlApplicationContext的继承关系如下： 2、现在开始仔细分析第一句，可以看出第一句就已经完成了spring配置文件的加载 12ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext( "classpath:spring-mvc.xml"); 3、查看classPathXmlApplicationContext的源码，下面表格是对象 对象名 类 型 作 用 归属类 configResources Resource[] 配置文件资源对象数组 ClassPathXmlApplicationContext configLocations String[] 配置文件字符串数组，存储配置文件路径 AbstractRefreshableConfigApplicationContext beanFactory DefaultListableBeanFactory 上下文使用的Bean工厂 AbstractRefreshableApplicationContext beanFactoryMonitor Object Bean工厂使用的同步监视器 AbstractRefreshableApplicationContext id String 上下文使用的唯一Id，标识此ApplicationContext AbstractApplicationContext parent ApplicationContext 父级ApplicationContext AbstractApplicationContext beanFactoryPostProcessors List&lt;BeanFactoryPostProcessor&gt; 存储BeanFactoryPostProcessor接口，Spring提供的一个扩展点 AbstractApplicationContext startupShutdownMonitor Object refresh方法和destory方法公用的一个监视器，避免两个方法同时执行 AbstractApplicationContext shutdownHook Thread Spring提供的一个钩子，JVM停止执行时会运行Thread里面的方法 AbstractApplicationContext resourcePatternResolver ResourcePatternResolver 上下文使用的资源格式解析器 AbstractApplicationContext lifecycleProcessor LifecycleProcessor 用于管理Bean生命周期的生命周期处理器接口 AbstractApplicationContext messageSource MessageSource 用于实现国际化的一个接口 AbstractApplicationContext applicationEventMulticaster ApplicationEventMulticaster Spring提供的事件管理机制中的事件多播器接口 AbstractApplicationContext applicationListeners Set Spring提供的事件管理机制中的应用监听器 AbstractApplicationContext 4、从构造方法可以看出，加载spring配置文件实际调用的是如下构造方法： 12345678910public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; //设置父级的ApplicationContext，null super(parent); //1.设置配置文件的路径， 2. 将路径中的占位符$&#123;placeholder&#125;使用系统的变量替换 setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125; &#125; 5、进入setConfigLocations(configLocations);的源码，这个方法是父类AbstractRefreshableConfigApplicationContext中的方法 1. 设置配置文件的路径 2. 替换路径中的占位符`${placeholder}`为系统变量中的值 1234567891011121314151617//locations : 配置文件路径-+public void setConfigLocations(String[] locations) &#123; if (locations != null) &#123; //断言 Assert.noNullElements(locations, "Config locations must not be null"); //存储配置文件路径的数组，存储去掉占位符后的文件路径数组 this.configLocations = new String[locations.length]; //遍历locations，解析占位符 for (int i = 0; i &lt; locations.length; i++) &#123; //调用resolvePath解析占位符 this.configLocations[i] = resolvePath(locations[i]).trim(); &#125; &#125; else &#123; this.configLocations = null; &#125; &#125; 6、进入resolvePath的源码可以知道，实际上执行的是AbstractPropertyResolver的doResolvePlaceholders方法，如下 123456789101112/*** text : 需要解析的路径* PropertyPlaceholderHelper ： 这个是解析系统占位符的辅助类，主要用来将占位符替换成系统的环境变量*/private String doResolvePlaceholders(String text, PropertyPlaceholderHelper helper) &#123; //调用PropertyPlaceholderHelper类中的replacePlaceholders方法 return helper.replacePlaceholders(text, new PropertyPlaceholderHelper.PlaceholderResolver() &#123; public String resolvePlaceholder(String placeholderName) &#123; return getPropertyAsRawString(placeholderName); &#125; &#125;); &#125; 7、进入PropertyHelper中的replacePlaceholders方法，实际上调用org.springframework.util.PropertyPlaceholderHelper这个类的parseStringValue解析占位符 实际调用的是parseStringValue方法 this.placeholderPrefix这个是占位符的前缀 ${,在创建PropertyHelper的时候就已经指定了占位符的placeholderPrefix=”${“ ,placeholderSuffix=”}”,valueSeparator=”:” 使用parseStringValue方法递归解析占位符中的内容 在parseStringValue方法中使用两次递归 placeholder = parseStringValue(placeholder, placeholderResolver, visitedPlaceholders);,这个是第一次，用来解析占位符中的placeholder是否还包含占位符，如果有占位符需要将其抽离出来，去掉${} propVal = parseStringValue(propVal, placeholderResolver, visitedPlaceholders); ，这个是第二次递归调用，用来解析propVal中的占位符 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public String replacePlaceholders(String value, PlaceholderResolver placeholderResolver) &#123; Assert.notNull(value, "Argument 'value' must not be null."); //调用的是parseStringValue方法 return parseStringValue(value, placeholderResolver, new HashSet&lt;String&gt;()); &#125;/*** strVal ： 需要解析的字符串，就是配置文件的路径* placeholderResolver ： 策略接口，占位符解析器* visitedPlaceholders ： 存储已经访问过的占位符**/protected String parseStringValue( String strVal, PlaceholderResolver placeholderResolver, Set&lt;String&gt; visitedPlaceholders) &#123; //将strval转换成StringBuilder，便于后续到操作 StringBuilder buf = new StringBuilder(strVal); //this.placeholderPrefix这个是占位符的前缀 $&#123;,在创建PropertyHelper的时候就已经指定了占位符的placeholderPrefix="$&#123;" ,placeholderSuffix="&#125;",valueSeparator=":" //获取前缀在这个配置文件路径中的开始索引 int startIndex = strVal.indexOf(this.placeholderPrefix); while (startIndex != -1) &#123; //占位符前缀在路径中的结束索引 int endIndex = findPlaceholderEndIndex(buf, startIndex); //如果结束索引存在 if (endIndex != -1) &#123; //此时取出$&#123;plcaeholder&#125;中的占位符内容placeholder String placeholder = buf.substring(startIndex + this.placeholderPrefix.length(), endIndex); //保存取出来的占位符内容placeholder String originalPlaceholder = placeholder; //如果占位符中的内容已经被访问过了，抛出出异常返回，递归结束的条件 if (!visitedPlaceholders.add(originalPlaceholder)) &#123; throw new IllegalArgumentException( "Circular placeholder reference '" + originalPlaceholder + "' in property definitions"); &#125; //递归解析已经取出的占位符中的内容 palceholder placeholder = parseStringValue(placeholder, placeholderResolver, visitedPlaceholders); //这个最重要的一步，将解析占位符内容placeholder的值，比如将java.version转换成1.8.0_60 String propVal = placeholderResolver.resolvePlaceholder(placeholder); if (propVal == null &amp;&amp; this.valueSeparator != null) &#123; int separatorIndex = placeholder.indexOf(this.valueSeparator); if (separatorIndex != -1) &#123; String actualPlaceholder = placeholder.substring(0, separatorIndex); String defaultValue = placeholder.substring(separatorIndex + this.valueSeparator.length()); propVal = placeholderResolver.resolvePlaceholder(actualPlaceholder); if (propVal == null) &#123; propVal = defaultValue; &#125; &#125; &#125; //如果解析出来的占位符不为空，比如$&#123;java.version&#125;将被解析成 1.8.0_60 if (propVal != null) &#123; //此时继续递归解析出1.8.0_60中的占位符 propVal = parseStringValue(propVal, placeholderResolver, visitedPlaceholders); //将路径中的占位符替换成系统变量的值，比如将$&#123;java.version&#125; 替换成 1.8.0_60 buf.replace(startIndex, endIndex + this.placeholderSuffix.length(), propVal); if (logger.isTraceEnabled()) &#123; logger.trace("Resolved placeholder '" + placeholder + "'"); &#125; //继续在路径字符串中剩余的子串中查找占位符，如果有占位符，那么还会继续解析占位符 startIndex = buf.indexOf(this.placeholderPrefix, startIndex + propVal.length()); &#125; else if (this.ignoreUnresolvablePlaceholders) &#123; // Proceed with unprocessed value. startIndex = buf.indexOf(this.placeholderPrefix, endIndex + this.placeholderSuffix.length()); &#125; else &#123; throw new IllegalArgumentException("Could not resolve placeholder '" + placeholder + "'" + " in string value \"" + strVal + "\""); &#125; //将已转换成功的占位符从以访问的集合中移除即可 visitedPlaceholders.remove(originalPlaceholder); &#125; else &#123; startIndex = -1; &#125; &#125; return buf.toString(); //将解析完成之后的配置文件返回 &#125; 8、总之一句话 ： setConfigLocations(configLocations);的作用就是将客户端传入的配置文件路径，先解析占位符，之后将解析完成之后的配置文件路径存储起来 9、现在进入ClassPathXmlApplicationContext中的refresh方法，实际上调用的是父类org.springframework.context.support.AbstractApplicationContext的方法，下面我们一个一个方法分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//刷新spring上下文public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; //在刷新之前设置一些参数，比如设置开始时间戳，上下文是否激活的标志，输出刷新上下文的信息，验证一些必要的属性 prepareRefresh(); //需要创建beanFactory，如果已经存在beanFactory，那么关闭，详细其请看 10 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 准备上下文工厂，详情见12 prepareBeanFactory(beanFactory); try &#123; //允许子类向后置处理器添加组件 postProcessBeanFactory(beanFactory); // 调用BeanFactoryPostProcessor和BeanDefintionRegistoryPostProcessor这两个后置处理器 invokeBeanFactoryPostProcessors(beanFactory); // 注册BeanPostProcessor,用来拦截bean的创建，详情见 14 registerBeanPostProcessors(beanFactory); //初始化消息源 initMessageSource(); // 初始化应用程序事件广播器，用户可以自定义一个事件广播器，如果用户没有定义，那么使用默认的事件广播器SimpleApplicationEventMulticaster initApplicationEventMulticaster(); // 在其他子类中初始化bean onRefresh(); // 检测事件监听器 registerListeners(); //完成实例化剩余的单例(non-lazy-init) finishBeanFactoryInitialization(beanFactory); // 完成刷新，初始化生命周期处理器...... finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125; &#125; 10、进入obtainFreshBeanFactory ，分析源码 1234567891011121314151617181920212223242526272829303132333435363738394041//AbastractApplicationContext的方法protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; //实际刷新上下文的方法，这个方法就是实际的刷新上下文方法，其中会调用loadBeanDefinitions(beanFactory);加载配置文件中的内容到BeanDefiniton中 refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug("Bean factory for " + getDisplayName() + ": " + beanFactory); &#125; return beanFactory; &#125; //org.springframework.context.support.AbstractRefreshableApplicationContext中的方法 //AbstractApplicationContext的子类中的方法 @Override protected final void refreshBeanFactory() throws BeansException &#123; //如果其中有beanfactory，那么销毁 if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; //重新创建一个beanFactory DefaultListableBeanFactory beanFactory = createBeanFactory(); //设置序列化id beanFactory.setSerializationId(getId()); //定制beanFactory，设置相关属性，包括是否允许覆盖名称的不同定义的对象及循环依赖以及 //设置@Autowired和@Qualifier，注解解析器QualifierAnnotationAutowireCandidateResolver customizeBeanFactory(beanFactory); //加载BeanDefine 详情见 11 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException("I/O error parsing bean definition source for " + getDisplayName(), ex); &#125; &#125; 11、 进入loadBeanDefinitions(beanFactory);方法 ​ 1、主要调用的是XmlBeanDefinitionReader其中的loadBeanDefinitions方法，详情请看我的spring之BeanDefinitonReader解析 12345678910111213141516//这个是org.springframework.context.support.AbstractXmlApplicationContext类中的方法protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; //创建要给beanDefinitionReader，用于读取BeanDefinition //详情见 BeanDefinitonReader的源码解析 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); //配置XmlBeanDefinitionReader beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); initBeanDefinitionReader(beanDefinitionReader); //加载BeanDefiniton，主要的功能从配置文件中读取BeanDefiniton注册到注册表中 loadBeanDefinitions(beanDefinitionReader);&#125; 12、prepareBeanFactory ：准备BeanFactory，目前还不太明白，后续分析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//准备BeanFactory，设置一些参数，比如后置处理器，protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; //设置类加载器 beanFactory.setBeanClassLoader(getClassLoader()); //设置表达式解析器，用来解析BeanDefiniton中的带有表达式的值 beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 配置后置处理器，主要的作用就是在spring实例化bean的前后做一些操作 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); //忽略自动装配的类，这些类都不能使用@Resource或者@Autowired自动装配获取对象 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); //注册可解析的自动装配类 beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); //在添加一个应用程序监听器 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); //检查这些类是否被 if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // 将下面这些类注册到容器中，使用registerSingleton方法注册，我们可以直接从容器中获取这些类的对象使用 if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125; &#125; 13、调用BeanFactory的后置处理器，主要的功能就是调用注册在容器中的BeanFactoryPostProcessor和BeanDefinitionRegistoryPostProcessor ​ 1、BeanFactoryPostProcessor这个是后置处理器，实现这个类可以修改容器中bean的数据信息，可以在spring配置文件加载之后执行，在单例实例化之前调用，因此可以在其中修改和获取bean的实例化的信息，通过BeanDefintion ​ 2、先调用BeanDefinitionRegistryPostProcessor，按照优先级调用，比如分为实现PriorityOrdered这个接口和Orderd这个接口的，分开调用 ​ 3、再调用实现BeanFactoryPostProcessor这个接口的，也是按照优先级别调用，和上面的流程一样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150//实例化和调用BeanFactory后置处理器，必须在单例实例化之前调用protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; //调用后置处理器注册委托类的方法调用，getBeanFactoryPostProcessors用于获取注册的全部的BeanFactoryPostProcessor PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); &#125;//实际的调用方法，PostProcessorRegistrationDelegate中的方法public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // Invoke BeanDefinitionRegistryPostProcessors first, if any. Set&lt;String&gt; processedBeans = new HashSet&lt;String&gt;(); //如果beanFactory是BeanDefinitionRegistry的子类，BeanDefinitionRegistry使用来向注册表中注册Bean的元信息的(BeanDefintion) if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; //存放BeanFactoryPostProcessor List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new LinkedList&lt;BeanFactoryPostProcessor&gt;(); //存放BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; registryPostProcessors = new LinkedList&lt;BeanDefinitionRegistryPostProcessor&gt;(); //遍历。判断是否是BeanDefinitionRegistryPostProcessor实例 for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryPostProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; //调用BeanDefinitionRegistryPostProcessor registryPostProcessor.postProcessBeanDefinitionRegistry(registry); //添加 registryPostProcessors.add(registryPostProcessor); &#125; else &#123; //表示这个是BeanFactoryPostProcessor实例，添加进集合 regularPostProcessors.add(postProcessor); &#125; &#125; //--- 根据类型类型获取beanFactory中注册的BeanDefinitionRegistryPostProcessor的bean的所有名称数组 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); // ---- 首先调用的是BeanDefinitionRegistryPostProcessor类型的后置处理器 //存放实现PriorityOrdered这个接口的BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanDefinitionRegistryPostProcessor&gt;(); //遍历，如果实现了PriorityOrdered这个接口就保存下来 for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; //按照优先级排序 OrderComparator.sort(priorityOrderedPostProcessors); //添加进入集合 registryPostProcessors.addAll(priorityOrderedPostProcessors); //首先调用实现PriorityOrdered这个接口的BeanDefinitionRegistryPostProcessor invokeBeanDefinitionRegistryPostProcessors(priorityOrderedPostProcessors, registry); // ---- 下面是调用实现Orderd这个接口的BeanDefinitionRegistryPostProcessor postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); List&lt;BeanDefinitionRegistryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanDefinitionRegistryPostProcessor&gt;(); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; OrderComparator.sort(orderedPostProcessors); registryPostProcessors.addAll(orderedPostProcessors); invokeBeanDefinitionRegistryPostProcessors(orderedPostProcessors, registry); // ---- 最终调用剩余全部的BeanDefinitionRegistryPostProcessor boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; BeanDefinitionRegistryPostProcessor pp = beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class); registryPostProcessors.add(pp); processedBeans.add(ppName); pp.postProcessBeanDefinitionRegistry(registry); reiterate = true; &#125; &#125; &#125; // 调用BeanFactoryPostProcessor接口中的方法，因为BeanDefitionRegistory继承了这个接口 invokeBeanFactoryPostProcessors(registryPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; //--- 下面是调用实现BeanFactoryPostProcessor接口的类，和上面的流程一样 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // Separate between BeanFactoryPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. OrderComparator.sort(priorityOrderedPostProcessors); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; OrderComparator.sort(orderedPostProcessors); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); &#125; 14、注册BeanPostProcessor，用来拦截Bean的创建，这个接口可以实现在Bean初始化和初始化之后执行相关的操作，会有单独一篇解读 ​ 1、这个注册BeanPostProcessor思想和上面的调用BeanFactoryPostProcessor的思想一样，按照优先级注册，通过判断是否实现PriorityOrdered和orderd接口，按照优先级排序注册到BeanFactory中，其实注册的方法就是将这个后置处理器添加到beanFactory中的List&lt;BeanPostProcessor&gt; beanPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//依然这里依然调用的PostProcessorRegistrationDelegate，其中包含了注册后置处理器和调用后置处理器的方法，相当于一个代理人protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this); &#125;//PostProcessorRegistrationDelegate中的注册BeanPostProcessors的方法//其中beanFactory这个新创建的beanFactory，其中的BeanPostProcessor都没有注册，applicationContext这个是之前创建的，其中的处理器已经注册过了public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; //根据类型新加载全部的BeanFactoryProcessor的类， String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); //创建BeanPostProcessor检测器 int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. OrderComparator.sort(priorityOrderedPostProcessors); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; OrderComparator.sort(orderedPostProcessors); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. OrderComparator.sort(internalPostProcessors); registerBeanPostProcessors(beanFactory, internalPostProcessors); beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext)); &#125; 总结1、入口 1ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext("spring-test.xml"); 2、解析传入的路径中的占位符，集合org.springframework.core.env.AbstractPropertyResolver和org.springframework.util.PropertyPlaceholderHelper 3、刷新上下文 ​ 1、prepareRefresh() : 准备刷新，设置一些活动标志，比如开始时间，当前的状态 ​ 2、ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory()：从spring的配置文件中加载bean，封装成BeanDefinition，注册到注册表中，创建beanFactory ​ 3、prepareBeanFactory(beanFactory); ：准备BeanFactory，设置累加载器，添加后置处理器，SPL表达式解析器，向ioc容器中注入一些组件 ​ 4、postProcessBeanFactory(beanFactory); ： 允许子类做一些处理操作 ​ 5、invokeBeanFactoryPostProcessors(beanFactory); ：调用BeanFactoryProcessor，先是调用BeanDefitionRegistoyPostProcessor,之后调用BeanFactoryProcessor ​ 6、registerBeanPostProcessors(beanFactory); ： 将配置文件中读取的Bean的后置处理器注册到容器中 ​ 7、initMessageSource(); ：初始化消息源，用于国际化 ​ 8、initApplicationEventMulticaster() ： 初始化事件广播器，判断容器中是否已经注册了该组件，如果没有该组件，那么使用默认的 ​ 9、onRefresh(); ：子类初始化一些特殊的bean ​ 10、registerListeners(); ：注册事件监听器 ​ 11、finishBeanFactoryInitialization(beanFactory) ：完成初始化，初始化非懒加载的bean ​ 12、finishRefresh(); ：完成刷新，最后一步，初始化生命周期处理器，派发事件 参考文章 https://blog.csdn.net/turkeyzhou/article/category/365505/2 https://www.evget.com/article/2016/2/23/23576.html http://www.cnblogs.com/killbug/p/6087648.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring-Data-Redis]]></title>
      <url>%2F2018%2F09%2F02%2FSpring-Data-Redis%2F</url>
      <content type="text"><![CDATA[Spring-Data-Redis添加依赖 需要spring的版本为4.xxx 12345678910111213&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.8.9.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置RedisTemplate 在/src/main/resource文件夹下新建一个redis.properties文件，其中设置redis的配置信息 12345678910111213hostName=39.105.123.197 port=6379timeout=15000usePool=truemaxIdle=80minIdle=80maxWaitMillis=500minEvictableIdleTimeMillis=300000numTestsPerEvictionRun=3timeBetweenEvictionRunsMillis=60000testOnBorrow=truetestOnReturn=falsetestOnCreate=false 在src/main/resource文件夹下新建一个文件spring-redis.xml 创建连接池JedisPoolConfig 创建连接工厂JedisConnectionFactory 配置RedisTemplate，用于操作Redis数据库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;!-- 加载redis.properties,其中定义了数据库的配置信息 --&gt; &lt;util:properties id="redisConfig" location="classpath:redis.properties" /&gt; &lt;!-- 配置Redis的连接池 --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;!-- 配置最大空闲连接数，当空闲连接超过该值时就挨个关闭多余的连接，但不能小于minldle --&gt; &lt;property name="maxIdle" value="#&#123;redisConfig.maxIdle&#125;"&gt;&lt;/property&gt; &lt;!-- 配置最小空闲连接数 --&gt; &lt;property name="minIdle" value="#&#123;redisConfig.minIdle&#125;"&gt;&lt;/property&gt; &lt;!-- 验证连接是否有效 --&gt; &lt;!-- 设置获取连接的时候测试连接是否可用，默认为false --&gt; &lt;property name="testOnBorrow" value="#&#123;redisConfig.testOnBorrow&#125;"&gt;&lt;/property&gt; &lt;!-- 新建连接的时候测试连接是否可用，默认为false --&gt; &lt;property name="testOnCreate" value="#&#123;redisConfig.testOnCreate&#125;"&gt;&lt;/property&gt; &lt;!-- 将连接释放回连接池的时候测试连接 默认为false --&gt; &lt;property name="testOnReturn" value="#&#123;redisConfig.testOnReturn&#125;"&gt;&lt;/property&gt; &lt;!-- 设置等待获取连接池连接的时间，一旦超过这个时间，抛出异常 单位毫秒 --&gt; &lt;property name="maxWaitMillis" value="#&#123;redisConfig.maxWaitMillis&#125;"&gt;&lt;/property&gt; &lt;!-- 连接空闲多久从池中去除，单位为毫秒 &lt;=0表示禁用 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="#&#123;redisConfig.minEvictableIdleTimeMillis&#125;"&gt;&lt;/property&gt; &lt;!-- 设置每次测试多少空闲连接 &lt;=0表示禁用 --&gt; &lt;property name="numTestsPerEvictionRun" value="#&#123;redisConfig.numTestsPerEvictionRun&#125;"&gt;&lt;/property&gt; &lt;!-- 设置定时测试时间，单位毫秒 &lt;=0表示禁用 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="#&#123;redisConfig.timeBetweenEvictionRunsMillis&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="jedisConnFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;!-- 设置是否使用连接池，默认为true --&gt; &lt;property name="usePool" value="#&#123;redisConfig.usePool&#125;" /&gt; &lt;!-- 设置连接池，使用上面配置好的连接池jedisPoolConfig --&gt; &lt;property name="poolConfig" ref="jedisPoolConfig"&gt;&lt;/property&gt; &lt;!-- 设置远程的IP地址 --&gt; &lt;property name="hostName" value="#&#123;redisConfig.hostName&#125;" /&gt; &lt;!-- 设置端口号，默认为6379 --&gt; &lt;property name="port" value="#&#123;redisConfig.port&#125;"&gt;&lt;/property&gt; &lt;!-- 设置获取连接的超时时间 --&gt; &lt;property name="timeout" value="#&#123;redisConfig.timeout&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置 StringRedisSerializer序列化 --&gt; &lt;bean id="stringRedisSerializer" class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt; &lt;bean id="jdkSerializationRedisSerializer" class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer" /&gt; &lt;!-- 配置RedisTemplate，其中封装了操作Redis的各种方法 --&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;!-- 配置Jedis的连接工厂，引用上面 --&gt; &lt;property name="connectionFactory" ref="jedisConnFactory" /&gt; &lt;!-- 配置key的序列化 一般都会使用stringRedisSerializer，默认使用的是JdkSerializationRedisSerializer --&gt; &lt;property name="keySerializer" ref="stringRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 配置JdkSerializationRedisSerializer序列化 --&gt; &lt;property name="valueSerializer" ref="jdkSerializationRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 配置hashkey的序列化，就是field --&gt; &lt;property name="hashKeySerializer" ref="stringRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 配置hashvalue的值的序列化 --&gt; &lt;property name="hashValueSerializer" ref="jdkSerializationRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 开始redis事务，使用mulit和exec即可实现事务的操作和回滚 --&gt; &lt;property name="enableTransactionSupport" value="true"&gt;&lt;/property&gt; &lt;/bean&gt; 序列化问题 Spring Data Redis提供了对Key-Value的序列号，在使用RedisTemplate对象是默认使用JdkSerializationRedisSerializer实现。还提供了其它的序列化实现如：Jackson2JsonRedisSerializer，JacksonJsonRedisSerializer，GenericToStringSerializer，StringRedisSerializer，OxmSerializer。 各种序列化的方式有各种的优点，需要自己权衡使用 上面我们使用的是JdkSerializationRedisSerializer，但是我们的key使用的是StringRedisSerializer 实体类需要实现序列化接口 RedisTemplate 这个封装了redis中的所有命令，只需要我们调用即可 API文档 常用的类 Key类型操作 ValueOperations Redis String/Value 操作 ListOperations Redis List 操作 SetOperations Redis Set 操作 ZSetOperations Redis Sort Set 操作 HashOperations Redis Hash 操作 Value约束操作 BoundValueOperations Redis String/Value key 约束 BoundListOperations Redis List key 约束 BoundSetOperations Redis Set key 约束 BoundZSetOperations Redis Sort Set key 约束 BoundHashOperations Redis Hash key 约束 spring中处理Redis的事务1、spring的事务管理器一定要使用注解方式的，不能使用aop方式的 2、需要在spring-data-redis中开启redis事务，只需要添加如下一条语句即可 12&lt;!-- 开始redis事务，使用mulit和exec即可实现事务的操作和回滚 --&gt;&lt;property name="enableTransactionSupport" value="true"&gt;&lt;/property&gt; 3、在spring中使用RedisTemplate.multi和exec方法即可完成事务的控制 1234567public Object addUser(User user) throws Exception &#123; userMapper.insertSelective(user); System.out.println(user.getId()); template.opsForValue().set("user:"+user.getId(), user); System.out.println(10/0); return null; &#125; 4、参考文章：https://blog.csdn.net/qq_34021712/article/details/75949756 工具类 通过项目中的使用，自己总结了redis的工具类，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381import java.util.ArrayList;import java.util.Collection;import java.util.Collections;import java.util.HashMap;import java.util.HashSet;import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.TimeUnit;import javax.annotation.Resource;import org.apache.xmlbeans.impl.xb.xsdschema.Public;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ZSetOperations.TypedTuple;import org.springframework.stereotype.Component;import com.sun.corba.se.impl.oa.poa.ActiveObjectMap.Key;import com.techwells.teammission.domain.User;/** * redis的工具类 * @author chenjiabing */public class RedisUtils &#123; private RedisTemplate&lt;String, Object&gt; template; public final RedisTemplate&lt;String, Object&gt; getTemplate() &#123; return template; &#125; public final void setTemplate(RedisTemplate&lt;String, Object&gt; template) &#123; this.template = template; &#125; /** * 向redis中添加对象,string类型的对象 * @param object 需要存储的对象 * @param key 存储的键 * @throws Exception 出现异常信息 */ public void addStringObject(String key,Object object)throws Exception&#123; template.opsForValue().set(key,object); &#125; /** * 添加指定的key到Redis中 * @param key 指定的Ke * @param object 数据 * @param timeout 过期时间 * @param unit 时间单位 * @throws Exception */ public void addStringObject(String key,Object object,Long timeout,TimeUnit unit) throws Exception&#123; this.addStringObject(key, object); template.expire(key, timeout, unit); &#125; /** * 根据键值从redis中获取对象 string类型的对象 * @param key key * @return 返回对象 * @throws Exception 抛出的异常 */ public Object getStringObject(String key)throws Exception&#123; Object object=template.opsForValue().get(key); return object; &#125; /** * 根据key删除指定的值 * @param key key * @throws Exception 异常信息 */ public void deleteObject(String key)throws Exception&#123; template.delete(key); &#125; /** * 批量删除对象 * @param keys key的集合 */ public void deleteObjectBatch(Collection&lt;String&gt; keys)throws Exception&#123; template.delete(keys); &#125; /** * 根据key更新值 * @param key key * @param object value * @throws Exception 异常信息 */ public void modifyStringObject(String key,Object object)throws Exception&#123; this.addStringObject(key, object); &#125; /** * 添加数据在Hash中 * @param key key * @param field 指定的域 * @param object 数据 */ public void addHashObject(String key,String field,Object object)throws Exception&#123; template.opsForHash().put(key, field, object); &#125; /** * 向hash中添加数据，并且设置过期的时间 * @param key key * @param field 域 * @param object 数据 * @param timeout 过期时间 * @param unit 单位 * @throws Exception */ public void addHashObject(String key,String field,Object object,Long timeout,TimeUnit unit)throws Exception&#123; this.addHashObject(key, field, object); this.setExpireTimeForKey(key, timeout, unit); &#125; /** * 批量添加数据到指定的hash中 * @param key key * @param map 需要添加的数据 Map&lt;field,value&gt; * @param expireTime 过期时间，单位秒,如果为null，默认永远不过期 */ public void addHashObjectBatch(String key,Map&lt;Object, Object&gt; map,Long expireTime,TimeUnit unit)throws Exception&#123; template.opsForHash().putAll(key,map); if (expireTime!=null) &#123; this.setExpireTimeForKey(key, expireTime,unit); //设置过期时间 &#125; &#125; /** * 为指定的key设置过期时间 * @param key key * @param timeout 过期时间 * @param unit 指定时间的单位 */ public void setExpireTimeForKey(String key,Long timeout,TimeUnit unit)&#123; template.expire(key, timeout, unit); &#125; /** * 删除指定的key * @param key */ public void deleteKey(String key)&#123; template.delete(key); &#125; /** * 根据key，field从hash中获取数据 * @param key * @param field * @return Object对象 */ public Object getHashObject(String key,String field)throws Exception&#123; return template.opsForHash().get(key, field); &#125; /** * 修改指定key，field中的数据 * @param key * @param field * @param object */ public void modifyHashObject(String key,String field,Object object)throws Exception&#123; this.addHashObject(key, field, object); &#125; /** * 删除指定的key和field中的数据 * @param key * @param field */ public void deleteHashObject(String key,String field)throws Exception&#123; this.deleteHashObjectBatch(key, new Object[]&#123;field&#125;); &#125; /** * 根据key和fields批量获取其中的数据 * @param key key * @param fields &#123;@link Collection&lt;Object&gt; &#125; * @throws Exception */ public void getHashObjectBatch(String key,Collection&lt;Object&gt; fields)throws Exception&#123; template.opsForHash().multiGet(key, fields); &#125; /** * 批量删除指定key和fields的数据 * @param key key * @param fields 需要删除的域 * @throws Exception */ public void deleteHashObjectBatch(String key,Object[] fields)throws Exception&#123; template.opsForHash().delete(key,fields); &#125; /** * 添加数据到ZSet中 * @param key 指定的key * @param value 指定的value * @param score 指定的score */ public void addZSetObject(String key,String value,double score)throws Exception&#123; template.opsForZSet().add(key, value, score); &#125; /** * 批量添加数据到Zset中 * @param key 指定的key * @param typedTuple &#123;@link TypedTuple&#125; */ public void addZSetObjectBatch(String key,Set&lt;TypedTuple&lt;Object&gt;&gt; typedTuple)&#123; template.opsForZSet().add(key, typedTuple); &#125; /** * 根据key获取start--end之间的数据 * @param key 指定key * @param start 开始索引，从0开始 * @param end 结束索引 * @return &#123;@link Set&lt;Object&gt;&#125; */ public Set&lt;Object&gt; getZSetObject(String key,Long start,Long end)&#123; return template.opsForZSet().range(key, start, end); &#125; /** * 根据Score的范围获取数据 * @param key 指定的key值 * @param min score的最小值 * @param max score的最大值 * @return &#123;@link Set&lt;Object&gt;&#125; */ public Set&lt;Object&gt; getZSetObjectRangeByScore(String key,Long min,Long max)&#123; return template.opsForZSet().rangeByScore(key, min, max); &#125; /** * 根据Score的范围获取数据,分页获取 * @param key 指定的key * @param min 最小值 * @param max 最大值 * @param offset 偏移量 * @param count 数量 * @return */ public Set&lt;Object&gt; getZSetObjectRangeByScore(String key,Long min,Long max,Long offset,Long count)&#123; return template.opsForZSet().rangeByScore(key, min, max, offset, count); &#125; /** * 向List中添加元素，从表头添加 * @param key * @param value */ public void addLeftListObject(String key,Object value)&#123; template.opsForList().leftPush(key, value); &#125; /** * 向List中添加元素，从表尾添加 * @param key * @param value */ public void addRightListObject(String key,Object value)&#123; template.opsForList().rightPush(key, value); &#125; /** * 向List中添加元素，从表头添加 * @param key * @param value * @param timeOut 过期时间 * @param unit 单位 */ public void addLeftListObject(String key,Object value,Long timeOut,TimeUnit unit)&#123; template.opsForList().leftPush(key, value); this.setExpireTimeForKey(key, timeOut, unit); //设置过期时间 &#125; /** * 批量从表头添加数据 * @param key * @param timeout ： 过期时间 如果为null表示永久不过期 * @param timeUnit : 时间单位 * @param values &#123;@link Collection&lt;Object&gt;&#125; */ public void addLeftListObjectBatch(String key,Collection&lt;Object&gt; values,Long timeout,TimeUnit unit)&#123; template.opsForList().leftPushAll(key, values); if (timeout!=null) &#123; this.setExpireTimeForKey(key, timeout, unit); &#125; &#125; /** * 批量从表尾添加数据 * @param key * @param values &#123;@link Collection&lt;Object&gt;&#125; */ public void addRigthListObjectBatch(String key,Collection&lt;Object&gt; values,Long timeout,TimeUnit unit)&#123; template.opsForList().rightPushAll(key, values); if (timeout!=null) &#123; this.setExpireTimeForKey(key, timeout, unit); &#125; &#125; /** * 获取指定范围内的数据 * @param key * @param i 开始的索引 从0开始 * @param j 结束的索引，-1 表示结尾 * @return &#123;@link List&lt;Object&gt;&#125; */ public List&lt;Object&gt; getRangeListObject(String key,int i,int j)&#123; return template.opsForList().range(key, i, j); &#125; /** * 根据实体类的key和指定的查询参数、方法名称获取指定的key * @param domainKey 实体类指定的key * @param params 参数 Map&lt;String,Object&gt; * @param functionName : 方法的名称 * @return */ public static String getRedisKey(String domainKey,String functionName,PagingTool pagingTool)throws Exception&#123; StringBuilder builder=new StringBuilder(); Map&lt;String,Object&gt; params=pagingTool.getParams(); builder.append(domainKey+"_"+functionName+"_"+pagingTool.getStartNum()+"_"+pagingTool.getPageSize()+"_"); for (String key : params.keySet()) &#123; builder.append(key+"="+params.get(key)+"_"); &#125; return builder.toString(); &#125; /** * 将Collection&lt;?extend Object&gt;的集合转换成Collection&lt;Object&gt; * @param list 需要转换的集合 * @return Collection&lt;Object&gt; * @throws Exception */ public static Collection&lt;Object&gt; convertToCollection(Collection&lt;? extends Object&gt; list) throws Exception&#123; List&lt;Object&gt; arrayList=new ArrayList&lt;Object&gt;(list.size()); for (Object object : list) &#123; arrayList.add(object); &#125; return arrayList; &#125; /** * 将指定的List集合中的元素逆向 * @param objects List&lt;? extends Object&gt; */ public static void reverse(List&lt;? extends Object&gt; objects)&#123; Collections.reverse(objects); &#125; /** * 删除所有的键值 */ public void delteAllKeys()&#123; Set&lt;String&gt; keys=template.keys("*"); //获取所有的key template.delete(keys); //删除所有的键值 &#125; &#125; 文档 RedisTemplate API 优质博文 https://blog.csdn.net/u010690828/article/details/77141083]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring-data-elasticsearch]]></title>
      <url>%2F2018%2F09%2F02%2Fspring-data-elasticsearch%2F</url>
      <content type="text"><![CDATA[spring-data-elasticsearch SpringBoot整合es文档 @Document @Document(indexName = &quot;es&quot;,type = &quot;user&quot;,shards = 5,replicas = 0) ： 标注在实体类上，声明存储的索引和类型 indexName： 索引名称 type：索引类型 shards：分片的数量 replicas：副本的数量 refreshInterval： 刷新间隔 indexStoreType：索引文件存储类型 @Field 标注在属性上，用来指定属性的类型。其中的属性如下： analyzer：指定分词器，es中默认使用的标准分词器，比如我们需要指定中文IK分词器，可以指定值为ik_max_word type： 指定该属性在es中的类型，其中的值是FileType类型的值，比如FileType.Text类型对应es中的text类型 index：指定该词是否需要索引，默认为true store：指定该属性内容是否需要存储，默认为 fielddata ：指定该属性能否进行排序，因为es中的text类型是不能进行排序（已经分词了） searchAnalyzer ： 指定搜索使用的分词器 在插入数据之前我们需要先运行程序添加mapping，对于没有指定@Field的属性此时是不会创建索引的，而是在插入数据的时候自动创建索引。但是对于@Field注解标注的属性如果没有先加载生成mapping，等到插入数据的时候是没有效果的 如果使用该注解，那么必须指定其中的type属性 @Id 主键注解，标识一个属性为主键 Date类型的存储 es中默认存储Date类型的是一个时间戳，如果我们需要指定格式的存储，那么需要在@Field这个注解中指定日期的格式。如下： 123@Field(type = FieldType.Date,format = DateFormat.custom, pattern ="yyyy-MM-dd HH:mm:ss")@JsonFormat(shape = JsonFormat.Shape.STRING, pattern ="yyyy-MM-dd HH:mm:ss", timezone = "GMT+8") private Date birthday; 创建一个实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * @Document : 这个是ES的注解，在类使用，指定实体类的索引和类型。默认所有的属性都是索引的 * 1、indexName ： 指定索引 * 2、type：指定类型 * 3、shards：指定分片的数量 * 4、replicas：指定副本的数量 */@Document(indexName = "es",type = "user",shards = 5,replicas = 0)public class User &#123; @Id //指定这个是主键 private Integer userId; @Field(type = FieldType.Text,analyzer = "ik_max_word",fielddata = true,store = false) private String userName; private String password; @Field(type = FieldType.Date, store = true, format = DateFormat.custom, pattern ="yyyy-MM-dd HH:mm:ss") @JsonFormat(shape = JsonFormat.Shape.STRING, pattern ="yyyy-MM-dd HH:mm:ss", timezone = "GMT+8") private Date birthday; private List&lt;String&gt; hobbies; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public List&lt;String&gt; getHobbies() &#123; return hobbies; &#125; public void setHobbies(List&lt;String&gt; hobbies) &#123; this.hobbies = hobbies; &#125; @Override public String toString() &#123; return "User&#123;" + "userId=" + userId + ", userName='" + userName + '\'' + ", password='" + password + '\'' + ", birthday=" + birthday + ", hobbies=" + hobbies + '&#125;'; &#125;&#125; 定义查询接口 官网上提供了各种各样的方法，我们使用继承ElasticsearchRepository这个接口的方式拓展查询接口，基本的接口： 123 public interface UserRepo extends ElasticsearchRepository&lt;User,Integer&gt; &#123; //不需要实现其中的方法，只需要继承即可，spring-data-es会为我们自动完成&#125; 常用方法如下： index(T t) ：添加数据 save(T t)：添加数据 count()： 获取数据总数 findAll()：获取所有的数据，返回的是一个java.lang.Iterable Iterable&lt;T&gt; findAllById(Iterable&lt;ID&gt; ids)：根据Id批量返回数据 saveAll(Iterable entity) ：批量保存数据，可以传入List delete(T t) ： 删除指定的实体类，只需要指定实体类中的Id即可 deleteAll()：删除所有的数据 deleteById(ID Id)：根据Id删除数据 existsById(ID Id)： 判断指定Id的数据是否存在 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 //添加数据 @Test public void test3()&#123; User user=new User(); user.setUserId(1); user.setUserName("郑元梅"); user.setBirthday(new Date()); user.setPassword("12345678"); List&lt;String&gt; hobbies=new ArrayList&lt;&gt;(); hobbies.add("篮球"); hobbies.add("足球"); user.setHobbies(hobbies);// userRepo.save(user); //调用其中的save方法保存信息 userRepo.index(user); //调用index方法添加数据 &#125; //获取其中的所有数据 @Test public void test4()&#123; Iterable&lt;User&gt; iterable=userRepo.findAll(); Iterator&lt;User&gt; iterator=iterable.iterator(); while (iterator.hasNext())&#123; System.out.println(iterator.next()); &#125; &#125; @Test public void test5()&#123; List&lt;User&gt; users=new ArrayList&lt;&gt;(); User user=new User(); user.setUserId(4); user.setUserName("张三"); user.setBirthday(new Date()); user.setPassword("12345678"); List&lt;String&gt; hobbies=new ArrayList&lt;&gt;(); hobbies.add("台球"); hobbies.add("足球"); user.setHobbies(hobbies); User user1=new User(); user1.setUserId(5); user1.setUserName("郑元梅"); user1.setBirthday(new Date()); user1.setPassword("12345678"); user1.setHobbies(hobbies); users.add(user); users.add(user1); userRepo.saveAll(users); //保存List中的所有数据 &#125; //删除指定的数据 @Test public void test6()&#123; User user=new User(); user.setUserId(5); userRepo.delete(user); &#125; @Test public void test7()&#123; List&lt;User&gt; users=userRepo.selectAll(); for (User user :users ) &#123; System.out.println(user); &#125; &#125; 自定义查询 spring-data-elasticsearch为我们自动完成了许多的查询，我们只需要按照其中的规范使用即可。 查询方法定义以get或者find开头即可 关于es中各种查询，我们可以参照下表进行定义，文档 And findByNameAndPrice {&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Or findByNameOrPrice {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Is findByName {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Not findByNameNot {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Between findByPriceBetween {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} LessThanEqual findByPriceLessThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} GreaterThanEqual（&gt;=） findByPriceGreaterThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Before（&lt;=） findByPriceBefore {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} After findByPriceAfter {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Like（?%）（如果需要实现%?%可以使用fuzzy） findByNameLike {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} StartingWith findByNameStartingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} EndingWith findByNameEndingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}} Contains/Containing findByNameContaining {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}} In findByNameIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}} NotIn findByNameNotIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}} Near findByStoreNear Not Supported Yet ! True findByAvailableTrue {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} False findByAvailableFalse {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}} OrderBy findByAvailableTrueOrderByNameDesc {&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247package com.techwells.es;import com.techwells.beans.User;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.elasticsearch.annotations.Document;import org.springframework.data.elasticsearch.annotations.Query;import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;import java.util.Date;import java.util.List;public interface UserRepo extends ElasticsearchRepository&lt;User,Integer&gt;&#123; /** * 根据userId获取用户信息 * @param userId * @return */ User findUserByUserId(Integer userId); /** * 根据用户查找用户信息 * @param userName * @return */ List&lt;User&gt; findByUserName(String userName); /** * 根据用户名和密码查找用户信息，使用的是must查询 * 参数的顺序不能颠倒 * @param userName * @param password * @return */ List&lt;User&gt; findByUserNameAndPassword(String userName,String password); /** * 根据用户名或者地址进行查询，满足其一即可，使用的是should * 参数不能颠倒 * @param userName * @param address * @return */ List&lt;User&gt; findByUserNameOrAddress(String userName,String address); /** * 使用@Query注解自定义查询语句，其中的?是占位符，0表示第一个参数 * @param userName * @return */ @Query("&#123;\n" + " \"bool\": &#123;\n" + " \"must\": [\n" + " &#123;\n" + " \"match\": &#123;\n" + " \"userName\": \"?0\"\n" + " &#125;\n" + " &#125;\n" + " ]\n" + " &#125;\n" + " &#125;") List&lt;User&gt; selectByUserName(String userName); /** * 查询密码不为null的用户信息 * @return */ @Query("&#123;\n" + " \"bool\": &#123;\n" + " \"must\":&#123;\n" + " \"exists\":&#123;\n" + " \"field\":\"password\"\n" + " &#125;\n" + " &#125;\n" + " &#125;\n" + " &#125;") List&lt;User&gt; findByPasswordIsNotNull(); /** * 查询密码为null的用户信息 * @return */ @Query("&#123;\n" + " \"bool\": &#123;\n" + " \"must_not\":&#123;\n" + " \"exists\":&#123;\n" + " \"field\":\"password\"\n" + " &#125;\n" + " &#125;\n" + " &#125;\n" + " &#125;") List&lt;User&gt; findByPasswordIsNull(); /** * 查询密码不是password的用户信息，使用的must_not * @param password * @return */ List&lt;User&gt; findByPasswordNot(String password); /** * 查询用户名是userName但是密码表示password的信息，必须同时满足 * @param userName * @param password * @return */ List&lt;User&gt; findByUserNameAndPasswordNot(String userName,String password); /** * 查询年龄在from-to之间的用户，包含form和to，使用的是range查询 * @param from 起始 * @param to 截止 * @return */ List&lt;User&gt; findByAgeBetween(Integer from,Integer to); /** * 查询年龄小于age的用户信息 * @param age 年龄 * @return */ List&lt;User&gt; findByAgeLessThan(Integer age); /** * 年龄小于等于age的用户信息 */ List&lt;User&gt; findByAgeLessThanEqual(Integer age); /** * 年龄大于age的用户 * @param age * @return */ List&lt;User&gt; findByAgeGreaterThan(Integer age); /** * 年龄大于等于age的用户 * @param age * @return */ List&lt;User&gt; findByAgeGreaterThanEqual(Integer age); /** * 年龄小于等于age的用户信息 * @param age * @return */ List&lt;User&gt; findByAgeBefore(Integer age); /** * 年龄大于等于age的用户 * @param age * @return */ List&lt;User&gt; findByAgeAfter(Integer age); /** * 模糊查找，密码中以pwd开头用户信息，`content%`， * @param content * @return */ List&lt;User&gt; findByPasswordLike(String content); /** * 查询密码中包含content的用户信息 %content% * @param content * @return */ List&lt;User&gt; findByPasswordContaining(String content); /** * 查询密码以pwd开头的用户信息，和Like一样的效果 * @param pwd * @return */ List&lt;User&gt; findByPasswordStartingWith(String pwd); /** * 查询密码以pwd结尾的用户信息 * @param pwd * @return */ List&lt;User&gt; findByPasswordEndingWith(String pwd); /** * 查找年龄在集合中的用户信息 * @param ages * @return */ List&lt;User&gt; findByAgeIn(List&lt;Integer&gt; ages); /** * 查找年龄不在集合中的用户信息 * @param ages * @return */ List&lt;User&gt; findByAgeNotIn(List&lt;Integer&gt; ages); /** * 根据用户名查询并且按照年龄降序排列 * @param userName * @return */ List&lt;User&gt; findByUserNameOrderByAgeDesc(String userName); /** * 根据用户名查询并且按照年龄降序排列、用户名升序排列 * @param userName * @return */ List&lt;User&gt; findByUserNameOrderByAgeDescUserNameAsc(String userName); /** * 根据出生日期进行降序排列 * @param userName * @return */ List&lt;User&gt; findByUserNameOrderByBirthdayDesc(String userName); /** * 返回前2条数据 * @param userName * @return */ List&lt;User&gt; findTop2ByUserName(String userName); /** * 根据用户名分页查询 * @param userName * @param pageable * @return */ Page&lt;User&gt; findByUserName(String userName, Pageable pageable);&#125; 使用@Query定义自己的es语句1234567891011121314151617/** * 使用@Query注解自定义查询语句，其中的?是占位符，0表示第一个参数 * @param userName * @return */ @Query("&#123;\n" + " \"bool\": &#123;\n" + " \"must\": [\n" + " &#123;\n" + " \"match\": &#123;\n" + " \"userName\": \"?0\"\n" + " &#125;\n" + " &#125;\n" + " ]\n" + " &#125;\n" + " &#125;") List&lt;User&gt; selectByUserName(String userName); 控制结果集数量 https://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/#repositories.limit-query-result 使用Top或者First控制返回的数量，如下： 123456/** * 返回前2条数据 * @param userName * @return */ List&lt;User&gt; findTop2ByUserName(String userName); 分页查询 https://www.tianmaying.com/tutorial/spring-jpa-page-sort 直接使用org.springframework.data.domain.Pageable进行分页排序即可 page：从０开始，第几页，默认为0 size：每页显示的数量 sort：排序的方向 其中的方法如下： getTotalElements()：返回数据的总数，不是分页的总数，而是根据条件查询到的全部的数据的总数 getContent()：获取分页的数据集合List&lt;T&gt; getTotalPages()：获取总共几页的数据 iterator()：获取迭代器 剩余的方法如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface Slice&lt;T&gt; extends Streamable&lt;T&gt; &#123; //返回当前是第几页 int getNumber(); //返回每页显示的数量 int getSize(); //返回当前页获取到的元素数量 int getNumberOfElements(); //返回当前页元素的集合 List&lt;T&gt; getContent(); //判断当前页是否存在数据 boolean hasContent(); //获取排序的Sort Sort getSort(); //判断当前页是否是第一页 boolean isFirst(); //判断当前页是否是最后一页 boolean isLast(); //判断是否还有下一页 boolean hasNext(); //判断是否有前一页 boolean hasPrevious(); //返回当前页的pageable default Pageable getPageable() &#123; return PageRequest.of(getNumber(), getSize(), getSort()); &#125; //返回下一页的Pageable Pageable nextPageable(); //返回前一页的pageable Pageable previousPageable(); &lt;U&gt; Slice&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; converter);&#125; 单条件分页排序 只使用了一个字段进行排序 12345678910@Test public void test3()&#123; Sort sort=new Sort(Sort.Direction.DESC,"age"); Pageable pageable=new PageRequest(9,1,sort); Page&lt;User&gt; users=userRepo.findByUserName("李",pageable); System.out.println(users.getTotalPages()); for (User user:users.getContent()) &#123; System.out.println(user); &#125; &#125; 多条件分页排序 使用Order进行排序条件 1234567891011121314@Test public void test3()&#123; List&lt;Sort.Order&gt; orders=new ArrayList&lt;&gt;(); orders.add(new Sort.Order(Sort.Direction.DESC,"age"));//按照年龄降序排列 orders.add(new Sort.Order(Sort.Direction.ASC,"userId")); //按照用户Id升序排列 Sort sort=new Sort(orders); //使用orders Pageable pageable=new PageRequest(0,10,sort); Page&lt;User&gt; users=userRepo.findByUserName("李",pageable); System.out.println(users.getTotalPages()); for (User user:users.getContent()) &#123; System.out.println(user); &#125; &#125; 日期格式问题 未完 使用ElasticsearchTemplate 未完 ………..待续………………… 参考文档 https://blog.csdn.net/lijingyao8206/article/details/78614536 https://www.jianshu.com/p/27e1d583aafb https://blog.csdn.net/a772304419/article/details/79200141 https://www.cnblogs.com/liqipeng/p/7657854.html https://my.oschina.net/kipeng/blog/1799827 https://blog.csdn.net/sofighter/article/details/77840094 https://es.yemengying.com/4/4.1.html sptring-data-es的API]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[es集群管理]]></title>
      <url>%2F2018%2F09%2F02%2Fes%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[集群管理 https://www.cnblogs.com/aubin/p/8012840.html cluster 代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。 shards 代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。 replicas 代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。 recovery 代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。 river 代表es的一个数据源，也是其它存储方式（如：数据库）同步数据到es的一个方法。它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的。 gateway 代表es索引快照的存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。gateway对索引快照进行存储，当这个es集群关闭再重新启动时就会从gateway中读取索引备份数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。 discovery.zen 代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。 Transport 代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。 注意事项 同一个索引的分片和副本不能存在同一台机器上，因为在一台机器上没有意义，因此你如果使用的是单机版的话，不必指定副本的个数，即使指定了，那么es也不会将其存放在一台机器上的 监控集群健康状况 https://www.elastic.co/guide/cn/elasticsearch/guide/current/_cluster_health.html#_cluster_health API：GET _cluster/health。返回的结果如下： number_of_nodes 和 number_of_data_nodes 这个命名完全是自描述的。 active_primary_shards 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。 active_shards 是涵盖了所有索引的所有分片的汇总值，即包括副本分片。 relocating_shards 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。 initializing_shards 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing 状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从 initializing 状态开始。 unassigned_shards 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片） 123456789101112&#123; "cluster_name": "elasticsearch_zach", //集群名称 "status": "green", //集群的状态名称 "timed_out": false, "number_of_nodes": 1, //节点的个数 "number_of_data_nodes": 1, "active_primary_shards": 10, //主分片的个数 "active_shards": 10, //涵盖了所有索引的_所有_分片的汇总值，即包括副本分片。 "relocating_shards": 0, //分片的个数 "initializing_shards": 0, "unassigned_shards": 0&#125; 其中的status状态如下： green：所有的主分片和副本分片都已分配。你的集群是 100% 可用的。 yellow：所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。 red：至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。 使用GET _cluster/health?level=indices能够获取更加详细的信息 GET _cluster/health?level=shards： shards 选项会提供一个详细得多的输出，列出每个索引里每个分片的状态和位置。这个输出有时候很有用，但是由于太过详细会比较难用。如果你知道哪个索引有问题了，本章讨论的其他 API 显得更加有用一点。 监控单个节点 https://www.elastic.co/guide/cn/elasticsearch/guide/current/_monitoring_individual_nodes.html 索引统计 https://www.elastic.co/guide/cn/elasticsearch/guide/current/_index_stats.html cat API [https://www.elastic.co/guide/cn/elasticsearch/guide/current/_cat_api.html] 重要配置的修改 https://www.elastic.co/guide/cn/elasticsearch/guide/current/important-configuration-changes.html http://www.cnblogs.com/ljhdo/p/4959412.html http://lxw1234.com/archives/2015/12/582.htm https://blog.csdn.net/an74520/article/details/8219814 参考文章 http://www.cnblogs.com/ljhdo/p/4959412.html http://lxw1234.com/archives/2015/12/582.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[中文分词器的使用]]></title>
      <url>%2F2018%2F09%2F02%2F%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[中文分词器的使用 ik_max_word：会将文本做最细粒度的拆分 ik_smart：做最粗粒度的拆分 查询 自动映射默认使用的标准的分词器，如果想要使用IK中文分词器，那么需要手动创建映射，如下： 12345678910111213141516171819202122232425262728PUT /lib &#123; "mappings" : &#123; "user" : &#123; "properties" : &#123; "userId" : &#123; "type" : "integer" &#125;, "date":&#123; "type": "date", "format": "yyyy-MM-dd HH:mm:ss" &#125;, "age":&#123; "type": "integer" &#125;, "name":&#123; "type": "text", "analyzer": "ik_max_word" //使用IK分词器 &#125;, "address":&#123; "type": "text", "analyzer": "ik_max_word" //使用IK分词器 &#125; &#125; &#125; &#125;&#125; 添加数据 123456789101112131415161718192021222324PUT /lib/user/1&#123; "name":"陈加兵", "age":22, "date":"2012-11-11 12:00:00", "address":"上海市松江区"&#125;PUT /lib/user/2&#123; "name":"郑元梅", "age":22, "date":"2012-11-11 12:00:00", "address":"湖北武汉"&#125;PUT /lib/user/3&#123; "name":"张三", "age":22, "date":"2012-11-11 12:00:00", "address":"江苏省淮安市"&#125; 我们可以查看address这个字段使用中文分词器的效果，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253GET lib/_analyze&#123; "field": "address", "text": "江苏省淮安市"&#125;//分词结果如下：&#123; "tokens": [ &#123; "token": "江苏省", "start_offset": 0, "end_offset": 3, "type": "CN_WORD", "position": 0 &#125;, &#123; "token": "江苏", "start_offset": 0, "end_offset": 2, "type": "CN_WORD", "position": 1 &#125;, &#123; "token": "省", "start_offset": 2, "end_offset": 3, "type": "CN_CHAR", "position": 2 &#125;, &#123; "token": "淮安市", "start_offset": 3, "end_offset": 6, "type": "CN_WORD", "position": 3 &#125;, &#123; "token": "淮安", "start_offset": 3, "end_offset": 5, "type": "CN_WORD", "position": 4 &#125;, &#123; "token": "市", "start_offset": 5, "end_offset": 6, "type": "CN_CHAR", "position": 5 &#125; ]&#125; 通过上面的分词，我们可以进行查询了，如下： 1234567891011121314151617181920212223242526GET /lib/user/_search&#123; "query": &#123; "match": &#123; "address": "江苏" &#125; &#125;&#125;GET /lib/user/_search&#123; "query": &#123; "match": &#123; "address": "淮安" &#125; &#125;&#125;GET /lib/user/_search&#123; "query": &#123; "term": &#123; "address": "淮安" &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[es各种查询]]></title>
      <url>%2F2018%2F09%2F02%2Fes%E5%90%84%E7%A7%8D%E6%9F%A5%E8%AF%A2%2F</url>
      <content type="text"><![CDATA[请求体查询简单查询 【不推荐】空查询1、GET /lib/user/_search ： 查询lib索引下的user类型的全部数据 2、GET /lib/_search ：查询lib索引下的全部类型的数据 3、GET /_search ：查询全部索引下的数据 精确值查找 当进行精确值查找时， 我们会使用过滤器（filters）。过滤器很重要，因为它们执行速度非常快，不会计算相关度（直接跳过了整个评分阶段）而且很容易被缓存。我们会在本章后面的 过滤器缓存 中讨论过滤器的性能优势，不过现在只要记住：请尽可能多的使用过滤式查询。 term查询 elasticsearch对这个搜索的词语不做分词，用于精确匹配，比如Id，数值类型的查询。 可以用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text）。 实例 批量插入数据 没有手动插入映射，因此ＥｌａｓｔｉｃＳｅａｒｃｈ会为我们自动创建映射，这就意味着只要是文本就会为我们使用分词器分词。 123456789POST /my_store/products/_bulk&#123; "index": &#123; "_id": 1 &#125;&#125;&#123; "price" : 10, "productID" : "XHDK-A-1293-#fJ3" &#125;&#123; "index": &#123; "_id": 2 &#125;&#125;&#123; "price" : 20, "productID" : "KDKE-B-9947-#kL5" &#125;&#123; "index": &#123; "_id": 3 &#125;&#125;&#123; "price" : 30, "productID" : "JODL-X-1937-#pV7" &#125;&#123; "index": &#123; "_id": 4 &#125;&#125;&#123; "price" : 30, "productID" : "QQPX-R-3956-#aD8" &#125; 查询数值 使用constant_score查询以非评分模式来执行 term 查询并以一作为统一评分，这样返回的结果的评分全部是1 使用constant_score将term转化为过滤器查询 12345678910111213141516171819202122232425262728293031323334353637383940GET /my_store/products/_search&#123; "query" : &#123; "constant_score" : &#123; "filter" : &#123; "term" : &#123; "price" : 20 &#125; &#125; &#125; &#125;&#125;//结果如下&#123; "took": 1, "timed_out": false, "_shards": &#123; "total": 5, "successful": 5, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 1, "max_score": 1, "hits": [ &#123; "_index": "my_store", "_type": "products", "_id": "2", "_score": 1, "_source": &#123; "price": 20, "productID": "KDKE-B-9947-#kL5" &#125; &#125; ] &#125;&#125; 查询文本 文本怎样分词 大写字母转换为小写字母 复数变成单数 去掉特殊字符 由于term是精确查询，但是在查询文本的时候，很有可能这个文本已经进行了分词，但是term查询的时候搜索的词不分词，因此可能两个文本明明是一样的，但是却匹配不上。 123456789101112GET /my_store/products/_search&#123; "query" : &#123; "constant_score" : &#123; "filter" : &#123; "term" : &#123; "productID" : "XHDK-A-1293-#fJ3" //虽然和插入的数据一样，但是却查询不到 &#125; &#125; &#125; &#125;&#125; 从上面的结果可以看到，由于term查询默认是不对搜索的词进行分词的，但是在查询的文本是分词的，因此这里肯定是查询不到的，我们可以使用分词分析器看看这个productID如何实现分词的，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647GET /my_store/_analyze&#123; "field": "productID", //指定分词的域 "text": "XHDK-A-1293-fJ3-the" //文本内容&#125;//结果如下：&#123; "tokens": [ &#123; "token": "xhdk", "start_offset": 0, "end_offset": 4, "type": "&lt;ALPHANUM&gt;", "position": 0 &#125;, &#123; "token": "a", "start_offset": 5, "end_offset": 6, "type": "&lt;ALPHANUM&gt;", "position": 1 &#125;, &#123; "token": "1293", "start_offset": 7, "end_offset": 11, "type": "&lt;NUM&gt;", "position": 2 &#125;, &#123; "token": "fj3", "start_offset": 12, "end_offset": 15, "type": "&lt;ALPHANUM&gt;", "position": 3 &#125;, &#123; "token": "the", "start_offset": 16, "end_offset": 19, "type": "&lt;ALPHANUM&gt;", "position": 4 &#125; ]&#125; 从上面的结果可知: 在分词的过程中自动去掉了特殊字符，比如-和&amp; 大写字母全部转为小写 解决 如果需要使用term精确匹配查询文本，那么这个文本就不能使用分词器分词，因此需要手动创建索引的映射（mapping），如下： 12345678910111213141516DELETE my_store //先删除索引PUT /my_store //手动指定映射&#123; "mappings" : &#123; "products" : &#123; "properties" : &#123; "productID" : &#123; "type" : "string", "index" : "not_analyzed" //不分词 &#125; &#125; &#125; &#125;&#125; 此时如果再查询，那么就会精确匹配到这个信息了。 terms 对于多个关键字的查询，假设我们需要查询price在10,20,30中的其中一个即可，那么需要使用terms指定多组值 精确查询，不会使用分词器 12345678GET /my_store/products/_search&#123; "query":&#123; "terms":&#123; "price":[20,10,30] &#125; &#125;&#125; 指定文档数量 (from ,size) 假设我们需要对前两个文档进行查询，那么可以使用from和size指定文档的数量，如下： 12345678910GET /my_store/products/_search&#123; "from":0, //从第一文档开始 "size":2, //查询两个文档 "query":&#123; "terms":&#123; "price":[20,10,30] &#125; &#125;&#125; 返回指定的字段 _source 在使用查询的时候默认返回的是全部的字段，那么我们可以使用_source指定返回的字段 123456789GET /lib/user/_search&#123; "_source":["address","age"], "query": &#123; "match_phrase": &#123; "address": "huibei,wuhan" &#125; &#125;&#125; 同时我们也可以排除不返回哪些字段，使用exclude即可 123456789101112GET /lib/user/_search&#123; "_source":&#123; "exclude": ["address","age"], //排除字段 "include": ["name","date"] //包含的字段 &#125;, "query": &#123; "match_phrase": &#123; "address": "huibei,wuhan" &#125; &#125;&#125; 返回版本号 默认的查询返回版本号，我们可以在查询体中加上version:true即可 1234567891011GET /my_store/products/_search&#123; "version":true, "from":0, "size":2, "query":&#123; "terms":&#123; "price":[20,10,30] &#125; &#125;&#125; match查询 match查询和term查询相反，知道分词器的存在，会对搜索的词语进行分词。 上面使用match查询productId的时候，因为terms不知道分词器的存在，因此查询不到，但是我们使用match查询可以匹配到，如下： 12345678GET /my_store/products/_search&#123; "query" : &#123; "match" : &#123; "productID" : "XHDK-A-1293-#fJ3" &#125; &#125;&#125; 比如说我们要查找姓名是zhaoliu或者zhaoming的，那么只需要使用match即可 12345678GET /my_store/products/_search&#123; "query" : &#123; "match" : &#123; "name" : "zhaoliu zhaoming" //会对这个短语进行分词，分出两个，之后去查询 &#125; &#125;&#125; match_all 查询所有 123456789GET /my_store/products/_search&#123; "query": &#123; "match_all": &#123; &#125; &#125;&#125; match_phrase 短语匹配查询 类似 match 查询， match_phrase 查询首先将查询字符串解析成一个词项列表，然后对这些词项进行搜索，但只保留那些包含 全部 搜索词项，且 位置 与搜索词项相同的文档。 比如对于 quick fox 的短语搜索可能不会匹配到任何文档，因为没有文档包含的 quick 词之后紧跟着 fox 。 位置顺序必须一致 12345678GET /lib/user/_search&#123; "query": &#123; "match_phrase": &#123; "address": "huibei,wuhan" &#125; &#125;&#125; 获取你会觉得短语匹配太严格了，那么可以使用slop这个关键字指定相隔的步长，https://www.elastic.co/guide/cn/elasticsearch/guide/current/slop.html 排序 使用sort可以进行排序 12345678910111213141516171819202122GET /lib/user/_search&#123; "_source":&#123; "exclude": ["address","name"], "include": ["age","date"] &#125;, "query": &#123; "match_phrase": &#123; "address": "huibei,wuhan" &#125; &#125;, "sort": [ //指定排序 &#123; "age": &#123; //对字段age进行排序 "order": "desc" &#125;, "address": &#123; //address排序 "order": "asc" &#125; &#125; ]&#125; range https://www.elastic.co/guide/cn/elasticsearch/guide/current/_ranges.html gt: &gt; 大于（greater than） lt: &lt; 小于（less than） gte: &gt;= 大于或等于（greater than or equal to） lte: &lt;= 小于或等于（less than or equal to） 日期查询 可以查询日期的范围，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849GET /lib/user/_search&#123; "query": &#123; "range": &#123; "date": &#123; "gt": "2010-11-11", //大于 "lt": "2012-12-31" //小于 &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "query": &#123; "range": &#123; "date": &#123; "gt":"now" //查询大于现在时间的文档 &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "query": &#123; "range": &#123; "date": &#123; "gt":"now-1h" //查询距离现在一小时之内的文档，直接使用now减去一小时即可 &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "query": &#123; "range": &#123; "date": &#123; "gt": "2010-11-11 00:00:00", //指定时分秒查询 "lt": "2012-12-31 00:00:00" &#125; &#125; &#125;&#125; 时间格式参考如下：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/mapping-date-format.html 数字1234567891011GET /lib/user/_search&#123; "query": &#123; "range": &#123; "price": &#123; "gt": 10, //数值范围查找 "lt": 20 &#125; &#125; &#125;&#125; 字符串范围 range 查询同样可以处理字符串字段， 字符串范围可采用 字典顺序（lexicographically） 或字母顺序（alphabetically）。例如，下面这些字符串是采用字典序（lexicographically）排序的： 5, 50, 6, B, C, a, ab, abb, abc, b 在倒排索引中的词项就是采取字典顺序（lexicographically）排列的，这也是字符串范围可以使用这个顺序来确定的原因。 123456"range" : &#123; "title" : &#123; "gte" : "a", "lt" : "b" &#125;&#125; wildcard查询 允许使用通配符*和？进行查询 *: 代表一个或者多个字符 ?：代表任意一个字符 123456789101112131415161718GET team/user/_search&#123; "query": &#123; "wildcard": &#123; "name":"chen*" &#125; &#125;&#125;GET team/user/_search&#123; "query": &#123; "wildcard": &#123; "name":"chen?iabing" &#125; &#125;&#125; 模糊查询 fuzzy 假设我们需要查询chenjiabing这个名字，那么使用模糊查询的话，如果其中有个字符写错了，也是能够查询到的 12345678GET team/user/_search&#123; "query": &#123; "fuzzy": &#123; "name":"chejiabing" &#125; &#125;&#125; 高亮查询123456789101112131415GET team/user/_search&#123; "query": &#123; "fuzzy": &#123; "name":"chejiabing" &#125; &#125;, "highlight": &#123; "pre_tags": ["&lt;span style='color:red'&gt;"], //指定包裹的标签前半部分，默认的是&lt;em&gt; "post_tags": ["&lt;/span&gt;"], //指定后半部分 "fields": &#123; "name": &#123;&#125; //name字段高量 &#125; &#125;&#125; null值的查询 exists这个语句用来查询存在值的信息，如果和must结合表示查询不为null的数据，如果must_not集合表示查询为null的数据，如下： 12345678910111213141516171819202122232425262728//查询password=null的数据GET ea/user/_search&#123; "query": &#123; "bool": &#123; "must_not":&#123; "exists":&#123; "field":"password" &#125; &#125; &#125; &#125;&#125;//查询password!=null的数据GET ea/user/_search&#123; "query": &#123; "bool": &#123; "must":&#123; "exists":&#123; "field":"password" &#125; &#125; &#125; &#125;&#125; filter查询 缓存，不返回相关性，速度比query快 简单的过滤查询 使用post_filter 12345678GET /lib/user/_search&#123; "post_filter": &#123; "term": &#123; "age":22 &#125; &#125;&#125; bool过滤查询 语法如下： must ：所有的语句都 必须（must） 匹配，与 AND 等价。 must_not ：所有的语句都 不能（must not） 匹配，与 NOT 等价。 should：至少有一个语句要匹配，与 OR 等价。 1234567&#123; "bool" : &#123; "must" : [], "should" : [], "must_not" : [], &#125;&#125; 其中的每一个部分都是可选的 实例 must中的内容查询是并列的，相当于sql中的and，所有的条件都满足才可以 12345678910111213141516171819202122232425262728GET /lib/user/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123;"term": &#123;"age":22&#125;&#125;, &#123;"match":&#123;"address": "湖北"&#125;&#125; ] &#125; &#125;&#125;GET /lib/user/_search&#123; "post_filter": &#123; "bool": &#123; "should": [ &#123;"term":&#123;"name":"郑元梅"&#125;&#125;, &#123;"term":&#123;"age":33&#125;&#125; ], "must_not": [ &#123;"term":&#123;"age":22&#125;&#125; ] &#125; &#125;&#125; 嵌套bool过滤查询 我们需要执行sql语句如下： 1select * from user where name="郑元梅" or age=33 or(age=22 and price=33); 123456789101112131415161718192021GET /lib/user/_search&#123; "query": &#123; "bool": &#123; "should": [ &#123;"term":&#123;"name":"郑元梅"&#125;&#125;, &#123;"term":&#123;"age":33&#125;&#125;, &#123; "bool": &#123; "must": [ &#123;"term":&#123;"age":22&#125;, &#123;"term":&#123;"price":33&#125;&#125; &#125; ] &#125; &#125; ] &#125; &#125;&#125; 范围过滤1234567891011GET /lib/user/_search&#123; "post_filter": &#123; "range": &#123; "age": &#123; "gte": 20, "lte": 21 &#125; &#125; &#125;&#125; 非空的过滤查询 select * from user where address is not null 12345678910111213GET /lib/user/_search&#123; "query": &#123; "bool": &#123; "filter": &#123; "exists": &#123; "field": "address" &#125; &#125; &#125; &#125;&#125; 聚合查询 在sql中有许多的聚合函数，那么在Elasticsearch中页存在这些聚合函数，比如sum，avg，count等等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061GET /lib/user/_search&#123; "size": 0, //在使用聚合的时候，默认还会返回全部的文档结果，如果不需要，可以使用size限制 "aggs": &#123; "sum_age": &#123; //sum_age 指定返回字段的名称 "sum": &#123; //sum是指定的聚合函数的名称 "field": "age" //这里指定聚合的字段 &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "size": 0, "aggs": &#123; "avg_age": &#123; "avg": &#123; "field": "age" &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "size": 0, "aggs": &#123; "max_age": &#123; "max": &#123; "field": "age" &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "size": 0, "aggs": &#123; "min_age": &#123; "min": &#123; "field": "age" &#125; &#125; &#125;&#125;GET /lib/user/_search&#123; "size": 0, "aggs": &#123; "cardinality_age": &#123; "cardinality": &#123; //查询某个字段的基数，就是对应的字段有多少个不同的值 "field": "age" &#125; &#125; &#125;&#125; 分组（group），使用的是terms 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748GET /lib/user/_search&#123; "size": 0, "aggs": &#123; "age_group": &#123; "terms": &#123; "field": "date" //按照日期进行分组 &#125; &#125; &#125;&#125;//结果如下：&#123; "took": 6, "timed_out": false, "_shards": &#123; "total": 5, "successful": 5, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 6, "max_score": 0, "hits": [] &#125;, "aggregations": &#123; "age_group": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": 1352635200000, "key_as_string": "2012-11-11 12:00:00", "doc_count": 5 //分组的数量 &#125;, &#123; "key": 1352592000000, "key_as_string": "2012-11-11 00:00:00", "doc_count": 1 &#125; ] &#125; &#125;&#125; 对年龄是22岁的用户按照date进行分组，如下： 12345678910111213141516GET /lib/user/_search&#123; "size": 0, "query": &#123; "term": &#123; "age": "22" &#125; &#125;, "aggs": &#123; "age_group": &#123; "terms": &#123; "field": "date" &#125; &#125; &#125;&#125; 对年龄是22岁的用户按照date进行分组，并且计算每组的平均年龄 1select *,avg(age) from user group by date; 12345678910111213141516171819202122GET /lib/user/_search&#123; "query": &#123; "term": &#123; "age": "22" &#125; &#125;, "aggs": &#123; "age_group": &#123; "terms": &#123; "field": "date" &#125;, "aggs": &#123; //直接在分组的聚合中，再次使用聚合求age的均值 "age_avg": &#123; "avg": &#123; "field": "age" &#125; &#125; &#125; &#125; &#125;&#125; 对年龄是22岁的用户按照date进行分组，并且计算每组的平均年龄，最后按照平均年龄进行排序 12345678910111213141516171819202122232425GET /lib/user/_search&#123; "query": &#123; "term": &#123; "age": "22" &#125; &#125;, "aggs": &#123; "age_group": &#123; "terms": &#123; "field": "date", "order": &#123; "age_avg": "asc" //按照聚合查询的平均年龄进行升序排序 &#125; &#125;, "aggs": &#123; "age_avg": &#123; "avg": &#123; "field": "age" &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[es中的mapping]]></title>
      <url>%2F2018%2F09%2F02%2Fes%E4%B8%AD%E7%9A%84mapping%2F</url>
      <content type="text"><![CDATA[Mapping GET /index/type/_mapping 我们可以使用上面的语句检查自己创建的文档的映射，如果类型映射错误，那么将会造成意想不到的结果 核心数据类型 Elasticsearch 支持 如下简单域类型： 字符串: string text ：支持分词 keyword ：不分词 整数 : byte, short, integer, long 浮点数: float, double 布尔型: boolean 日期: date 日期和数值类型的数据不会进行分词，只有精确查询才能查询到。 text类型的数据会进行分词，我们只需要查询部分单词即可查询到结果 复杂核心类型 https://www.elastic.co/guide/cn/elasticsearch/guide/current/complex-core-fields.html 手动指定Mapping12345678910111213141516171819202122232425PUT /lib //指定索引为lib&#123; "mappings":&#123; "user":&#123; //指定索引类型为user "properties":&#123; "name":&#123; "type":"text", //指定类型 "analyzer": "standard" //指定分词器 &#125;, "age":&#123; "type":"integer" &#125;, "date":&#123; "type":"date" &#125;, "address":&#123; "type":"text", "analyzer": "standard" &#125; &#125; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[es初探]]></title>
      <url>%2F2018%2F09%2F02%2Fes%E5%88%9D%E6%8E%A2%2F</url>
      <content type="text"><![CDATA[ES初探文档元数据1、_index ：文档在哪存放 2、_type ：文档表示的对象类别 3、_id ：文档唯一标识 自动生成Id1、如果在Put数据的时候没有指定Id，那么会自动生成一个唯一的ID，如下： 12345678910111213141516171819202122POST /website/blog/&#123; "title": "My second blog entry", "text": "Still trying this out...", "date": "2014/01/01"&#125;//生成的数据如下：&#123; "_index": "website", "_type": "blog", "_id": "AWVlzX7Ur7Pz0UFcO81u", //自动生成的Id "_version": 1, "result": "created", "_shards": &#123; "total": 2, "successful": 1, "failed": 0 &#125;, "created": true&#125; 版本号 _version1、ElasticSearch为了实现并发访问，每次实行更新、删除、添加之后都会为版本号自增1。 2、在删除，更新的之前会保存这个版本号，更新删除操作执行完成之后会自动比较此时的version的值，如果不同，表示被别的进程改变了，一次保证并发的安全性 检索文档的部分字段1、当我们检索字段的时候，默认会为我们查询全部的文档字段，但是我们 可以使用_source指定返回的字段，如下： 1GET /website/blog/123?_source=title,text 判断文档是否存在1、使用HEAD风格的请求方式： 1HEAD /website/blog/123 创建新文档1、文档的确定有三个元数据指定：index,type,id 2、创建文档的时候，如果想不覆盖原来的文档，那么需要检查文档是否存在，如果存在就不插入，有两种方式，如下： ​ 1、使用op_type=create，如果文档已经存在了，那么返回409状态码。如果创建成功了，那么会返回201 Created 123456PUT /website/blog/123?op_type=create&#123; "title": "My first blog entry", "text": "Just trying this out...", "date": "2014/01/02"&#125; ​ 2、使用_create，如果失败返回409,如果创建成功了，那么会返回201 Created 123456PUT /website/blog/123/_create&#123; "title": "My first blog entry", "text": "Just trying this out...", "date": "2014/01/02"&#125; 批量获取文档1、ElasticSearch可以批量获取多个文档中的数据，也可以批量获单个文档中的多条数据 批量获取不同的文档1、使用mgetAPI批量获取文档 ​ 1、docs：指定了要获取的文档 ​ 2、_source：指定需要返回的字段，不指定，默认返回全部的字段 12345678910111213141516GET /_mget&#123; "docs" : [ &#123; "_index" : "website", //文档的索引 "_type" : "blog", //文档类型 "_id" : 2 // Id &#125;, &#123; "_index" : "website", "_type" : "pageviews", "_id" : 1, "_source": "views" &#125; ]&#125; 2、响应的内容也是和请求的顺序一致，如下： ​ 1、查询到的数据存储在docs数组中，字段封装在_source中 12345678910111213141516171819202122232425&#123; "docs" : [ &#123; "_index" : "website", "_id" : "2", "_type" : "blog", "found" : true, "_source" : &#123; "text" : "This is a piece of cake...", "title" : "My first external blog entry" &#125;, "_version" : 10 &#125;, &#123; "_index" : "website", "_id" : "1", "_type" : "pageviews", "found" : true, "_version" : 2, "_source" : &#123; "views" : 2 &#125; &#125; ]&#125; 批量获取单个文档的值1、如果只是获取单个文档中的多条数据，那么只需要在GET请求中指定index和type即可，此时只需要传入不同数据的Id即可，如下： ​ 1、其中ids是一个数组，用来封装数据的Id 1234GET /website/blog/_mget&#123; "ids" : [ "2", "1" ]&#125; ​ 2、请求成功的顺序是按照ids数组中的Id返回的，如下： 123456789101112131415161718192021222324252627&#123; "docs": [ &#123; "_index": "website", "_type": "blog", "_id": "123", "_version": 1, "found": true, "_source": &#123; "title": "My first blog entry", "text": "Just trying this out...", "date": "2014/01/01" &#125; &#125;, &#123; "_index": "website", "_type": "blog", "_id": "1", "_version": 2, "found": true, "_source": &#123; "title": "My first blog entry", "text": "Starting to get the hang of this..." &#125; &#125; ]&#125; 2、即使在GET请求中指定了index和type的值，但是我们也可以在下面覆盖他们的值，这样就可以查询不同文档或者不同索引中的数据了，如下： ​ 1、不想覆盖的可以不用自定index和type的值，只需要指定的id的值即可 1234567GET /website/blog/_mget&#123; "docs" : [ &#123; "_id" : 2 &#125;, &#123; "_type" : "pageviews", "_id" : 1 &#125; ]&#125; 代价较小的批量操作1、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/bulk.html 空搜索1、返回集群下的所有的索引和文档，不需要指定索引、文档、id。默认只是返回前10条 1GET /_search 2、返回结果中的各个值的含义参见：https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/empty-search.html#_shards 多索引，多文档的搜索1、/_search ：在所有的索引中搜索所有的类型 2、/gb/_search ：在 gb 索引中搜索所有的类型 3、/gb,us/_search：在 gb 和 us 索引中搜索所有的文档 4、/g*,u*/_search：在任何以 g 或者 u 开头的索引中搜索所有的类型 5、/gb/user/_search：在 gb 索引中搜索 user 类型 6、/gb,us/user,tweet/_search：在 gb 和 us 索引中搜索 user 和 tweet 类型 7、/_all/user,tweet/_search：在所有的索引中搜索 user 和 tweet 类型 分页查询【超过1000条的分页数据不推荐】1、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/pagination.html#pagination 2、size ：显示应该返回的结果数量，默认是 10 3、from ：显示应该跳过的初始结果数量，默认是 0 4、实例如下： 123GET /_search?size=5 //查询前5条的数据GET /_search?size=5&amp;from=5 //查询第2页，每页显示5条数据GET /_search?size=5&amp;from=10 //查询第3页的数据，每页显示5条数据 5、分布式中的深度分页的问题，可以在文档中查看详细信息。总之分页请求的数据不要超过1000条 6、在 重新索引你的数据 中解释了如何 能够 有效获取大量的文档。 轻量搜索【不推荐使用】0、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/search-lite.html#query-string-query 1、返回group索引中文档类型为employee中的内容，筛选条件为：文档中的所有字段的值只要有等于Smith的都返回，如下： ​ 1、_all：用于指定对文档中的所有字段进行筛选，只要有一个字段成立，那么这个文档就会被选中，但是返回的结果中有相关度的分析 ​ 2、如果不指定任何字段，那么默认就是使用_all进行筛选 1234GET /group/employee/_search?q=Smith//这条语句的效果和上面的语句一样GET /_all/employee/_search?q=_all:Smith 2、查询一个文档中指定字段的值等于Smith，如下我们查询文档中的字段last_name这个值等于Smith的所有文档内容 1GET /group/employee/_search?q=last_name:Smith 倒排索引1、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/inverted-index.html 2、创建规范： ​ 1、单词不区分大小写 ​ 2、不区分单复数，将单数和复数的单词一律提取出来单数即可 ​ 3、意思相近的词只提取一个 ​ 分析与分析器1、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/analysis-intro.html 2、什么时候使用分词器？ ​ 1、查找全文域的时候使用，比如使用轻量搜索中的_all ​ 2、精确查找不使用分词器，比如Date类型的数据，默认将其看成单独的一个词条 3、测试分词器 12345GET /_analyze&#123; "analyzer": "standard", //指定分词器 "text": "Text to analyze" //指定需要分割的字符串&#125; 返回结果如下： ​ 1、token 是实际存储到索引中的词条。 position 指明词条在原始文本中出现的位置。 start_offset 和 end_offset 指明字符在原始字符串中的位置。 12345678910111213141516171819202122232425&#123; "tokens": [ &#123; "token": "text", "start_offset": 0, "end_offset": 4, "type": "&lt;ALPHANUM&gt;", "position": 0 &#125;, &#123; "token": "to", "start_offset": 5, "end_offset": 7, "type": "&lt;ALPHANUM&gt;", "position": 1 &#125;, &#123; "token": "analyze", "start_offset": 8, "end_offset": 15, "type": "&lt;ALPHANUM&gt;", "position": 2 &#125; ]&#125; 映射1、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/mapping-intro.html 2、Elasticsearch 支持 如下简单域类型： 12345字符串: string整数 : byte, short, integer, long浮点数: float, double布尔型: boolean日期: date 3、如果我们在添加数据的时候使用双引号包裹起来的，那么会被动态映射为字符串类型。 copy_to1、我们在查询文本的时候可能会同时会对多个文本中的内容进行查询匹配，那么就需要对多个字段进行筛选了，比如我们需要对name和address这两个字段同时进行匹配，那么效率肯定会比对一个字段进行筛选的低，因此可以使用copy_to字段将这两个字段中的内容存储在同一个字段中，那么就可以实现对一个字段的查询等同于对两个字段的查询，如下： 12345678910111213141516PUT lib/user/_mapping&#123; "properties": &#123; "name":&#123; "type": "text", "copy_to": "name_address" //将name这个字段的文本内容复制到name_address中 &#125;, "age":&#123; "type": "integer" &#125;, "address":&#123; "type": "text", "copy_to": "name_address" // //将address这个字段的文本内容复制到name_address中 &#125; &#125;&#125; 2、此时就可以使用query查询了，如下：查询名字为Jack，address为jiangsusheng的 12345678910111213141516171819202122GET /lib/user/_search&#123; "query": &#123; "match": &#123; "name_address": "Jack,jiangsusheng" //直接使用name_address即可 &#125; &#125;&#125;//等同于GET /lib/user/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123;"term":&#123;"name":"Jack"&#125;&#125;, &#123;"match":&#123;"address":"jiangsusheng"&#125;&#125; ] &#125; &#125;&#125; 字符串排序 默认字符串是不能排序的，因为自动创建的映射将字符串映射为text类型，将会被分词，因此不能进行排序，但是我们知道字符串类型中有一个keyword类型不会被分词，因此我们可以再为需要排序的字符串字段指定一个keyword类型的字段用于排序，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051PUT /lib4&#123; "settings":&#123; "number_of_shards":5, //主分片的数量 "number_of_replicas":0 //副本分片的数量 &#125;, "mappings":&#123; "user":&#123; "properties": &#123; "name":&#123; "type": "text", "copy_to": "name_address", "fields": &#123; //使用fields指定另外一个字段raw "raw":&#123; "type": "keyword" //类型为keyword &#125; &#125;， "fielddata": true //将fielddata指定为true &#125;, "age":&#123; "type": "integer" &#125;, "address":&#123; "type": "text", "copy_to": "name_address" &#125; &#125; &#125; &#125; &#125;//排序如下：GET /lib4/user/_search&#123; "query": &#123; "match": &#123; "age":22 &#125; &#125;, "sort": [ &#123; "name": &#123; //对字符串类型的name进行排序 "order": "desc" &#125; &#125; ]&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[es的crud]]></title>
      <url>%2F2018%2F09%2F02%2Fes%E7%9A%84crud%2F</url>
      <content type="text"><![CDATA[ElasticSearch的简单的CRUD1、ElasticSearch使用的是RestFul风格的API 2、http://39.105.123.197:5601/ 添加索引1、需要指定索引，文档的类型，文档的Id 2、使用PUT风格的提交方式，如下： 1、`group`：索引名称 2、`employee`：文档的名字 3、`1`：对应的id 123456789101112131415161718192021222324252627PUT /group/employee/1&#123; "first_name" : "John", "last_name" : "Smith", "age" : 25, "about" : "I love to go rock climbing", "interests": [ "sports", "music" ]&#125;PUT /group/employee/2&#123; "first_name" : "Jane", "last_name" : "Smith", "age" : 32, "about" : "I like to collect rock albums", "interests": [ "music" ]&#125;PUT /group/employee/3&#123; "first_name" : "Douglas", "last_name" : "Fir", "age" : 35, "about": "I like to build cabinets", "interests": [ "forestry" ]&#125; 检索文档1、使用GET风格的方式检索,GET/index/document/id如下： 12GET /group/employee/1GET /group/employee/2 删除文档1、使用DELETE风格的方式删除，DELETE /index/document/id，如下： 1DELETE /megacorp/employee/2 修改文档直接覆盖全部1、使用PUT覆盖当前的文档,使用这种方式会更新整个文档。 2、这种方式和部分更新的最大区别就是增大了网络的开销 12345678PUT /group/employee/3&#123; "first_name" : "TOM", "last_name" : "TOM", "age" : 60, "about": "I like to build cabinets", "interests": [ "forestry" ]&#125; 部分更新0、https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/partial-updates.html 1、文档是不可变的，因此部分的更新也是在内部重复着检索-修改-重建索引 的处理过程 。但是我们对于直接覆盖的方式，可以减少网络传输的时间 2、对指定的文档增加字段，使用doc，如下 1234567POST /megacorp/employee/2/_update&#123; "doc" : &#123; "tags" : [ "testing" ], "views": 0 &#125;&#125; 3、修改已存在的变量的值，使用ctx._source指定文档中的变量，这里的是将views加1 1234POST /megacorp/employee/2/_update&#123; "script" : "ctx._source.views+=1"&#125; 4、更新可能不存在的值，如果这个值不存在，那么就添加进去，这个很像MongoDB中的检索，使用upsert完成,如下： 1234567POST /megacorp/employee/2/_update&#123; "script" : "ctx._source.views+=1", "upsert": &#123; "views": 1 &#125;&#125; 5、更新和冲突 1、ElasticSearch在文档更新的时候，每个进程会自动保存版本号_version的值，更改成功之后，如果版本号改变了，那么表示这个文档已经被人更新过了，此时就会更新请求失败。但是我们可以使用指定的参数指定在更新失败之前尝试的更新的次数,retry_on_conflict，如下： 1234567POST /megacorp/employee/2/_update?retry_on_conflict=5 &#123; "script" : "ctx._source.views+=1", "upsert": &#123; "views": 0 &#125;&#125; 参考文档1、https://www.elastic.co/guide/cn/elasticsearch/guide/current/getting-started.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[es的安装]]></title>
      <url>%2F2018%2F09%2F02%2Fes%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
      <content type="text"><![CDATA[安装包安装1、官网下载安装包 2、不能以root身份运行，因此需要新建一个用户专门运行elasticSearch 1、`groupadd esgroup` 2、`useradd esuser -g esgroup -p esuser` 3、将elasticSearch文件夹下的运行身份添加到esuser中：`chown -R esgroup:esuser elasticSearch/ ` 4、`su esuser `切换用户 5、进入bin文件夹中，使用`./elasticSearch` 3、需要在服务器上开启9200端口，使用firewall-cmd --permanent --add-port=9200/tcp 4、如果提示没有开启防火墙，那么使用service firewalld start Docker安装1、docker pull elasticsearch ： 直接下载最新版本的即可 2、挂在目录，挂载之前我们需要启动一个容器用于cp指定目录下的内容，否则将不能挂载成功 1、`docker run -e ES_JAVA_OPTS=&quot;-Xmx256m -Xms256m&quot; --name myele -p 9200:9200 -d 73e6fdf8bd4f` ：先运行容器，不指定挂载的目录 2、cp容器中的配置到本地的服务器目录 1、`docker cp myele:/usr/share/elasticsearch/lib /elasticsearch/lib `： 复制lib目录下的所有文件到本地的/elasticsearch/lib目录 2、`docker cp myele:/usr/share/elasticsearch/config /elasticsearch/config` ： 复制config所有文件到本地 3、`docker cp myele:/usr/share/elasticsearch/plugins /elasticsearch/plugins`：复制plugins到本地 4、`docker cp myele:/usr/share/elasticsearch/logs /elasticsearch/logs` ：复制logs下的文件到本地 5、`docker cp myele:/usr/share/elasticsearch/data /elasticsearch/data`：复制data目录下的文件到本地 3、开启9200和9300端口 4、修改：sysctl -w vm.max_map_count=262144 5、启动容器并且挂载目录,如下： 1docker run -e ES_JAVA_OPTS="-Xmx256m -Xms256m" --name ele -v /elasticsearch/lib:/usr/share/elasticsearch/lib -v /elasticsearch/config:/usr/share/elasticsearch/config -v /elasticsearch/plugins:/usr/share/elasticsearch/plugins -v /elasticsearch/logs:/usr/share/elasticsearch/logs: -v /elasticsearch/data:/usr/share/elasticsearch/data -d -p 9200:9200 -p 9300:9300 73e6fdf8bd4f 启动1、前台启动： ./bin/elasticSearch 2、后台启动：./bin/elasticsearch -d 指定内存空间安装常见错误1、https://blog.csdn.net/qq_21387171/article/details/53577115 安装kibana1、docker pull kibana ： 默认拉取最新版本的，这里的版本要和elasticsearch的版本一致 2、firewall-cmd --permanent --add-port=5601/tcp：开启服务器上的5601端口 3、docker run --name mykibana -e ELASTICSEARCH_URL=http://some-elasticsearch:9200 -p 5601:5601 -d kibana : 运行kibana，需要指定elasticsearch的地址 4、此时运行成功之后即可访问：http://IP:5601 配置中文分词器IK1、从github中下载和ElasticSearch对应版本的IK分词器： 下载地址 2、使用maven编译 ： 1、由于我安装docker最新版本的elasticsearch版本是5.6.10，但是下载对应的IK分词器编译出来的是5.6.9版本的，此时就不行，因此我们可以修改下载IK中的pom.xml的elasticsearch版本为5.6.10，如下： 123456789101112&lt;properties&gt; &lt;elasticsearch.version&gt;5.6.10&lt;/elasticsearch.version&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;elasticsearch.assembly.descriptor&gt;$&#123;project.basedir&#125;/src/main/assemblies/plugin.xml&lt;/elasticsearch.assembly.descriptor&gt; &lt;elasticsearch.plugin.name&gt;analysis-ik&lt;/elasticsearch.plugin.name&gt; &lt;elasticsearch.plugin.classname&gt;org.elasticsearch.plugin.analysis.ik.AnalysisIkPlugin&lt;/elasticsearch.plugin.classname&gt; &lt;elasticsearch.plugin.jvm&gt;true&lt;/elasticsearch.plugin.jvm&gt; &lt;tests.rest.load_packaged&gt;false&lt;/tests.rest.load_packaged&gt; &lt;skip.unit.tests&gt;true&lt;/skip.unit.tests&gt; &lt;gpg.keyname&gt;4E899B30&lt;/gpg.keyname&gt; &lt;gpg.useagent&gt;true&lt;/gpg.useagent&gt; &lt;/properties&gt; 3、修改完成之后使用mvn package命令打包即可 4、将target中的realease目录下的压缩包解压 5、将解压出来的elasticsearch下的所有文件全部拷贝到elasticsearch中的plugins下的ik文件夹中 6、重启即可 参考文章1、https://www.elastic.co/guide/cn/elasticsearch/guide/current/running-elasticsearch.html 2、https://es.xiaoleilu.com/010_Intro/20_Document.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java后端学习之路]]></title>
      <url>%2F2018%2F09%2F02%2FJava%E5%90%8E%E7%AB%AF%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[Java后端学习之路转载自https://github.com/xingshaocheng/architect-awesome 数据结构 队列 集合 链表、数组 字典、关联数组 栈 树 二叉树 完全二叉树 平衡二叉树 二叉查找树（BST） 红黑树 B-，B+，B*树 LSM 树 BitSet 常用算法 排序、查找算法 选择排序 冒泡排序 插入排序 快速排序 归并排序 希尔排序 堆排序 计数排序 桶排序 基数排序 二分查找 Java 中的排序工具 布隆过滤器 字符串比较 KMP 算法 深度优先、广度优先 贪心算法 回溯算法 剪枝算法 动态规划 朴素贝叶斯 推荐算法 最小生成树算法 最短路径算法 并发 Java 并发 多线程 线程安全 一致性、事务 事务 ACID 特性 事务的隔离级别 MVCC 锁 Java中的锁和同步类 公平锁 &amp; 非公平锁 悲观锁 乐观锁 &amp; CAS ABA 问题 CopyOnWrite容器 RingBuffer 可重入锁 &amp; 不可重入锁 互斥锁 &amp; 共享锁 死锁 操作系统 计算机原理 CPU 多级缓存 进程 线程 协程 Linux 设计模式 设计模式的六大原则 23种常见设计模式 应用场景 单例模式 责任链模式 MVC IOC AOP UML 微服务思想 康威定律 运维 &amp; 统计 &amp; 技术支持 常规监控 APM 统计分析 持续集成(CI/CD) Jenkins 环境分离 自动化运维 Ansible puppet chef 测试 TDD 理论 单元测试 压力测试 全链路压测 A/B 、灰度、蓝绿测试 虚拟化 KVM Xen OpenVZ 容器技术 Docker 云技术 OpenStack DevOps 文档管理 中间件 Web Server Nginx OpenResty Tengine Apache Httpd Tomcat 架构原理 调优方案 Jetty 缓存 本地缓存 客户端缓存 服务端缓存 Web缓存 Memcached Redis 架构 回收策略 Tair 消息队列 消息总线 消息的顺序 RabbitMQ RocketMQ ActiveMQ Kafka Redis 消息推送 ZeroMQ 定时调度 单机定时调度 分布式定时调度 RPC Dubbo Thrift gRPC 数据库中间件 Sharding Jdbc 日志系统 日志搜集 配置中心 API 网关 网络 协议 OSI 七层协议 TCP/IP HTTP HTTP2.0 HTTPS 网络模型 Epoll Java NIO kqueue 连接和短连接 框架 零拷贝（Zero-copy） 序列化(二进制协议) Hessian Protobuf 数据库 基础理论 数据库设计的三大范式 MySQL 原理 InnoDB 优化 索引 聚集索引, 非聚集索引 复合索引 自适应哈希索引(AHI) explain NoSQL MongoDB Hbase 搜索引擎 搜索引擎原理 Lucene Elasticsearch Solr sphinx 性能 性能优化方法论 容量评估 CDN 网络 连接池 性能调优 大数据 流式计算 Storm Flink Kafka Stream 应用场景 Hadoop HDFS MapReduce Yarn Spark 安全 web 安全 XSS CSRF SQL 注入 Hash Dos 脚本注入 漏洞扫描工具 验证码 DDoS 防范 用户隐私信息保护 序列化漏洞 加密解密 对称加密 哈希算法 非对称加密 服务器安全 数据安全 数据备份 网络隔离 内外网分离 登录跳板机 授权、认证 RBAC OAuth2.0 双因素认证（2FA） 单点登录(SSO) 常用开源框架 开源协议 日志框架 Log4j、Log4j2 Logback ORM 网络框架 Web 框架 Spring 家族 工具框架 分布式设计 扩展性设计 稳定性 &amp; 高可用 硬件负载均衡 软件负载均衡 限流 应用层容灾 跨机房容灾 容灾演练流程 平滑启动 数据库扩展 读写分离模式 分片模式 服务治理 服务注册与发现 服务路由控制 分布式一致 CAP 与 BASE 理论 分布式锁 分布式一致性算法 PAXOS Zab Raft Gossip 两阶段提交、多阶段提交 幂等 分布式一致方案 分布式 Leader 节点选举 TCC(Try/Confirm/Cancel) 柔性事务 分布式文件系统 唯一ID 生成 全局唯一ID 一致性Hash算法 设计思想 &amp; 开发模式 DDD(Domain-driven Design - 领域驱动设计) 命令查询职责分离(CQRS) 贫血，充血模型 Actor 模式 响应式编程 Reactor RxJava Vert.x DODAF2.0 Serverless Service Mesh 项目管理 架构评审 重构 代码规范 代码 Review RUP 看板管理 SCRUM 敏捷开发 极限编程（XP） 结对编程 PDCA 循环质量管理 FMEA管理模式 通用业务术语 技术趋势 政策、法规 法律 严格遵守刑法253法条 架构师素质 团队管理 招聘 资讯 行业资讯 公众号列表 博客 团队博客 个人博客 综合门户、社区 问答、讨论类社区 行业数据分析 专项网站 其他类 推荐参考书 在线电子书 纸质书 开发方面 架构方面 技术管理方面 基础理论 工具方面 大数据方面 技术资源 开源资源 手册、文档、教程 在线课堂 会议、活动 常用APP 找工作 工具 代码托管 文件服务 综合云服务商 VPS 数据结构队列 《java队列——queue详细分析》 非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。 阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。 《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》 集合 《Java Set集合的详解》 链表、数组 《Java集合详解–什么是List》 字典、关联数组 《Java map 详解 - 用法、遍历、排序、常用API等》 栈 《java数据结构与算法之栈（Stack）设计与实现》 《Java Stack 类》 《java stack的详细实现分析》 Stack 是线程安全的。 内部使用数组保存数据，不够时翻倍。 树二叉树每个节点最多有两个叶子节点。 《二叉树》 完全二叉树 《完全二叉树》 叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 《浅谈数据结构-平衡二叉树》 《浅谈算法和数据结构: 八 平衡查找树之2-3树》 二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。 《浅谈算法和数据结构: 七 二叉查找树》 红黑树 《最容易懂得红黑树》 添加阶段后，左旋或者右旋从而再次达到平衡。 《浅谈算法和数据结构: 九 平衡查找树之红黑树》 B-，B+，B*树MySQL是基于B+树聚集索引组织表 《B-树，B+树，B*树详解》 《B-树，B+树与B*树的优缺点比较》 B+ 树的叶子节点链表结构相比于 B- 树便于扫库，和范围检索。 LSM 树LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。 Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。 《LSM树 VS B+树》 B+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能。 LSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。 《LSM树（Log-Structured Merge Tree）存储引擎》 极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。 优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。 Hbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。 BitSet经常用于大规模数据的排重检查。 《Java Bitset类》 《Java BitSet（位集）》 常用算法 《常见排序算法及对应的时间复杂度和空间复杂度》 排序、查找算法 《常见排序算法及对应的时间复杂度和空间复杂度》 选择排序 《Java中的经典算法之选择排序（SelectionSort）》 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。 冒泡排序 《冒泡排序的2种写法》 相邻元素前后交换、把最大的排到最后。 时间复杂度 O(n²) 插入排序 《排序算法总结之插入排序》 快速排序 《坐在马桶上看算法：快速排序》 一侧比另外一次都大或小。 归并排序 《图解排序算法(四)之归并排序》 分而治之，分成小份排序，在合并(重建一个新空间进行复制)。 希尔排序TODO 堆排序 《图解排序算法(三)之堆排序》 排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。 计数排序 《计数排序和桶排序》 和桶排序过程比较像，差别在于桶的数量。 桶排序 《【啊哈！算法】最快最简单的排序——桶排序》 《排序算法（三）：计数排序与桶排序》 桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。 每个桶单独进行排序，然后再遍历每个桶。 基数排序按照个位、十位、百位、…依次来排。 《排序算法系列：基数排序》 《基数排序》 二分查找 《二分查找(java实现)》 要求待查找的序列有序。 时间复杂度 O(logN)。 《java实现二分查找-两种方式》 while + 递归。 Java 中的排序工具 《Arrays.sort和Collections.sort实现原理解析》 Collections.sort算法调用的是合并排序。 Arrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。 布隆过滤器常用于大数据的排重，比如email，url 等。 核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。 优点：空间和时间效率都很高。 缺点：随着存入的元素数量增加，误算率随之增加。 《布隆过滤器 – 空间效率很高的数据结构》 《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》 《基于Redis的布隆过滤器的实现》 基于 Redis 的 Bitmap 数据结构。 《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》 使用Java中的 BitSet 类 和 加权和hash算法。 字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP） 核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。 《字符串匹配的KMP算法》 深度优先、广度优先 《广度优先搜索BFS和深度优先搜索DFS》 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 回溯算法 《 五大常用算法之四：回溯法》 剪枝算法 《α-β剪枝算法》 动态规划 《详解动态规划——邹博讲动态规划》 《动态规划算法的个人理解》 朴素贝叶斯 《带你搞懂朴素贝叶斯分类算法》 P(B|A)=P(A|B)P(B)/P(A) 《贝叶斯推断及其互联网应用1》 《贝叶斯推断及其互联网应用2》 推荐算法 《推荐算法综述》 《TOP 10 开源的推荐系统简介》 最小生成树算法 《算法导论–最小生成树（Kruskal和Prim算法）》 最短路径算法 《Dijkstra算法详解》 并发Java 并发 Java 并发知识合集 JAVA并发知识图谱 多线程 《40个Java多线程问题总结》 线程安全 《Java并发编程——线程安全及解决机制简介》 一致性、事务事务 ACID 特性 《数据库事务ACID特性》 事务的隔离级别 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。 序列化：所有事物串行处理（牺牲了效率） 《理解事务的4种隔离级别》 数据库事务的四大特性及事务隔离级别 《MySQL的InnoDB的幻读问题 》 幻读的例子非常清楚。 通过 SELECT … FOR UPDATE 解决。 《一篇文章带你读懂MySQL和InnoDB》 图解脏读、不可重复读、幻读问题。 MVCC 《【mysql】关于innodb中MVCC的一些理解》 innodb 中 MVCC 用在 Repeatable-Read 隔离级别。 MVCC 会产生幻读问题（更新时异常。） 《轻松理解MYSQL MVCC 实现机制》 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间 每次只操作比当前版本小（或等于）的 行。 锁Java中的锁和同步类 《Java中的锁分类》 主要包括 synchronized、ReentrantLock、和 ReadWriteLock。 《Java并发之AQS详解》 《Java中信号量 Semaphore》 有数量控制 申请用 acquire，申请不要则阻塞；释放用 release。 《java开发中的Mutex vs Semaphore》 简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。 公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。 《公平锁与非公平锁》 默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。 悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。 《【MySQL】悲观锁&amp;乐观锁》 乐观锁的方式：版本号+重试方式 悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。 《Mysql查询语句使用select.. for update导致的数据库死锁分析》 mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。 锁相同数据的不同索引条件可能会引起死锁。 《Mysql并发时经典常见的死锁原因及解决方法》 乐观锁 &amp; CAS 《乐观锁的一种实现方式——CAS》 和MySQL乐观锁方式相似，只不过是通过和原值进行比较。 ABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。 《Java CAS 和ABA问题》 《Java 中 ABA问题及避免》 AtomicStampedReference 和 AtomicStampedReference。 CopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。 《JAVA中写时复制(Copy-On-Write)Map实现》 实现读写分离，读取发生在原始数据上，写入发生在副本上。 不用加锁，通过最终一致实现一致性。 《聊聊并发-Java中的Copy-On-Write容器》 RingBuffer 《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》 可重入锁 &amp; 不可重入锁 《可重入锁和不可重入锁》 通过简单代码举例说明可重入锁和不可重入锁。 可重入锁指同一个线程可以再次获得之前已经获得的锁。 可重入锁可以用户避免死锁。 Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock 《ReenTrantLock可重入锁（和synchronized的区别）总结》 synchronized 使用方便，编译器来加锁，是非公平锁。 ReenTrantLock 使用灵活，锁的公平性可以定制。 相同加锁场景下，推荐使用 synchronized。 互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。 共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。 《ReadWriteLock场景应用》 死锁 《“死锁”四个必要条件的合理解释》 互斥、持有、不可剥夺、环形等待。 Java如何查看死锁？ JConsole 可以识别死锁。 java多线程系列：死锁及检测 jstack 可以显示死锁。 操作系统计算机原理 《操作系统基础知识——操作系统的原理，类型和结构》 CPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。 《从Java视角理解CPU缓存和伪共享》 进程TODO 线程 《线程的生命周期及状态转换详解》 协程 《终结python协程—-从yield到actor模型的实现》 线程的调度是由操作系统负责，协程调度是程序自行负责 与线程相比，协程减少了无谓的操作系统切换. 实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换. Linux 《Linux 命令大全》 设计模式设计模式的六大原则 《设计模式的六大原则》 开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。 里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。 依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。 接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。 合成复用原则：尽量使用合成/聚合,而不是使用继承。 23种常见设计模式 《设计模式》 《23种设计模式全解析》 《设计模式类图与示例》 应用场景 《细数JDK里的设计模式》 结构型模式： 适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy 创建模式: 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。 工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。 原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。 单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。 行为模式： 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。 命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。 空对象模式：如 java.util.Collections#emptyList()。 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。 《Spring-涉及到的设计模式汇总》 《Mybatis使用的设计模式》 单例模式 《单例模式的三种实现 以及各自的优缺点》 《单例模式－－反射－－防止序列化破坏单例模式》 使用枚举类型。 责任链模式TODO MVC 《MVC 模式》 模型(model)－视图(view)－控制器(controller) IOC 《理解 IOC》 《IOC 的理解与解释》 正向控制：传统通过new的方式。反向控制，通过容器注入对象。 作用：用于模块解耦。 DI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。 AOP 《轻松理解AOP(面向切面编程)》 《Spring AOP详解》 《Spring AOP的实现原理》 Spring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。 《Spring AOP 实现原理与 CGLIB 应用》 Spring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类 UML 《UML教程》 微服务思想 《微服务架构设计》 《微服务架构技术栈选型手册》 康威定律 《微服务架构的理论基础 - 康威定律》 定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。 定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。 定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。 定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。 《微服务架构核⼼20讲》 运维 &amp; 统计 &amp; 技术支持常规监控 《腾讯业务系统监控的修炼之路》 监控的方式：主动、被动、旁路(比如舆情监控) 监控类型： 基础监控、服务端监控、客户端监控、 监控、用户端监控 监控的目标：全、块、准 核心指标：请求量、成功率、耗时 《开源还是商用？十大云运维监控工具横评》 Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。 《监控报警系统搭建及二次开发经验》 命令行监控工具 《常用命令行监控工具》 top、sar、tsar、nload 《20个命令行工具监控 Linux 系统性能》 《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》 APMAPM — Application Performance Management 《Dapper，大规模分布式系统的跟踪系统》 CNCF OpenTracing，中文版 主要开源软件，按字母排序 Apache SkyWalking CAT CNCF jaeger Pinpoint Zipkin 《开源APM技术选型与实战》 主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。 统计分析 《流量统计的基础：埋点》 常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度 《APP埋点常用的统计工具、埋点目标和埋点内容》 第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。 《美团点评前端无痕埋点实践》 所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。 持续集成(CI/CD) 《持续集成是什么？》 《8个流行的持续集成工具》 Jenkins 《使用Jenkins进行持续集成》 环境分离开发、测试、生成环境分离。 《开发环境、生产环境、测试环境的基本理解和区》 自动化运维Ansible 《Ansible中文权威指南》 《Ansible基础配置和企业级项目实用案例》 puppet 《自动化运维工具——puppet详解》 chef 《Chef 的安装与使用》 测试TDD 理论 《深度解读 - TDD（测试驱动开发）》 基于测试用例编码功能代码，XP（Extreme Programming）的核心实践. 好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈； 单元测试 《Java单元测试之JUnit篇》 《JUnit 4 与 TestNG 对比》 TestNG 覆盖 JUnit 功能，适用于更复杂的场景。 《单元测试主要的测试功能点》 模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。 压力测试 《Apache ab 测试使用指南》 《大型网站压力测试及优化方案》 《10大主流压力/负载/性能测试工具推荐》 《真实流量压测工具 tcpcopy应用浅析》 《nGrinder 简易使用教程》 全链路压测 《京东618：升级全链路压测方案，打造军演机器人ForceBot》 《饿了么全链路压测的探索与实践》 《四大语言，八大框架｜滴滴全链路压测解决之道》 《全链路压测经验》 A/B 、灰度、蓝绿测试 《技术干货 | AB 测试和灰度发布探索及实践》 《nginx 根据IP 进行灰度发布》 《蓝绿部署、A/B 测试以及灰度发布》 虚拟化 《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》 KVM 《KVM详解，太详细太深入了，经典》 《【图文】KVM 虚拟机安装详解》 Xen 《Xen虚拟化基本原理详解》 OpenVZ 《开源Linux容器 OpenVZ 快速上手指南》 容器技术Docker 《几张图帮你理解 docker 基本原理及快速入门》 《Docker 核心技术与实现原理》 《Docker 教程》 云技术OpenStack 《OpenStack构架知识梳理》 DevOps 《一分钟告诉你究竟DevOps是什么鬼？》 《DevOps详解》 文档管理 Confluence-收费文档管理系统 GitLab? Wiki 中间件Web ServerNginx 《Ngnix的基本学习-多进程和Apache的比较》 Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。 事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。 《nginx与Apache的对比以及优缺点》 nginx只适合静态和反向代理，不适合处理动态请求。 OpenResty 官方网站 《浅谈 OpenResty》 通过 Lua 模块可以在Nginx上进行开发。 agentzh 的 Nginx 教程 Tengine 官方网站 Apache Httpd 官方网站 Tomcat架构原理 《TOMCAT原理详解及请求过程》 《Tomcat服务器原理详解》 《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》 《四张图带你了解Tomcat系统架构》 《JBoss vs. Tomcat: Choosing A Java Application Server》 Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Spring。 Jboss 实现全部了JEE特性，软件开源免费、文档收费。 调优方案 《Tomcat 调优方案》 启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）； 《tomcat http协议与ajp协议》 《AJP与HTTP比较和分析》 AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。 并发高时，AJP协议优于HTTP协议。 Jetty 《Jetty 的工作原理以及与 Tomcat 的比较》 《jetty和tomcat优势比较》 架构比较:Jetty的架构比Tomcat的更为简单。 性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。 其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。 缓存 《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》 本地缓存 《HashMap本地缓存》 《EhCache本地缓存》 堆内、堆外、磁盘三级缓存。 可按照缓存空间容量进行设置。 按照时间、次数等过期策略。 《Guava Cache》 简单轻量、无堆外、磁盘缓存。 《Nginx本地缓存》 《Pagespeed—懒人工具，服务器端加速》 客户端缓存 《浏览器端缓存》 主要是利用 Cache-Control 参数。 《H5 和移动端 WebView 缓存机制解析与实战》 服务端缓存Web缓存 nuster - nuster cache varnish - varnish cache squid - squid cache Memcached 《Memcached 教程》 《深入理解Memcached原理》 采用多路复用技术提高并发性。 slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。 《Memcached软件工作原理》 《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》 《memcache 中 add 、 set 、replace 的区别》 区别在于当key存在还是不存在时，返回值是true和false的。 《memcached全面剖析》 Redis 《Redis 教程》 《redis底层原理》 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 《Redis持久化方式》 RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。 AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。 也可以两者结合使用。 《分布式缓存–序列3–原子操作与CAS乐观锁》 架构 《Redis单线程架构》 回收策略 《redis的回收策略》 Tair 官方网站 《Tair和Redis的对比》 特点：可以配置备份节点数目，通过异步同步到备份节点 一致性Hash算法。 架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。 几种存储引擎: MDB，完全内存性，可以用来存储Session等数据。 Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作 LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。 Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。 消息队列 《消息队列-推/拉模式学习 &amp; ActiveMQ及JMS学习》 RabbitMQ 消费者默认是推模式（也支持拉模式）。 Kafka 默认是拉模式。 Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。 Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。 《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》 消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。 《消息总线VS消息队列》 消息的顺序 《如何保证消费者接收消息的顺序》 RabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。 《RabbitMQ的应用场景以及基本原理介绍》 《消息队列之 RabbitMQ》 《RabbitMQ之消息确认机制（事务+Confirm）》 RocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。 《RocketMQ 实战之快速入门》 《RocketMQ 源码解析》 ActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。 《ActiveMQ消息队列介绍》 Kafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。 官方网站 《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》 《Kafka分区机制介绍与示例》 Redis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。 《Redis学习笔记之十：Redis用作消息队列》 ZeroMQTODO 定时调度单机定时调度 《linux定时任务cron配置》 《Linux cron运行原理》 fork 进程 + sleep 轮询 《Quartz使用总结》 《Quartz源码解析 —- 触发器按时启动原理》 《quartz原理揭秘和源码解读》 定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。 分布式定时调度 《这些优秀的国产分布式任务调度系统，你用过几个？》 opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares 《Quartz任务调度的基本实现原理》 Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的 《Elastic-Job-Lite 源码解析》 《Elastic-Job-Cloud 源码解析》 RPC 《从零开始实现RPC框架 - RPC原理及实现》 核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。 《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》 Dubbo 官方网站 dubbo实现原理简单介绍 SPI TODO Thrift 官方网站 《Thrift RPC详解》 支持多语言，通过中间语言定义接口。 gRPC服务端可以认证加密，在外网环境下，可以保证数据安全。 官方网站 《你应该知道的RPC原理》 数据库中间件Sharding Jdbc 官网 日志系统日志搜集 《从零开始搭建一个ELKB日志收集系统》 《用ELK搭建简单的日志收集分析系统》 《日志收集系统-探究》 配置中心 Apollo - 携程开源的配置中心应用 Spring Boot 和 Spring Cloud 支持推、拉模式更新配置 支持多种语言 《基于zookeeper实现统一配置管理》 《 Spring Cloud Config 分布式配置中心使用教程》 servlet 3.0 异步特性可用于配置中心的客户端 《servlet3.0 新特性——异步处理》 API 网关主要职责：请求转发、安全认证、协议转换、容灾。 《API网关那些儿》 《谈API网关的背景、架构以及落地方案》 《使用Zuul构建API Gateway》 《Spring Cloud Gateway 源码解析》 《HTTP API网关选择之一Kong介绍》 网络协议OSI 七层协议 《OSI七层协议模型、TCP/IP四层模型学习笔记》 TCP/IP 《深入浅出 TCP/IP 协议》 《TCP协议中的三次握手和四次挥手》 HTTP 《http协议详解(超详细)》 HTTP2.0 《HTTP 2.0 原理详细分析》 《HTTP2.0的基本单位为二进制帧》 利用二进制帧负责传输。 多路复用。 HTTPS 《https原理通俗了解》 使用非对称加密协商加密算法 使用对称加密方式传输数据 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。 《八大免费SSL证书-给你的网站免费添加Https安全加密》 网络模型 《web优化必须了解的原理之I/o的五种模型和web的三种工作模式》 五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用、事件(信号)驱动I/O、异步I/O，前四种I/O属于同步操作，I/O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。 三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。 《select、poll、epoll之间的区别总结》 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。 select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。 poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。 《select，poll，epoll比较 》 在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 《深入理解Java NIO》 NIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务 《BIO与NIO、AIO的区别》 《两种高效的服务器设计模型：Reactor和Proactor模型》 Epoll 《epoll使用详解（精髓）》 Java NIO 《深入理解Java NIO》 《Java NIO编写Socket服务器的一个例子》 kqueue 《kqueue用法简介》 连接和短连接 《TCP/IP系列——长连接与短连接的区别》 框架 《Netty原理剖析》 Reactor 模式介绍。 Netty 是 Reactor 模式的一种实现。 零拷贝（Zero-copy） 《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》 多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。 序列化(二进制协议)Hessian 《Hessian原理分析》 Binary-RPC;不仅仅是序列化 Protobuf 《Protobuf协议的Java应用例子》 Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。 《Protocol Buffers序列化协议及应用》 关于协议的解释；缺点：可读性差; 《简单的使用 protobuf 和 protostuff》 protostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。 数据库基础理论数据库设计的三大范式 《数据库的三大范式以及五大约束》 第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）； MySQL原理 《MySQL的InnoDB索引原理详解》 《MySQL存储引擎－－MyISAM与InnoDB区别》 两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁 《myisam和innodb索引实现的不同》 InnoDB 《一篇文章带你读懂Mysql和InnoDB》 优化 《MySQL36条军规》 《MYSQL性能优化的最佳20+条经验》 《SQL优化之道》 《mysql数据库死锁的产生原因及解决办法》 《导致索引失效的可能情况》 《 MYSQL分页limit速度太慢优化方法》 原则上就是缩小扫描范围。 索引聚集索引, 非聚集索引 《MySQL 聚集索引/非聚集索引简述》 《MyISAM和InnoDB的索引实现》 MyISAM 是非聚集，InnoDB 是聚集 复合索引 《复合索引的优点和注意事项》 自适应哈希索引(AHI) 《InnoDB存储引擎——自适应哈希索引》 explain 《MySQL 性能优化神器 Explain 使用分析》 NoSQLMongoDB MongoDB 教程 《Mongodb相对于关系型数据库的优缺点》 优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越； 缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方； Hbase 《简明 HBase 入门教程（开篇）》 《深入学习HBase架构原理》 《传统的行存储和（HBase）列存储的区别》 《Hbase与传统数据库的区别》 空数据不存储，节省空间，且适用于并发。 《HBase Rowkey设计》 rowkey 按照字典顺序排列，便于批量扫描。 通过散列可以避免热点。 搜索引擎搜索引擎原理 《倒排索引–搜索引擎入门》 Lucene 《Lucene入门简介》 Elasticsearch 《Elasticsearch学习，请先看这一篇！》 《Elasticsearch索引原理》 Solr 《 Apache Solr入门教程》 《elasticsearch与solr比较》 sphinx 《Sphinx 的介绍和原理探索》 性能性能优化方法论 《15天的性能优化工作，5方面的调优经验》 代码层面、业务层面、数据库层面、服务器层面、前端优化。 《系统性能优化的几个方面》 容量评估 《联网性能与容量评估的方法论和典型案例》 《互联网架构，如何进行容量设计？》 评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS CDN 网络 《CDN加速原理》 《国内有哪些比较好的 CDN？》 连接池 《主流Java数据库连接池比较与开发配置实战》 性能调优 《九大Java性能调试工具，必备至少一款》 大数据流式计算Storm 官方网站 《最详细的Storm入门教程》 Flink 《Flink之一 Flink基本原理介绍》 Kafka Stream 《Kafka Stream调研：一种轻量级流计算模式》 应用场景例如： 广告相关实时统计； 推荐系统用户画像标签实时更新； 线上服务健康状况实时监测； 实时榜单； 实时数据统计。 Hadoop 《用通俗易懂的话说下hadoop是什么,能做什么》 《史上最详细的Hadoop环境搭建》 HDFS 《【Hadoop学习】HDFS基本原理》 MapReduce 《用通俗易懂的大白话讲解Map/Reduce原理》 《 简单的map-reduce的java例子》 Yarn 《初步掌握Yarn的架构及原理》 Spark 《Spark(一): 基本架构及原理》 安全web 安全XSS 《xss攻击原理与解决方法》 CSRF 《CSRF原理及防范》 SQL 注入 《SQL注入》 Hash Dos 《邪恶的JAVA HASH DOS攻击》 利用JsonObject 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。 《一种高级的DoS攻击-Hash碰撞攻击》 《关于Hash Collision DoS漏洞：解析与解决方案》 脚本注入 《上传文件漏洞原理及防范》 漏洞扫描工具 《DVWA》 W3af OpenVAS详解 验证码 《验证码原理分析及实现》 《详解滑动验证码的实现原理》 滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。 《淘宝滑动验证码研究》 DDoS 防范 《学习手册：DDoS的攻击方式及防御手段》 《免费DDoS攻击测试工具大合集》 用户隐私信息保护 用户密码非明文保存，加动态salt。 身份证号，手机号如果要显示，用 “*” 替代部分字符。 联系方式在的显示与否由用户自己控制。 TODO 《个人隐私包括哪些》 《在互联网上，隐私的范围包括哪些？》 《用户密码保存》 序列化漏洞 《Lib之过？Java反序列化漏洞通用利用分析》 加密解密对称加密 《常见对称加密算法》 DES、3DES、Blowfish、AES DES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。 DES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。 哈希算法 《常用的哈希算法》 MD5 和 SHA-1 已经不再安全，已被弃用。 目前 SHA-256 是比较安全的。 《基于Hash摘要签名的公网URL签名验证设计方案》 非对称加密 《常见非对称加密算法》 RSA、DSA、ECDSA(螺旋曲线加密算法) 和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。 256位的ECC秘钥的安全性等同于3072位的RSA秘钥。 《区块链的加密技术》 服务器安全 《Linux强化论：15步打造一个安全的Linux服务器》 数据安全数据备份TODO 网络隔离内外网分离TODO 登录跳板机在内外环境中通过跳板机登录到线上主机。 《搭建简易堡垒机》 授权、认证RBAC 《基于组织角色的权限设计》 《权限系统与RBAC模型概述》 《Spring整合Shiro做权限控制模块详细案例分析》 OAuth2.0 《理解OAuth 2.0》 《一张图搞定OAuth2.0》 双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证 常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key） 【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html) 单点登录(SSO) 《单点登录原理与简单实现》 CAS单点登录框架 常用开源框架开源协议 《开源协议的选择》 如何选择一个开源软件协议 日志框架Log4j、Log4j2 《log4j 详细讲解》 《log4j2 实际使用详解》 《Log4j1,Logback以及Log4j2性能测试对比》 Log4J 异步日志性能优异。 Logback 《最全LogBack 详解、含java案例和配置说明》 ORM 《ORM框架使用优缺点》 主要目的是为了提高开发效率。 MyBatis： 《mybatis缓存机制详解》 一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效 二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。 《MyBatis学习之代码生成器Generator》 网络框架TODO Web 框架Spring 家族Spring Spring 简明教程 Spring Boot 官方网站 《Spring Boot基础教程》 Spring Cloud Spring Boot 中文索引站 Spring Cloud 中文文档 《Spring Cloud基础教程》 工具框架 《Apache Commons 工具类介绍及简单使用》 《Google guava 中文教程》 分布式设计扩展性设计 《架构师不可不知的十大可扩展架构》 总结下来，通用的套路就是分布、缓存及异步处理。 《可扩展性设计之数据切分》 水平切分+垂直切分 利用中间件进行分片如，MySQL Proxy。 利用分片策略进行切分，如按照ID取模。 《说说如何实现可扩展性的大型网站架构》 分布式服务+消息队列。 《大型网站技术架构（七）–网站的可扩展性架构》 稳定性 &amp; 高可用 《系统设计：关于高可用系统的一些技术方案》 可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。 隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。 解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。 限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。 降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。 熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。 自动化测试：通过完善的测试，减少发布引起的故障。 灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。 《关于高可用的系统》 设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。 硬件负载均衡 《转！！负载均衡器技术Nginx和F5的优缺点对比》 主要是和F5对比。 《软/硬件负载均衡产品 你知多少？》 软件负载均衡 《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS 《DNS负载均衡》 配置简单，更新速度慢。 《Nginx负载均衡》 简单轻量、学习成本低；主要适用于web应用。 《借助LVS+Keepalived实现负载均衡 》 配置比较负载、只支持到4层，性能较高。 《HAProxy用法详解 全网最详细中文文档》 支持到七层（比如HTTP）、功能比较全面，性能也不错。 《Haproxy+Keepalived+MySQL实现读均衡负载》 主要是用户读请求的负载均衡。 《rabbitmq+haproxy+keepalived实现高可用集群搭建》 限流 《谈谈高并发系统的限流》 计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。 漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。 令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。 Nginx 限流：通过 limit_req 等模块限制并发连接数。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GitHub上优秀的资源]]></title>
      <url>%2F2018%2F09%2F02%2FGitHub%E4%B8%8A%E4%BC%98%E7%A7%80%E7%9A%84%E8%B5%84%E6%BA%90%2F</url>
      <content type="text"><![CDATA[GitHub上优秀的资源语言无关类 操作系统 鸟哥的Linux私房菜 (简体) Linux 系统高级编程 The Linux Command Line (中英文版) Linux 设备驱动 (第三版) 深入分析Linux内核源码 UNIX TOOLBOX Docker中文指南 Docker —— 从入门到实践 FreeRADIUS新手入门 Mac 开发配置手册 FreeBSD 使用手册 Linux 命令行(中文版) 智能系统 一步步搭建物联网系统 web服务器 Nginx开发从入门到精通 (淘宝团队出品) 版本控制 Git教程 （本文由 @廖雪峰 创作，如果觉得本教程对您有帮助，可以去 iTunes 购买） git – 简易指南 猴子都能懂的GIT入门 Git 参考手册 Pro Git Git Magic GotGitHub Git Community Book 中文版 Mercurial 使用教程 HgInit (中文版) 沉浸式学 Git Git-Cheat-Sheet （感谢 @flyhigher139 翻译了中文版） GitHub秘籍 NoSQL NoSQL数据库笔谈 (PDF) Redis 设计与实现 Redis 命令参考 带有详细注释的 Redis 3.0 代码 带有详细注释的 Redis 2.6 代码 The Little MongoDB Book The Little Redis Book Neo4j 简体中文手册 v1.8 Neo4j .rb 中文資源 MySQL MySQL索引背后的数据结构及算法原理 项目相关 持续集成（第二版） (译言网) 让开发自动化系列专栏 追求代码质量 selenium 中文文档 Joel谈软件 約耳談軟體(Joel on Software) Web 关于浏览器和网络的 20 项须知 前端知识体系 浏览器开发工具的秘密 Chrome 开发者工具中文手册 Chrome扩展开发文档 Grunt中文文档 移动Web前端知识库 正则表达式30分钟入门教程 前端开发体系建设日记 移动前端开发收藏夹 JSON风格指南 HTTP 接口设计指北 前端资源分享（一） 前端资源分享（二） 前端代码规范 及 最佳实践 w3school教程整理 大数据 大数据/数据挖掘/推荐系统/机器学习相关资源 编程艺术 程序员编程艺术 每个程序员都应该了解的内存知识(译)【第一部分】 取悦的工序：如何理解游戏 (豆瓣阅读，免费书籍) 其他 OpenWrt智能、自动、透明翻墙路由器教程 语言相关类AWK awk程序设计语言 C/C++ C++ 并发编程指南 (@傅海平ICT) Linux C编程一站式学习 (宋劲杉, 北京亚嵌教育研究中心) CGDB中文手册 100个gdb小技巧 100个gcc小技巧 ZMQ 指南 How to Think Like a Computer Scientist (中英文版) 跟我一起写Makefile(PDF) GNU make中文手册 GNU make 指南 Google C++ 风格指南 C/C++ Primer (by @andycai) 简单易懂的C魔法 Cmake 实践 (PDF版) C++ FAQ LITE(中文版) C++ Primer 5th Answers CSS/HTML 学习CSS布局 通用 CSS 笔记、建议与指导 CSS参考手册 Emmet 文档 前端代码规范 (腾讯alloyteam团队) Dart Dart 语言导览 Fortran Fortran77和90/95编程入门 Java 实时 Java 系列 Apache Shiro 用户指南 使用 Eclipse 和 Java SE 6 创建独立 Web Services 应用程序 第 1 部分: Web Services 服务端应用程序 第 2 部分: Web 服务客户端应用程序 JavaServer Faces 1.2 入门 第 1 部分: 构建基本应用程序 第 2 部分: JSF 生命周期、转换、检验和阶段监听器 用 Eclipse Europa 进行 Web 开发 第 1 部分: Eclipse Java EE 第 2 部分: PHP 开发工具 第 3 部分: Ruby Development Toolkit 和 RadRails 使用 JavaServer Faces 构建 Apache Geronimo 应用程序 第 1 部分: 使用 Eclipse 和 Apache MyFaces Core 构建基本的应用程序 第 2 部分: 在 JavaServer Faces 中使用 Tomahawk 第 3 部分: 使用 ajax4jsf 添加 Ajax 功能 第 4 部分: 使用 Apache Trinidad 组件扩展 JSF 第 5 部分: 将 JSF 应用程序与 Spring 集成 Apache Geronimo 和 Spring 框架 第 1 部分: 开发方法学 第 2 部分: 构建第一个应用程序 第 3 部分: 集成 DAO 与 ORM 第 4 部分: 混合使用 Spring AOP 和 Spring Web Flow 第 5 部分: Spring MVC 第 6 部分: Spring MVC：使用 Web 视图技术 终极 mashup —— Web 服务和语义 Web 第 1 部分: 使用与组合 Web 服务 第 2 部分: 管理 Mashup 数据缓存 第 3 部分: 理解 RDF 和 RDFs 第 4 部分: 创建本体 第 5 部分: 切换 Web 服务 Jersey 2.x 用户指南 MyBatis中文文档 JavaScript Google JavaScript 代码风格指南 Airbnb JavaScript 规范 JavaScript 标准参考教程（alpha） Javascript编程指南 (源码) javascript 的 12 个怪癖 JavaScript 秘密花园 JavaScript核心概念及实践 (PDF) (此书已由人民邮电出版社出版发行，但作者依然免费提供PDF版本，希望开发者们去购买，支持作者) 《JavaScript 模式》翻译，此书中文版有售，但是纸质书翻译的还没有这个版本翻译的好 命名函数表达式探秘 (注:原文由为之漫笔翻译，原始地址无法打开，所以此处地址为我博客上的备份) 学用 JavaScript 设计模式 (开源中国) 深入理解JavaScript系列 ECMAScript 6 入门 (作者：阮一峰) jQuery jQuery 解构 简单易懂的JQuery魔法 How to write jQuery plugin Node.js Node入门 七天学会NodeJS Nodejs Wiki Book (繁体中文) express.js 中文文档 koa 中文文档 使用 Express + MongoDB 搭建多人博客 Express框架 nodejs文档 Node.js 包教不包会 Learn You The Node.js For Much Win! (中文版) Node debug 三法三例 underscore.js Underscore.js中文文档 backbone.js backbone.js入门教程 (PDF) Backbone.js入门教程第二版 Developing Backbone.js Applications(中文版) AngularJS AngularJS最佳实践和风格指南 AngularJS中译本 AngularJS入门教程 构建自己的AngularJS 在Windows环境下用Yeoman构建AngularJS项目 zepto 简明中文手册 Sea.js Hello Sea.js CoffeeScript CoffeeScript Cookbook The Little Book on CoffeeScript中文版 ExtJS Ext4.1.0 中文文档 Chrome扩展及应用开发 JavaScript入门教程 PHP PHP调试技术手册(PDF) XDebug 2中文手册(译) (CHM) PHP之道 PHP 最佳实践 PHP安全最佳实践 深入理解PHP内核 PHP扩展开发及内核应用 CodeIgniter 用户指南 Laravel4 中文文档 Laravel 入门 Symfony2中文文档 (未译完) Phalcon中文文档（翻译进行中） YiiBook几本Yii框架的在线教程 简单易懂的PHP魔法 swoole文档及入门教程 iOS iOS开发60分钟入门 iOS7人机界面指南 Google Objective-C Style Guide 中文版 iPhone 6 屏幕揭秘 Apple Watch开发初探 马上着手开发 iOS 应用程序 网易斯坦福大学公开课：iOS 7应用开发字幕文件 Android Android Design(中文版) Google Android官方培训课程中文版 Android学习之路 Python 小白的Python教程 简明Python教程 零基础学Python Python 2.7 官方教程中文版 Python 3.3 官方教程中文版 深入 Python 3 PEP8 Python代码风格规范 Google Python 风格指南 中文版 Python入门教程 (PDF) Python的神奇方法指南 笨办法学 Python （PDF版下载） Django 文档中文版 Django 最佳实践 The Django Book 中文版 web.py 0.3 新手指南 Web.py Cookbook 简体中文版 Dive Into Python 中文版 Bottle 文档中文版 (需翻墙) Flask 文档中文版 Jinja2 文档中文版 Werkzeug 文档中文版 Flask之旅 Introduction to Tornado 中文翻译 Python自然语言处理中文版 （感谢陈涛同学的翻译，也谢谢 @shwley 联系了作者） Python 绘图库 matplotlib 官方指南中文翻译 Scrapy 0.25 文档 ThinkPython Ruby Ruby 风格指南 Rails 风格指南 笨方法學 Ruby Ruby on Rails 指南 Ruby on Rails 實戰聖經 Ruby on Rails Tutorial 原书第 2 版 (本书网页版免费提供，电子版以 PDF、EPub 和 Mobi 格式提供购买，仅售 9.9 美元) 编写Ruby的C拓展 Ruby 源码解读 Shell Shell脚本编程30分钟入门 Go Go编程基础 Go入门指南 学习Go语言 (PDF) Go Web 编程 (此书已经出版，希望开发者们去购买，支持作者的创作) Go实战开发 (当我收录此项目时，作者已经写完第三章，如果读完前面章节觉得有帮助，可以给作者捐赠，以鼓励作者的继续创作) Network programming with Go 中文翻译版本 Groovy 实战 Groovy 系列 LaTeX 一份其实很短的 LaTeX 入门文档 一份不太简短的 LATEX 2ε 介绍 （PDF版） LISP ANSI Common Lisp 中文翻譯版 Lua Lua编程入门 Haskell Real World Haskell 中文版 R R语言忍者秘笈 Scala Scala课堂 (Twitter的Scala中文教程) Effective Scala(Twitter的Scala最佳实践的中文翻译) Scala指南 Swift The Swift Programming Language 中文版 Perl Modern Perl 中文版 Perl 程序员应该知道的事 Prolog 笨办法学Prolog Vim中文文档 Vimscript 笨方法学Vimscript 中译本 Vim中文文档 读书笔记及其它读书笔记 编译原理（紫龙书）中文第2版习题答案 把《编程珠玑》读薄 Effective C++读书笔记 Golang 学习笔记、Python 学习笔记、C 学习笔记 (PDF) Jsoup 学习笔记 学习笔记: Vim、Python、memcached 图灵开放书翻译计划–C++、Python、Java等 蒂姆·奥莱利随笔 （由译言网翻译，电子版免费） Octave 入门 （PDF版） SICP 解题集 精彩博客集合 正则表达式简明参考 测试相关 移动APP自动化测试优秀框架Appium API Reference V1.2.0 CN]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx之location详解]]></title>
      <url>%2F2018%2F09%2F02%2FNginx%E4%B9%8Blocation%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[location详解1、root 1 、location中root指定的只是相对路径，需要和路径结合起来映射地址，比如 12345location ^~/static/ &#123; ## 这里的root需要和路径结合使用，即是映射的文件位置为 /usr/alyingboy/static root /usr/alyingboy/; index index.html&#125; 2、此时我们访问 IP/static/a.css ，那么就会找到 `/usr/alyingboy/static/a.css` 2、 alias 1、 alias指定的是绝对路径，不会和location中的路径结合使用，而是直接使用地址映射到文件，比如 12345location ^~/static/ &#123; ## 不会路径结合映射地址，那么这里就会直接映射到/usr/alyingboy/文件夹下的文件 alias /usr/alyingboy/; index index.html&#125; 2、如果定义的路径是文件夹，那么需要使用`/`结尾 3、一旦配置请求location映射到了指定的位置，那么下面全部的文件夹和文件都可以映射到，不需要在配置对其的映射，比如，但是如果使用其中的文件名重新映射了地址，那么这个路径将不能使用 123456# /usr/alyingboy/文件夹下的全部文件包括子文件夹和文件都可以使用指定的地址访问到，比如访问地址为 ：# IP/static/a.txt ,那么这个地址访问的是/usr/alyingboy/static/a.txt文件location / &#123; root /usr/alyingboy/; index index.html;&#125; 路径匹配 = 开头表示精确匹配。如 A 中只匹配根目录结尾的请求，后面不能带任何字符串； ^~ 开头表示uri以某个常规字符串开头，不是正则匹配； ~ 开头表示区分大小写的正则匹配； ~* 开头表示不区分大小写的正则匹配； / 通用匹配, 如果没有其它匹配,任何请求都会匹配到。 12345678910111213141516171819202122232425262728293031323334353637383940414243location = / &#123; # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ]&#125;location / &#123; # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ]&#125;location /documents/ &#123; # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ]&#125;location ~ /documents/Abc &#123; # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ]&#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ]&#125;location /images/ &#123; # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ]&#125;location /images/abc &#123; # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F与G的放置顺序是没有关系的 [ configuration G ]&#125;location ~ /images/abc/ &#123; # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 # 因为都是正则匹配，优先级一样，选择最上面的 [ configuration H ]&#125;location ~* /js/.*/\.js 优先级 ( location = ) &gt; ( location 完整路径 ) &gt; ( location ^~ 路径 ) &gt; ( location ~,~* 正则顺序 ) &gt; ( location 部分起始路径 ) &gt; ( / ) ### 推荐使用 1234567891011121314151617181920#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。#这里是直接转发给后端应用服务器了，也可以是一个静态首页# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125;# 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125;#第三个规则就是通用规则，用来转发动态请求到后端应用服务器#非静态文件请求就默认是动态请求，自己根据实际把握#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了location / &#123; proxy_pass http://tomcat:8080/&#125; 参考文章1、官方中文文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker基本使用]]></title>
      <url>%2F2018%2F09%2F02%2Fdocker%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[docker入门配置阿里云的镜像加速器1、登录阿里云控制台，找到自己的控制台，配置docker的镜像加速，在自己的centos7的机器上执行下述命令即可: 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://rxx4pnmv.mirror.aliyuncs.com"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 简单使用1、搜索镜像：docker search image ​ 1、image是镜像的名字 1docker search mysql ---- 搜索全部的mysql镜像 2、拉取镜像：docker pull image：tag ​ 1、image是镜像的名称 ​ 2、tag是镜像的版本，如果不指定tag，那么默认拉取最新的latest 12docker pull mysql --- 拉取最新版本的mysqldocker pull mysql:5.5 -- 指定版本 3、列出本地所有的镜像：docker images [options] 12345678910111213docker images -a -- 列出本地所有的镜像docker images -q --显示镜像Ｉｄdocker images -aq -- 显示所有的镜像iddocker images -- 查看本地的镜像列表docker images mysql -- 列出本地仓库中镜像名称为mysql的镜像，会列出所有的版本docker images mysql:5.5 --- 列出指定版本的镜像docker image ls -f since=mysql:5.5 --- 列出所有在mysql:5.5之后拉取的镜像，之前的只需要将since改成before即可 4、查看镜像，容器，数据卷所占用的空间 : docker system df 5、显示本地仓库中虚悬镜像 docker image ls -f dangling=true 6、删除虚悬镜像： docker image prune 7、删除本地镜像：docker rmi [options],&lt;image&gt; 12345678910111、先列出所有的镜像 docker images2、删除指定的本地镜像 docker rmi image_id 使用Id删除镜像3、强制删除镜像 docker rmi image_id 4、使用仓库名和标签删除指定镜像 docker rmi mysql:5.5 如果没有指定tag，那么默认是latest，这里的mysql是仓库的名字5、docker rmi mysql nginx 删除多个镜像，比如mysql，nginx6、删除全部镜像 docker rmi $(dokcer images -aq) 8、运行容器：docker run [options] image ... 12345678910111213141516171819202122232425262728293031-a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；-d: 后台运行容器，并返回容器ID；-i: 以交互模式运行容器，通常与 -t 同时使用；-p: 端口映射，格式为：主机(宿主)端口:容器端口-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；--name="nginx-lb": 为容器指定一个名称；--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；-h "mars": 指定容器的hostname；-e username="ritchie": 设置环境变量；--env-file=[]: 从指定文件读入环境变量；--cpuset="0-2" or --cpuset="0,1,2": 绑定容器到指定CPU运行；-m :设置容器使用内存最大值；--net="bridge": 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；--link=[]: 添加链接到另一个容器；--expose=[]: 开放一个端口或一组端口； 123451、docker pull centos -- 拉取一个centos2、docker run -it --name mycentos 5182e96772bf --- 以交互形式运行该centos，就会在控制台上有一个输入终端3、docker run --name tomcat01 -d -p 8081:8080 tomcat -- 运行tomcat，将docker的8081端口映射到tomcat的默认端口8080 9、退出容器： exit 10、列出当前所有的运行的容器 docker ps 123456789101112131415-a :显示所有的容器，包括未运行的。-f :根据条件过滤显示的内容。--format :指定返回值的模板文件。-l :显示最近创建的容器。-n :列出最近创建的n个容器。--no-trunc :不截断输出。-q :静默模式，只显示容器编号。-s :显示总的文件大小。 11、启动容器 ： docker start container，其中container可以是容器的名字，也可以是容器的Id 1docker start mycentos ## 启动之前停止的容器 12、重启容器 docker restart container 1docker restart mycentos -- 重启容器 13、停止容器：docker stop container，平滑的停止 14、杀掉当前正在运行的容器：docker kill container 12docker kill mycentos docker kill -s mycentos 15、删除容器：docker rm container 12345docker rm containerId -- 删除已经关闭的容器docker rm -f containerId -- 删除正在运行的容器，强制删除docker rm $(docker ps -aq) -- 删除当前全部的容器 重要命令1、启动守护式的容器（后台运行） ： docker run --name mycentos -d centos 2、查看容器的日志信息：docker logs [options] container 1234567-f : 跟踪日志输出--since :显示某个开始时间的所有日志-t : 显示时间戳--tail :仅列出最新N条容器日志 1docker logs -f mycentos 3、查看容器中运行的进程信息： docker top container，这个命令和Linux中的ps一样的效果 1234docker top mymysql 查看当前正在运行的mysql的进程信息，如下：UID PID PPID C STIME TTY TIME CMD999 40347 40331 18 00:58 ? 00:00:02 mysqld 4、查看容器内部的细节： docker inspect container 1docker inspect mycentos 5、进入正在运行的容器，并以命令行的形式进行交互：docker attach container 1docker attach myCentos -- 进入正在运行的centos 6、在运行的容器中执行命令 docker exec 1docker exec -it mysql bash -- 这个命令将会连接上mysql的终端，可以执行命令行 持久化数据 — 数据卷1、docker run -it -v /宿主机绝对路径:/docker容器内的路径 镜像名 12345678910111213141516# 这个命令是在后台执行运行一个tomcat容器，使用-v可以在服务器的根目录下创建一个myDataVolum，在tomcat的根目录中创建一个dataVolumContainer文件夹1、docker run -d --name tomcat01 -v /myDataVolum:/dataVolumContainer tomcat## 进入tomcat 的根目录查看是否存在这个文件夹2、docker exec -it tomcat01 /bin/bash## 查看此时的tomcat的内部实现细节，可以看到有一段文字如下：3、 docker inspect tomcat01 "HostConfig": &#123; "Binds": [ "/myData:/myDataContainer" ],4、在服务器的根目录下查看是否存在这个文件 2、此时的我们docker容器中的目录dataVolumContainer和服务器下的目录myDataVolum就可以实现数据共享了，即是实时的互相共享数据。 3、有了这个数据卷我们将一些容器的配置文件和服务器本地的配置文件绑定在一起，那么我们只需要修改服务器中的配置文件即可。 安装mysql1、在服务器新建文件夹，用来和容器中的mysql共享配置信息和日志（当然也可以不用创建，会自动创建） ​ 1、在服务器的根目录下新建mysql的配置文件夹，用于和docker容器mysql的配置文件挂载 ：/mysql/conf.d ​ 2、新建一个日志文件夹，用于挂载日志信息：/mysql/logs ​ 3、新建一个文件夹，挂载data目录：/mysql/data 2、拉取指定版本的镜像：docker pull mysql:5.7 3、运行镜像，指定挂载目录 1docker run --name mysql -p 3306:3306 -v /mysql/data:/var/lib/mysql -v /mysql/conf.d:/etc/mysql/conf.d -v /mysql/logs:/logs -e MYSQL_ROOT_PASSWORD=12345 -d mysql:5.7 4、移植配置文件到我们服务器的配置文件目录中：/mysql/conf.d/，新建一个配置文件mysql.cnf，内容如下： 1234[mysql]default-character-set=utf8[mysqld]character-set-server=utf8 5、新建配置文件mysqldump.cnf,内容如下： 1234[mysqldump]quickquote-namesmax_allowed_packet = 16M 6、连接数据库，在docker容器中连接：docker exec -it mysql bash 7、远程登录服务器的mysql：mysql -h 47.123.23.44 -u root -p 8、查看mysql的日志信息：docker logs mysql 9、我们在使用docker run命令的时候传入一个或者多个参数指定mysql的环境变量，如下： 123456MYSQL_ROOT_PASSWORD：必须。用于设置MySQLroot用户的密码MYSQL_DATABASE：可选。用于指定镜像启动容器时要创建的数据库。如果提供了用户/密码，则会将该用户做为此数据库的超级用户。MYSQL_USER，MYSQL_PASSWORD：可选。用于创建一个新用户并设置密码。MYSQL_ALLOW_EMPTY_PASSWORD：可选。设置为yes时，则可以使用空密码登录MYSQL_RANDOM_ROOT_PASSWORD：可选。设置为yes时会为root用户设置一个随机密码（使用pwgen），所生成的随机密码会被输出到stdoutMYSQL_ONETIME_PASSWORD：可选。为root用户指定一个一次性密码，该密码会在用户首次登录时强制修改 10、参考文章：https://itbilu.com/linux/docker/EyP7QP86M.html 安装Nginx0、https://lvtao.net/config/docker-nginx.html 1、https://my.oschina.net/u/3375733/blog/1591091 1、在服务器上创建文件夹（可以不创建，会自动创建），用于和docker容器中的Nginx的共享数据，文件夹如下： 123451、html目录将映射为nginx容器配置的虚拟目录2、logs目录将映射为nginx容器的日志目录3、conf目录里的配置文件将映射为nginx容器的配置文件 2、拉取最新的Nginx，docker pull nginx 3、运行容器，使用-v指定共享的容器卷，如下： ​ 1、运行下面的指令会报错，因为-v /nginx/conf/nginx.conf:/etc/nginx/nginx.conf这个nginx.conf根本不知道是文件夹还是文件，因此我们应该现在服务器上建立一个和nginx一样的配置文件，那么执行下面的语句将会正确执行 ​ 1、首先先运行一个nginx容器，名字为mynginx ​ 2、执行docker cp mynginx:/etc/nginx/nginx.conf /nginx/conf/,将配置文件复制到/nginx/conf/下 ​ 3、执行下面的语句 1docker run --name mynginx -p 80:80 -v /nginx/html:/usr/share/nginx/html -v /nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /nginx/logs:/var/log/nginx/ -v /nginx/www:/usr/share/nginx/www -d nginx ​ 参考文章1、https://yeasy.gitbooks.io/docker_practice/content/image/list.html 2、https://itbilu.com/linux/docker 3、http://docs.linux.xyz/docs/show/24]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springBoot高级]]></title>
      <url>%2F2018%2F09%2F02%2FspringBoot%E9%AB%98%E7%BA%A7%2F</url>
      <content type="text"><![CDATA[springBoot高级普通缓存1、在springBoot中可以使用注解式开发缓存，默认没有开启缓存中间件，那么使用的就是存储在Map中的原理，但是我们还可以配置自己的缓存中间件，比如redis 2、引入依赖，启动器 12345&lt;!--导入缓存的启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; 3、开启缓存，在主配置类上添加EnableCaching这个注解即可，如下： 12345//批量扫描com.tellwess.springbootserver.mappers这个包下面的所有mapper@MapperScan(value ="com.tellwess.springbootserver.mappers")@EnableCaching //开启缓存注解@SpringBootApplicationpublic class SpringbootServerApplication &#123; 4、使用注解版本的mybatis和数据库进行交互，其中的UserMapper如下： 123456789101112131415161718/** * User对应的Mapper */public interface UserMapper &#123; @Select("select * from t_user where user_id=#&#123;userId&#125;") public User selectUserById(Integer userId); @Options(useGeneratedKeys = true,keyProperty = "userId") @Insert(&#123;"insert into t_user(name,gender,age) values(#&#123;name&#125;,#&#123;gender&#125;,#&#123;age&#125;)"&#125;) public int insertUser(User user); @Delete("delete from t_user where user_id=#&#123;userId&#125;") public int deleteUser(Integer userId); @Select("select * from t_user where name=#&#123;name&#125;") public User selectUserByName(String name);&#125; 5、在service层中使用缓存的各种注解实现缓存的操作，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * @CacheConfig ： 这个注解用于指定这个service类中的缓存操作的公共属性，比如缓存的名字可以使用cacheNames指定，那么在下面的每一个注解中都可以不指定，默认使用的就是这个指定的 */@Service//@CacheConfig(cacheNames = "user",keyGenerator = "myGenerate")public class UserService &#123; @Resource private UserMapper userMapper; /** *@Cacheable : 这个注解是在方法运行之前检查缓存中是否存在指定的key的数据，如果存在，那么直接返回 * 如果不存在，那么执行方法体，最后将方法体返回的结果添加到缓存中 * 1、 cacheNames/value : 指定cache的名字,指定将方法的返回值放在那个缓存中，是数组的方式 * 2、key : 指定缓存的key，如果不指定的，那么默认使用方法参数的值，当然也是可以使用一些表达式指定这个key的值 * 1、spEL表达式： * 1、当前被调用的方法名称 ---- #root.methodName ---- #root.method.name * 2、当前目标对象 ---- #root.target * 3、当前目标对象的类 ----- #root.targetClass * 4、当前被调用对象的参数列表 ---- #root.args[index] * 5、方法参数的名字，直接使用`#名字`即可获取参数的值 ------ `#userId` * 6、方法的返回值 ----- #result * 3、keyGenerator : key的生成器，这个和key只能同时指定一个，当然也是可以自定义这个生成器 * 4、condition : 指定缓存的条件，只有满足这个条件的时候才会使用缓存 --- condition = "#userId&gt;2" * 5、unless : 当这个条件为true的时候就不缓存，这个和condition条件相反。 * 1、这个可以使用返回的结果进行判断，比如当我们对返回结果为空的时候不使用缓存，那么可以写成unless = "#result==null" * * 6、cacheManager : 指定缓存管理器 * 7、sync ： 是否使用异步模式 * 8、注意：springBoot默认是将返回值为null的时候也会将其缓存起来，我们可以使用unless条件对结果进行判断是否缓存 * * */ @Cacheable(value = &#123;"user"&#125;,key = "#userId",condition = "#userId&gt;2",unless = "#result==null") public User getUser(Integer userId)&#123; System.out.println("查询数据库"); return userMapper.selectUserById(userId); &#125; /** * @CachePut ： 这个注解的作用是，在方法体执行完成之后，将返回的结果添加到缓存中，可以用于添加和修改操作 * 其中可以设置的参数和@cacheable差不多 * 注意：**只要是标注了这个注解之后，那么这个方法一定是要执行的，因为需要将方法执行的结果添加到缓存中** * */ @CachePut(value = "user",key = "#user.userId") public User addUser(User user)&#123; System.out.println("添加用户"); userMapper.insertUser(user); return user; &#125; /** * @CacheEvict : 这个注解的作用是清除缓存，默认是在执行方法体之后清除缓存，如果执行的代码出现了异常，那么这个清除缓存将不会执行 * 1、vaue ： 指定缓存的名字 * 2、key : 指定需要删除的key * 3、allEntries ： 是否删除指定缓存中的全部缓存，默认为false，一旦指定为true，那么将会删除value指定的cache中的全部缓存 * 4、beforeInvocation : 是否在执行方法体的代码之前执行清除缓存，默认为false，如果指定了为true，那么就会在方法执行之前清除缓存， * 此时如果方法体运行出错，那么缓存中的数据将不能回滚 */ @CacheEvict(value = "user",key = "#userId") public void deleteUser(Integer userId)&#123; System.out.println("调用了删除的方法"); userMapper.deleteUser(userId); &#125; /** * @Caching : 这个是一个组合注解，针对一个方法逻辑中多种的缓存操作 * 1、cacheable ： 一个数组，其中指定@Cacheable这个注解，可以指定多个，用于在执行方法之前先查询缓存，如果没有才会执行方法体，并且将结果缓存起来 * 2、put： 一个数组，其中只能指定@CachePut这个注解，可以指定多个，用于在执行方法之后将返回的结果添加到缓存中 * 3、evict ： 一个数组，其中只能指定＠CacheEvict这个注解，用于在方法执行完成之后清除缓存 */ @Caching( cacheable = &#123; @Cacheable(value = "user",key = "#name") //首先根据name从缓存中获取数据，如果没有将会把缓存的结果添加到缓存中 &#125;, put = &#123; @CachePut(value = "user",key = "#result.age"), @CachePut(value = "user",key = "#result.gender"), &#125; ) public User getUserByName(String name)&#123; System.out.println("调用getUserByName方法"); return userMapper.selectUserByName(name); &#125;&#125; Redis缓存1、添加场景启动器，如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 2、在全局配置文件中配置redis的连接配置，如下： 123456789101112131415161718# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=172.31.19.222 # Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 3、一旦注入这个场景启动器，那么将会为我们自动配置，我们可以直接使用spring-data-redis操作redis，如下： 123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootCacheApplicationTests &#123; @Resource private StringRedisTemplate stringRedisTemplate; //存储key和value都是字符串的数据 @Resource private RedisTemplate&lt;String,Object&gt; redisTemplate; //操作key和value都是Object的数据 @Test public void contextLoads() &#123; stringRedisTemplate.opsForValue().append("hello","hello world"); &#125;&#125; 4、springBoot默认是使用的jdk的序列化方式将数据保存在Redis中，但是我们可以自定义自己的序列化规则，可以指定的json序列化器，如下： 12345678910111213141516//指定一个redis的配置类@Configurationpublic class RedisConfig &#123; //指定自己的RedisTemplate，并且指定默认的序列化器为json的，只需要设置默认的即可，因为value和key的序列化器和默认的是一样的，不需要重复指定 @Bean public RedisTemplate&lt;Object, User&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, User&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); //指定json的序列化器 Jackson2JsonRedisSerializer&lt;User&gt; serializer=new Jackson2JsonRedisSerializer&lt;User&gt;(User.class); template.setDefaultSerializer(serializer); //设置为默认的序列化器 return template; &#125;&#125; 5、只要引入redis的场景启动器，那么就会为我们配置一个RedisCache这个名字的缓存管理器，因此不需要重新配置了，那么我们可以直接使用缓存的注解了。此时使用缓存注解的时候就会将数据存储在redis中了。但是默认的保存的数据还是使用jdk序列化后的结果。 6、个人觉得使用缓存不需要使用注解，手写代码应该更加灵活一些。 SpringBoot共用session http://www.ityouknow.com/springboot/2016/03/06/spring-boot-redis.html springBoot高级普通缓存1、在springBoot中可以使用注解式开发缓存，默认没有开启缓存中间件，那么使用的就是存储在Map中的原理，但是我们还可以配置自己的缓存中间件，比如redis 2、引入依赖，启动器 12345&lt;!--导入缓存的启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; 3、开启缓存，在主配置类上添加EnableCaching这个注解即可，如下： 12345//批量扫描com.tellwess.springbootserver.mappers这个包下面的所有mapper@MapperScan(value ="com.tellwess.springbootserver.mappers")@EnableCaching //开启缓存注解@SpringBootApplicationpublic class SpringbootServerApplication &#123; 4、使用注解版本的mybatis和数据库进行交互，其中的UserMapper如下： 123456789101112131415161718/** * User对应的Mapper */public interface UserMapper &#123; @Select("select * from t_user where user_id=#&#123;userId&#125;") public User selectUserById(Integer userId); @Options(useGeneratedKeys = true,keyProperty = "userId") @Insert(&#123;"insert into t_user(name,gender,age) values(#&#123;name&#125;,#&#123;gender&#125;,#&#123;age&#125;)"&#125;) public int insertUser(User user); @Delete("delete from t_user where user_id=#&#123;userId&#125;") public int deleteUser(Integer userId); @Select("select * from t_user where name=#&#123;name&#125;") public User selectUserByName(String name);&#125; 5、在service层中使用缓存的各种注解实现缓存的操作，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * @CacheConfig ： 这个注解用于指定这个service类中的缓存操作的公共属性，比如缓存的名字可以使用cacheNames指定，那么在下面的每一个注解中都可以不指定，默认使用的就是这个指定的 */@Service//@CacheConfig(cacheNames = "user",keyGenerator = "myGenerate")public class UserService &#123; @Resource private UserMapper userMapper; /** *@Cacheable : 这个注解是在方法运行之前检查缓存中是否存在指定的key的数据，如果存在，那么直接返回 * 如果不存在，那么执行方法体，最后将方法体返回的结果添加到缓存中 * 1、 cacheNames/value : 指定cache的名字,指定将方法的返回值放在那个缓存中，是数组的方式 * 2、key : 指定缓存的key，如果不指定的，那么默认使用方法参数的值，当然也是可以使用一些表达式指定这个key的值 * 1、spEL表达式： * 1、当前被调用的方法名称 ---- #root.methodName ---- #root.method.name * 2、当前目标对象 ---- #root.target * 3、当前目标对象的类 ----- #root.targetClass * 4、当前被调用对象的参数列表 ---- #root.args[index] * 5、方法参数的名字，直接使用`#名字`即可获取参数的值 ------ `#userId` * 6、方法的返回值 ----- #result * 3、keyGenerator : key的生成器，这个和key只能同时指定一个，当然也是可以自定义这个生成器 * 4、condition : 指定缓存的条件，只有满足这个条件的时候才会使用缓存 --- condition = "#userId&gt;2" * 5、unless : 当这个条件为true的时候就不缓存，这个和condition条件相反。 * 1、这个可以使用返回的结果进行判断，比如当我们对返回结果为空的时候不使用缓存，那么可以写成unless = "#result==null" * * 6、cacheManager : 指定缓存管理器 * 7、sync ： 是否使用异步模式 * 8、注意：springBoot默认是将返回值为null的时候也会将其缓存起来，我们可以使用unless条件对结果进行判断是否缓存 * * */ @Cacheable(value = &#123;"user"&#125;,key = "#userId",condition = "#userId&gt;2",unless = "#result==null") public User getUser(Integer userId)&#123; System.out.println("查询数据库"); return userMapper.selectUserById(userId); &#125; /** * @CachePut ： 这个注解的作用是，在方法体执行完成之后，将返回的结果添加到缓存中，可以用于添加和修改操作 * 其中可以设置的参数和@cacheable差不多 * 注意：**只要是标注了这个注解之后，那么这个方法一定是要执行的，因为需要将方法执行的结果添加到缓存中** * */ @CachePut(value = "user",key = "#user.userId") public User addUser(User user)&#123; System.out.println("添加用户"); userMapper.insertUser(user); return user; &#125; /** * @CacheEvict : 这个注解的作用是清除缓存，默认是在执行方法体之后清除缓存，如果执行的代码出现了异常，那么这个清除缓存将不会执行 * 1、vaue ： 指定缓存的名字 * 2、key : 指定需要删除的key * 3、allEntries ： 是否删除指定缓存中的全部缓存，默认为false，一旦指定为true，那么将会删除value指定的cache中的全部缓存 * 4、beforeInvocation : 是否在执行方法体的代码之前执行清除缓存，默认为false，如果指定了为true，那么就会在方法执行之前清除缓存， * 此时如果方法体运行出错，那么缓存中的数据将不能回滚 */ @CacheEvict(value = "user",key = "#userId") public void deleteUser(Integer userId)&#123; System.out.println("调用了删除的方法"); userMapper.deleteUser(userId); &#125; /** * @Caching : 这个是一个组合注解，针对一个方法逻辑中多种的缓存操作 * 1、cacheable ： 一个数组，其中指定@Cacheable这个注解，可以指定多个，用于在执行方法之前先查询缓存，如果没有才会执行方法体，并且将结果缓存起来 * 2、put： 一个数组，其中只能指定@CachePut这个注解，可以指定多个，用于在执行方法之后将返回的结果添加到缓存中 * 3、evict ： 一个数组，其中只能指定＠CacheEvict这个注解，用于在方法执行完成之后清除缓存 */ @Caching( cacheable = &#123; @Cacheable(value = "user",key = "#name") //首先根据name从缓存中获取数据，如果没有将会把缓存的结果添加到缓存中 &#125;, put = &#123; @CachePut(value = "user",key = "#result.age"), @CachePut(value = "user",key = "#result.gender"), &#125; ) public User getUserByName(String name)&#123; System.out.println("调用getUserByName方法"); return userMapper.selectUserByName(name); &#125;&#125; Redis缓存1、添加场景启动器，如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 2、在全局配置文件中配置redis的连接配置，如下： 123456789101112131415161718# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=172.31.19.222 # Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 3、一旦注入这个场景启动器，那么将会为我们自动配置，我们可以直接使用spring-data-redis操作redis，如下： 123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootCacheApplicationTests &#123; @Resource private StringRedisTemplate stringRedisTemplate; //存储key和value都是字符串的数据 @Resource private RedisTemplate&lt;String,Object&gt; redisTemplate; //操作key和value都是Object的数据 @Test public void contextLoads() &#123; stringRedisTemplate.opsForValue().append("hello","hello world"); &#125;&#125; 4、springBoot默认是使用的jdk的序列化方式将数据保存在Redis中，但是我们可以自定义自己的序列化规则，可以指定的json序列化器，如下： 12345678910111213141516//指定一个redis的配置类@Configurationpublic class RedisConfig &#123; //指定自己的RedisTemplate，并且指定默认的序列化器为json的，只需要设置默认的即可，因为value和key的序列化器和默认的是一样的，不需要重复指定 @Bean public RedisTemplate&lt;Object, User&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, User&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); //指定json的序列化器 Jackson2JsonRedisSerializer&lt;User&gt; serializer=new Jackson2JsonRedisSerializer&lt;User&gt;(User.class); template.setDefaultSerializer(serializer); //设置为默认的序列化器 return template; &#125;&#125; 5、只要引入redis的场景启动器，那么就会为我们配置一个RedisCache这个名字的缓存管理器，因此不需要重新配置了，那么我们可以直接使用缓存的注解了。此时使用缓存注解的时候就会将数据存储在redis中了。但是默认的保存的数据还是使用jdk序列化后的结果。 6、个人觉得使用缓存不需要使用注解，手写代码应该更加灵活一些。 SpringBoot共用session http://www.ityouknow.com/springboot/2016/03/06/spring-boot-redis.html springBoot异步任务springBoot定时任务 sprignBoot定时任务是与quartz整合，不需要添加任何的依赖 在springBoot的启动类上添加@EnableScheduling注解开启定时调度 在需要定时调度的方法上添加@Scheduled这个注解即可，其中可以指定cron表达式 和其他的定时方式，如下： 123@Scheduled(fixedRate = 6000) ：上一次开始执行时间点之后6秒再执行@Scheduled(fixedDelay = 6000) ：上一次执行完毕时间点之后6秒再执行@Scheduled(initialDelay=1000, fixedRate=6000) ：第一次延迟1秒后执行，之后按fixedRate的规则每6秒执行一次 实例123456789101112@Service //注入到容器中public class QuartService &#123; /** * 开启定时调度任务，使用cron表达式指定时间 */ @Scheduled(cron="0/1 * * * * ? ") //指定cron表达式每秒执行一次 public void sysHello()&#123; System.out.println("say hello"); &#125;&#125; 启动类上添加注解开启定时任务 12345678@SpringBootApplication@EnableScheduling //开启定时任务调度public class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springBoot基本使用]]></title>
      <url>%2F2018%2F09%2F02%2FspringBoot%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[获取配置文件中的值@ConfigurationProperties1、这个注解默认只能从全局配置文件中获取信息，全局配置有两个，如下： ​ 1、application.properties ​ 2、application.yml yml1、key和value之间需要空格 2、缩进显示层次关系，缩进多少无所谓，只要左对齐那么就是一个层级关系的 3、key: value :： 表示一个键值对，注意一定要有空格 4、大小写敏感 5、属性的值如果是字符串可以直接写，不需要加上双引号或者单引号 ​ 1、双引号：加上双引号的值不会转义里面的特殊字符，比如字符串中包含一个换行符，那么就会在输出的时候换行 ​ 2、单引号：会转义特殊的字符，会直接输出换行符为\n 6、List和Set的表示方法： 12345678# key与value之间空格pets: - dog - pig - cat## 行内的写法：pets: [dog,pig,cat] 7、Map的写法 1map: &#123;name: Jack,age: 22,gender: 女&#125; 8、举例 1、JavaBean： 1234567891011121314/** * ConfigurationProperties ： 这个注解表示这个实体类的值来自于配置文件中，当然包括properties和yaml文件 * prefix表示这个配置文件中的前缀 */@Component //注入到容器中@ConfigurationProperties(prefix = "person")public class Person &#123; private String name; private int age; private List&lt;Object&gt; list; private Map&lt;String,Object&gt; map; private User user; private Date birthday;&#125; 2、application.yml 1234567891011person: name: 陈加兵 age: 22 list: - zhangsan - lisi user: name: 郑元梅 age: 22 map: &#123;name: Jack,age: 22,gender: 女&#125; birthday: 2012/12/11 3、添加一个依赖，将会在配置文件中自动提示 123456&lt;!--导入这个处理器，在配置文件中将会自动提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 4、测试类： 123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class TeammissionServerApplicationTests &#123; @Autowired private Person person; //自动注入 @Test public void contextLoads() &#123; System.out.println(person); //输出配置信息 &#125;&#125; properties1、依然可以使用@ConfigurationProperties这个注解获取配置文件的值，不过和yml文件中的配置有很大的区别，如下： 12345678person.age=22person.name=陈加兵person.birthday=2012/12/11person.list=a,b,cperson.map.name=陈加兵person.map.age=22person.user.name=Jackperson.user.age=33 @Value1、这个注解是spring中的注解，用于获取配置文件的值 使用方式 作用 @Value(“${}”) 获取配置文件中的值 @Value(“#{}”) 获取配置文件中的值，不过需要使用这个指定id @Value(“value”) 可以直接为变量赋值 2、不支持JSR303校验 @PropertySource1、我们在使用@configurationProperties获取文件中的信息的时候，默认只能从默认的配置文件中获取信息，如果我们需要自己单独定义一个配置文件，那么需要使用@PropertySource这个注解获取其中的信息 2、 我们在项目路径下新建一个person.properties文件，其中的内容如下： 12345678person.age=22person.name=陈加兵person.birthday=2012/12/11person.list=a,b,cperson.map.name=陈加兵person.map.age=22person.user.name=Jackperson.user.age=33 3、在Person这个实体类中添加如下的注解配置，使用@PropertySource这个注解加载这个配置文件，如下： 12345678910111213141516/** * ConfigurationProperties ： 这个注解表示这个实体类的值来自于配置文件中，当然包括properties和yaml文件 * prefix表示这个配置文件中的前缀 */@PropertySource(value =&#123;"classpath:person.properties"&#125;) //从自定义的配置文件中获取信息@Component //注入到容器中@ConfigurationProperties(prefix = "person") //获取前缀为person的信息public class Person &#123; private String name; private int age; private List&lt;Object&gt; list; private Map&lt;String,Object&gt; map; private User user; private Date birthday;&#125; 4、使用@PropertySource这个注解能够导入自定义的配置文件并且获取其中的值 5、 使用这个注解只能加载properties文件，无法加载YAML文件 @ImportSource1、在springBoot中几乎没有配置文件，全部都是使用注解，那么我们如果需要使用配置文件，我们该如何让这个配置文件生效呢？ 2、我们可以使用这个注解加载自己的配置文件xml，不过在springBoot中不赞成这样做，因为可以使用配置类来代替配置文件xml 3、我们在项目的resource文件下新建一个beans.xml，其中配置了如下的信息： 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="person" class="com.telles.teammissionserver.bean.Person"&gt; &lt;property name="age" value="22"&gt;&lt;/property&gt; &lt;property name="name" value="陈加兵"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 4、我们现在需要将其加入到IOC容器中，必须使用@ImportSource这个注解，我们需要在项目的主配置类上添加这个注解导入配置文件 123456789//使用这个注解可以导入自定义的配置文件xml,其中的value值是一个数组，可以填写多个值@ImportResource(value = &#123;"classpath:beans.xml"&#125;)@SpringBootApplicationpublic class TeammissionServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TeammissionServerApplication.class, args); &#125;&#125; 配置类1、我们在springBoot中已经完全舍弃了配置文件的形式来为容器注入组件，我们都是使用配置类的形式，每个项目在建立的时候都有一个主配置类，使用SpringBootApplication这个注解来标注的，我们也可以定义自己的配置类，只要使用@Configuration这个注解标注即表示当前类是一个配置类。 2、我们在新建一个包config专门存放配置类，在其中可以建立多个配置类，如下： 123456789101112131415@Configuration //指定这是一个配置类public class MainConfig &#123; /** * @Bean: 这个注解将其注入到IOC容器中 * 其中的返回类型Person就相当于class，方法名就是返回的id，在IOC容器中我们可以使用这个id获取自动 * 配置的实例 */ @Bean Person person()&#123; Person person=new Person(); person.setAge(22); person.setName("chen"); return person; &#125;&#125; 配置文件占位符1、可以使用随机数，如下： 1234## 使用随机的uuid为其复制person.name=$&#123;random.uuid&#125;## 配置一个随机的intperson.age=$&#123;random.int&#125; 2、可以使用占位符获取之前配置的值，如果没有可以使用:指定默认值 1234## 配置一个随机的intperson.age=$&#123;random.int&#125;# 使用占位符获取之前配置的值，如果这个值不存在，那么使用指定的默认值person.user.age=$&#123;person.age:33&#125; 多环境开发1、我们在开发的时候可能会面对多环境，比如生产环境，测试环境，上线运行环境，针对这几种不同的环境，我们可能需要的配置也是不相同的，此时我们就需要在不同的环境之间切换不同的配置文件。 properties1、我们可以在创建不同的properties文件，文件名如：application-{profile}.properties，比如，application-dev.properties和application-prod.properties这两个文件，此时我们可以springBoot的朱主配置文件中application.properties文件中添加如下的语句，用来激活某一种的配置文件： 12# 激活dev配置文件，那么此时springBoot就会以application-dev.properties文件为配置文件spring.profiles.active=dev yaml1、在yaml中不需要建立多个文件，因为yaml可以使用---区分不同的文档，只要在一个主配置文件application.yml中添加不同区域的文档，即使表示不同的文件，如下： 1234567891011121314151617181920212223## 文档块1，此时激活devserver: port: 8081spring: profiles: active: dev---## dev环境的配置server: port: 8080spring: profiles: dev---## prod环境的配置server: port: 8088spring: profiles: prod 配置文件加载位置1、springBoot项目创建的时候在classpath路径下的有一个application.properties文件，这个就是springBoot默认的文件位置，但是我们还可以在其他的位置指定配置文件，依然会生效。 2、springBoot有以下的位置可以放置配置文件，按照优先级由高到低如下： ​ 1、项目路径下的config文件夹中 ​ 2、直接放在项目路径下 ​ 3、classpath路径下的config文件夹中 ​ 4、直接放在classpath路径下【创建项目的时候默认位置】 3、classpth即是resource文件夹下 4、注意：无论放在哪个位置，默认加载的文件名称必须是application.properties 5、如果高优先级和低优先级共有的配置，那么高优先级会覆盖低优先级的配置，但是高优先级配置文件中的没有的配置，如果在低优先级的配置文件中存在，那么依然会生效，这样就可以形成互补的形式 6、可以在默认的配置文件application.properties文件中使用spring.config.location来指定外部的配置文件，如下： 1spring.config.location=/usr/local/application.properties 7、在项目已经发布出去之后，我们也可以使用命令行的方式指定配置文件的位置，如：java -jar springboot.jar --spring.config.location=/usr/local/application.properties 日志框架1、spring默认的规定的日志框架是self4j和logback，这是目前的主流的日志框架，如果想要使用self4j和log4j，那么需要使用指定的适配类进行接口的转换。转换关系如下图： 2、默认什么都不配置的情况下，日志是开启的，使用的是self4j+logback，日志的级别是info 3、我们可以在全局配置文件appliction.properties或者application.yml中修改默认的配置，比如修改默认的日志级别，控制台输出格式，输出的日志文件的位置 4、日志的输出级别由高到低的级别如下：ERROR, WARN, INFO, DEBUG, or TRACE. 5、在springBoot中支持自定义的日志配置如下： 123456789101112131415161718192021222324# 指定com.telles包下的所有类下的日志输出级别为debug,可以指定某个类或者某个包下的类所使用的日志级别logging.level.com.telles=error# 如果指定的相对路径，那么就是在当前项目下，如果指定的了绝对路径，比如c:\\log\\spring.log，那么就是在指定的位置上生成log输出的文件logging.file=log/spring.log# 也是指定的日志的文件的位置，不过是在当前项目的所在根目录下指定的文件的位置，比如/log/spring.log，这个就是在该项目的根目录中的log文件夹下指定的日志文件是spring.loglogging.path=/log/spring.log# 指定控制台输出的格式，但是也是有默认的格式，这个和log4j的配置是一样的logging.pattern.console=# 指定日志文件的输出格式logging.pattern.file=# 指定文件最大大小logging.file.max-size=# 指定日期的格式logging.pattern.dateformat=## 文件最大保存历史量logging.file.max-history= 6、当然也可以使用自定义的配置文件，但是命名有一定的规范，否则springBoot并不能自动识别，比如如果使用logback日志框架的话，那么自定义的配置文件的名称必须是logback-xxx.xml,放在resource文件夹下,否则将不能识别，基本的配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false"&gt; &lt;!--定义日志文件的存储地址 一般存储在服务器的文件夹中--&gt; &lt;property name="LOG_HOME" value="/tmp/logs" /&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出--&gt; &lt;pattern&gt;[%p]-[%c] - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名,使用日期进行拼接--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/web.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 &lt;logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE" /&gt; &lt;logger name="org.hibernate.type.descriptor.sql.BasicExtractor" level="DEBUG" /&gt; &lt;logger name="org.hibernate.SQL" level="DEBUG" /&gt; &lt;logger name="org.hibernate.engine.QueryParameters" level="DEBUG" /&gt; &lt;logger name="org.hibernate.engine.query.HQLQueryPlan" level="DEBUG" /&gt;--&gt; &lt;!--myibatis log configure--&gt; &lt;logger name="com.apache.ibatis" level="DEBUG"/&gt; &lt;logger name="java.sql.Connection" level="DEBUG"/&gt; &lt;logger name="java.sql.Statement" level="DEBUG"/&gt; &lt;logger name="java.sql.PreparedStatement" level="DEBUG"/&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="FILE" /&gt; &lt;/root&gt; &lt;!--日志异步到数据库 --&gt; &lt;!--&lt;appender name="DB" class="ch.qos.logback.classic.db.DBAppender"&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;日志异步到数据库 &amp;ndash;&amp;gt;--&gt; &lt;!--&lt;connectionSource class="ch.qos.logback.core.db.DriverManagerConnectionSource"&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;连接池 &amp;ndash;&amp;gt;--&gt; &lt;!--&lt;dataSource class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;--&gt; &lt;!--&lt;driverClass&gt;com.mysql.jdbc.Driver&lt;/driverClass&gt;--&gt; &lt;!--&lt;url&gt;jdbc:mysql://127.0.0.1:3306/databaseName&lt;/url&gt;--&gt; &lt;!--&lt;user&gt;root&lt;/user&gt;--&gt; &lt;!--&lt;password&gt;root&lt;/password&gt;--&gt; &lt;!--&lt;/dataSource&gt;--&gt; &lt;!--&lt;/connectionSource&gt;--&gt; &lt;!--&lt;/appender&gt;--&gt;&lt;/configuration&gt; 自定义日志文件1、springboot启动的时候会自动加载日志的配置文件，默认使用的是self4j+logback，虽然springBoot为我们自动配置了默认的配置，但是我们还是需要自己定义配置文件，我们可以创建一个配置文件放置在resuorce文件夹下面，但是命名规则确实有一些区别，如下： Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml, or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties 2、总结的说就是，如果使用logback的日志，那么可以指定一个logback.xml放置在resource文件夹下，那么springBoot将会默认加载这个配置，直接覆盖默认的配置。如果使用log4j这个日志框架，那么可以直接创建一个log4j.properties放置在resrouce文件夹下。如果使用log4j2这个日志，我们可以使用log4j2.xml这个日志文件放置在resoruce文件夹下。 日志框架的切换1、上面的日志文件都是一个配置文件针对多个环境，但是如果我们想要使用profile的功能，比如开发环境使用一个日志配置文件，运行环境使用另外一个配置文件，那么此时就需要使用日志框架的profile功能，此时的命名规则就必须是logback-{profile}.xml，比如使用logback框架的时候，那么我们可以配置logback-dev.xml作用与开发环境，使用logback-spring.xml用于运行环境。 2、虽然懂得了命名规则，那么需要在日志的配置文件中指定切换语句，如下： 1234567891011&lt;springProfile name="staging"&gt; &lt;!-- configuration to be enabled when the "staging" profile is active --&gt;&lt;/springProfile&gt;&lt;springProfile name="dev | staging"&gt; &lt;!-- configuration to be enabled when the "dev" or "staging" profiles are active --&gt;&lt;/springProfile&gt;&lt;springProfile name="!production"&gt; &lt;!-- configuration to be enabled when the "production" profile is not active --&gt;&lt;/springProfile&gt; 程序中使用日志1234import org.slf4j.Logger;import org.slf4j.LoggerFactory;private final Logger logger= LoggerFactory.getLogger(this.getClass()); SpringMVC的开发1、如果想要开发springmvc模块，只需要选中web模块即可，默认的springBoot会自动为我们创建一些自动配置，不用自己一步一步的搭建springMVC框架。但是如果我们需要自己全面接管或者在原有的基础上进行一些扩展的话，SpringBoot都提供了一些支持。 创建一个web模块1、创建项目，导入启动器，如下： 1234567891011121314151617181920212223242526 &lt;!--导入web模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!--springBoot的测试模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--导入这个处理器，在配置文件中将会自动提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--热启动，保证每次修改，程序都会自动更新--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 引入静态资源webjars的引入1、springMVC引入自动配置资源都是在org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration这个类中进行配置，因此静态资源位置的映射也是在这个类中完成的，如下，即是配置静态资源映射的方法 12345678910111213141516171819202122232425262728@Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); return; &#125; Duration cachePeriod = this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache() .getCachecontrol().toHttpCacheControl(); //请求/webjars/** if (!registry.hasMappingForPattern("/webjars/**")) &#123; customizeResourceHandlerRegistration(registry .addResourceHandler("/webjars/**") .addResourceLocations("classpath:/META-INF/resources/webjars/") .setCachePeriod(getSeconds(cachePeriod)) .setCacheControl(cacheControl)); &#125; //添加 /**资源映射 String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations( this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)) .setCacheControl(cacheControl)); &#125; &#125; 2、通过上面的代码可以知道任何/webjars/**这种请求的方式都会在classpath:/META-INF/resources/webjars/这个位置查找相关的静态资源 3、webjars：是一种以jar包的方式引入静态资源，比如引用jQuery、Bootstrap的文件，那么我们只需要引入对应的jar包即可访问这些静态资源，官方网址：https://www.webjars.org/ 4、比如我们现在引入jquery的jar，如下： 123456&lt;!--引入jquery的jar--&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1-1&lt;/version&gt; &lt;/dependency&gt; 5、此时我们看到导入webjas的目录结构，如下，自动配置的资源映射就是对应webjars下的资源位置， ​ 1)、此时如果想要获取jquery.js这个文件，那么可以通过http://localhost:8080/webjars/jquery/3.3.1-1/jquery.js这个url查询到指定的文件，这个就是相对于上面springBoot自动配置的webjars的映射位置 其他静态资源的引入1、除了映入webjars这个静态资源，我们还有自定义的css和js文件，那么我们也必须有一个位置放置这些资源，让springBoot能够访问到 2、/**是用来访问当前项目的任何资源，主要的就是静态文件夹，默认映射的位置如下： ​ 1）、classpath ： 指定的是java和resources文件夹 ​ 2）、这写文件夹都是存放静态资源的，那么肯定会发生冲突，比如多个文件夹存放的静态资源名称是一样的，那么我们该如何查找呢？ ​ 3）、这些文件夹是否顺序访问的，即是按照如下的优先级进行访问的，如果上一级找到了，那么将会返回，下面的文件夹将不会查找 1234&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;,&quot;classpath:/public/&quot; 3、我们可以在classpath路径下创建上面的四个文件夹用来存放静态资源文件夹，这样我们就可以访问到这些资源了。如下： 4、此时我将slider.css这个静态资源文件放置到static中，那么我们可以通过请求http://localhost:8080/slider.css，将可以访问到这个资源，主要就是去上面的四个文件夹下查找文件，如果有这个文件，那么就返回即可。 配置首页1、在springBoot中，首页也为我们自动配置了存放的位置 2、我们只需把首页index.html放置在静态资源文件夹下即可访问，比如我们放一个index.html在static文件夹下，直接访问http://localhost:8080/这个即可自动跳转首页 配置小图标１、我们可以放置一个favicon.ico图片在静态资源文件夹下，那么即可自动为我们的页面配置上小图标 自定义静态资源存放位置1、我们在全局配置文件中指定自己配置的资源存放位置，如下： 1spring.resources.static-locations=classpath:/myStatic 2、一旦配置这个路径，那么上面springBoot自动配置的路径将会失效 模板引擎1、sprintBoot不支持jsp，但是支持thymeleaf模板引擎，我们可以导入这个模板引擎 12345&lt;!--引入themleaf模板引擎--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; 2、我们不需要指定版本号，在springBoot中已经为我们指定了默认的版本号，如下： 12345&lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;thymeleaf-extras-data-attribute.version&gt;2.0.1&lt;/thymeleaf-extras-data-attribute.version&gt; &lt;thymeleaf-extras-java8time.version&gt;3.0.1.RELEASE&lt;/thymeleaf-extras-java8time.version&gt; &lt;thymeleaf-extras-springsecurity4.version&gt;3.0.2.RELEASE&lt;/thymeleaf-extras-springsecurity4.version&gt; &lt;thymeleaf-layout-dialect.version&gt;2.3.0&lt;/thymeleaf-layout-dialect.version&gt; 使用thymelefa1、我们只需要将所有的html文件放在teamplate下，那么thymeleaf将会自动解析其中的文件 2、引入下面的约束将会自动提示语法： 1&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; 语法1、th： 这个是使用th任意属性来替换原生属性，比如替换id使用th:id,class使用th:class 2、&lt;h1 th:text=&quot;${hello}&quot;&gt;成功访问&lt;/h1&gt; ：替换标签体内的文本 3、表达式： 123456789101112131415161718192021222324252627282930Simple expressions: Variable Expressions: $&#123;...&#125; Selection Variable Expressions: *&#123;...&#125; Message Expressions: #&#123;...&#125; Link URL Expressions: @&#123;...&#125; Fragment Expressions: ~&#123;...&#125; LiteralsText literals: &apos;one text&apos; , &apos;Another one!&apos; ,...Number literals: 0 , 34 , 3.0 , 12.3 ,...Boolean literals: true , falseNull literal: nullLiteral tokens: one , sometext , main ,...Text operations:String concatenation: +Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:Binary operators: + , - , * , / , %Minus sign (unary operator): -Boolean operations:Binary operators: and , orBoolean negation (unary operator): ! , notComparisons and equality:Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le )Equality operators: == , != ( eq , ne )Conditional operators:If-then: (if) ? (then)If-then-else: (if) ? (then) : (else)Default: (value) ?: (defaultvalue)Special tokens:Page 17 of 106No-Operation: _ springMVC的扩展1、在springBoot中依赖mvc的自动配置肯定是不够的，比如我们需要添加一个拦截器，那么肯定是需要自己配置的，此时我们就需要定义自己的配置类进行扩展功能。 2、扩展的意思是几保留了mvc的自动配置，也使用了一些自定义的功能。 3、自动扩展的实现： ​ 1）、定义一个配置类，使用@Configuration ​ 2）、继承WebMvcConfigurationSupport，这个类是一个抽象类，其中有实现springmvc的不同组件，如果需要那个组件，只需要实现其中的方法即可 ​ 3）、在这个类中实现其中的方法即可。 4、比如我们需要实现一个拦截器，那么我们需要创建一个拦截器类，如下： 1234567public class MyInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("使用拦截器"); return true; &#125;&#125; 5、我们需要在配置类中配置这个拦截器，如下： 123456789101112131415@Configuration //springBoot的自动配置类public class MyConfig extends WebMvcConfigurerAdapter &#123; //添加一个映射视图的组件，每次请求helloWorld都会映射到index.html @Override protected void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/helloWorld").setViewName("index"); &#125; //添加一个拦截器 @Override protected void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new MyInterceptor()).addPathPatterns("/**").excludePathPatterns("/helloWorld"); &#125;&#125; 全面接管SpringMVC1、全面接管的意思就是不需要springBoot的自动配置，而是全部使用自定义的配置 2、要实现全面接管springMVC，那么只需要在上面的配置上添加一个@EnableWebMvc，如下： 12345@Configuration //springBoot的自动配置类@EnableWebMvc //全面接管springMVCpublic class MyConfig extends WebMvcConfigurationSupport &#123; &#125; 指定日期格式1、springBoot默认的可以转换的日期格式：yyyy/MM/dd，那么我们可以在配置文件中改变这种配置格式，如下： 12## 指定日期格式spring.mvc.date-format=yyyy-MM-dd 2、一旦转换了这种日期的格式，那么当用户输入的日期格式为上面的那种才会自动转换成Date类型的数据，否则将会转换失败，出现异常 定制错误页面修改Tomcat的默认配置1、在springBoot默认使用的是嵌入式的tomcat容器，我们可以在全局配置文件中修改默认的tomcat的配置。 2、如何修改tomcat 的默认配置？ ​ 1）、在全局的配置文件application.properties中修改配置即可，如下： ​ 1）、这些配置全部都是对应着org.springframework.boot.autoconfigure.web.ServerProperties这个类，Tomcat的配置对应着org.springframework.boot.autoconfigure.web.ServerProperties.Tomcat 1234567## 指定编码格式## 如果需要修改tomcat的默认配置，我们需要修改server.tomcat.xxxserver.tomcat.uri-encoding=utf-8## 指定端口号## 如果需要修改server的默配置，我们需要修改server.xxxxserver.port=8080 注册Servlet、Filter、Listener1、在springBoot中如果需要用到Servlet、过滤器和监听器，那么就需要自己配置 2、配置三大组件对应的类为：ServletRegistrationBean、FilterRegistrationBean、ServletListenerRegistrationBean。我们只需要在自定义的配置类中将三个组件注册到容器中即可 3、完成注册三大组件 ​ 1）、创建自己的三大组件 ​ 2）、创建一个配置类，在其中创建注入三大组件即可，如下： 12345678910111213141516171819202122232425262728@Configuration //指定这是一个配置类public class MyWebConfig &#123; //注册自己的Servlet,在其中可以设置在配置文件中能够设置的值 @Bean //将这个组件添加到容器中 public ServletRegistrationBean registrationBean()&#123; //构造方法，第一个参数指定的是自己的Servlet，第二个参数指定的是映射的路径，是一个可变参数，可以指定多个参数 ServletRegistrationBean bean=new ServletRegistrationBean(new MyServlet(),"/hello","/myFine"); bean.setLoadOnStartup(1); return bean; &#125; //注册过滤器 @Bean public FilterRegistrationBean filterRegistrationBean()&#123; FilterRegistrationBean bean=new FilterRegistrationBean(); bean.setFilter(new MyFilter()); //设置自己的Filter bean.setUrlPatterns(Arrays.asList("/**")); //设置拦截的路径 return bean; &#125; //注册监听器 @Bean public ServletListenerRegistrationBean servletListenerRegistrationBean()&#123; ServletListenerRegistrationBean servletListenerRegistrationBean=new ServletListenerRegistrationBean&lt;MyListener&gt;(new MyListener()); return servletListenerRegistrationBean; &#125;&#125; 整合数据源1、需要导入mysql的驱动程序 2、导入的依赖如下： 123456789101112&lt;!--导入原生的jdbc启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--导入mysql的驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 3、我们可以在springBoot的配置文件中设置默认的mysql参数，如下： 123456789## 配置Jdbcspring: datasource: username: root password: root url: jdbc:mysql://localhost:3306/jdbc driver-class-name: com.mysql.jdbc.Driver ## type用来指定使用什么数据连接池 #type: 4、springBoot中默认支持的连接池都在org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration中展示出来，如下： ​ 1）、org.apache.tomcat.jdbc.pool.DataSource ​ 2）、com.zaxxer.hikari.HikariDataSource ​ 3）、org.apache.commons.dbcp2.BasicDataSource 5、当然我们也是可以自定义自己的数据源，我们只需要在配置文件中使用spring-datasource.type这个配置即可 整合Druid数据源0、https://www.cnblogs.com/niejunlei/p/5977895.html 1、导入依赖 123456&lt;!-- 添加数据库连接池 druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; 2、在全局配置文件中设置使用指定的数据源 1234567# 数据库访问配置# 主数据源，默认的spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/jdbcspring.datasource.username=rootspring.datasource.password=root 3、配置数据源参数，下面只是设置了部分的参数，在全局配置文件中设置： 1234567891011121314151617181920# 下面为连接池的补充设置，应用到上面所有数据源中# 初始化大小，最小，最大spring.datasource.initialSize=5spring.datasource.minIdle=5spring.datasource.maxActive=20# 配置获取连接等待超时的时间spring.datasource.maxWait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.timeBetweenEvictionRunsMillis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.minEvictableIdleTimeMillis=300000spring.datasource.validationQuery=SELECT 1 FROM DUALspring.datasource.testWhileIdle=truespring.datasource.testOnBorrow=falsespring.datasource.testOnReturn=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.datasource.poolPreparedStatements=truespring.datasource.maxPoolPreparedStatementPerConnectionSize=20# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 4、自定义一个DruidConfig，主要用来配置Druid，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration //指定Druid的数据源的配置类public class DruidConfig &#123; //配置druid的参数，并且将其注入到容器中 @ConfigurationProperties(prefix = "spring.datasource") @Bean public DruidDataSource druid()&#123; return new DruidDataSource(); &#125; /** * 配置监控 * 1、配置一个管理后台的Servlet * 2、配置一个监控的filter */ @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean=new ServletRegistrationBean(new StatViewServlet(),"/druid/*"); //设置初始化参数 Map&lt;String,Object&gt; initParams=new HashMap&lt;&gt;(); initParams.put("loginUsername","admin"); //设置登录的用户名 initParams.put("loginPassword","admin"); //设置登录的密码 initParams.put("resetEnable","false");// initParams.put("allow","localhost"); //允许localhost访问，默认是所有都能访问// initParams.put("deny","IP地址"); //设置拒绝访问的ip bean.setInitParameters(initParams); return bean; &#125; //配置监控的Filter @Bean public FilterRegistrationBean filterRegistrationBean()&#123; FilterRegistrationBean bean=new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,Object&gt; initParams=new HashMap&lt;&gt;(); initParams.put("exclusions","*.css,*.js,/druid/*"); //设置不拦截器的路径 bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList("/**")); return bean; &#125;&#125; 整合Mybatis1、添加mybatis的启动器，如下： 123456&lt;!--导入mybatis的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; 2、只需要引入这个启动器，那么springBoot就会自动导入如下的mybatis 123&lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;mybatis-spring.version&gt;1.3.1&lt;/mybatis-spring.version&gt; &lt;spring-boot.version&gt;1.5.6.RELEASE&lt;/spring-boot.version&gt; 注解版1、我们可以使用注解版本的mybatis，只需要创建一个Mapper即可。如下： 12345678910@Mapper //表明这个是mapper接口，会自动扫描public interface UserMapper &#123; @Select("select * from t_user where user_id=#&#123;userId&#125;") User selectUser(Integer userId); //插入，自增主键返回 @Options(useGeneratedKeys = true,keyProperty = "userId") @Insert("insert into t_user(name) values(#&#123;name&#125;)") int insertUser(User user);&#125; 2、使用注解版，如果需要配置mybaits的一些参数，比如驼峰命名法等配置，那么我们可以自定义一个配置类，如下： 12345678910111213141516171819202122import org.mybatis.spring.boot.autoconfigure.ConfigurationCustomizer;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Mybatis的配置类 */@Configurationpublic class MybatisConfig &#123; //自定义一个定制器，在其中可以针对mybatis配置不同的参数，就相当于一个mybatis的主配置文件 @Bean //注入到容器中 public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer() &#123; @Override public void customize(org.apache.ibatis.session.Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); //开启驼峰命名法 //在其中还可以配置myabtis的其他配置 &#125; &#125;; &#125;&#125; 3、除了自己配置自定义的配置类来指定mybatis的参数配置，我们还可以在全局配置文件中使用mybatis.来进行相关的配置，比如开启驼峰命名，如下： 1mybatis.configuration.map-underscore-to-camel-case=true 4、我们可以使用注解批量扫描mapper，这样我们就不需要在每一个Mapper接口都添加@Mapper这个注解，我们只需要在主配置类中添加@MapperScan这个注解即可，如下： 1234//批量扫描com.tellwess.springbootserver.mappers这个包下面的所有mapper@MapperScan(value ="com.tellwess.springbootserver.mappers")@SpringBootApplicationpublic class SpringbootServerApplication &#123; 配置文件1、我们将所有的mapper对应的配置文件放在classpath:mapper/*.xml下面的，其中的UserMapper.xml配置文件如下： 12345678910111213&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.tellwess.springbootserver.mappers.UserMapper" &gt; &lt;select id="selectUser" resultType="com.tellwess.springbootserver.entities.User"&gt; select * from t_user where user_id=#&#123;userId&#125; &lt;/select&gt; &lt;insert id="insertUser"&gt; insert into t_user(name) values(#&#123;name&#125;) &lt;/insert&gt;&lt;/mapper&gt; 2、创建一个UserMapper.java，如下： 1234567public interface UserMapper &#123; User selectUser(Integer userId); int insertUser(User user);&#125; 3、在主配置类下创建添加批量扫描注解，将接口注入到容器中，如下： 1234//批量扫描com.tellwess.springbootserver.mappers这个包下面的所有mapper@MapperScan(value ="com.tellwess.springbootserver.mappers")@SpringBootApplicationpublic class SpringbootServerApplication &#123; 4、在全局配置文件中设置*.xml配置文件的位置，让springBoot能够扫描到，如下： 12345## 配置mybatis的全局配置文件mybatis.mapper-locations=classpath:mapper/*.xml# 开启驼峰命名mybatis.configuration.map-underscore-to-camel-case=true# 在其中还可以配置mybatis其他的配置 springBoot对事务的支持1、在spring中我们如果需要添加事务，可能需要配置切面或者声明式注解，但是在springBoot中我们只需要直接使用即可，一切都为我们自动配置了。 2、要想使用声明式事务注解，那么需要导入spring.tx这个jar，其实这个jar在我们导入spring-boot-starter-jdbc的时候就已经为我们导入了，但是如果我们要是使用mybatis的话，那么只需要导入mybatis的场景启动器即可，因为其中就已经包含了jdbc的场景启动器，因此我们只需要导入mybatis的场景启动器即可，如下： 123456&lt;!--导入mybatis的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; 3、在需要添加事务的类上添加一个注解即可@Transactional，如下： 123@Transactional@Servicepublic class UserServiceImpl implements UserService &#123;&#125; 自动热部署 每次修改代码后都需要重新启动程序，但是我们可以使用热部署功能，只需要导入依赖即可。修改代码完成后按住Ctrl+F9即可自动热部署 123456&lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; SpringBoot对跨域的支持 https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#boot-features-cors 只需要在容器中注入org.springframework.web.servlet.config.annotation.WebMvcConfigurer这个实例即可，如下： 12345678910111213//添加跨域的功能 @Bean public WebMvcConfigurer corsConfigurer() &#123; return new WebMvcConfigurer() &#123; public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping("/**")// .allowedOrigins("http://192.168.1.97")// .allowedMethods("GET", "POST")// .allowCredentials(false).maxAge(3600); ; //对所有的路径都支持跨域的访问 &#125; &#125;; &#125; 以上是针对全局配置的跨域，如果需要对某一个controller中的请求使用跨域，可以使用@CrossOrigin(origins = &quot;http://192.168.1.97:8080&quot;, maxAge = 3600)这个注解标注在controller的类上，如下： 123@CrossOrigin(origins = "http://192.168.1.97:8080", maxAge = 3600)@RestControllerpublic class IndexController&#123;&#125; 上传文件大小的配置 配置文件的方式： 12345#multipart upload 文件上传#限制一次上传的单个文件的大小spring.http.multipart.maxFileSize=10Mb#限制一次上传的所有文件的总大小spring.http.multipart.maxRequestSize=10Mb 总结1、整合mybaits和数据源配置的所有依赖如下： 1234567891011121314151617181920&lt;!--导入mysql的驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 添加数据库连接池 druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;!--导入mybatis的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; springBoot配置文件能够配置的全部配置 https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#appendix 官方文档1、https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[StringUtils的源码解析]]></title>
      <url>%2F2018%2F08%2F04%2FStringUtils%E7%9A%84%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[StringUtils spring封装的字符串工具类 源码解析 isEmpty(Object str) ：判断当前字符串为空，如果为空返回true 如果字符串为空或者是个空字符串，那么返回true 123public static boolean isEmpty(Object str) &#123; return (str == null || "".equals(str)); &#125; hasLength(CharSequence str) ： 如果字符串的长度大于0，返回true 123public static boolean hasLength(CharSequence str) &#123; return (str != null &amp;&amp; str.length() &gt; 0); &#125; hasText(String str) ： 判断字符串str是否存在文本内容(不包含空字符) 1234567891011121314151617181920212223/** * StringUtils.hasText(null) = false * StringUtils.hasText("") = false * StringUtils.hasText(" ") = false * StringUtils.hasText("12345") = true * StringUtils.hasText(" 12345 ") = true*/public static boolean hasText(String str) &#123; //不为空并且包含指定的str返回true return (hasLength(str) &amp;&amp; containsText(str)); &#125;//判断当前字符串str是否存在文本内容private static boolean containsText(CharSequence str) &#123; int strLen = str.length(); //长度 for (int i = 0; i &lt; strLen; i++) &#123; //如果不是空白字符，说明其中有文本内容，返回true即可 if (!Character.isWhitespace(str.charAt(i))) &#123; return true; &#125; &#125; return false; &#125; public static boolean containsWhitespace(String str) ： 判断当前字符串str是否包含空白字符 123456789101112131415public static boolean containsWhitespace(String str) &#123; //如果长度为0直接返回false if (!hasLength(str)) &#123; return false; &#125; int strLen = str.length(); for (int i = 0; i &lt; strLen; i++) &#123; //遍历字符串，查看是否存在空白字符，存在即返回true if (Character.isWhitespace(str.charAt(i))) &#123; return true; &#125; &#125; return false; &#125; public static String trimWhitespace(String str) ： 去除字符串str中的空白字符 12345678910111213141516public static String trimWhitespace(String str) &#123; if (!hasLength(str)) &#123; return str; &#125; StringBuilder sb = new StringBuilder(str); //去除字符串前面的空白字符 while (sb.length() &gt; 0 &amp;&amp; Character.isWhitespace(sb.charAt(0))) &#123; sb.deleteCharAt(0); &#125; //去除字符串末尾的空白字符 while (sb.length() &gt; 0 &amp;&amp; Character.isWhitespace(sb.charAt(sb.length() - 1))) &#123; sb.deleteCharAt(sb.length() - 1); &#125; return sb.toString(); &#125; public static String trimAllWhitespace(String str) ：去除字符串中所有的空白字符 1234567891011121314151617public static String trimAllWhitespace(String str) &#123; if (!hasLength(str)) &#123; return str; &#125; int len = str.length(); //使用stringBuilder存储非空白字符 StringBuilder sb = new StringBuilder(str.length()); //遍历字符串，如果不是空白字符，那么直接添加到sb中 for (int i = 0; i &lt; len; i++) &#123; char c = str.charAt(i); if (!Character.isWhitespace(c)) &#123; sb.append(c); &#125; &#125; return sb.toString(); &#125; public static String trimLeadingWhitespace(String str) ：去除字符串前面的空白字符 123456789101112public static String trimLeadingWhitespace(String str) &#123; if (!hasLength(str)) &#123; return str; &#125; StringBuilder sb = new StringBuilder(str); //只是去除前面的空白字符 while (sb.length() &gt; 0 &amp;&amp; Character.isWhitespace(sb.charAt(0))) &#123; sb.deleteCharAt(0); &#125; return sb.toString(); &#125; public static String trimTrailingWhitespace(String str) ：去除末尾的空白字符 123456789101112public static String trimTrailingWhitespace(String str) &#123; if (!hasLength(str)) &#123; return str; &#125; StringBuilder sb = new StringBuilder(str); //去除末尾的 while (sb.length() &gt; 0 &amp;&amp; Character.isWhitespace(sb.charAt(sb.length() - 1))) &#123; sb.deleteCharAt(sb.length() - 1); &#125; return sb.toString(); &#125; public static String trimLeadingCharacter(String str, char leadingCharacter) ：去除字符串str前面的指定字符leadingCharacter 1234567891011public static String trimLeadingCharacter(String str, char leadingCharacter) &#123; if (!hasLength(str)) &#123; return str; &#125; StringBuilder sb = new StringBuilder(str); while (sb.length() &gt; 0 &amp;&amp; sb.charAt(0) == leadingCharacter) &#123; sb.deleteCharAt(0); &#125; return sb.toString(); &#125; public static String trimTrailingCharacter(String str, char trailingCharacter) ：去除字符串尾部的指定字符 trailingCharacter 1234567891011public static String trimTrailingCharacter(String str, char trailingCharacter) &#123; if (!hasLength(str)) &#123; return str; &#125; StringBuilder sb = new StringBuilder(str); while (sb.length() &gt; 0 &amp;&amp; sb.charAt(sb.length() - 1) == trailingCharacter) &#123; sb.deleteCharAt(sb.length() - 1); &#125; return sb.toString(); &#125; public static boolean startsWithIgnoreCase(String str, String prefix) ： 测试字符串str是否是以prefix开头的，忽略大小写 1234public static boolean startsWithIgnoreCase(String str, String prefix) &#123; return (str != null &amp;&amp; prefix != null &amp;&amp; str.length() &gt;= prefix.length() &amp;&amp; str.regionMatches(true, 0, prefix, 0, prefix.length())); &#125; public static boolean endsWithIgnoreCase(String str, String suffix)：测试字符串str是否是以suffix结尾的，忽略大小写 1234public static boolean endsWithIgnoreCase(String str, String suffix) &#123; return (str != null &amp;&amp; suffix != null &amp;&amp; str.length() &gt;= suffix.length() &amp;&amp; str.regionMatches(true, str.length() - suffix.length(), suffix, 0, suffix.length()));&#125; public static boolean substringMatch(CharSequence str, int index, CharSequence substring) ： 判断字符串str从index开始到结尾，是否与给定的substring相同 12345678910111213public static boolean substringMatch(CharSequence str, int index, CharSequence substring) &#123; //如果开始的索引加上匹配的子串大小大于原本的字符串的大小，表明不匹配，返回false if (index + substring.length() &gt; str.length()) &#123; return false; &#125; //逐个字符比较，一旦遇到不同的，直接返回false即可 for (int i = 0; i &lt; substring.length(); i++) &#123; if (str.charAt(index + i) != substring.charAt(i)) &#123; return false; &#125; &#125; return true; &#125; public static int countOccurrencesOf(String str, String sub) ： 返回子串sub在str中出现的次数 123456789101112131415public static int countOccurrencesOf(String str, String sub) &#123; if (!hasLength(str) || !hasLength(sub)) &#123; return 0; &#125; int count = 0; //数量 int pos = 0; //索引，从0开始统计 int idx; // str.indexOf(sub, pos) : 返回子串sub在str中从pos索引开始的下标 while ((idx = str.indexOf(sub, pos)) != -1) &#123; ++count; pos = idx + sub.length(); &#125; return count; &#125; 123456789101112131415161718192021222324252627282930public static String replace(String inString, String oldPattern, String newPattern) &#123; if (!hasLength(inString) || !hasLength(oldPattern) || newPattern == null) &#123; return inString; &#125; //index int index = inString.indexOf(oldPattern); if (index == -1) &#123; // no occurrence -&gt; can return input as-is return inString; &#125; int capacity = inString.length(); if (newPattern.length() &gt; oldPattern.length()) &#123; capacity += 16; &#125; StringBuilder sb = new StringBuilder(capacity); int pos = 0; // our position in the old string int patLen = oldPattern.length(); while (index &gt;= 0) &#123; sb.append(inString.substring(pos, index)); sb.append(newPattern); pos = index + patLen; index = inString.indexOf(oldPattern, pos); &#125; // append any characters to the right of a match sb.append(inString.substring(pos)); return sb.toString(); &#125; public static String replace(String inString, String oldPattern, String newPattern) ：将字符串inString中的oldPattern全部替换成newPattern 1234567891011121314151617181920public static String replace(String inString, String oldPattern, String newPattern) &#123; if (!hasLength(inString) || !hasLength(oldPattern) || newPattern == null) &#123; return inString; &#125; StringBuilder sb = new StringBuilder(); int pos = 0; // our position in the old string int index = inString.indexOf(oldPattern); //获取oldpattern在instring中的开始索引 // the index of an occurrence we've found, or -1 int patLen = oldPattern.length(); //遍历字符串，替换 while (index &gt;= 0) &#123; sb.append(inString.substring(pos, index)); sb.append(newPattern); pos = index + patLen; index = inString.indexOf(oldPattern, pos); &#125; sb.append(inString.substring(pos)); // remember to append any characters to the right of a match return sb.toString(); &#125; public static String delete(String inString, String pattern) ： 删除字符串inString中指定的pattern内容 1234public static String delete(String inString, String pattern) &#123; //使用空字符替换删除的pattern return replace(inString, pattern, ""); &#125; public static String deleteAny(String inString, String charsToDelete) ：删除字符串inString中指定的charsToDelete所有字符 123456789101112131415public static String deleteAny(String inString, String charsToDelete) &#123; if (!hasLength(inString) || !hasLength(charsToDelete)) &#123; return inString; &#125; StringBuilder sb = new StringBuilder(); //遍历字符串 for (int i = 0; i &lt; inString.length(); i++) &#123; char c = inString.charAt(i); //获取当前的字符 //如果当前的字符不在需要删除的charsToDelete中，那么添加到sb中 if (charsToDelete.indexOf(c) == -1) &#123; sb.append(c); &#125; &#125; return sb.toString(); &#125; public static String quote(String str) ：将字符串用单引号括起来 123public static String quote(String str) &#123; return (str != null ? "'" + str + "'" : null); &#125; public static String uncapitalize(String str) ：首字母小写 123456789101112131415161718public static String uncapitalize(String str) &#123; return changeFirstCharacterCase(str, false); &#125; private static String changeFirstCharacterCase(String str, boolean capitalize) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; StringBuilder sb = new StringBuilder(str.length()); if (capitalize) &#123; sb.append(Character.toUpperCase(str.charAt(0))); &#125; else &#123; sb.append(Character.toLowerCase(str.charAt(0))); &#125; sb.append(str.substring(1)); return sb.toString(); &#125; public static String capitalize(String str) ： 首字母大写 123public static String capitalize(String str) &#123; return changeFirstCharacterCase(str, true); &#125; public static String getFilename(String path) ： 取出给定的路径path中的文件名，比如/tmp/file.txt，那么取出的文件名为file.txt 1234567public static String getFilename(String path) &#123; if (path == null) &#123; return null; &#125; int separatorIndex = path.lastIndexOf(FOLDER_SEPARATOR); return (separatorIndex != -1 ? path.substring(separatorIndex + 1) : path); &#125; public static String getFilenameExtension(String path) ：获取给定路径的文件扩展名，比如/tmp/file.txt，那么返回的扩展名为txt 1234567891011121314public static String getFilenameExtension(String path) &#123; if (path == null) &#123; return null; &#125; int extIndex = path.lastIndexOf(EXTENSION_SEPARATOR); //获取最后一个.的索引 if (extIndex == -1) &#123; return null; &#125; int folderIndex = path.lastIndexOf(FOLDER_SEPARATOR); //获取最后一个/的索引 if (folderIndex &gt; extIndex) &#123; return null; &#125; return path.substring(extIndex + 1); &#125; public static String stripFilenameExtension(String path)：去掉给定路径的文件扩展名，比如：&quot;mypath/myfile.txt&quot; -&gt; &quot;mypath/myfile&quot;. 123456789101112131415161718192021/** * Strip the filename extension from the given path, * e.g. "mypath/myfile.txt" -&gt; "mypath/myfile". * @param path the file path (may be &#123;@code null&#125;) * @return the path with stripped filename extension, * or &#123;@code null&#125; if none */ public static String stripFilenameExtension(String path) &#123; if (path == null) &#123; return null; &#125; int extIndex = path.lastIndexOf(EXTENSION_SEPARATOR); if (extIndex == -1) &#123; return path; &#125; int folderIndex = path.lastIndexOf(FOLDER_SEPARATOR); if (folderIndex &gt; extIndex) &#123; return path; &#125; return path.substring(0, extIndex); &#125; public static String[] delimitedListToStringArray(String str, String delimiter) ：已指定的分隔符将字符串str分割成一个字符串数组，比如String[] strs=StringUtils.delimitedListToStringArray(&quot;chenjia,bing&quot;, &quot;,&quot;); 123public static String[] delimitedListToStringArray(String str, String delimiter) &#123; return delimitedListToStringArray(str, delimiter, null); &#125; public static String[] delimitedListToStringArray(String str, String delimiter, String charsToDelete) ： 不但使用分割符将字符串分割成数组，并且还去掉了字符串中的指定的字符，比如：String[] strs=StringUtils.delimitedListToStringArray(&quot;chenjia,bing&quot;, &quot;,&quot;,&quot;n&quot;); 1234567891011121314151617181920212223242526272829303132public static String[] delimitedListToStringArray(String str, String delimiter, String charsToDelete) &#123; if (str == null) &#123; return new String[0]; &#125; //没有分隔符直接返回原来字符串 if (delimiter == null) &#123; return new String[] &#123;str&#125;; &#125; List&lt;String&gt; result = new ArrayList&lt;String&gt;(); //如果分隔符为空，那么每一个字符都要分割 if ("".equals(delimiter)) &#123; for (int i = 0; i &lt; str.length(); i++) &#123; //删除指定的字符，并且添加到restult中 result.add(deleteAny(str.substring(i, i + 1), charsToDelete)); &#125; &#125; else &#123; //分割符不为空，并且不是空字符串 int pos = 0; int delPos; //定义需要进行删除的字符串的最后一个index //str.indexOf(delimiter, pos) : 从pos位置开始，获取分割符的索引，此时的 [pos,delpos]就是一个分割的字符串，那么我们需要对其删除指定的字符 while ((delPos = str.indexOf(delimiter, pos)) != -1) &#123; //删除一个子串中的指定字符，并且添加到result中 result.add(deleteAny(str.substring(pos, delPos), charsToDelete)); pos = delPos + delimiter.length(); //pos后移，移到下一个需要分割的字符串，也就是剩下的字符串 &#125; if (str.length() &gt; 0 &amp;&amp; pos &lt;= str.length()) &#123; // Add rest of String, but not in case of empty input. result.add(deleteAny(str.substring(pos), charsToDelete)); &#125; &#125; return toStringArray(result); //将List转换成字符串数组 &#125; public static String[] toStringArray(Collection&lt;String&gt; collection) ： 将指定的String类型的集合转换成String[] 1234567public static String[] toStringArray(Collection&lt;String&gt; collection) &#123; if (collection == null) &#123; return null; &#125; //调用Collection中的toArray(T[] a)方法,需要指定数组的容量 return collection.toArray(new String[collection.size()]); &#125; public static String[] sortStringArray(String[] array) ：对String[] 数组进行排序 12345678public static String[] sortStringArray(String[] array) &#123; //判断数组是否为空，这里的 org.springframework.util.ObjectUtils，也是一个工具类 if (ObjectUtils.isEmpty(array)) &#123; return new String[0]; &#125; Arrays.sort(array); //使用Arrays的排序，升序 return array; &#125; public static String[] trimArrayElements(String[] array) ： 将给定的字符串数组中的每一个字符串都去掉前后空格 123456789101112public static String[] trimArrayElements(String[] array) &#123; if (ObjectUtils.isEmpty(array)) &#123; return new String[0]; &#125; //创建一个新数组保存 String[] result = new String[array.length]; for (int i = 0; i &lt; array.length; i++) &#123; String element = array[i]; result[i] = (element != null ? element.trim() : null); &#125; return result; &#125; public static String[] removeDuplicateStrings(String[] array) ： 去掉字符串数组中重复的字符串 123456789101112public static String[] removeDuplicateStrings(String[] array) &#123; if (ObjectUtils.isEmpty(array)) &#123; return array; &#125; //使用集合set来去掉重复的元素 Set&lt;String&gt; set = new TreeSet&lt;String&gt;(); for (String element : array) &#123; set.add(element); &#125; //将集合转换成String[] return toStringArray(set); &#125; public static String[] split(String toSplit, String delimiter) ： 以分隔符分割字符串成两个数组，但是这个只是分割第一个分割符 123456789101112public static String[] split(String toSplit, String delimiter) &#123; if (!hasLength(toSplit) || !hasLength(delimiter)) &#123; return null; &#125; int offset = toSplit.indexOf(delimiter); if (offset &lt; 0) &#123; return null; &#125; String beforeDelimiter = toSplit.substring(0, offset); String afterDelimiter = toSplit.substring(offset + delimiter.length()); return new String[] &#123;beforeDelimiter, afterDelimiter&#125;; &#125; public static String arrayToDelimitedString(Object[] arr, String delim) ： 将数组中的每一元素以分割符组成对应的字符串 12345678910111213141516public static String arrayToDelimitedString(Object[] arr, String delim) &#123; if (ObjectUtils.isEmpty(arr)) &#123; return ""; &#125; if (arr.length == 1) &#123; return ObjectUtils.nullSafeToString(arr[0]); &#125; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; arr.length; i++) &#123; if (i &gt; 0) &#123; sb.append(delim); &#125; sb.append(arr[i]); &#125; return sb.toString(); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static String cleanPath(String path) &#123; if (path == null) &#123; return null; &#125; //将path中的\\全部替换成/ //如果这个路径是在windows下，如 c:\\image\\file.jpg,那么经过replace，将会变成 c://image//file.jpg String pathToUse = replace(path, WINDOWS_FOLDER_SEPARATOR, FOLDER_SEPARATOR); //获取pathToUse中:的索引 int prefixIndex = pathToUse.indexOf(":"); String prefix = ""; //前缀，比如 c: 或者 / //如果这个路径是在windows下，如 c:\\image\\file.jpg,那么经过replace，将会变成 c://image//file.jpg if (prefixIndex != -1) &#123; prefix = pathToUse.substring(0, prefixIndex + 1); //前缀变成 `c:` pathToUse = pathToUse.substring(prefixIndex + 1); //去掉前面的前缀 &#125; //如果pathToUse是以/开头，表示是linux下的路径 if (pathToUse.startsWith(FOLDER_SEPARATOR)) &#123; prefix = prefix + FOLDER_SEPARATOR; //前缀就是 / pathToUse = pathToUse.substring(1); //pathToUse就变成了去掉/之后的字符串 &#125; //将pathToUse使用/分割成一个字符串数组，比如pathToUse=home/chenjiabinbg/file.txt，那么数组为 ["home","chenjiabing","file.txt"] String[] pathArray = delimitedListToStringArray(pathToUse, FOLDER_SEPARATOR); List&lt;String&gt; pathElements = new LinkedList&lt;String&gt;(); int tops = 0; //遍历数组 for (int i = pathArray.length - 1; i &gt;= 0; i--) &#123; String element = pathArray[i]; //如果这个元素是表示当前路径的 .表示当前路径，..表示上一级路径 if (CURRENT_PATH.equals(element)) &#123; // Points to current directory - drop it. &#125; //如果是上一级路径，tops+1 else if (TOP_PATH.equals(element)) &#123; // Registering top path found. tops++; &#125; else &#123; if (tops &gt; 0) &#123; // Merging path element with element corresponding to top path. tops--; &#125; else &#123; // Normal path element found. pathElements.add(0, element); &#125; &#125; &#125; // Remaining top paths need to be retained. for (int i = 0; i &lt; tops; i++) &#123; pathElements.add(0, TOP_PATH); &#125; return prefix + collectionToDelimitedString(pathElements, FOLDER_SEPARATOR); &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring整合Log4j]]></title>
      <url>%2F2018%2F08%2F04%2Fspring%E6%95%B4%E5%90%88Log4j%2F</url>
      <content type="text"><![CDATA[spring使用Log4j常用日志框架介绍 转载自https://blog.csdn.net/liupeifeng3514/article/details/79624446 Log4j Apache Log4j是一个基于Java的日志记录工具。它是由Ceki Gülcü首创的，现在则是Apache软件基金会的一个项目。 Log4j是几种Java日志框架之一； Log4j 2 Apache Log4j 2是apache开发的一款Log4j的升级产品； Commons Logging Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging； Slf4j 类似于Commons Logging，是一套简易Java日志门面，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）； Logback 一套日志组件的实现（slf4j阵营）； Jul （Java Util Logging）,自Java1.4以来的官方日志实现。 日志切换 springBoot处切换 添加依赖12345&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt;&lt;/dependency&gt; 日志配置日志的输出级别的设置​ 1、OFF - FATAL - WARN - INFO - DEBUG - TRACE - ALL ​ 2、Log4j建议只使用四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。 比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来。 程序会打印高于或等于所设置级别的日志，设置的日志等级越高，打印出来的日志就越少。 如果设置级别为INFO，则优先级高于等于INFO级别（如：INFO、WARN、 ERROR）的日志信息将可以被输出,小于该级别的如DEBUG将不会被输出。 1234## level：设定日志记录的最低级别，可设的值有OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别，Log4j建议只使用中间四个级别。通过在这里设定级别，您可以控制应用程序中相应级别的日志信息的开关，比如在这里设定了INFO级别，则应用程序中所有DEBUG级别的日志信息将不会被打印出来。## appenderName：就是指定日志信息要输出到哪里。可以同时指定多个输出目的地，用逗号隔开。例如：log4j.rootLogger＝INFO,A1,B2,C3log4j.rootLogger=[level],appenderName1,appenderName2 配置日志的输出地​ 1、appenderName：自定义appderName，在log4j.rootLogger设置中使用； ​ 2、className：可设值如下： ​ (1) org.apache.log4j.ConsoleAppender（控制台） ​ (2) org.apache.log4j.FileAppender（文件） ​ (3) org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） ​ (4) org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） ​ (5) org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 1log4j.appender.appenderName = className (1) ConsoleAppender选项： Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Target=System.err：默认值是System.out。 (2 )FileAppender选项： Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 (3) DailyRollingFileAppender选项： Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。 DatePattern=’.’yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为logging.log4j，前一个月的日志文件名为logging.log4j.yyyy-MM。另外，也可以指定按周、天、时、分等来滚动日志文件，对应的格式如下： 1)’.’yyyy-MM：每月 2)’.’yyyy-ww：每周 3)’.’yyyy-MM-dd：每天 4)’.’yyyy-MM-dd-a：每天两次 5)’.’yyyy-MM-dd-HH：每小时 6)’.’yyyy-MM-dd-HH-mm：每分钟 (4) RollingFileAppender选项： Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 MaxFileSize=100KB：后缀可以是KB, MB或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。 MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文件。 配置日志信息的输出格式（Layout）1log4j.appender.appenderName.layout=className className：可设值如下： (1)org.apache.log4j.HTMLLayout（以HTML表格形式布局） (2)org.apache.log4j.PatternLayout（可以灵活地指定布局模式） (3)org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） (4)org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） (1) HTMLLayout选项： LocationInfo=true：输出java文件名称和行号，默认值是false。 Title=My Logging： 默认值是Log4J Log Messages。 (2)PatternLayout选项： ConversionPattern=%m%n：设定以怎样的格式显示消息。 格式说明如下 123456789101112131415161718%p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。%d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d&#123;yyyy/MM/dd HH:mm:ss,SSS&#125;。%r：输出自应用程序启动到输出该log信息耗费的毫秒数。%t：输出产生该日志事件的线程名。%l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。%c：输出日志信息所属的类目，通常就是所在类的全名。%M：输出产生日志信息的方法名。%F：输出日志消息产生时所在的文件名称。%L：输出代码中的行号。%m：输出代码中指定的具体日志信息。%n：输出一个回车换行符，Windows平台为"rn"，Unix平台为"n"。%x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。%%：输出一个"%"字符。另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如：1) c：指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。2) %-20c："-"号表示左对齐。3) %.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。 Log4j比较全面的配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576log4j.rootLogger=DEBUG,console,dailyFile,imlog4j.additivity.org.apache=true# 控制台(console)log4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.Threshold=DEBUGlog4j.appender.console.ImmediateFlush=truelog4j.appender.console.Target=System.errlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 日志文件(logFile)log4j.appender.logFile=org.apache.log4j.FileAppenderlog4j.appender.logFile.Threshold=DEBUGlog4j.appender.logFile.ImmediateFlush=truelog4j.appender.logFile.Append=truelog4j.appender.logFile.File=D:/logs/log.log4jlog4j.appender.logFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 回滚文件(rollingFile)log4j.appender.rollingFile=org.apache.log4j.RollingFileAppenderlog4j.appender.rollingFile.Threshold=DEBUGlog4j.appender.rollingFile.ImmediateFlush=truelog4j.appender.rollingFile.Append=truelog4j.appender.rollingFile.File=D:/logs/log.log4jlog4j.appender.rollingFile.MaxFileSize=200KBlog4j.appender.rollingFile.MaxBackupIndex=50log4j.appender.rollingFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.rollingFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 定期回滚日志文件(dailyFile)log4j.appender.dailyFile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.dailyFile.Threshold=DEBUGlog4j.appender.dailyFile.ImmediateFlush=truelog4j.appender.dailyFile.Append=truelog4j.appender.dailyFile.File=D:/logs/log.log4jlog4j.appender.dailyFile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.dailyFile.layout=org.apache.log4j.PatternLayoutlog4j.appender.dailyFile.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 应用于socketlog4j.appender.socket=org.apache.log4j.RollingFileAppenderlog4j.appender.socket.RemoteHost=localhostlog4j.appender.socket.Port=5001log4j.appender.socket.LocationInfo=true# Set up for Log Factor 5log4j.appender.socket.layout=org.apache.log4j.PatternLayoutlog4j.appender.socket.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# Log Factor 5 Appenderlog4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appenderlog4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000# 发送日志到指定邮件log4j.appender.mail=org.apache.log4j.net.SMTPAppenderlog4j.appender.mail.Threshold=FATALlog4j.appender.mail.BufferSize=10log4j.appender.mail.From = xxx@mail.comlog4j.appender.mail.SMTPHost=mail.comlog4j.appender.mail.Subject=Log4J Messagelog4j.appender.mail.To= xxx@mail.comlog4j.appender.mail.layout=org.apache.log4j.PatternLayoutlog4j.appender.mail.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 应用于数据库log4j.appender.database=org.apache.log4j.jdbc.JDBCAppenderlog4j.appender.database.URL=jdbc:mysql://localhost:3306/testlog4j.appender.database.driver=com.mysql.jdbc.Driverlog4j.appender.database.user=rootlog4j.appender.database.password=log4j.appender.database.sql=INSERT INTO LOG4J (Message) VALUES(&apos;=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n&apos;)log4j.appender.database.layout=org.apache.log4j.PatternLayoutlog4j.appender.database.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n# 自定义Appenderlog4j.appender.im = net.cybercorlin.util.logger.appender.IMAppenderlog4j.appender.im.host = mail.cybercorlin.netlog4j.appender.im.username = usernamelog4j.appender.im.password = passwordlog4j.appender.im.recipient = corlin@cybercorlin.netlog4j.appender.im.layout=org.apache.log4j.PatternLayoutlog4j.appender.im.layout.ConversionPattern=[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n Spring使用Log4j日志框架1、log4j框架指定日志输出文件只能使用绝对路径，但是我们的项目是跟着系统走的，因此我们需要将日志存放在项目的路径中，这样就需要获取到当前项目的路径，这里只需要在web.xml中添加一个Log4j的监听器即可实现，如下： 123456789101112131415161718192021222324&lt;!-- 设置根目录,必须每个项目的值都不相同，否则将会发生冲突如果一个tomcat部署多个项目的话 --&gt; &lt;context-param&gt; &lt;param-name&gt;webAppRootKey&lt;/param-name&gt; &lt;param-value&gt;lifecrystal.root&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 指定log4j配置文件的位置，项目路径下 --&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 3000表示 开一条watchdog线程每60秒扫描一下配置文件的变化;这样便于日志存放位置的改变 --&gt; &lt;context-param&gt; &lt;param-name&gt;log4jRefreshInterval&lt;/param-name&gt; &lt;param-value&gt;3000&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 1、log4j监听器，将webAppRootKey设置的值加载到系统参数中，这样就可以在配置文件中引用项目的路径 2、项目运行期间，每次改变配置文件中的值都会被监听到 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; 2、此时我们就可以在log4j.properties中使用${lifecrystal.root}获取到项目的路径，实际使用的就是System.getProperty() 12345678910111213141516171819202122232425262728293031323334353637#LOG 输出级别和输出的地方，分别为Console和File，这里到值可以随意改变，但是在下文一定要和这里的一样log4j.rootLogger=DEBUG,Console,File#################################输出到控制台，级别为DEBUG##############################################输出目的地方为控制台log4j.appender.Console=org.apache.log4j.ConsoleAppender## 以system.out的格式输出，黑色的log4j.appender.Console.Target=System.out## 只有在DEBUG的模式下才会在控制台输出log4j.appender.console.Threshold=DEBUG#在控制台输出的格式 log4j.appender.Console.layout = org.apache.log4j.PatternLayoutlog4j.appender.Console.layout.ConversionPattern=[%p]:[%c]:[%d&#123;yyyy/MM/dd HH:mm:ss&#125;] - %m%n#################################输出到文件中，级别为DEBUG##############################################文件大小到一定尺寸产生一个新文件log4j.appender.File = org.apache.log4j.RollingFileAppender#指定输出目录log4j.appender.File.File = $&#123;lifecrystal.root&#125;/logs/debug/logs.log#定义文件最大大小log4j.appender.File.MaxFileSize = 1000MB#DEBUG 日志log4j.appender.File.Threshold = DEBUGlog4j.appender.File.layout = org.apache.log4j.PatternLayoutlog4j.appender.File.layout.ConversionPattern =[%p] [%d&#123;yyyy-MM-dd HH\:mm\:ss &#125;][%c]%m%n##################################Mybatis的sql语句的输出，DEBUG级别#####################################################log4j.logger.com.ibatis=DEBUG log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUGlog4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUGlog4j.logger.java.sql.Connection=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG 3、在方法中使用Log4j调试一些内容，如下： 123456789101112131415161718@Controllerpublic class TestController &#123; private static Logger logger=Logger.getLogger(TestController.class); //获取Logger对象 @RequestMapping("/test/test") @ResponseBody public String test()&#123; System.out.println("这个是测试方法"); logger.debug("debug信息"); logger.info("info信息"); logger.error("这个是error级别的信息"); System.out.println(10/0); return "test"; &#125;&#125; 参考文章1、https://blog.csdn.net/qq_35029429/article/details/78826936]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring加载properties属性]]></title>
      <url>%2F2018%2F08%2F04%2Fspring%E5%8A%A0%E8%BD%BDproperties%E5%B1%9E%E6%80%A7%2F</url>
      <content type="text"><![CDATA[spring有两种方式加载properties中的属性第一种 使用&lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot; /&gt;在spring的配置文件中加载类路径下的资源文件 假设我们的jdbc.properties文件中的内容如下： 如果后面有重复的键值，将会覆盖前面的值 123456url=jdbc:mysql://localhost:3306/face?useUnicode=true&amp;characterEncoding=utf8driver=com.mysql.jdbc.Driveruser=rootpassword=rootinitSize=2maxSize=10 那么我们在spring的配置文件中配置数据源就直接使用里面的属性即可，如下，使用${}直接即可取出其中的属性 1234567891011&lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot; /&gt;&lt;!-- 数据源 --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;url&quot; value=&quot;#&#123;url&#125;&quot; /&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;driver&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;user&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot; /&gt; &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;initSize&#125;&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;maxSize&#125;&quot; /&gt;&lt;/bean&gt; 我们也可以使用@Value(&quot;${}&quot;)来取出其中的值 第二种 使用&lt;util:properties id=&quot;dbConfig&quot; location=&quot;classpath:db.properties&quot; /&gt;来加载文件中的属性值 假设db.properties文件如下： 123456url=jdbc:mysql://localhost:3306/face?useUnicode=true&amp;characterEncoding=utf8driver=com.mysql.jdbc.Driveruser=rootpassword=rootinitSize=2maxSize=10 配置的数据源如下： 123456789&lt;!-- 数据源 --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;url&quot; value=&quot;#&#123;dbConfig.url&#125;&quot; /&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;#&#123;dbConfig.driver&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;#&#123;dbConfig.user&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;#&#123;dbConfig.password&#125;&quot; /&gt; &lt;property name=&quot;initialSize&quot; value=&quot;#&#123;dbConfig.initSize&#125;&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;#&#123;dbConfig.maxSize&#125;&quot; /&gt;&lt;/bean&gt; 也可以使用 @Value(&quot;#{}&quot;)直接取出其中的值]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[maven使用总结]]></title>
      <url>%2F2018%2F07%2F01%2Fmaven%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Maven使用总结依赖范围 maven创建的工程的目录中包含main和test文件夹，分别表示主程序的文件夹和测试程序的文件夹 maven使用scop设置依赖范围，常用的依赖范围如下： compile ：编译依赖范围，在测试和运行都有效，这个是默认的依赖范围 对主程序是否有效：有效 对测试程序是否 有效： 有效 是否参与打包：参与`` 是否参与部署：参与 test：测试依赖的范围 对主程序是否有效：无效 对测试程序是否 有效： 有效 是否参与打包：不参与 典型的例子： junit provided 对主程序是否有效： 有效 对测试程序是否有效：有效 是否参与打包：不参与 是否参与部署：不参与 典型的例子：servlet-api 主要解决在开发中需要用到的，但是在部署的时候不需要的依赖，比如servlet-api，在开发中没有Tomcat运行环境，因此需要这个servlet-api，但是一旦部署在Tomcat中，Tomcat中会提供这个servlet-api，如果此时在添加的话会产生依赖冲突 Runtime ：测试和运行时需要。编译不需要。如JDBC驱动包 对测试程序是否有效：有效 对主程序是否有效：有效 是否参与部署： 参与 是否参与打包：参与 system：系统依赖范围。本地依赖，不在maven中央仓库 这个必须和systemPath结合使用，用来指定本地依赖的位置 12345678&lt;!-- 添加服务提供者的jar接口 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.tedu.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/dubbo-provider-helloService-0.0.1.jar&lt;/systemPath&gt; &lt;/dependency&gt; 依赖传递 在开发项目的时候，我们通常需要建立多个项目，如果一个项目中需要用到另外一个项目的类或者数据，那么需要引入这个项目快照 如果HelloFriend项目依赖Hello这个项目，此时的HelloFriend的pom.xml文件如下： 1234567891011121314151617&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;HelloFriend&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- 添加Hello这个项目的依赖快照 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 此时项目HelloFriend中存在依赖只有Hello项目这个jar，但是如果我们在Hello项目的pom.xml文件中添加一个junit的依赖，这个依赖范围为设置为compile，如下： 123456789&lt;dependencies&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 做了上面的操作，我们可以查看项目HelloFriend和Hello中都自动的导入了Junit依赖，这个就是依赖传递。 注意 依赖传递只有是依赖范围为compile的情况下才有作用，如果我们需要一个servlet-api的依赖，因为servlet-api这个jar在部署的时候会和Tomcat冲突，因此只能设置为provided，但是此时就不能依赖传递了，只能在每个项目中的pom.xml文件中都添加了 依赖排除 HelloFriend项目依赖Hello项目，其中compile范围的依赖都会导入HelloFriend中 使用dubbo默认会添加给我们添加spring-framework的版本为2.5.6，默认添加的依赖只能排除，不能在项目中再添加一个其他的版本，只有排除之后才能添加，否则会导致jar包冲突 Hello项目中的依赖为： 12345678910111213&lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 添加dubbo依赖的jar,会自动添加spring 2.5版本的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; 此时HelloFriend的项目需要使用4.3.13版本的spring，那么我们有如下解决办法： 在Hello项目中改变依赖，排除spring2.5版本的： 一般在公司中项目的版本都是定制好的，我们不可能随意改动父项目中定义好的版本，因此这个方法明显是不行的 12345678910111213141516171819&lt;!-- 使用spring4.3.13 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;!--排除spring2.5版本--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 我们可以在项目HelloFriend排除这个spring的依赖，那么我们就可以不需要改变Hello项目中的依赖了，如下： 这个才是正确的排除依赖的方式 1234567891011121314151617181920&lt;!-- SpringMVC --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 添加Hello这个项目的依赖快照 --&gt;&lt;dependency&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!--排除项目中的spring2.5的依赖，这个不会影响Hello项目中的版本--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 依赖原则依赖路径最短优先原则 假设项目MakeFriend依赖HelloFriend，并且HelloFriend依赖Hello项目。此时Hello项目中使用的log4j 1.2.14版本的，但是在HelloFriend版本中使用的是log4j1.2.17版本的，那么此时的MakeFriend应该选择什么版本呢？ Hello的依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.14&lt;/version&gt;&lt;/dependency&gt; HelloFriend依赖如下： 12345678910111213&lt;!-- 添加Hello这个项目的依赖快照 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--添加1.2.17版本的log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; MakeFriend的依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;HelloFriend&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 我们根据图形可以看到MakeFriend到HelloFriend的log4j1.2.17的路径是2，但是到Hello中的log4j1.2.14的路径为3，因此Maven会选择HelloFriend中的log4j1.2.17版本作为MakeFriend的依赖 pom文件中申明顺序优先 在路径都是一样的情况下，那么就要看在pom.xml文件中申明的顺序了，先申明的就使用哪个项目中的依赖版本 假设现在的依赖改变了，MakeFriend现在是直接依赖Hello和HelloFriend，如下图 我们可以看出此时到两个版本的依赖都是一样的路径为2，那么我们应该选择哪个版本呢，此时就需要看看在MakeFriend中的pom.xml文件的申明顺序 可以看出先申明的是HelloFriend，因此MakeFriend使用的是log4j1.2.17 123456789101112&lt;!-- 先申明HelloFriend,那么就要使用log4j.1.2.17版本 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;HelloFriend&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 覆写优先​ 生命周期 maven的生命周期有三个部分组成，分别为clean生命周期，site生命周期，default生命周期 生命周期调用的特点 三大生命周期中也会包含各个阶段，并且各个阶段是有序进行的，maven为了实现构建的自动化，如果我们使用了命令调用生命周期后面的处理阶段，那么会从最前面的阶段开始执行，不用每一个阶段都执行一遍。 clean生命周期 在进行真正的构建之前进行一些清理工作 clean生命周期包括： per-clean：执行了一些需要在clean之前完成的工作 clean：移除所有上一次构建生成的文件 post-clean：执行一些需要在clean之后立刻完成的工作 当我们执行mvn:clean命令的时候只会执行per-clean和clean这两个阶段的任务，不会执行post-clean的工作 default生命周期 构建的核心部分，编译、测试、打包、部署 包括如下的23个生命周期阶段： 生命周期阶段 描述 validate 检查工程配置是否正确，完成构建过程的所有必要信息是否能够获取到。 initialize 初始化构建状态，例如设置属性。 generate-sources 生成编译阶段需要包含的任何源码文件。 process-sources 处理源代码，例如，过滤任何值（filter any value）。 generate-resources 生成工程包中需要包含的资源文件。 process-resources 拷贝和处理资源文件到目的目录中，为打包阶段做准备。 compile 编译工程源码。 process-classes 处理编译生成的文件，例如 Java Class 字节码的加强和优化。 generate-test-sources 生成编译阶段需要包含的任何测试源代码。 process-test-sources 处理测试源代码，例如，过滤任何值（filter any values)。 test-compile 编译测试源代码到测试目的目录。 process-test-classes 处理测试代码文件编译后生成的文件。 test 使用适当的单元测试框架（例如JUnit）运行测试。 prepare-package 在真正打包之前，为准备打包执行任何必要的操作。 package 获取编译后的代码，并按照可发布的格式进行打包，例如 JAR、WAR 或者 EAR 文件。 pre-integration-test 在集成测试执行之前，执行所需的操作。例如，设置所需的环境变量。 integration-test 处理和部署必须的工程包到集成测试能够运行的环境中。 post-integration-test 在集成测试被执行后执行必要的操作。例如，清理环境。 verify 运行检查操作来验证工程包是有效的，并满足质量要求。 install 安装工程包到本地仓库中，该仓库可以作为本地其他工程的依赖。 deploy 拷贝最终的工程包到远程仓库中，以共享给其他开发人员和工程。 当一个阶段通过 Maven 命令调用时，例如mvn compile，只有该阶段之前以及包括该阶段在内的所有阶段会被执行。 Site生命周期 Maven Site 插件一般用来创建新的报告文档、部署站点等。 包含以下阶段 pre-site：执行一些需要在生成站点文档之前完成的工作 site：生成项目的站点文档 post-site：执行一些需要生成站点文档之后完成的工作 site-deploy：将生成站点文档部署到特定的服务器上 Maven统一管理依赖的版本号 假设如下的依赖： 12345678910111213&lt;!-- SpringMVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring-JDBC,要和spring-webmvc的版本一致 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt; &lt;/dependency&gt; 那么当我们需要改变spring的依赖版本号为4.3.12.RELEASE，那么我们只有逐个改变version中的值，现在是两个依赖比较好改变的，如果要有很多个的话，那么难免会改错，因此我们需要使用一种方式统一管理依赖的版本号。我们可以使用&lt;properties&gt;标签来管理，新的配置文件如下： properties中的标签体可以任意指定，如果需要引用定义的标签体中的内容，那么直接使用${标签体}即可 此时我们要是改变版本，那么只需要改变&lt;properties&gt;中的版本即可 1234567891011121314151617181920212223&lt;!-- 使用properties管理版本号 --&gt; &lt;properties&gt; &lt;!-- 这里的标签体可以任意指定，后续只要使用$&#123;&#125;引用标签体即可使用其中定义的内容 --&gt; &lt;spring-version&gt;4.3.13.RELEASE&lt;/spring-version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- SpringMVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;!-- version使用$&#123;&#125; --&gt; &lt;version&gt;$&#123;spring-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring-JDBC,要和spring-webmvc的版本一致 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 继承 我们知道只有compile范围内的依赖才可以传递，但是对于test和provided中的依赖却是不可以传递的，那么必须在每个项目中都要添加依赖，此时肯定会出现每个项目中依赖版本不一致的情况，这样对于每个人的开发来说是比较困难的，因为不同版本的依赖使用的方式也不同，此时我们就需要统一管理这个版本了。 下面我们以junit的版本控制为例 步骤 创建一个父工程Hello-Parent，打包的方式为pom 在Hello-Parent中的pom.xml文件中使用dependencyManagement管理版本，控制junit的版本依赖 12345678910111213141516171819202122232425262728&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello-Parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 使用properties控制版本号 --&gt; &lt;properties&gt; &lt;junit-version&gt;4.12&lt;/junit-version&gt; &lt;/properties&gt; &lt;!-- 使用dependencyManagement管理版本 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit-version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;/project&gt; 在子工程中使用parent标签指定声明对父工程的引用 1234567&lt;parent&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello-Parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 使用relativePath指定父工程的相对位置 --&gt; &lt;relativePath&gt;../Hello-Parent&lt;/relativePath&gt;&lt;/parent&gt; 将子工程坐标和父工程坐标重复的地方删除，不删除也没关系 在子工程中删除junit的version标签，表明是继承自父工程的版本，不需要指定 123456&lt;!-- Junit --&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;!--此时不需要指定version了，因为父工程中已经指定了--&gt;&lt;/dependency&gt; 子工程全部的配置 1234567891011121314151617181920212223242526&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 这里的groupId和父工程中的重复了，因此可以删除 &lt;groupId&gt;cn.tedu&lt;/groupId&gt;--&gt; &lt;artifactId&gt;Hello&lt;/artifactId&gt; &lt;!-- 这里的version版本也和父工程的重复了，因此可以删除 &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; --&gt; &lt;parent&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello-Parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 使用relativePath指定父工程的相对位置 --&gt; &lt;relativePath&gt;../Hello-Parent&lt;/relativePath&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;!--不需要指定version--&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 聚合 我们在开发项目的时候都是分模块开发的，此时如果想要使用maven安装这个项目的话，那么需要一个一个的安装，但是我们可以使用聚合的方式，可以实现一次性安装。并且安装还是有先后顺序的，一定要先安装父工程，否则将会找不到依赖信息，我们使用聚合的方式就没有先后安装的障碍了，maven会为我们自动的解决 步骤 创建一个maven工程，打包方式为pom，当然也是可以直接使用父工程 在pom.xml配置文件中配置module 详细的pom.xml如下： 12345678910111213141516171819202122232425&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello-Manager&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 继承父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;Hello-Parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 使用relativePath指定父工程的相对位置 --&gt; &lt;relativePath&gt;../Hello-Parent&lt;/relativePath&gt; &lt;/parent&gt; &lt;!-- 使用聚合的方式 --&gt; &lt;modules&gt; &lt;module&gt;../Hello-Parent&lt;/module&gt; &lt;module&gt;../Hello&lt;/module&gt; &lt;module&gt;../HelloFriend&lt;/module&gt; &lt;module&gt;../MakeFriend&lt;/module&gt; &lt;/modules&gt; &lt;/project&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[二叉树]]></title>
      <url>%2F2018%2F07%2F01%2F%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
      <content type="text"><![CDATA[二叉树定义二叉树是每个节点最多有两个子树的树结构。它有五种基本形态：二叉树可以是空集；根可以有空的左子树或右子树；或者左、右子树皆为空。 基本术语 度：节点所拥有子节点的个数 叶子节点：度为0的节点，即是没有子节点的节点 分支节点：度不为0的节点 根节点： 没有父节点的节点 层次：根节点的层次为1，其余节点的层次等于该双亲节点的层次加1 深度：树中节点的最大层次 性质 性质1：二叉树第i层上的结点数目最多为 2^{i-1} (i≥1)。 性质2：深度为k的二叉树至多有2{k}-1个结点(k≥1)。 性质3：包含n个结点的二叉树的高度至少为log2 (n+1)。 性质4：在任意一棵二叉树中，若终端结点的个数为n0，度为2的结点数为n2，则n0=n2+1。 满二叉树定义 除了最后一层，所有分支节点的子节点个数为2 特点 叶子只能出现在最后一层。 非叶子结点度一定是2. 在同样深度的二叉树中，满二叉树的结点个数最多，叶子树最多。 完全二叉树定义 若设二叉树的深度为h，除第 h 层外，其它各层 (1~h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是完全二叉树。 完全二叉树是由满二叉树而引出来的。对于深度为K的，有n个结点的二叉树，当且仅当其每一个结点都与深度为K的满二叉树中编号从1至n的结点一一对应时称之为完全二叉树。 一棵二叉树至多只有最下面的一层上的结点的度数可以小于2，并且最下层上的结点都集中在该层最左边的若干位置上，而在最后一层上，右边的若干结点缺失的二叉树，则此二叉树成为完全二叉树。 判断完全二叉树 完全二叉树：叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树 满二叉树必然是完全二叉树，完全二叉树不一定是满二叉树 特点 叶子结点只可能在最大的两层上出现,对任意结点，若其右分支下的子孙最大层次为L，则其左分支下的子孙的最大层次必为L 或 L+1; 满二叉树一定是完全二叉树，完全二叉树不一定是满二叉树 只允许最后一层有空缺结点且空缺在右边，即叶子结点只能在层次最大的两层上出现 对任一结点，如果其右子树的深度为j，则其左子树的深度必为j或j+1。 即度为1的点只有1个或0个 二叉查找树定义 二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树。 没有键值相等的节点（no duplicate nodes）。 插入节点12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 插入节点 * @param value 节点的值 */ public void insertNode(int value)&#123; //如果根节点为null if (root==null) &#123; root=new Node(value,null,null); //创建根节点,此时没有左右子节点 return; //返回即可，表示插入成功，这个插入的节点就是根节点 &#125; //如果根节点已经存在，那么就需要从根节点开始比较大小 Node currentNode=root; //当前节点 Node parentNode=root; //当前节点的父节点，需要保存这个节点 boolean isLeftChild=true; //记录待插入的数是parentNode的左节点还是右节点 //当当前节点不为空，表示没有找到插入的位置，当currentNode节点为null的时候，那么这个就是待插入的位置 while(currentNode!=null)&#123; parentNode=currentNode; //保存当前节点的父节点 //如果待插入的值小于当前值，那么到当前节点的左子树中查找 if (value&lt;currentNode.getValue()) &#123; currentNode=currentNode.getLeftChild(); //当前节点继续向下成为左子节点 isLeftChild=true; //左节点 &#125;else if (value&gt;currentNode.getValue()) &#123; //如果待插入的数大于当前节点的值，那么到当前节点的右边查找 currentNode=currentNode.getRightNode(); isLeftChild=false; &#125;else &#123; //value和currentNode.value相等，不允许插入 System.out.println(value+"已经存在，不允许插入"); return; //直接返回，后面的数字不用插入了 &#125; &#125; //循环结束，此时的parentNode就是待插入数字的父节点 //如果待插入的节点是左子节点 if (isLeftChild) &#123; Node node=new Node(value, null, null); parentNode.setLeftChild(node); //设置左节点 &#125;else &#123; //是右子节点 Node node=new Node(value, null, null); parentNode.setRightNode(node); //设置右节点 &#125; &#125; 查找指定值 比较需要查找的值，如果大于当前节点的值，在其右子树中查找，如果小于当前节点的值，在其左子树中查找 123456789101112131415161718/** * 在二叉查找树中查找指定的值 * @param value * @return 返回的找到的节点，如果为null表示没有找到 * 从根节点查找，比较值，如果大于，在右子树中查找，如果小于在左子树中查找 */public Node findValue(int value)&#123; Node currentNode=this.root; //从根节点开始查找 //如果currentNode不为null并且值不相等，跳出循环的条件是：要么没有找到，返回null，要么找到了，值相等 while(currentNode!=null&amp;&amp;currentNode.value!=value)&#123; if (value&lt;currentNode.getValue()) &#123; currentNode=currentNode.getLeftChild(); &#125;else &#123; currentNode=currentNode.getRightNode(); &#125; &#125; return currentNode;&#125; 删除节点 分为三种： 删除叶子节点 删除只有一个子节点的节点 删除含有两个子节点的节点 参考文章 https://www.cnblogs.com/Michaelwjw/p/6384428.html 二叉树的遍历前序遍历 访问顺序： 先访问父结点，再前序遍历左子树，最后再前面序遍历右子树，即是： 父节点 – 左 子树 — 右子树 图中遍历的结果是： 从根节点开始，访问1 访问2，此时的2作为父节点，访问左子树 访问4，此时的4作为父节点，访问左子树，没有左子树，访问右子树，也没有右子树，此时开始访问父节点4的右子树 访问5，此时的5作为父节点，访问左子树 访问7，此时的7作为父节点，访问左子树，没有，访问右子树 访问8 ，此时的8作为父节点，访问左子树，没有，访问右子树没有，此时以1作为父节点，开始访问有节点 访问3，此时的3作为父节点，访问左子树，没有，访问右子树 访问6，此时的6作为父节点，左右节点都没有，访问结束 最后的前序遍历为：1，2，4，5，7，8，3，6。 递归调用的算法如下： 123456789101112131415161718//前序遍历对外的方法 public void PreOrder()&#123; PreOrder(this.root); //从根节点开始访问 &#125; /** * 前序遍历 * 递归 * @param node 父节点 */ private void PreOrder(Node node)&#123; //如果节点不为null if (node!=null) &#123; System.out.println(node.getValue()); //输出值 PreOrder(node.getLeftChild()); //访问左子树 PreOrder(node.getRightNode()); //访问右子树 &#125; &#125; 中序遍历 先中序遍历左子树，然后再访问根结点，最后再中序遍历右子树即左—根—右 总的来说，把当前节点看成是根节点，如果这个根节点还存在左子树，继续向下，直到当前节点不存在左子树，那么输出当前节点即可，然后输出父节点的值，然后输出右子树的值，如此反复即可 中序遍历的规则是【左根右】，我们从root节点A看起； 此时A是根节点，遍历A的左子树； A的左子树存在，找到B，此时B看做根节点，遍历B的左子树； B的左子树不存在，返回B，根据【左根右】的遍历规则，记录B，遍历B的右子树； B的右子树存在，找到C，此时C看做根节点，遍历C的左子树； C的左子树存在，找到D，由于D是叶子节点，无左子树，记录D，无右子树，返回C，根据【左根右】的遍历规则，记录C，遍历C的右子树； C的右子树不存在，返回B，B的右子树遍历完，返回A； 至此，A的左子树遍历完毕，根据【左根右】的遍历规则，记录A，遍历A的右子树； A的右子树存在，找到E，此时E看做根节点，遍历E的左子树； E的左子树不存在，返回E，根据【左根右】的遍历规则，记录E，遍历E的右子树； E的右子树存在，找到F，此时F看做根节点，遍历F的左子树； F的左子树存在，找到G，此时G看做根节点，遍历G的左子树； G的左子树存在，找到H，由于H是叶子节点，无左子树，记录H，无右子树，返回G，根据【左根右】的遍历规则，记录G，遍历G的右子树； G的右子树存在，找到K，由于K是叶子节点，无左子树，记录K，无右子树，返回G，根据【左根右】的遍历规则，记录F，遍历F的右子树； F的右子树不存在，返回F，E的右子树遍历完毕，返回A； 至此，A的右子树也遍历完毕； 详细的算法如下： 123456789101112//中序遍历对外的方法 public void InOrder()&#123; InOrder(this.root); //传入根节点 &#125; private void InOrder(Node node)&#123; if (node!=null) &#123; InOrder(node.getLeftChild()); //先遍历左子树 System.out.println(node.getValue()); InOrder(node.getRightNode()); //遍历右子树 &#125; &#125; 后续遍历 先后序遍历左子树，然后再后序遍历右子树，最后再访问根结点即左—右—根。 总的来说，把当前节点当做根节点，只要是存在左右子树的继续向下，不输出当前节点的值，直到没有左右子树才输出，再返回，如此反复即可 总结： 当根据顺序访问的时候，只要当前节点没有左右节点或者左右节点已经输出过了，才可以输出当前节点的值 详细过程如下： 从根节点1开始，访问左子树2，把2当成根节点，访问左子树4，把4当成根节点，访问左子树，没有，输出4 返回父节点2，把2当成根节点，此时的左子树4已经输出了，那么开始访问右子树5，把5当成根节点，访问左子树7，把7当成根节点，访问左子树，没有，但是存在右子树8，把8当成根节点，访问左子树，没有，访问右子树，没有，此时输出8 返回父节点7，发现不存在左节点，右节点8已经输出了，因此输出7 返回父节点5，发现左节点7已经输出了，并且没有右子树，因此输出5 返回父节点2，发现左右节点都输出了，因此继续返回父4节点1 把1当成根节点，发现左子树已经遍历完成，访问左子树3，把当前的3当成根节点，访问左子树，没有，访问右子树6，把6当成根节点，发现左右子树都不存在，输出6 返回父节点3，发现没有左子树，并且右节点6已经输出了，因此输出3 返回父节点1，输出1 最终的顺序为：4,8,7,5,6,3,1 详细算法如下： 12345678910111213//后序遍历对外的方法 public void PostOrder()&#123; this.PostOrder(this.root); //从根节点开始 &#125; //后序遍历 private void PostOrder(Node node)&#123; if(node!=null)&#123; PostOrder(node.getLeftChild()); //遍历左子树 PostOrder(node.getRightNode()); //遍历右子树 System.out.println(node.getValue()); //输出 &#125; &#125; 红黑树 http://www.cnblogs.com/skywang12345/p/3245399.html 参考文章 https://www.cnblogs.com/polly333/p/4740355.html#8 https://www.cnblogs.com/Michaelwjw/p/6384428.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[堆排序]]></title>
      <url>%2F2018%2F07%2F01%2F%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
      <content type="text"><![CDATA[堆排序堆的定义 堆(heap)，这里所说的堆是数据结构中的堆，而不是内存模型中的堆。堆通常是一个可以被看做一棵树，它满足下列性质： [性质一] 堆中任意节点的值总是不大于(不小于)其子节点的值； [性质二] 堆总是一棵完全树。 将任意节点不大于其子节点的堆叫做最小堆或小根堆，而将任意节点不小于其子节点的堆叫做最大堆或大根堆。常见的堆有二叉堆、左倾堆、斜堆、二项堆、斐波那契堆等等。 排序的过程 将数组建成最大堆或者最小堆 取出堆顶的数据和数组末尾的数据交换，此时对前面的数据再次建堆，再取堆顶的数据和数组中的倒数第二个交换，……………………. 代码实现构造大顶堆 实现从大到小的排序 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class HeapSort &#123; /** * 构造大顶堆 * 1. 根节点的值一定要比子节点的值大 * 堆的向下调整 * @param array 需要调整的数组 * @param start 调整的起始位置 * @param end 调整的终止位置 * 索引从0开始 * 当前节点的左节点： 2*i+1 * 右节点： 2**i+2 */ public static void max_heap_down(int[] array,int start,int end)&#123; int currentIndex=start; //保存当前节点的下标 int leftIndex=2*currentIndex+1; //当前节点左节点的下标 //当当前节点的左节点的下标小于终止下标的时候，因为堆是一个完全的二叉树，因此只要没有左子树就一定没有右子树，因此只需要判断左节点的下标即可 //只要满足这个条件就表示一定存在左右节点 while(leftIndex&lt;end)&#123; //当左节点的值小于右节点，那么此时只需要将当前值和右节点的值比较，这里的leftIndex+1是右子节点的下标 //如果没有执行if体内的语句，那么此时的左右节点最大的下标就是左节点的下标 if(array[leftIndex]&lt;array[leftIndex+1])&#123; leftIndex++; //此时的下标编程右节点的下标 &#125; //如果当前节点大于等于左右子节点中的最大值，那么就不用调整了，直接跳出 if (array[currentIndex]&gt;=array[leftIndex]) &#123; break; &#125;else &#123; //如果小于，此时需要调整，将当前节点和左右子节点最大值交换 int temp=array[currentIndex]; //交换数字 array[currentIndex]=array[leftIndex]; array[leftIndex]=temp; currentIndex=leftIndex; //此时的当前节点的下标 leftIndex=2*currentIndex+1; //当前节点的左子节点也需要改变了 &#125; &#125; &#125; /** * 堆排序，从小到大 * @param array 待排序的数组 */ public static void heap_sort_asc(int[] array)&#123; //从索引为array.length/2-1的位置到0，开始向下调整，那么调整好的数组就是一个大顶堆 for(int i=array.length/2-1;i&gt;=0;i--)&#123; //进行向下调整 max_heap_down(array, i, array.length-1); &#125; //从最后一个元素开始对序列进行调整，不断的调整，直到第一个元素 for (int i = array.length-1; i &gt;0; i--) &#123; //此时array[0]就是最大的元素，因此和最后一个元素交换 int temp=array[i]; array[i]=array[0]; array[0]=temp; //此时最后一个元素就是最大的，因此我们对前面的元素继续构造大顶堆 max_heap_down(array, 0, i-1); &#125; &#125; public static void main(String[] args) &#123; int[] array=&#123;12,3,4,45,1,45,6,72,4&#125;; heap_sort_asc(array); for (int i = 0; i &lt; array.length; i++) &#123; System.out.println(array[i]); &#125; &#125;&#125; 转载 [http://www.cnblogs.com/skywang12345/p/3610187.html] (http://www.cnblogs.com/skywang12345/p/3610187.html) http://www.cnblogs.com/skywang12345/p/3602162.html#a43]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shell排序]]></title>
      <url>%2F2018%2F07%2F01%2Fshell%E6%8E%92%E5%BA%8F%2F</url>
      <content type="text"><![CDATA[Shell 排序定义 希尔排序(Shell Sort)是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 该方法实质上是一种分组插入方法 比较相隔较远距离（称为增量）的数，使得数移动时能跨过多个元素，则进行一次比[2] 较就可能消除多个元素交换。 D.L.shell于1959年在以他名字命名的排序算法中实现了这一思想。算法先将要排序的一组数按某个增量d分成若干组，每组中记录的下标相差d.对每组中全部元素进行排序，然后再用一个较小的增量对它进行，在每组中再进行排序。当增量减到1时，整个要排序的数被分成一组，排序完成。 一般的初次取序列的一半为增量，以后每次减半，直到增量为1。 给定实例的shell排序的排序过程 假设待排序文件有10个记录，其关键字分别是：49，38，65，97，76，13，27，49，55，04。增量序列的取值依次为：5，2，1 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041public class ShellSort &#123; public static void main(String[] args) &#123; int[] data = new int[] &#123; 5, 3, 6, 2, 1, 9, 4, 8, 7 &#125;; print(data); shellSort(data, data.length); print(data); &#125; /** shell排序的实现算法，原理就是使用不同的增量进行分组，之后对每个分组进行插入排序 */ public static void shellSort(int[] array, int n) &#123; int gap, i, j; //使用增量分割子序列，这里的gap就是增量，使用增量对数组进行分割 for (gap = n / 2; gap &gt; 0; gap /= 2) &#123; // 内层的两个循环对每一个子序列同时做直接插入排序 for (i = gap; i &lt; n; i++)&#123; int insertNode=array[i]; //待插入的数据 j=i-gap; //待插入数据的前一个下标 //循环结束的条件是insertNode&gt;=array[j],那么此时的insertNode需要插入的位置就是array[j+1]这个位置了 while(j&gt;=0&amp;&amp;insertNode&lt;array[j])&#123; array[j+gap]=array[j]; //元素后移 j=j-gap; &#125; array[j+gap]=insertNode; //此时的array[j+gap]就是待插入的位置 &#125; &#125; &#125; public static void print(int[] data) &#123; for (int i = 0; i &lt; data.length; i++) &#123; System.out.print(data[i] + "\t"); &#125; System.out.println(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL性能优化]]></title>
      <url>%2F2018%2F06%2F26%2FMySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[MySQL性能优化查看数据库性能参数 show status like &quot;value&quot; ：value是要查询的参数值，常用的值如下： 优化查询分析查询语句 Mysql中提供explain和describe来分析查询语句 格式：explain select selectStatemnt explain select * from user where id=1; 查询结果如下： 查询的参数分析如下: 使用索引查询的优化注意点 索引是可以提高查询速度，但是并不是使用带有索引的字段查询时，索引都能起作用 使用索引有几种特殊的情况，在这些特殊的情况下，有可能使用索引字段查询时，索引并没有起作用。下面会详细介绍 1. 使用LIKE关键字查询 使用Like关键字查询的时候，如果匹配字符串的第一个字符为%，那么索引不会起作用。只有%不在第一个位置，索引才会起作用。 我们使用name字段的索引name_index查询用户信息，如下 explain select * from user where name like &quot;%a&quot;; ： 我们看到查询出来的信息，字段possible_keys的值为NULL，这里表示没有使用name的索引name_index，并且这里的rows显示扫描的行数 explain select * from user where name like &quot;J%&quot;; ：显示的possible_keys字段的值是name_index，表示使用了name字段的索引进行查询了 2. 使用组合索引查询 匹配左前缀，只要使用了组合索引中的最左边的那个索引值进行查询，那么就会使用组合索引进行查询 Mysql可以为多列创建索引，可以同时为16个字段创建索引。对于组合索引，只有查询条件中使用了这些字段的第一个字段时，才会使用索引查询。 我们分析查询用户信息的语句，看看对于组合索引的使用 创建组合索引name_age_index ：create index name_age_index on user(name,age) 使用分析查询语句：explain select * from user where age=22; ：这里查询没有使用第一个字段name字段查询，显示possible_keys为NULL表示没有相关索引 使用分析查询语句：explain select * from user where name=&quot;Jack&quot; ：这里使用了第一个字段进行查询，显示的possible_keys为name_index，key为name_index表示使用了name_index进行查询了 explain select * from user where name=&quot;Jack&quot; and age=22 ： 同样是使用了name_index索引进行查询 3. 使用or关键字查询语句 在查询条件中只有or关键字，并且or的前后的两个条件的列都是索引的时候，查询中才会使用索引，否则不使用索引。 我们仍然分析查询用户信息的语句，使用OR关键字查询 为字段age创建索引：create index age_index on user(age) 分析查询：explain select * from user where id=1 or name=&quot;Jack&quot;; ：由于这里的name字段没有创建索引，显示的key为NULL表示该条查询语句并没有使用索引查询 分析查询：explain select * from user where id=1 or age=22; ：由于id和age都创建了索引并且key显示为PRIMARY,age_index，表示使用了索引查询 4. 索引排序 mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作，尽量不要包含多个列的排序，如果需要最好给这些列建复合索引。 5. 逻辑运算 不使用NOT IN 、&lt;&gt;、！=操作，但&lt;,&lt;=，=，&gt;,&gt;=,BETWEEN,IN是可以用到索引的 6. 使用短索引 对串列进行索引，如果可以就应该指定一个前缀长度。例如，如果有一个char（255）的列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 7. 如何使用索引来排序在排序操作中如果能使用到索引来排序，那么可以极大的提高排序的速度，要使用索引来排序需要满足以下两点即可。 1、ORDER BY子句后的列顺序要与组合索引的列顺序一致，且所有排序列的排序方向（正序/倒序）需一致 2、所查询的字段值需要包含在索引列中，及满足覆盖索引 通过例子来具体分析 在user_test表上创建一个组合索引 1 ALTER TABLE user_test ADD INDEX index_user(user_name , city , age); 可以使用到索引排序的案例 1234567 1、SELECT user_name, city, age FROM user_test ORDER BY user_name; 2、SELECT user_name, city, age FROM user_test ORDER BY user_name, city; 3、SELECT user_name, city, age FROM user_test ORDER BY user_name DESC, city DESC; 4、SELECT user_name, city, age FROM user_test WHERE user_name = ‘feinik’ ORDER BY city; 注：第4点比较特殊一点，如果where查询条件为索引列的第一列，且为常量条件，那么也可以使用到索引 无法使用索引排序的案例 1、sex不在索引列中 1 SELECT user_name, city, age FROM user_test ORDER BY user_name, sex; 2、排序列的方向不一致 1 SELECT user_name, city, age FROM user_test ORDER BY user_name ASC, city DESC; 3、所要查询的字段列sex没有包含在索引列中 1 SELECT user_name, city, age, sex FROM user_test ORDER BY user_name; 4、where查询条件后的user_name为范围查询，所以无法使用到索引的其他列 1 SELECT user_name, city, age FROM user_test WHERE user_name LIKE ‘feinik%’ ORDER BY city; 优化子查询 子查询就是一个select语句中嵌套多个select语句，虽然子查询使用起来方便灵活，但是执行的效率并不高。在执行子查询的时候需要为内层的查询语句结果建立一个临时表，然后外层的语句从临时表中查询数据。查询完毕之后再撤销临时表。因此子查询的速度会受到一定的影响。 在Mysql中，可以使用连接Join查询代替子查询，连接查询不需要建立临时表，速度要比子查询要快。如果查询中使用索引的话，性能会更好 优化数据库结构1. 将字段很多的表分解成多个表 对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大的时候，会由于使用频率低的字段存在而变慢。 实例 假设会员表（members）存储会员登录认证信息，该表中有很多字段，如id，姓名，密码，地址，电话，个人描述等字段。其中地址，电话，个人描述字段并不常用。我们可以将这些字段分离出来形成一张新的表（member_detail）。表中有member_id，address，phone，description。其中member_id表示会员编号和members表中的id字段值对应 1234567891011121314create table members( id int(11) primary key auto_increment, name varchar(20) default null, password varchar(20) default null, last_login_time datetime default null, last_login_ip varchar(100) default null);create table member_detail( member_id int(11) not null default 0, address varchar(100) default null, phone varchar(16) default null, description text); 如果我们需要查询会员信息，可以使用连接查询：select * from members left join member_detail on members.id=member_detail.member_id; 通过这种分解可以提高查询效率，可以优化数据库的性能，因为我们大部分时间需要查询和操作的表就是members 2. 增加中间表 对于需要经常联合查询的表，可以使用建立中间表用以提高查询速度。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后把原来的联合查询改为对中间表的查询，以此来提高查询效率。 假设有一个会员信息表(vip)，其中存储的是每一个会员的信息，还有一个会员组信息表（vip_group)其中存储的是会员组的信息，比如名称，备注信息。现在我们需要经常查询的是会员的名字及其所在会员组的信息，使用联合查询的语句如下： select vip.name,vg.name,vg.remark from vip left join vip_group on vip.groupId=vg.id 我们可以添加一个中间表temp_group，表中存储的是会员名，会员组名称，会员组信息，我们将连接查询的结果添加到中间表中，那么我们以后就可以直接到中间表中查询了，不用每次都联合查询了。 3. 增加冗余字段 设计数据库的时候应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致优雅。但是，合理的增加冗余字段可以提高查询速度。 表的规范程度越高，表与表之间的关系就越多，需要连接查询的情况就越多。例如，员工信息表存储在staff表中，部门信息存储在department表中，通过staff表中的department_id字段与department建立联系。如果要查询一个员工所在部门的名称，必须从staff表中查找员工所在部门编号，然后根据这个编号从department表中查找部门的名称。如果经常需要进行这个操作，连接查询会浪费很多时间。此时我们可以在staff表中添加一个department_name字段，用来记录部门名称，这样就不需要每次连接操作了。 冗余字段会导致很多问题，比如字段的值在一个表中改变了，在另外一个表中也要更新这个数据，很可能造成数据不一致，因此要根据实际需要综合分析是否使用冗余字段 ## 优化插入记录的速度 插入记录的时候，影响插入速度的只要是索引、唯一性校验、一次插入多条记录等。根据这些情况，可以分别进行优化 1. 禁用唯一性检查 插入数据之前执行set unique_checks=0来禁止对唯一性索引的检查，执行完成之后再执行set unique_checks=1 2. 禁用外键检查 插入数据之前执行禁止外键检查，数据插入完成之后再恢复对外键的检查，语句如下： set foreign_key_checks=0 ：禁用 set foreign_key_checks=1 ：启用外键检查 3. 禁止自动提交 插入数据之前禁止事务的自动提交，在数据插入完成之后，执行恢复自动提交 set autocommit=0 set autocommit=1 优化Mysql服务器 对硬件的优化，对Mysql服务的参数进行优化 优化服务器硬件 优化MySQL参数 参考文章 http://www.cnblogs.com/clsn/p/8214048.html https://blog.csdn.net/u013087513/article/details/77899412]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL触发器]]></title>
      <url>%2F2018%2F06%2F26%2FMySQL%E8%A7%A6%E5%8F%91%E5%99%A8%2F</url>
      <content type="text"><![CDATA[MySQL触发器定义 MySQL的触发器和存储过程一样，都是嵌入到MysQL中的一段程序，不过触发器不要调用，而是由事件触发的，这些事件包括insert，update，delete语句，如果定义了触发程序，当数据执行这些语句的时候就会激发触发器执行相应的操作。 创建触发器创建一行执行语句的触发器 格式：create trigger trigger_name trigger_time trigger_event on table for each row trigger_stmt trigger_name ：触发器的名字 trigger_time： 触发器触发的时机，取值为before，after before：表示在激发触发器的语句执行之前执行触发器的执行语句 after：表示在激发触发器的语句执行之后执行触发器的执行语句 trigger_event：触发事件，取值为insert，update，delete insert ：比如Mysql中的insert和replace语句就会触发这个事件 update：更新某一行的数据会激发这个事件，比如update语句 delete：删除某一行的时候激发触发器，可能通过delete或者replace语句激发 table：标识建立触发器的表名，即是当那张表发生了insert，update，delete事件激发触发器 trigger_stmt：触发器执行的语句 执行语句中不能返回结果集 实例： new.age：获取新插入的字段age的值 new.name ： 获取新插入的name字段的值 1234567891011-- 创建user表create table user(id int primary key auto_increment,name varchar(10),age int); -- 设置用户变量@sum，用于统计年龄set @sum=0; -- 插入数据,将会在插入数据之前激发触发器，执行触发器中定义的语句，计算出插入的年龄总和赋值给@suminsert into user(name,age) values(&quot;Jack&quot;,22),(&quot;Tom&quot;,33);-- 创建触发器，insert事件，在user表插入数据之前执行语句，其中的new.age是获取插入的每一行的age字段的值create trigger sum before insert on user for each row set @sum=@sum+new.age; 创建多行执行语句的触发器 格式： 1234567delimiter // create trigger trigger_name trigger_time trigger_event on table for each row begin -- 语句执行列表 end //delimiter ; 实例 如果修改的名字和已经存在的重复，那么就设置异常（主键冲突）取消后面的更新语句，不过这个一定要使用before的触发时间 new.name : 表示修改之后的name字段的值，如果没有修改，那么和之前的一样 old.name ：表示修改之前的name字段的值 触发器不能撤销后面的操作，如果想要撤销操作可以制造异常，那么后面的语句就不会执行了，如下面的程序制造了主键冲突的异常 123456789101112131415-- 创建user表create table user(id int primary key auto_increment,name varchar(10),age int);-- 创建触发器delimiter // create trigger testUpdate before update on user for each row begin declare total int default 0; -- 创建一个total变量，统计数量 select count(*) from user where name=new.name into total; -- 根据修改之后的name查询出数量赋值给total if old.name!=new.name&amp;&amp;total!=0 -- count!=0并且确实修改了名字表示修改的名字重复 then set new.id=1; -- 名字重复导致主键冲突抛出异常，这样后续的语句就不会执行了 end if; end //delimiter ; 查看触发器查看所有触发器 show triggers [from database] ： 查看当前数据的所有的触发器 show triggers from test \G : 查看test数据库中的所有触发器 show triggers \G ： 有条理的显示所有触发器 查看指定的触发器 如果需要查看指定的触发器，那么可以从information_schema数据库中的triggers表中查询指定的触发器 select * from information_schema.triggers where trigger_name=&quot;testUpdate&quot;\G where后面是条件 删除触发器 drop db.trigger_name : 删除指定数据库中的触发器 db ：数据库的名字 trigger_name ：触发器的名字 触发器执行的顺序 我们建立的数据库一般都是InnoDB数据库，其上建立的表是事务性表，也就是事务安全的。这时，若SQL语句或触发器执行失败，MySQL 会回滚事务，有： 如果 BEFORE 触发器执行失败，SQL 无法正确执行。 SQL 执行失败时，AFTER 型触发器不会触发。 AFTER 类型的触发器执行失败，SQL 会回滚。 NEW 和 OLD 在INSERT 型触发器中，NEW用来表示将要（BEFORE）或已经（AFTER）插入的新数据； 在UPDATE型触发器中，OLD 用来表示将要或已经被修改的原数据，NEW 用来表示将要或已经修改为的新数据； 在 DELETE型触发器中，OLD 用来表示将要或已经被删除的原数据； 使用方式 NEW/OLD.columName : 比如获取更新后的name字段的值 new.name 注意 OLD 是只读的，不可以使用set修改 new是可以修改的，我们可以在触发器中使用set语句修改]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL中的锁]]></title>
      <url>%2F2018%2F06%2F26%2FMySQL%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
      <content type="text"><![CDATA[MySQL中的锁数据库引擎 数据库的引擎分为MyISAM和InnoDB和其他的 不同的数据库引擎默认使用的锁是不同的 MyISAM默认使用的是表级别锁，InnoDB默认使用的是行级锁 我们在使用的时候，一般都是使用InnoDB，支持事务，事务安全等功能 锁的分类 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 InnoDB锁的模式 InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。 行级锁和表级锁本来就有许多不同之处，另外，事务的引入也带来了一些新问题。 默认使用的是行级锁 1.事务（Transaction）及其ACID属性 事务是由一组SQL语句组成的逻辑处理单元，事务具有4属性，通常称为事务的ACID属性。 原性性（Actomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以操持完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 2.并发事务带来的问题 相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持可以支持更多的用户。但并发事务处理也会带来一些问题，主要包括以下几种情况。 更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改保存其更改副本的编辑人员覆盖另一个编辑人员所做的修改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题 脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。 不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。 幻读（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 3.事务隔离级别 在并发事务处理带来的问题中，“更新丢失”通常应该是完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。 “脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。数据库实现事务隔离的方式，基本可以分为以下两种。 一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。 另一种是不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot），并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（ＭultiVersion Concurrency Control，简称MVCC或MCC），也经常称为多版本数据库。 数据库的事务隔离级别越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的，同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。 为了解决“隔离”与“并发”的矛盾，ISO/ANSI SQL92定义了４个事务隔离级别，每个级别的隔离程度不同，允许出现的副作用也不同，应用可以根据自己业务逻辑要求，通过选择不同的隔离级别来平衡＂隔离＂与＂并发＂的矛盾 事务４种隔离级别比较 隔离级别/读数据一致性及允许的并发副作用 读数据一致性 脏读 不可重复读 幻读 未提交读（Read uncommitted） 最低级别，只能保证不读取物理上损坏的数据 是 是 是 已提交度（Read committed） 语句级 否 是 是 可重复读（Repeatable read） 事务级 否 否 是 可序列化（Serializable） 最高级别，事务级 否 否 否 两种行级锁 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁 共享锁好像只读锁，可以允许多个事务同时读这行数据，但是不允许修改（排他锁） 如果一个事务获取共享锁了，那么其他事务只能获取这一行的共享锁，而不能获取这行的排他锁 排他锁（X）：允许获得排他锁的事务更新数据，但是组织其他事务获得相同数据集的共享锁和排他锁。 相当于只写锁，只能同时允许一个事务对该行数据的更新，并且也不允许其他的事务读这行的数据 如果一个事务获取了这行数据的排他锁，那么其他的事务将不能获取这行数据的共享锁和排它锁，只有等待前一个事务释放才有机会获取 对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及及数据集加排他锁（Ｘ） 对于普通SELECT语句，InnoDB不会任何锁；事务可以通过以下语句显示给记录集加共享锁或排锁。 共享锁（Ｓ）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE 排他锁（X）：SELECT * FROM table_name WHERE ... FOR UPDATE 两种表级锁 意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁 意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。 意向锁是InnoDB自动加的，不需用户干预 InnoDB行锁兼容模式 当一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之如果请求不兼容，则该事务就等待锁释放。 当前锁模式/是否兼容/请求锁模式 X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 兼容 冲突 兼容 S 冲突 冲突 兼容 兼容 IS 冲突 兼容 兼容 兼容 InnoDB行锁实现原理 InnoDB行锁是通过给索引项加锁实现的，如果没有索引，InnoDB会通过隐藏的聚簇索引来对记录加锁。 也就是说：如果不通过索引条件检索数据，那么InnoDB将对表中所有数据加锁，实际效果跟表锁一样。 分析 我们知道数据库会为主键id创建唯一性索引，如果一个事务执行select * from user where id=1 for update，那么执行完成之后数据库仅仅是为id=1这行的数据添加排他锁，其他事务对其他行的数据还是可以获取共享锁和排他锁的，即是其他事务还是可以对其他行的数据执行增删改查的。但是对于id=1这行的数据只能select不能更新插入。如果执行了update user set name=&quot;Jack&quot; where id=1，会自动为id=1这行数据添加排他锁，其他的事务对改行数据不能做任何的操作（可以select），但是可以对其他行的数据仍然可以执行操作 此时如果一个事务执行了update user set name=&quot;Jack&quot; where age=22，因为age不是索引，那么会自动添加表级锁锁住user表中的全部数据，那么此时所有的数据在另外一个事务中只能查询了，不能执行更新和插入了 此时如果我们为age添加索引：create index age_index on user(age)，再执行update user set name=&quot;Jack&quot; where age=22，那么此时添加的就是行级锁，仅仅锁住的是age=22的那些行，另外的事务还是可以操作其他行的数据 实例 加入共享锁，where id，id默认是唯一索引 排他锁的例子 使用select * from .... for update 添加排他锁 行锁的三种情形 以下的三种情形都是针对索引项的，不是索引项的会自动使用表级锁锁住全表 Record lock ：对索引项加锁，即锁定一条记录。 Gap lock：对索引项之间的间隙、对第一条记录前的间隙或最后一条记录后的间隙加锁，即锁定一个范围的记录，不包含记录本身 Next-key Lock：锁定一个范围的记录并包含记录本身（上面两者的结合）。 间隙锁（Next-Key锁） 只针对带有区间的操作，比如&gt;30或者&lt;3等 当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制不是所谓的间隙锁（Next-Key锁）。 举例来说，假如emp表中只有101条记录，其empid（主键，唯一索引）的值分别是1,2,…,100,101，下面的SQL： SELECT * FROM emp WHERE empid &gt; 100 FOR UPDATE 是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。 InnoDB使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。 很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。 实例 我们给age添加了索引，那么在一个事务中执行select * from user where age&gt;22 for update 或者update user set name=&quot;Jack&quot; where age&gt;22 ，都会为user表中age&gt;22这个区间的数据添加间隙锁那么只要age的范围在22~positive infinity之间的数据另外一个事务都不可以更新或者插入，在age&lt;=22之间的数据是可以操作的，比如insert，update 什么时候使用表锁 对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个另特殊事务中，也可以考虑使用表级锁。 第一种情况是：事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。 第二种情况是：事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。 当然，应用中这两种事务不能太多，否则，就应该考虑使用ＭyISAＭ表。 在InnoDB下 ，使用表锁要注意以下两点。 （１）使用LOCK TALBES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。 （２）在用LOCAK TABLES对InnoDB锁时要注意，要将AUTOCOMMIT设为0，否则ＭySQL不会给表加锁；事务结束前，不要用UNLOCAK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK产不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁，正确的方式见如下语句。 例如，如果需要写表t1并从表t读，可以按如下做： 12345SET AUTOCOMMIT=0;LOCAK TABLES t1 WRITE, t2 READ, ...;[do something with tables t1 and here];COMMIT;UNLOCK TABLES; 关于死锁 ＭyISAM表锁是deadlock free的，这是因为ＭyISAM总是一次性获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但是在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了InnoDB发生死锁是可能的。 发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并退回，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获取所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。 通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小、以及访问数据库的SQL语句，绝大部分都可以避免。下面就通过实例来介绍几种死锁的常用方法。 （１）在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序为访问表，这样可以大大降低产生死锁的机会。如果两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可能避免。 （２）在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低死锁的可能。 （３）在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应该先申请共享锁，更新时再申请排他锁，甚至死锁。 （４）在REPEATEABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT…ROR UPDATE加排他锁，在没有符合该记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可以避免问题。 （５）当隔离级别为READ COMMITED时，如果两个线程都先执行SELECT…FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第１个线程提交后，第２个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第３个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。 总结对于ＭyISAM的表锁，主要有以下几点（１）共享读锁（S）之间是兼容的，但共享读锁（S）和排他写锁（X）之间，以及排他写锁之间（X）是互斥的，也就是说读和写是串行的。 （２）在一定条件下，ＭyISAM允许查询和插入并发执行，我们可以利用这一点来解决应用中对同一表和插入的锁争用问题。 （３）ＭyISAM默认的锁调度机制是写优先，这并不一定适合所有应用，用户可以通过设置LOW_PRIPORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定LOW_PRIORITY选项来调节读写锁的争用。 （４）由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，ＭyISAM表可能会出现严重的锁等待，可以考虑采用InnoDB表来减少锁冲突。 对于InnoDB表，主要有以下几点 （１）InnoDB的行销是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。 （２）InnoDB间隙锁机制，以及InnoDB使用间隙锁的原因。 （３）在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。 （４）ＭySQL的恢复和复制对InnoDB锁机制和一致性读策略也有较大影响。 （５）锁冲突甚至死锁很难完全避免。 在了解InnoDB的锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括： 尽量使用较低的隔离级别 精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会。 选择合理的事务大小，小事务发生锁冲突的几率也更小。 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁。 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大减少死锁的机会。 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响。 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁。 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。 参考文章 http://www.cnblogs.com/chenqionghe/p/4845693.html http://www.cnblogs.com/chenqionghe/p/4845693.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql存储过程和存储函数]]></title>
      <url>%2F2018%2F06%2F26%2FMysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%92%8C%E5%AD%98%E5%82%A8%E5%87%BD%E6%95%B0%2F</url>
      <content type="text"><![CDATA[Mysql存储过程和存储函数存储过程的好处 增强SQL语言的功能和灵活性：存储过程可以用控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 标准组件式编程：存储过程被创建后，可以在程序中被多次调用，而不必重新编写该存储过程的SQL语句。而且数据库专业人员可以随时对存储过程进行修改，对应用程序源代码毫无影响。 较快的执行速度：如果某一操作包含大量的Transaction-SQL代码或分别被多次执行，那么存储过程要比批处理的执行速度快很多。因为存储过程是预编译的。在首次运行一个存储过程时查询，优化器对其进行分析优化，并且给出最终被存储在系统表中的执行计划。而批处理的Transaction-SQL语句在每次运行时都要进行编译和优化，速度相对要慢一些。 减少网络流量：针对同一个数据库对象的操作（如查询、修改），如果这一操作所涉及的Transaction-SQL语句被组织进存储过程，那么当在客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而大大减少网络流量并降低了网络负载。 作为一种安全机制来充分利用：通过对执行某一存储过程的权限进行限制，能够实现对相应的数据的访问权限的限制，避免了非授权用户对数据的访问，保证了数据的安全。 存储函数创建存储函数 在Mysql中有许多已经存在的存储函数，比如CONCAT(..),LENGTH(str)。但是我们也可以自己定义存储函数。 格式如下： 12345678910delimiter // -- 指定分割符 create function fun_name() returns type -- type是执行存储函数返回的类型 begin -- 执行其他的语句 return (); -- 返回的数据 end //delimiter ; -- 指定创建结束 returns type : 指定存储函数返回的类型，比如returns char(50),returns int 存储函数有且只有一个返回值 return () : 存储函数的返回值，这里的返回值类型需要和returns type中的类型一致，如果不一致会强制转换 return (select name from user where id=1); 下面我们创建一个存储函数，返回user表中的id=1的name值 12345678delimiter // create function selectUserById() returns varchar(50) begin return (select name from user where id=1); end // delimiter ; 指定参数 在存储函数创建的时候还可以指定参数，这个参数是用户调用的时候输入的。 存储函数中的参数默认是IN参数，而存储过程中的参数可以是IN、OUT、INOUT 直接使用parameter 类型指定即可，如果有多个参数可以使用,分割 在调用的时候直接使用select funName(parmeter1,....);即可 12345678delimiter // create function selectUserById(uid int) returns varchar(50) begin return (select name from user where id=uid); end // delimiter ; 调用存储函数 存储函数是依赖数据库的，因此我们需要在指定的数据库中调用，或者前面指定数据库的名称 select selectUserById(); : 直接在存储函数所在数据库中调用 select dbName.selectUserById(); : 直接使用数据库的名称调用 删除存储函数 drop function selectUserById; ：直接在存储函数所在数据库中直接删除存储函数 drop function dbName.selectUserById; ：使用数据库名称删除存储函数 查看存储函数状态 格式：show function status [like pattern] ： 查看存储函数的状态 show function status \G : 查看所有的存储函数状态,\G是一种特定格式的输出 show function status like &#39;select%&#39;\G ：查看select开头的存储函数状态，\G是一种特定格式的输入。 查看存储函数的定义 格式：show create function dbName.funName show create function test.selectUserById \G; ：查询test数据库中的存储函数selectUserById的定义，\G是一种特定的输出格式 修改存储函数 变量的使用 变量的作用范围是begin.....end程序中 定义变量 格式：declare var_name,.... type [default value] declare age int default 22 ：定义一个局部变量age，类型为int，默认值为22 declare var1,var2,var3 int ： 定义三个局部变量，类型为int 全部变量的声明一定要在赋值的前面，否则报错 定义用户变量 用户变量以@开头 set @pin=10 为变量赋值 格式：set var1=value1,[var2=value2,....] set age=33; ： 设置age的值为33 set var1=22,var2=33: 同时设置多个值 123declare var1,var2,var3 int;set var1=22,var2=33;set var3=var1+var2; 使用select col_name[,...] into var_name[,....] table_expr : 使用select查询得到的结果赋值给变量 这个select把选定的列的值直接赋值给对应位置的变量 table_expr: 可以是表的查询条件，其中包含from 表名 123declare uname varchar(10); -- 定义变量unamedeclare uage int; -- 定义变量uageselect name,age into uname,uage from user where id=1; -- 将id=1的用户姓名和年龄赋值给变量 实例在存储函数中使用 在存储函数中定义局部变量，并且获取输出 12345678910delimiter // create function selectUserById(uid int) returns varchar(50) begin declare uname varchar(50); select name into uname from user where id=uid; return uname; end // delimiter ; 在存储过程中使用123456789101112delimiter // create procedure selectUserById(IN uid int) begin declare offest,count int; -- 定义偏移量 set offest=0,count=2; -- 赋值 if uid is not null -- 如果uid不为null，按照id查询 then select * from user where id=uid; -- 按照id查询 else select * from user limit offest,count; -- 否则uid为null，按照分页查询前面两个 end if; end //delimiter ; call selectUserById(1); ： 查询id=1的用户信息 call selectUserById(null); ：查询所有的用户信息，显示前面两个 注释 MySQL存储过程可使用两种风格的注释： 双杠：–，该风格一般用于单行注释 C风格： 一般用于多行注释 流程控制标签的使用 在begin和end之间使用 IF - THEN - ELSEIF - ELSE -ENDIF 格式 1234567begin if expression -- 判断条件 then .... ; -- 条件成立执行 elseif .....; -- 其他条件 else ..... ; -- 条件相反执行 endif; -- 结束ifend 可以不是成对出现，比如只有if，或者if-else 如果没有else，那么可以省略，比如if - then - endif 判断相等使用= 实例 123456789101112delimiter // create procedure selectUserById(IN uid int) begin declare offest,count int; -- 定义偏移量 set offest=0,count=2; -- 赋值 if uid is not null -- 如果uid不为null，按照id查询 then select * from user where id=uid; -- 按照id查询 else select * from user limit offest,count; -- 否则uid为null，按照分页查询前面两个 end if; end //delimiter ; CASE - WHEN - THEN - ELSE - END CASE 这个和java中的switch-case-default相似 格式： 1234567case expr when value1 then ....; when value2 then .....; when......; .... else .......;end case; 实例 创建一个存储过程，使用case 1234567891011121314delimiter // create procedure deleteUserById(IN uid int) begin case uid -- uid做选择 when 1 -- uid==1 then delete from user where id=1; when 2 -- uid==2 then delete from user where id=2; else delete from user; -- 删除全部 end case; end; //delimiter ; LOOP - ENDLOOP LOOP只是创建一个循环执行的过程，并不进行条件判断，这个和while不一样，不需要判断条件，如果不跳出，那么将会永远的执行的下去。但是我们可以使用leave跳出循环 格式： 123[LOOP_LABEL]:LOOP statement;END LOOP [LOOP_LABEL]; 实例 执行这个语句可以插入9条数据，如果i&gt;=10跳出循环 1234567891011121314delimiter // create procedure insertUserByName(IN uname varchar(50)) begin declare i int default 0; add_loop:loop -- 开始循环 set i=i+1; -- id++操作 insert into user(name) values(uname); -- 插入语句 if i&gt;=10 then leave add_loop; -- 使用leave跳出循环 end if; end loop add_loop; -- 结束循环 end //delimiter ; LEAVE 和循环一起使用，用于退出循环控制，见上面的例子 ITERATE 格式：iterate label iterate只可以出现在LOOP，REPEAT，WHIE语句内，表示再次循环的意思，label表示循环的标志 实例 如果p&lt;10重复执行p++ 12345678910111213141516delimiter // create procedure doiterate() begin declare p int default 0; -- 定义局部变量 my_loop:loop set p=p+1; -- p++ if p&lt;10 then iterate my_loop; -- 继续执行前面的循环的语句，p++ elseif p&gt;20 then leave my_loop; end if select &quot;p在10到20之间&quot; -- 输出语句 end loop my_loop; end //delimiter ; REPEAT 这个也是循环语句，相当于do-while 格式： 1234[repeat_loop]: repeat statement_list; until exper -- 没有分号 end repeat; 实例 123456789101112delimiter // create procedure dorepeat() begin declare p int default 0; -- 定义局部变量 my_loop:repeat set p=p+1; select p; until p&gt;10 -- 当p&gt;10的时候循环结束 end repeat my_loop; end //delimiter ; WHILE 这个和REPEAT不同，先进行判断，然后才执行语句 格式： 123[while_label]:while expr do statement_list; end while [while_lable]; 实例 12345678910delimiter // create procedure dowhile() begin declare p int default 0; -- 定义局部变量 my_loop:while p&lt;10 do -- 满足条件才执行 set p=p+1; -- p++ end while my_loop; -- 结束循环 end //delimiter ; 存储过程 存储过程没有返回值 创建存储过程 格式： 1234567delimiter //create procedure p_name([IN,OUT,INOUT]parameter 类型.....) begin -- 执行功能 end //delimiter ; 参数 存储过程根据需要可能会有输入、输出、输入输出参数，如果有多个参数用”,”分割开。MySQL存储过程的参数用在存储过程的定义，共有三种参数类型,IN,OUT,INOUT: IN参数的值必须在调用存储过程时指定，在存储过程中修改该参数的值不能被返回，为默认值 OUT:该值可在存储过程内部被改变，并可返回 INOUT:调用时指定，并且可被改变和返回 过程体 过程体的开始与结束使用BEGIN与END进行标识。 实例 定义一个根据id查询的查询用户信息的存储过程，这里的id是由用户输入的，因此可以使用IN参数 1234567delimiter // create procedure selectUserById(IN uid int) begin select * from user where id=uid; end //delimiter ; 调用存储过程 格式：call procedure_name(...) call selectUserById(1); : 直接在当前的数据库中调用存储过程selectUserById call db_name.selectUsrById(1) : 指定数据库的名字调用 查看存储过程的状态 格式：show procedure status like pattern \G show procedure status like &quot;select%&quot;\G : 查看select开头的存储过程状态 show procedure status \G : 查看所有的存储过程状态 查询的结果如下： 12345678910111213*************************** 1. row *************************** Db: test -- 数据库名称 Name: selectUserById -- 存储过程的名字 Type: PROCEDURE Definer: root@localhost Modified: 2018-06-25 22:25:44 Created: 2018-06-25 22:25:44 Security_type: DEFINER Comment: character_set_client: utf8collation_connection: utf8_general_ci Database Collation: utf8_general_ci1 row in set (0.01 sec) 查看存储过程的定义 格式：show create procedure db.pro_name show create procedure test.selectUserById\G : 查询数据库test中存储过程的定义 返回的结果如下： 12345678910*************************** 1. row *************************** Procedure: selectUserById sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `selectUserById`(IN uid int)beginselect * from user where id=uid;endcharacter_set_client: utf8collation_connection: utf8_general_ci Database Collation: utf8_general_ci 删除存储过程 格式drop procedure pro_name drop procedure selectUserById : 删除当前数据库的selectUserById的存储过程 drop procedure test.selectUserById;: 删除test数据库的selectUserById的存储过程 游标cursor 在面对大量的数据的时候，游标能够一行一行的读取数据 声明游标 格式：declare cursor_name cursor for select_statement cursor_name : 游标的变量名称 select_statement ：表示select语句，用于返回一个结果集给游标 比如： declare users cursor for select name,age from user; 打开游标 格式：open cursor_name; open users 使用游标获取一行数据 格式：fetch cursor_name into var_name[,var_name,...] cursor_name：表示游标的名称 var_name ： 表示将select语句查询到的一行信息存入到该参数中，var_name必须在声明游标之前定义好 比如： fetch user into uname,uage 关闭游标 格式：close cursor_name 实例 使用游标获取user表中的一行数据 123456789101112131415delimiter // create procedure selectOneUser() begin declare uname varchar(50); -- 定义uname存储 declare uage int; -- 定义uage存储 declare users cursor for select name,age from user; -- 声明游标 open users; -- 打开游标 fetch users into uname,uage; -- 获取一行数据到存储到uname和uage中 select uname as name,uage as age; -- 输出一行的结果 close users; -- 关闭游标 end //delimiter ;call selectOneUser(); -- 调用存储过程，此时只是输出第一行的数据 使用循环获取所有的数据 这里使用循环获取，首先需要使用select count(*)获取总数 12345678910111213141516171819202122delimiter // create procedure selectUsers() begin declare uname varchar(50); -- 定义uname存储 declare uage int; -- 定义uage存储 declare total int default 0; -- 定义count，这个用来统计总数 declare i int default 1; -- 用来循环 declare users cursor for select name,age from user; -- 声明游标 select count(*) from user into total; -- 查询总数 open users; -- 打开游标 -- 开始循环遍历 my_loop:while i&lt;=total do set i=i+1; -- i++ fetch users into uname,uage; -- 获取一行数据到存储到uname和uage中 select uname as name,uage as age; -- 输出一行的结果 end while my_loop; close users; -- 关闭游标 end //delimiter ;call selectUsers(); -- 调用存储过程，获取全部数据 使用HANDLER判断游标是否还有元素 continue HANDLER for not found 当游标中没有值的时候就会指定返回的值 1234567891011121314151617181920delimiter // create procedure selectUsers() begin declare uname varchar(50); -- 定义uname存储 declare uage int; -- 定义uage存储 declare flag int default 1; -- 创建结束游标的标志，默认值为1 declare users cursor for select name,age from user; -- 声明游标 declare continue HANDLER for not found set flag=0; -- 指定游标结束时的返回值 open users; -- 打开游标 my_loop:loop if flag=0 -- 这里使用=，否则报错 then leave my_loop; -- 跳出循环 end if; fetch users into uname,uage; -- 获取一行数据到存储到uname和uage中 select uname as name,uage as age; -- 输出一行的结果 end loop my_loop; close users; -- 关闭游标 end //delimiter ; 存储过程和存储函数的区别 存储函数可以使用return返回一个返回值，但是存储过程不能有返回值，如果需要实现返回的功能，可以使用OUT参数实现返回 存储函数只能有输入参数，而且不能带in, 而存储过程可以有多个in,out,inout参数。 存储过程中的语句功能更强大，存储过程可以实现很复杂的业务逻辑，而函数有很多限制，如不能在函数中使用insert,update,delete,create等语句；存储函数只完成查询的工作，可接受输入参数并返回一个结果，也就是函数实现的功能针对性比较强。 存储过程可以调用存储函数。但函数不能调用存储过程。 存储过程一般是作为一个独立的部分来执行(call调用)。而函数可以作为查询语句的一个部分来调用。 总结 存储过程中可以使用call调用其他的存储过程，但是不能使用drop语句删除其他的存储过程 存储过程的参数不要和数据库表的字段相同，否则将出现无法预料的结果 参考文章 https://www.cnblogs.com/mark-chan/p/5384139.html ​ 12345678910delimiter // create function selectUserById() returns varchar(50) begin declare uname varchar(50); select name into uname from user where id=2; return uname; end // delimiter ;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之Callable、Future、FutureTask]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BCallable%E3%80%81Future%E3%80%81FutureTask%2F</url>
      <content type="text"><![CDATA[并发编程之Callable、Future、FutureTask 在前面的文章中我们讲述了创建线程的2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。 这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。 如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。 而自从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果。 Callable与Runnable 先说一下java.lang.Runnable吧，它是一个接口，在它里面只声明了一个run()方法 由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。 123public interface Runnable &#123; public abstract void run();&#125; Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call() 可以看到，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本： 123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); Future Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 Future类位于java.util.concurrent包下，它是一个接口： 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 三种功能 1）判断任务是否完成； 2）能够中断任务； 3）能够获取任务执行结果。 FutureTask 我们先来看一下FutureTask的实现： 1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; FutureTask类实现了RunnableFuture接口，我们看一下RunnableFuture接口的实现： 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 构造器 事实上，FutureTask是Future接口的一个唯一实现类。 1234public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125; 实例使用Callable+Future获取执行结果12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); Future&lt;Integer&gt; result = executor.submit(task); executor.shutdown(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+result.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125; 使用Callable+FutureTask获取执行结果123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Test &#123; public static void main(String[] args) &#123; //第一种方式 ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); executor.submit(futureTask); executor.shutdown(); //第二种方式，注意这种方式和第一种方式效果是类似的，只不过一个使用的是ExecutorService，一个使用的是Thread /*Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); Thread thread = new Thread(futureTask); thread.start();*/ try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之线程池的使用]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[并发编程之线程池的使用 转载自http://www.cnblogs.com/dolphin0520/p/3932921.html https://blog.csdn.net/wanghao_0206/article/details/76460877 Java中的ThreadPoolExecutor类 java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： 12345678910111213141516&gt; public class ThreadPoolExecutor extends AbstractExecutorService &#123;&gt; .....&gt; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,&gt; BlockingQueue&lt;Runnable&gt; workQueue);&gt; &gt; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,&gt; BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory);&gt; &gt; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,&gt; BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler);&gt; &gt; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,&gt; BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler);&gt; ...&gt; &#125;&gt; &gt; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 12345678&gt; TimeUnit.DAYS; //天&gt; TimeUnit.HOURS; //小时&gt; TimeUnit.MINUTES; //分钟&gt; TimeUnit.SECONDS; //秒&gt; TimeUnit.MILLISECONDS; //毫秒&gt; TimeUnit.MICROSECONDS; //微妙&gt; TimeUnit.NANOSECONDS; //纳秒&gt; &gt; workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： SynchronousQueue ArrayBlockingQueue LinkedBlockingQueue threadFactory：线程工厂，主要用来创建线程 handler：表示当拒绝处理任务时的策略，有以下四种取值： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常 ThreadPoolExecutor.DiscardOldestPolicy :丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 使用实例1234567891011121314151617181920212223242526272829303132333435public class Test &#123; public static void main(String[] args) &#123; //指定各种参数和缓存队列 ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); for(int i=0;i&lt;15;i++)&#123; MyTask myTask = new MyTask(i); executor.execute(myTask); //执行线程 System.out.println("线程池中线程数目："+executor.getPoolSize()+"，队列中等待执行的任务数目："+ executor.getQueue().size()+"，已执行玩别的任务数目："+executor.getCompletedTaskCount()); &#125; executor.shutdown(); //终止执行，等待缓存队列中的线程全部执行完成之后才会终止 &#125;&#125; //线程class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println("正在执行task "+taskNum); try &#123; Thread.currentThread().sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("task "+taskNum+"执行完毕"); &#125;&#125; 从执行结果可以看出，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。 使用工具类Executors 不过在java doc中，并不提倡我们直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池 几个静态方法可以创建ExecutorService实例 123Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor(); //创建容量为1的缓冲池Executors.newFixedThreadPool(int); //创建固定容量大小的缓冲池 源码如下 12345678910111213141516public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 从它们的具体实现来看，它们实际上也是调用了ThreadPoolExecutor，只不过参数都已配置好 newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue； newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue； newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 实际中，如果Executors提供的三个静态方法能满足要求，就尽量使用它提供的三个方法，因为自己去手动配置ThreadPoolExecutor的参数有点麻烦，要根据实际任务的类型和数量来进行配置。 另外，如果ThreadPoolExecutor达不到要求，可以自己继承ThreadPoolExecutor类进行重写。 使用实例12345678910111213141516171819202122public class TestThreadFactory &#123; public static void main(String[] args) &#123; MyThread thread=new MyThread(); //创建MyThread //创建固定大小的线程池 ExecutorService pService=Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 11; i++) &#123; pService.execute(new Thread(thread)); //在线程池中获取线程并且执行 &#125; pService.shutdown(); //执行完毕之后关闭 &#125;&#125;class MyThread implements Runnable&#123; private Integer count=0; public void run() &#123; synchronized (this) &#123; System.out.println("线程池开始使用"); System.out.println("执行其他的操作"); System.out.println(count++); &#125; &#125;&#125; AbstractExecutorService AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 ExecutorService 继承Executor接口 源码 12345678910111213141516171819202122public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; Executor 源码 123public interface Executor &#123; void execute(Runnable command);&#125; ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor的关系 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法： execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果（Future相关内容将在下一篇讲述）。 shutdown()和shutdownNow()是用来关闭线程池的。 深入剖析线程池实现原理线程池状态 在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态： 12345volatile int runState; static final int RUNNING = 0;static final int SHUTDOWN = 1;static final int STOP = 2;static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性；下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 任务的执行 在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量： 12345678910111213141516171819private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 线程池中的线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 任务缓存队列及排队策略 在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue&lt;Runnable&gt;，通常可以取下面三种类型： ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小 LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务 任务拒绝策略 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： 1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 线程池关闭 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize() setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java内存模型]]></title>
      <url>%2F2018%2F06%2F26%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[Java内存模型 Java内存模型规范了Java虚拟机与计算机内存是如何协同工作的。Java虚拟机是一个完整的计算机的一个模型，因此这个模型自然也包含一个内存模型——又称为Java内存模型。 如果你想设计表现良好的并发程序，理解Java内存模型是非常重要的。Java内存模型规定了如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量。 原始的Java内存模型存在一些不足，因此Java内存模型在Java1.5时被重新修订。这个版本的Java内存模型在Java8中人在使用。 Java内存模型内部原理 Java内存模型把Java虚拟机内部划分为线程栈和堆。这张图演示了Java内存模型的逻辑视图。 每一个运行在Java虚拟机里的线程都拥有自己的线程栈。这个线程栈包含了这个线程调用的方法当前执行点相关的信息。一个线程仅能访问自己的线程栈。一个线程创建的本地变量对其它线程不可见，仅自己可见。即使两个线程执行同样的代码，这两个线程任然在在自己的线程栈中的代码来创建本地变量。因此，每个线程拥有每个本地变量的独有版本。 所有原始类型的本地变量都存放在线程栈上，因此对其它线程不可见。一个线程可能向另一个线程传递一个原始类型变量的拷贝，但是它不能共享这个原始类型变量自身。 堆上包含在Java程序中创建的所有对象，无论是哪一个对象创建的。这包括原始类型的对象版本。如果一个对象被创建然后赋值给一个局部变量，或者用来作为另一个对象的成员变量，这个对象任然是存放在堆上。 下面这张图演示了调用栈和本地变量存放在线程栈上，对象存放在堆上。 一个本地变量可能是原始类型，在这种情况下，它总是“呆在”线程栈上。 一个本地变量也可能是指向一个对象的一个引用。在这种情况下，引用（这个本地变量）存放在线程栈上，但是对象本身存放在堆上。 线程栈中存放的是堆上对象的引用，我们可以通过线程栈中的引用访问到这个对象 一个对象可能包含方法，这些方法可能包含本地变量。这些本地变量任然存放在线程栈上，即使这些方法所属的对象存放在堆上。 放在堆上的对象可以有多个方法，如果这个方法中存在本地变量，那么这些本地变量都是存放在线程栈中的 一个对象的成员变量可能随着这个对象自身存放在堆上。不管这个成员变量是原始类型还是引用类型。 静态成员变量跟随着类定义一起也存放在堆上。 一个堆上的对象中如果存在静态成员变量，那么这个静态成员变量也是存放在堆上 存放在堆上的对象可以被所有持有对这个对象引用的线程访问。当一个线程可以访问一个对象时，它也可以访问这个对象的成员变量。如果两个线程同时调用同一个对象上的同一个方法，它们将会都访问这个对象的成员变量，但是每一个线程都拥有这个本地变量的私有拷贝。 下图演示了上面提到的点： 两个线程拥有一些列的本地变量。其中一个本地变量（Local Variable 2）执行堆上的一个共享对象（Object 3）。这两个线程分别拥有同一个对象的不同引用。这些引用都是本地变量，因此存放在各自线程的线程栈上。这两个不同的引用指向堆上同一个对象。 注意，这个共享对象（Object 3）持有Object2和Object4一个引用作为其成员变量（如图中Object3指向Object2和Object4的箭头）。通过在Object3中这些成员变量引用，这两个线程就可以访问Object2和Object4。 这张图也展示了指向堆上两个不同对象的一个本地变量。在这种情况下，指向两个不同对象的引用不是同一个对象。理论上，两个线程都可以访问Object1和Object5，如果两个线程都拥有两个对象的引用。但是在上图中，每一个线程仅有一个引用指向两个对象其中之一。 因此，什么类型的Java代码会导致上面的内存图呢？如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041public class MyRunnable implements Runnable() &#123; public void run() &#123; methodOne(); &#125; public void methodOne() &#123; int localVariable1 = 45; MySharedObject localVariable2 = MySharedObject.sharedInstance; //... do more with local variables. methodTwo(); &#125; public void methodTwo() &#123; Integer localVariable1 = new Integer(99); //... do more with local variable. &#125;&#125;public class MySharedObject &#123; //static variable pointing to instance of MySharedObject public static final MySharedObject sharedInstance = new MySharedObject(); //member variables pointing to two objects on the heap public Integer object2 = new Integer(22); public Integer object4 = new Integer(44); public long member1 = 12345; public long member1 = 67890;&#125; 如果两个线程同时执行run()方法，就会出现上图所示的情景。run()方法调用methodOne()方法，methodOne()调用methodTwo()方法。 methodOne()声明了一个原始类型的本地变量和一个引用类型的本地变量。 每个线程执行methodOne()都会在它们对应的线程栈上创建localVariable1和localVariable2的私有拷贝。localVariable1变量彼此完全独立，仅“生活”在每个线程的线程栈上。一个线程看不到另一个线程对它的localVariable1私有拷贝做出的修改。 每个线程执行methodOne()时也将会创建它们各自的localVariable2拷贝。然而，两个localVariable2的不同拷贝都指向堆上的同一个对象。代码中通过一个静态变量设置localVariable2指向一个对象引用。仅存在一个静态变量的一份拷贝，这份拷贝存放在堆上。因此，localVariable2的两份拷贝都指向由MySharedObject指向的静态变量的同一个实例。MySharedObject实例也存放在堆上。它对应于上图中的Object3。 注意，MySharedObject类也包含两个成员变量。这些成员变量随着这个对象存放在堆上。这两个成员变量指向另外两个Integer对象。这些Integer对象对应于上图中的Object2和Object4. 注意，methodTwo()创建一个名为localVariable的本地变量。这个成员变量是一个指向一个Integer对象的对象引用。这个方法设置localVariable1引用指向一个新的Integer实例。在执行methodTwo方法时，localVariable1引用将会在每个线程中存放一份拷贝。这两个Integer对象实例化将会被存储堆上，但是每次执行这个方法时，这个方法都会创建一个新的Integer对象，两个线程执行这个方法将会创建两个不同的Integer实例。methodTwo方法创建的Integer对象对应于上图中的Object1和Object5。 还有一点，MySharedObject类中的两个long类型的成员变量是原始类型的。因为，这些变量是成员变量，所以它们任然随着该对象存放在堆上，仅有本地变量存放在线程栈上。 硬件内存架构 现代硬件内存模型与Java内存模型有一些不同。理解内存模型架构以及Java内存模型如何与它协同工作也是非常重要的。这部分描述了通用的硬件内存架构，下面的部分将会描述Java内存是如何与它“联手”工作的。 下面是现代计算机硬件架构的简单图示： 一个现代计算机通常由两个或者多个CPU。其中一些CPU还有多核。从这一点可以看出，在一个有两个或者多个CPU的现代计算机上同时运行多个线程是可能的。每个CPU在某一时刻运行一个线程是没有问题的。这意味着，如果你的Java程序是多线程的，在你的Java程序中每个CPU上一个线程可能同时（并发）执行。 每个CPU都包含一系列的寄存器，它们是CPU内内存的基础。CPU在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为CPU访问寄存器的速度远大于主存。 每个CPU可能还有一个CPU缓存层。实际上，绝大多数的现代CPU都有一定大小的缓存层。CPU访问缓存层的速度快于访问主存的速度，但通常比访问内部寄存器的速度还要慢一点。一些CPU还有多层缓存，但这些对理解Java内存模型如何和内存交互不是那么重要。只要知道CPU中可以有一个缓存层就可以了。 一个计算机还包含一个主存。所有的CPU都可以访问主存。主存通常比CPU中的缓存大得多。 通常情况下，当一个CPU需要读取主存时，它会将主存的部分读到CPU缓存中。它甚至可能将缓存中的部分内容读到它的内部寄存器中，然后在寄存器中执行操作。当CPU需要将结果写回到主存中去时，它会将内部寄存器的值刷新到缓存中，然后在某个时间点将值刷新回主存。 当CPU需要在缓存层存放一些东西的时候，存放在缓存中的内容通常会被刷新回主存。CPU缓存可以在某一时刻将数据局部写到它的内存中，和在某一时刻局部刷新它的内存。它不会再某一时刻读/写整个缓存。通常，在一个被称作“cache lines”的更小的内存块中缓存被更新。一个或者多个缓存行可能被读到缓存，一个或者多个缓存行可能再被刷新回主存。 Java内存模型和硬件内存架构之间的桥接 上面已经提到，Java内存模型与硬件内存架构之间存在差异。硬件内存架构没有区分线程栈和堆。对于硬件，所有的线程栈和堆都分布在主内中。部分线程栈和堆可能有时候会出现在CPU缓存中和CPU内部的寄存器中。如下图所示： 当对象和变量被存放在计算机中各种不同的内存区域中时，就可能会出现一些具体的问题。主要包括如下两个方面： 线程对共享变量修改的可见性 当读，写和检查共享变量时出现race conditions 下面我们专门来解释以下这两个问题。 共享对象可见性 如果两个或者更多的线程在没有正确的使用volatile声明或者同步的情况下共享一个对象，一个线程更新这个共享对象可能对其它线程来说是不接见的。 想象一下，共享对象被初始化在主存中。跑在CPU上的一个线程将这个共享对象读到CPU缓存中。然后修改了这个对象。只要CPU缓存没有被刷新会主存，对象修改后的版本对跑在其它CPU上的线程都是不可见的。这种方式可能导致每个线程拥有这个共享对象的私有拷贝，每个拷贝停留在不同的CPU缓存中。 下图示意了这种情形。跑在左边CPU的线程拷贝这个共享对象到它的CPU缓存中，然后将count变量的值修改为2。这个修改对跑在右边CPU上的其它线程是不可见的，因为修改后的count的值还没有被刷新回主存中去。 解决这个问题你可以使用Java中的volatile关键字。volatile关键字可以保证直接从主存中读取一个变量，如果这个变量被修改后，总是会被写回到主存中去。 Race Conditions 如果两个或者更多的线程共享一个对象，多个线程在这个共享对象上更新变量，就有可能发生race conditions。 想象一下，如果线程A读一个共享对象的变量count到它的CPU缓存中。再想象一下，线程B也做了同样的事情，但是往一个不同的CPU缓存中。现在线程A将count加1，线程B也做了同样的事情。现在count已经被增在了两个，每个CPU缓存中一次。 如果这些增加操作被顺序的执行，变量count应该被增加两次，然后原值+2被写回到主存中去。 然而，两次增加都是在没有适当的同步下并发执行的。无论是线程A还是线程B将count修改后的版本写回到主存中取，修改后的值仅会被原值大1，尽管增加了两次。 下图演示了上面描述的情况： 解决这个问题可以使用Java同步块。一个同步块可以保证在同一时刻仅有一个线程可以进入代码的临界区。同步块还可以保证代码块中所有被访问的变量将会从主存中读入，当线程退出同步代码块时，所有被更新的变量都会被刷新回主存中去，不管这个变量是否被声明为volatile。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之线程管理]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[并发编程之线程管理线程的未捕获异常与监控 如果线程的run方法抛出异常未被铺货（Uncaught Exception），那么随着run方法的退出，相应的线程也会提前终止。对于线程的这种异常终止，我们如何得知并做出可能的补救动作，例如重新创建并启动一个替代线程。 Jdk中使用UncaughtExceptionHandler接口实现了对线程的异常信息的监控和处理 其中有一个uncaughtException(Thread a, Throwable e)方法，在这里我们可以将线程抛出的异常信息记录到日志中，或者开启一个替代线程继续提供服务 实例12345678910111213141516171819202122232425262728293031323334353637383940public class ThreadTest &#123; public static void main(String[] args) &#123; ErrHandler handle = null; ThreadA a = null; a = new ThreadA(); //创建线程对象 handle = new ErrHandler(); //创建UncaughtExceptionHandler a.setUncaughtExceptionHandler((UncaughtExceptionHandler) handle); a.start(); //启动 &#125; &#125; /** * 自定义的一个UncaughtExceptionHandler */class ErrHandler implements UncaughtExceptionHandler &#123; /** * 这里可以做任何针对异常的处理,比如记录日志等等 * @param a : 抛出异常的线程对象 * @param e : 抛出的异常信息，可以获取异常信息 */ public void uncaughtException(Thread a, Throwable e) &#123; //做一些日志管理 System.out.println("This is:" + a.getName() + ",Message:" + e.getMessage()); //开启一个另外的线程提供服务 System.out.println("现在执行另外一个替代线程提供服务......"); &#125;&#125; /** * 拥有UncaughtExceptionHandler的线程 */class ThreadA extends Thread &#123; public void run() &#123; double i = 12 / 0;// 抛出异常的地方 &#125;&#125; 线程工厂 http://ifeve.com/thread-management-13/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之信号量]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8F%2F</url>
      <content type="text"><![CDATA[并发编程之信号量详解1、Semaphore可以控同时访问的线程个数 2、Semaphore类位于java.util.concurrent包下，它提供了2个构造器： 12345678 //参数permits表示许可数目，即同时可以允许多少线程进行访问public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;//这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可public Semaphore(int permits, boolean fair) &#123; sync = (fair)? new FairSync(permits) : new NonfairSync(permits);&#125; 3、重要方法，acquire()、release()方法： acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可 release()用来释放许可。注意，在释放许可之前，必须先获获得许可 这4个方法都会被阻塞 1234public void acquire() throws InterruptedException &#123; &#125; //获取一个许可public void acquire(int permits) throws InterruptedException &#123; &#125; //获取permits个许可public void release() &#123; &#125; //释放一个许可public void release(int permits) &#123; &#125; //释放permits个许可 不阻塞的方法如下： 12345678//尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire() &#123; &#125;; //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(int permits) &#123; &#125;; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; 通过availablePermits()方法得到可用的许可数目 举例 我们知道读锁可以允许多个线程同时进行读取，我们可以使用信号量来限制线程个数，如下 12345678910111213141516171819202122232425262728293031323334public class TestSemaphore &#123; private static final Semaphore semaphore=new Semaphore(5,true); //创建5个信号量同时用与读文件 private static final ReentrantReadWriteLock rwLock= new ReentrantReadWriteLock(); private static final Lock rLock=rwLock.readLock(); //获取读锁 public static void main(String[] args) &#123; //执行10个线程，通过信号量控制，只能5个线程5个线程的执行 for (int i = 0; i &lt; 10; i++) &#123; MyThread thread=new MyThread(); thread.setName("线程"+(i+1)); thread.start(); &#125; &#125; static class MyThread extends Thread&#123; @Override public void run() &#123; reader(); &#125; //读方法 public void reader()&#123; rLock.lock(); //获取读锁 try &#123; semaphore.acquire(); //获取信号量，信号量-1，如果没有成功获取，那么阻塞 System.out.println(this.getName()+"正在读文件"); Thread.sleep(1000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; semaphore.release(); //释放信号量 rLock.unlock(); //释放锁 &#125; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之阻塞队列]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
      <content type="text"><![CDATA[并发编程之阻塞队列1. 什么是阻塞队列阻塞队列（BlockingQueue）是 Java 5 并发新特性中的内容，阻塞队列的接口是 java.util.concurrent.BlockingQueue，它提供了两个附加操作：当队列中为空时，从队列中获取元素的操作将被阻塞；当队列满时，向队列中添加元素的操作将被阻塞。 阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器。 阻塞队列提供了四种操作方法： 抛出异常：当队列满时，再向队列中插入元素，则会抛出IllegalStateException异常。当队列空时，再向队列中获取元素，则会抛出NoSuchElementException异常。 返回特殊值：当队列满时，向队列中添加元素，则返回false，否则返回true。当队列为空时，向队列中获取元素，则返回null，否则返回元素。 一直阻塞：当阻塞队列满时，如果生产者向队列中插入元素，则队列会一直阻塞当前线程，直到队列可用或响应中断退出。当阻塞队列为空时，如果消费者线程向阻塞队列中获取数据，则队列会一直阻塞当前线程，直到队列空闲或响应中断退出。 超时退出：当队列满时，如果生产线程向队列中添加元素，则队列会阻塞生产线程一段时间，超过指定的时间则退出返回false。当队列为空时，消费线程从队列中移除元素，则队列会阻塞一段时间，如果超过指定时间退出返回null。 2. Java中的阻塞队列JDK7提供了7个阻塞队列。分别是 下面分别简单介绍一下： ArrayBlockingQueue：是一个用数组实现的有界阻塞队列，此队列按照先进先出（FIFO）的原则对元素进行排序。支持公平锁和非公平锁。【注：每一个线程在获取锁的时候可能都会排队等待，如果在等待时间上，先获取锁的线程的请求一定先被满足，那么这个锁就是公平的。反之，这个锁就是不公平的。公平的获取锁，也就是当前等待时间最长的线程先获取锁】 LinkedBlockingQueue：一个由链表结构组成的有界队列，此队列的长度为Integer.MAX_VALUE。此队列按照先进先出的顺序进行排序。既可以实现无界队列也可以实现无界队列 PriorityBlockingQueue： 一个支持线程优先级排序的无界队列，默认自然序进行排序，也可以自定义实现compareTo()方法来指定元素排序规则，不能保证同优先级元素的顺序。 DelayQueue： 一个实现PriorityBlockingQueue实现延迟获取的无界队列，在创建元素时，可以指定多久才能从队列中获取当前元素。只有延时期满后才能从队列中获取元素。（DelayQueue可以运用在以下应用场景：1.缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。2.定时任务调度。使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。） SynchronousQueue： 一个不存储元素的阻塞队列，每一个put操作必须等待take操作，否则不能添加元素。支持公平锁和非公平锁。SynchronousQueue的一个使用场景是在线程池里。Executors.newCachedThreadPool()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。 LinkedTransferQueue： 一个由链表结构组成的无界阻塞队列，相当于其它队列，LinkedTransferQueue队列多了transfer和tryTransfer方法。 LinkedBlockingDeque： 一个由链表结构组成的双向阻塞队列。队列头部和尾部都可以添加和移除元素，多线程并发时，可以将锁的竞争最多降到一半。 Java中线程安全的内置队列还有两个：ConcurrentLinkedQueue和LinkedTransferQueue，它们使用了CAS这种无锁的方式来实现了线程安全的队列。无锁的方式性能好，但是队列是无界的，用在生产系统中，生产者生产速度过快，可能导致内存溢出。有界的阻塞队列ArrayBlockingQueue和LinkedBlockingQueue，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap格式的数据结构。这样的话就只剩下ArrayBlockingQueue。（先埋个坑在这儿，近来接触到了disruptor，感觉妙不可言。disruptor） 3. 阻塞队列的实现原理这里分析下ArrayBlockingQueue的实现原理。 构造方法: 123ArrayBlockingQueue(int capacity);ArrayBlockingQueue(int capacity, boolean fair);ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) ArrayBlockingQueue提供了三种构造方法，参数含义如下： capacity：容量，即队列大小。 fair：是否公平锁。 c：队列初始化元素，顺序按照Collection遍历顺序。 插入元素： 123456789101112public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; 从源码可以看出，生产者首先获得锁lock，然后判断队列是否已经满了，如果满了，则等待，直到被唤醒，然后调用enqueue插入元素。 12345678910private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();&#125; 以上是enqueue的实现，实现的操作是插入元素到一个环形数组，然后唤醒notEmpty上阻塞的线程。 获取元素： 1234567891011public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; 从源码可以看出，消费者首先获得锁，然后判断队列是否为空，为空，则等待，直到被唤醒，然后调用dequeue获取元素。 123456789101112131415private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings("unchecked") E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); return x;&#125; 以上是dequeue的实现，获取环形数组当前takeIndex的元素，并及时将当前元素置为null，设置下一次takeIndex的值takeIndex++，然后唤醒notFull上阻塞的线程。 还有其他方法offer(E e)、poll()、add(E e)、remove()、 offer(E e, long timeout, TimeUnit unit)等的实现，因为常用take和put，这些方法就不一一赘述了。 4. 阻塞队列的基本使用使用阻塞队列实现生产者-消费者模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Created by noly on 2017/5/19. */public class BlockingQueueTest &#123; public static void main (String[] args) &#123; ArrayBlockingQueue&lt;Integer&gt; queue = new ArrayBlockingQueue&lt;Integer&gt;(10); Consumer consumer = new Consumer(queue); Producer producer = new Producer(queue); producer.start(); consumer.start(); &#125;&#125;class Consumer extends Thread &#123; private ArrayBlockingQueue&lt;Integer&gt; queue; public Consumer(ArrayBlockingQueue&lt;Integer&gt; queue)&#123; this.queue = queue; &#125; @Override public void run() &#123; while(true) &#123; try &#123; Integer i = queue.take(); System.out.println("消费者从队列取出元素:" + i); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class Producer extends Thread &#123; private ArrayBlockingQueue&lt;Integer&gt; queue; public Producer(ArrayBlockingQueue&lt;Integer&gt; queue)&#123; this.queue = queue; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; try &#123; queue.put(i); System.out.println("生产者向队列插入元素:" + i); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 如果不使用阻塞队列，使用Object.wait()和Object.notify()、非阻塞队列实现生产者-消费者模式，考虑线程间的通讯，会非常麻烦。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之死锁]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%AD%BB%E9%94%81%2F</url>
      <content type="text"><![CDATA[并发编程之死锁定义 是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 产生的条件 互斥条件：所谓互斥就是线程在某一时间内独占资源。 每一次的资源只能被一个线程使用 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。 一个线程在获取资源的时候，此时另外一个线程请求资源的时候保持不放 不剥夺条件:线程已获得资源，在末使用完之前，不能强行剥夺。 资源只能被持有者线程主动释放，不能被强行剥夺 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。 分析 我们可以把锁看做一个资源，这个资源正好符合互斥条件，不剥夺条件的要求。那么可能产生死锁的代码特征就是在持有一个锁的情况下去申请另外一个锁，这个通常就是意味着嵌套 一个线程在已经持有一个锁的情况下再次申请这个锁（比如，一个类的同步方法调用该类的另外一个同步方法）并不会导致死锁，这是因为Java中的锁（包括内部锁synchronized和显示锁Lock）都是可重入的（Reentrant），这种情况下线程再次申请这个锁是可以成功的。因此我们必须使用不同对象的锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.demo.test;/** * 一个简单的死锁类 * t1先运行，这个时候flag==true,先锁定obj1,然后睡眠1秒钟 * 而t1在睡眠的时候，另一个线程t2启动，flag==false,先锁定obj2,然后也睡眠1秒钟 * t1睡眠结束后需要锁定obj2才能继续执行，而此时obj2已被t2锁定 * t2睡眠结束后需要锁定obj1才能继续执行，而此时obj1已被t1锁定 * t1、t2相互等待，都需要得到对方锁定的资源才能继续执行，从而死锁。 */public class DeadLock implements Runnable&#123; private static Object obj1 = new Object(); private static Object obj2 = new Object(); private boolean flag; public DeadLock(boolean flag)&#123; this.flag = flag; &#125; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + "运行"); if(flag)&#123; synchronized(obj1)&#123; System.out.println(Thread.currentThread().getName() + "已经锁住obj1"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized(obj2)&#123; // 执行不到这里 System.out.println("1秒钟后，"+Thread.currentThread().getName() + "锁住obj2"); &#125; &#125; &#125;else&#123; synchronized(obj2)&#123; System.out.println(Thread.currentThread().getName() + "已经锁住obj2"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized(obj1)&#123; // 执行不到这里 System.out.println("1秒钟后，"+Thread.currentThread().getName() + "锁住obj1"); &#125; &#125; &#125; &#125;&#125; 避免死锁 锁排序法，相关线程使用全局统一的顺序申请锁 加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁） 比如使用tryLock(timeout) : 尝试获取锁，如果获取不到不会持续等待 死锁检测 总结1、让程序每次至多只能获得一个锁。当然，在多线程环境下，这种情况通常并不现实。 2、设计时考虑清楚锁的顺序，尽量减少嵌在的加锁交互数量。 3、既然死锁的产生是两个线程无限等待对方持有的锁，那么只要等待时间有个上限不就好了。当然synchronized不具备这个功能，但是我们可以使用Lock类中的tryLock方法去尝试获取锁，这个方法可以指定一个超时时限，在等待超过该时限之后便会返回一个失败信息。 参看文章 http://www.cnblogs.com/xiaoxi/p/8311034.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之线程协作]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[并发编程之线程协作wait / notify / notifyAll Object.wait()/Object.notify()/Object.notifyAll()可用于实现等待和通知。 wait()方法可以使其执行的线程被暂停，该方法用来实现等待。 进入阻塞状态(Block) 只有在持有一个对象的锁的时候才可以调用wait()方法，因此Object.wait()总是放在相应对象所领导的临界区中，必须和synchronized关键字进行使用 在执行wait方法的同时也会释放同步锁，从而线程进入阻塞状态 notify()用于唤醒一个被暂停的线程，调用该方法可以实现通知 必须使用和wait()方法一样的对象调用 必须使用synchronized关键字，并且在执行完毕之后会释放同步锁 唤醒的是当前对象上的任意一个等待的线程 被唤醒的等待线程在其占用的处理器继续运行的时候，需要再次申请Object对应的内部锁(synchronized) notifyAll() 用于唤醒当前对象中的全部等待线程 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class TestThread &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread thread=new MyThread(); new Thread(thread,"线程1").start(); Thread.sleep(2000); thread.testNotifyAll(); &#125; &#125;class MyThread implements Runnable&#123; private final Object object=new Object(); //创建一个Object对象，用于线程同步锁和调用wait方法 private volatile boolean flag=true; //保护条件 private int count=0; public void run() &#123; this.testWait(); &#125; //测试等待 public void testWait()&#123; //循环执行 while(true)&#123; //必须和调用wait的方法是一个对象 synchronized (object) &#123; while(!this.flag)&#123; try &#123; System.out.println(Thread.currentThread().getName()+" 等待被唤醒...."); object.wait(); &#125; catch (InterruptedException e) &#123; System.out.println("线程被终止....."); &#125; &#125; this.doAction(); //执行其他的动作 &#125; &#125; &#125; //测试唤醒线程，随机唤醒一个线程 public void testNotify()&#123; synchronized (object) &#123; this.flag=true; //从当前object的等待线程中随机唤醒一个线程 object.notify(); &#125; &#125; //唤醒所有线程 public void testNotifyAll()&#123; synchronized (object) &#123; this.flag=true; object.notifyAll(); //唤醒当前对象上的所有等待线程 &#125; &#125; //执行其他动作 public void doAction()&#123; System.out.println("执行其他的功能"); count++; if (count==10) &#123; flag=false; //改变flag的值 ，将会wait &#125; &#125;&#125; 条件变量condition 和wait，notify()思想一样，不过这个要和显示锁Lock结合使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class TestThread &#123; private static final Lock lock=new ReentrantLock(); //创建显示锁 private static final Condition condition=lock.newCondition(); //创建条件变量 private static volatile boolean flag=true; //保护条件 public static void main(String[] args) throws InterruptedException &#123; Thread thread1=new Thread()&#123; public void run() &#123; testWait(); &#125;; &#125;; thread1.start(); Thread thread2=new Thread()&#123; public void run() &#123; testSignal(); &#125;; &#125;; thread2.start(); &#125; public static void testWait()&#123; while(true)&#123; lock.lock(); //获取显示锁 try &#123; if (!flag) &#123; condition.await(); &#125; doAction(); &#125; catch (InterruptedException exception) &#123; exception.printStackTrace(); &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125; &#125; public static void testSignal()&#123; while(true)&#123; lock.lock(); //获取锁 try &#123; if (flag) &#123; System.out.println("执行其他的动作"); &#125;else &#123; flag=true; Thread.sleep(5000); condition.signal(); //唤醒线程 &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; lock.unlock(); &#125; &#125; &#125; public static void doAction()&#123; System.out.println("执行其他的动作"); flag=false; //改变flag &#125; &#125; 倒计时协调器 CountDownLatch栅栏 CycliBarrier阻塞队列BlockingQueue信号量Semaphore参考文章 http://www.cnblogs.com/dolphin0520/p/3920385.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之volatile]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bvolatile%2F</url>
      <content type="text"><![CDATA[并发编程之volatile volatile称之为轻量级锁，保证了可见性和原子性。 volatile不会引起上下文切换，因此是轻量级的 volatile的作用 保障可见性，有序性和Long，double类型变量读写操作的原子性 volatile仅仅能保证对其修饰的变量的写操作以及读操作本身的原子性，而这并不表示volatile变量的赋值操作一定具有原子性，例如，如下对volatile修饰的变量count的赋值操作并不是原子操作：count++ count++可以分为如下步骤 读取count的值 count+1 将count+1的值赋值给count 如果count是一个共享变量，那个该赋值操作实际上是一个read-modify-write操作。其执行过程中其他线程可能已经更新了count的值，因此该操作不具备不可分割性，也就不是原子操作。如果变量count是一个局部变量，那么该赋值操作就是一个原子操作。 一般而言如果对volatile修饰的赋值操作，其右边的表达式中只要设计共享变量（包括被volatile修饰的变量本身），那么这个赋值操作就不是原子操作，此时就需要结合锁来保证原子性了 原理保证可见性原理 对volatile修饰的变量的读操作之前插入一个加载屏障，能够刷新处理器缓存，使其读取的读取到的变量都是线程更新后的最新值。 对volatile修饰的变量的写操作(修改)之后插入一个存储屏障，能够冲刷处理器缓存，保证后续的线程读取到的值是最新的。 保证有序性原理 结合释放屏障和获取屏障保证了有序性 总结 volatile的写操作相当于锁的释放的效果，java虚拟机会在该操作之前插入一个释放屏障，并在该操作只有插入一个存储屏障 释放屏障禁止了volatile写操作与该操作之前的任何读写操作进行重排序，从而保证了volatile写操作之前的任何读写操作会先于volatile写操作之前提交，即其他线程看到写线程对volatile变量的更新时，写线程在更新volatile变量之前执行的内存操作的结果对于度鲜橙必然是可见的。即是保障了有序性 存储屏障保证了在写操作之后的更新能够冲刷处理器缓存，使得后续的读线程能够获取最新的值 volatile的读操作相当于获取锁的效果，Java虚拟机会在该操作之前插入一个加载屏障，并在该操作之后插入一个获取屏障 加载屏障用于刷新处理器缓存区，保证读取到volatile修饰变量的最新值，保证可见性 获取屏障禁止volatile读操作之后的任何读写操作与volatile读操作进行重排序。因此保证了有序性 volatile变量的开销 volatile变量的读写不会导致上下文切换，因此开销比锁小 读取volatile变量每次都需要从高速缓存或者主内存中读取，而无法暂存在寄存器中，因此可能比读取普通变量的成本要高 使用场景 使用volatile变量作为状态标志。比如volatile int flag=false,其他线程会读取该状态作为执行某一个操作的依据 单例模式下的双重校验锁的实现效果，其中必须使用volatile，否则并不能保证对象可见性 参考文章 http://www.cnblogs.com/dolphin0520/p/3920373.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之线程同步机制的底层助手内存屏障]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%95%E5%B1%82%E5%8A%A9%E6%89%8B%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%2F</url>
      <content type="text"><![CDATA[线程同步机制的底层助手 ：内存屏障前提 我们知道锁是可以保证可见性的，线程在获取锁和释放锁的时候会分别执行两个动作来保证可见性: 刷新处理器缓存 ：保证了持有该锁的线程能够读取到前一个线程对共享数据的更新 冲刷处理器缓存 ：保证了持有该锁的线程对共享数据所做的更新会对后续获取该锁的线程来说是保持可见的 Java虚拟机是借助内存屏障（Memory Barrier）实现上述的两个动作。 按照可见性划分 按照可见性划分内存屏障分为加载屏障(Load Barrier)和存储屏障(Store Barrier) 加载屏障的作用是刷新处理器缓存暴保证获取该锁的线程能够读取到前一个线程对共享数据的更新 存储屏障的作用是冲刷处理器缓存保证当前线程对共享变量的更新对后续获取该锁的线程来说是可见的 保证可见性的原理 Java虚拟机会在MonitorExit(释放锁)对应的机器指令之后插入一个存储屏障，这个就保障了写线程在释放锁之前在临界区中对共享变量所做的更新对度鲜橙的处理器来说是可同步的。相应的Java虚拟机会在MonitorEnter（申请锁）对应的机器码之前插入一个加载屏障，这个使得线程能够获取到前面线程对共享数据的更新 按照有序性划分 按照有序性划分，内存屏障分为获取屏障(Acquire Barrier)和释放屏障（Release Barrier） 获取屏障的使用方式是在一个读操作（包括Read-Modify-Write）之后插入获取屏障，其作用是禁止该读操作与后面的任何读写操作之间进行重排序，这相当于在进行后续操作之前先要获取相应共享数据的所有权。 释放屏障的使用方式是在一个写操作之前插入释放屏障，其作用是禁止该写操作与前面的任何读写操作之间进行重排序。这相当于在对响应共享数据操作技术后释放所有权。 保证可见性和原子性详解图形]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之上下文切换]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%2F</url>
      <content type="text"><![CDATA[多线程之上下文切换定义 在单处理器的情况下，每个线程的执行时间是根据时间片大小决定或者自身的其他原因，如果一个线程被迫或者主动暂停运行时，另外一个线程(可能是同一个进程中的线程或者其他进程中的)可以被操作系统(线程调度器)选中占用处理器开始或者继续运行。这种一个线程被暂停，即是被剥夺处理器使用的权利，另外一个线程被选中开始或者继续运行的过程就叫做上下文切换 一个线程被剥夺处理器的使用权而被暂停运行就被称之为切出 一个线程被操作系统（线程调用器）选中占用处理器开始或者继续运行就被称之为切入 在线程的数量大于核心处理器的数量的时候，我们看到连续运行的线程，实际上是以断断续续的运行方式使其任务进展的。这种方式意味着在切入和切出的时候操作系统需要保存和恢复相应线程的进入信息，即是切入和切出的那一刻线程执行的任务进行到什么程度了（如计算结果以及执行到了哪条指令）。这个保存的进度信息叫做上下文 在切出的时候，操作系统需要将上下文信息保存在内存中，以便稍后处理器继续运行该线程的时候能够在此信息的基础上继续运行 在切入的时候操作系统需要从内存中加载和恢复被选中的线程上下文信息，以在之前的基础上继续运行 上下文切换的分类和诱因自发性的上下文切换 自发性上下文切换是指线程由于自身因素导致的切出。一个线程在运行过程中执行下列方法可能会导致线程自发性的上下文切换 sleep() wait() yield(() ： 这个方法可能导致 join() LockSupport.park() 线程发起了IO操作（如读取文件） 或者等待其他线程的持有的锁也会导致自发性上下文切换 非自发性上下文切换 由于线程调度器的原因被迫切出 时间片用完 一个更高优先级的线程需要运行 垃圾回收器在执行垃圾回收的过程中可能也是需要暂停线程才能完成工作 上下文切换的花销 上下文切换的花销是必须的，即使在多核的处理器系统中上下文切换也是必须的，因为我们需要执行的线程的数量总是大于处理器的数量。 直接开销 操作系统保存和恢复上下文所需要的开销，主要是时间的开销 线程调度器进行线程调度的开销（比如按照一定规则决定哪一个线程会占用处理器） 间接开销 处理高速缓存重新加载的开销，一个被迫切出的线程在另外一个处理器切入运行，由于这个处理器之前可能没有运行过该线程，那么这个线程在运行过程中需访问的变量仍然需要该处理器从主内存或者通过一致性协议从其他处理器加载到高速缓存之中，这个也是需要时间消耗的 上下文切换可能导致整个一级高速缓存被冲刷（Flush），即一级高速缓存中的内容会被写入下一级高速缓存或者主内存中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之多线程状态]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%2F</url>
      <content type="text"><![CDATA[多线程状态总的执行图： 所有状态： 1，创建状态(new) 在程序中用构造方法创建了一个线程对象后，新的线程对象便处于新建状态，此时，它已经有了相应的 内存空间和其他资源，但还处于不可运行状态。新建一个线程对象可采用Thread 类的构造方法来实现，例 如，“Thread thread=new Thread();”。 2，就绪状态(Runnable) 新建线程对象后，调用该线程的start()方法就可以启动线程。当线程启动时，线程进入就绪状态。此时， 线程将进入线程队列排队，等待CPU 服务，这表明它已经具备了运行条件。 3，运行状态(Running) 当就绪状态的线程被调用并获得处理器资源时，线程就进入了运行状态。此时，自动调用该线程对象 的run()方法。run()方法定义了该线程的操作和功能。 4，堵塞状态(Block) 一个正在执行的线程在某些特殊情况下，如被人为挂起或需要执行耗时的输入/输出操作时，将让出 CPU 并暂时中止自己的执行，进入堵塞状态。堵塞时，线程不能进入排队队列，只有当引起堵塞的原因被 消除后，线程才可以转入就绪状态。 5，死亡状态(Dead) 线程调用stop()方法时或run()方法执行结束后，即处于死亡状态。处于死亡状态的线程不具有继续运 行的能力。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[并发编程之三大性质]]></title>
      <url>%2F2018%2F06%2F26%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E4%B8%89%E5%A4%A7%E6%80%A7%E8%B4%A8%2F</url>
      <content type="text"><![CDATA[多线程的三大性质原子性 对共享变量更新操作的时候，要保证执行不可分割，比如银行转账，一旦在多线程的环境下将其分割了，那么可能造成的后果可能是转账的账户钱少了，但是转到的账户的钱可能不是那么多或者根本没有转过去 在单线程的环境下没有所谓的原子性，都是顺序执行的 多线程的环境下对共享变量的访问(读写)才会涉及原子性 使用Lock和sychronized可以解决原子性问题 可见性 在多线程的环境下，一个线程的对共享变量的更新，后续的线程访问这个共享变量的时候能否立即读取这个更新后的结果 原因 程序中的变量可能是被分配到寄存器中，而不是主内存中。每个处理器都有寄存器，而一个处理器的寄存器不能读取另外一个处理器的寄存器的内容。因此如果两个线程运行在不同的处理器上，而共享变量被分配到寄存器上存储，那么可见性问题就出现了 每一个处理器都有自己的高速缓存区，即使共享变量在主存中， 在线程执行的时候会将复制一个副本存放在高速缓存中，一个线程更新共享变量之后会更新到高速缓存中，还没有来得及更新到主存中的时候，另外的线程就开始执行了，那么此时的共享变量就不是更新之后的，出现了可见性问题 处理器并不是直接与主内存直接打交道执行读写操作的，而是通过寄存器，高速缓存，写缓冲器和无效化队列等部件执行内存的读写。 解决 虽然每个处理器不能直接读写不同处理器的高速缓存，但是我们可以缓存一致协议来读取其他处理器中的高速缓存的内容，并将读取的内容更新到自己的高速缓存。这种一个处理器从其自身处理器缓存之外的其他存储部件中读取数据并将其更新到该处理器高速缓存的过程称之为缓存同步 使用voliate关键字可以解决可见性问题 public voliate int a 有序性 即程序执行的顺序按照代码的先后顺序执行 指令重排序1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子： 1234int a = 10; //语句1int r = 2; //语句2a = a + 3; //语句3r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 解决 使用voliate 参考文档 http://www.cnblogs.com/dolphin0520/p/3920373.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MongoDB使用总结]]></title>
      <url>%2F2018%2F06%2F26%2FMongoDB%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[MongoDB使用总结数据库操作 show dbs : 显示所有的数据库 use user : 选择数据库user，如果这个数据库存在，那么就使用，不存在就新建，但是此时的数据库中根本不存在数据，因此使用show dbs不能显示该数据库 db.dropDatabase() : 删除数据库，其中的db表示当前数据库 集合操作(表) 在MongoDB中，数据库中的集合相当于SQL中的表，一个数据库中可以存在多个集合，每一个集合都是一个JSON文档形式的存储 show tables : 显示所有的集合 show collections : 显示所有的集合 创建集合 db.createCollection(name, options) 文档 删除集合 db.collection.drop() db.user.drop() : 删除user集合 文档操作 一个集合中可以包含多条文档，一个文档就相当于SQL中的一条数据，这里的文档是JSON格式的文档 插入文档 db.collectionName.insert(JSON) db.user.insert({name:&quot;陈加兵&quot;,age:22}) : 向user集合中插入一条文档，如果这个user集合不存在，那么就会新建一个，这个方法默认会为我们插入一个_id 更新文档update() 方法用于更新已存在的文档。语法格式如下： 123456789db.collection.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 参数说明： query : update的查询条件，类似sql update查询内where后面的。 update : update的对象和一些更新的操作符（如$,​$inc…）等，也可以理解为sql update查询内set后面的 upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。 multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。 writeConcern :可选，抛出异常的级别。 实例 db.user.update({name:&quot;jack&quot;},{$set:{name:&quot;tom&quot;}}) ：相当于sql语句中的update user set name=&quot;tom&quot; where name=&quot;jack&quot;,不过这里默认只是更新一条 db.user.update({name:&quot;陈加兵&quot;},{$set:{name:&quot;郑元梅&quot;}},{multi:true}) ： 更新所有的数据 db.user.update({name:&quot;陈加兵&quot;},{$set:{name:&quot;郑元梅&quot;}},{upsert:true}) : 更新数据，如果不存在就插入 这里的query条件也是可以使用逻辑比较的，比如age&gt;12，后续在讲到查询文档的时候会详细描述 删除文档 删除格式，默认是删除多条，但是我们可以设置justone : true或者justone：1即可删除一条数据 1234567db.collection.remove( &lt;query&gt;, &#123; justOne: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) db.user.remove({name:&quot;陈加兵&quot;}) : 删除全部name=陈加兵的文档 db.user.remove({}) : 删除集合user中的全部文档 db.user.remove({}) : 删除全部文档，因为这里没有条件 db.user.remove({name:&quot;陈加兵&quot;},{justone:true}) : 只删除一条文档 查询文档 db.collection.findOne(query,projection) ： 只显示满足条件的一条文档 格式：db.collection.find(query,projection) ： 查询满足条件的全部文档 query ：可选， 查询的条件，相当于where子句 projection： 可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略） 插入数据（准备）1234db.user.insert(&#123;name:"Jack",age:22&#125;)db.user.insert(&#123;name:"Tom",age:40&#125;)db.user.insert(&#123;name:"Mary",age:25&#125;)db.user.insert(&#123;name:"Lucy",age:22&#125;) 查询全部 db.user.find().pretty() ： 这里没有指定查询条件，那么就是查询全部 指定显示字段 默认显示全部的字段，但是我们可以指定projection来显示指定的字段 inclusion模式，指定返回的键，比如db.user.find({},{name:1}),这里只会显示_id和name这两个字段，其他的字段都是不会显示的 exclusion模式，指定不反回的键，比如db.user.find({},{name:0}) : 这里只会显示age和_id,只有name不显示 两种模式不可以混用，比如db.user.find({},{name:1,age:0}) ,这个是不可以的 指定查询条件 db.user.find({name:&quot;Jack&quot;}) ： 查询name=Jack的全部文档内容 db.user.find({name:&quot;Jack&quot;},{name:0}) : 不显示name字段 AND条件 db.user.find({name:&quot;Jack&quot;,age:22}) ： 查询name=Jack并且age=22的文档信息 db.user.find({$and:[{expression1},{expression2},{experssion3},......]}) db.user.find({$and:[{name:&quot;Jack&quot;},{age:22}]}) : 和上面一样的效果 OR 条件 db.user.find({$or:[{expression1},{expression2},{expression3}......]}) db.user.find({$or:[{name:&quot;Jack&quot;},{age:25}]}) : 查找name=Jack或者age=25的文档信息 AND 和 OR 联合使用 db.user.find({name:&quot;Jack&quot;,$or:[{_id:1},{age:22}]}) : 查找name=Jack and (_id=1 or age=22) 条件操作符 (&gt;) 大于 - $gt (&lt;) 小于 - $lt (&gt;=) 大于等于 - $gte (&lt;= ) 小于等于 - $lte (!=) 不等于 - $ne 实例 db.user.find({age:{$gt:22}}) : 查找 age&gt;22的信息 db.user.find({age:{$gte:22},name:&quot;Jack&quot;}) : 查找age&gt;=22 and name=Jack的信息 limit 指定显示记录的条数 db.user.find().limit(2) : 只显示两条记录 db.user.find({name:&quot;Jack&quot;}).limit(2) skip 跳过的条数 db.user.find().skip(10) : 跳过前面的十条记录，显示后面的 分页查询 显示第三页，每页显示10条信息，相当于SQL中的select * from user limit 20,5 db.user.find().skip(20).limit(5) sort 排序 在MongoDB中使用使用sort()方法对数据进行排序，sort()方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中1 为升序排列，而-1是用于降序排列。 db.collection.find().sort({key:1}) db.user.find().sort({age:-1}) : 按照age降序排列 db.user.find({},{name:1,age:1}).sort({age:-1,name:1}) : 按照name升序，age降序排列 limit，skip，sort执行顺序 执行顺序为：sort() — &gt; skip() —-&gt; limit() ,这个相当于SQL中的select * from name where group by having order by limit m,n 这种顺序一样 $in 表示一个数据在多个数据中，类似于SQL中的in db.user.find({age:{$in:[22,33,44]}}) : 查找age in (22,33,44)之中的任意一个 $nin 相当于SQL中的not in db.user.find({age:{$nin:[22,33,44]}}) $exists 表示不存在 db.user.find({sex:{$exists:false}}) : 查找不存在sex这个字段的文档 slice $slice操作符控制查询返回的数组中元素的个数。此操作符根据参数{ field: value } 指定键名和键值选择出文档集合，并且该文档集合中指定array键将返回从指定数量的元素。如果count的值大于数组中元素的数量，该查询返回数组中的所有元素的。 语法：db.collection.find( { field: value }, { array: {$slice: count }}); 下面将查询grades中的前两个数 12345db.user.find(&#123;name:&apos;jack&apos;&#125;,&#123;grades:&#123;$slice:2&#125;,name:1,age:1,&apos;school.name&apos;:1&#125;);//输出，可以看出这里的grades只输出了前面两个&#123; &quot;_id&quot; : ObjectId(&quot;59057c16f551d8c9003d31df&quot;), &quot;name&quot; : &quot;jack&quot;, &quot;age&quot; : 22, &quot;grades&quot; : [ 22, 33 ], &quot;school&quot; : &#123; &quot;name&quot; : &quot;shida&quot; &#125; &#125; 下面将输出后3个数据 1234db.user.find(&#123;name:&apos;jhon&apos;&#125;,&#123;grades:&#123;$slice:-3&#125;,name:1&#125;);//输出&#123; &quot;_id&quot; : ObjectId(&quot;59057c16f551d8c9003d31e0&quot;), &quot;name&quot; : &quot;jhon&quot;, &quot;grades&quot; : [ 22, 44, 88 ] &#125; 下面介绍指定一个数组作为参数。数组参数使用[ skip , limit ] 格式，其中第一个值表示在数组中跳过的项目数,第二个值表示返回的项目数。 123456db.user.find(&#123;name:&apos;jack&apos;&#125;,&#123;grades:&#123;$slice:[2,2]&#125;,name:1&#125;); //这里将会跳过前面的两个，直接得到后面的两个数据//输出&#123; &quot;_id&quot; : ObjectId(&quot;59057c16f551d8c9003d31df&quot;), &quot;name&quot; : &quot;jack&quot;, &quot;grades&quot; : [ 44, 55 ] &#125; count 统计数量 db.user.find().count() : 统计全部的数量 db.user.find({name:&quot;Jack&quot;}).count() : 统计name=Jack的人数 索引 db.collection.ensureIndex({key1:1}) : 创建索引，其中的key的值如果为1表示按照升序创建索引，-1表示降序创建索引 db.user.ensureIndex({name:1}) ： 单个索引 db.user.ensureIndex({name:1,age:-1}) : 复合索引 ensureIndex() 接收可选参数，可选参数列表如下： Parameter Type Description background Boolean 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 “background” 可选参数。 “background” 默认值为false。 unique Boolean 建立的索引是否唯一。指定为true创建唯一索引。默认值为false. name string 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称。 dropDups Boolean 在建立唯一索引时是否删除重复记录,指定 true 创建唯一索引。默认值为 false. sparse Boolean 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.。默认值为 false. expireAfterSeconds integer 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。 v index version 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。 weights document 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重。 default_language string 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语 language_override string 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的language，默认值为 language. db.user.ensureIndex({age:1},{background:true}) : 在后台创建索引 聚合 参考文章 db.collection.aggregate(pipeline,options) db.user.aggregate([{$group:{_id:null,count:{$sum:1}}}]) : 查询总数，相当于select count(*) from user,这里的聚合函数$sum表示求和，可以使用$引用集合中的字段，也可以直接使用数字，这里填写1就表示查询到一条记录就加一，那么最后显示的就是总数了。 _id : 表示需要分组的字段，如果为null表示不分组 db.user.aggregate([{$group:{_id:&quot;$name&quot;,sum_age:{$sum:&quot;$age&quot;}}}]) : 根据字段name分组,对字段age求和，输入如下 1234567&#123; "_id" : "Mary", "sum_age" : 75 &#125;&#123; "_id" : "Jack", "sum_age" : 66 &#125;&#123; "_id" : "zhengyunamei", "sum_age" : 0 &#125;&#123; "_id" : "Tom", "sum_age" : 120 &#125;&#123; "_id" : "陈加兵", "sum_age" : 22 &#125;&#123; "_id" : "Lucy", "sum_age" : 66 &#125;&#123; "_id" : "郑元梅", "sum_age" : 22 &#125; db.user.aggregate([{$group:{_id:null,max_age:{$max:&quot;$age&quot;}}}]) : 求出年龄最大的人信息 1&#123; "_id" : null, "max_age" : 40 &#125; 常用的聚合 表达式 描述 实例 $sum 计算总和。 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$sum : “$likes”}}}]) $avg 计算平均值 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$avg : “$likes”}}}]) $min 获取集合中所有文档对应值得最小值。 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$min : “$likes”}}}]) $max 获取集合中所有文档对应值得最大值。 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$max : “$likes”}}}]) $push 在结果文档中插入值到一个数组中。 db.mycol.aggregate([{$group : {_id : “$by_user”, url : {$push: “$url”}}}]) $addToSet 在结果文档中插入值到一个数组中，但不创建副本。 db.mycol.aggregate([{$group : {_id : “$by_user”, url : {$addToSet : “$url”}}}]) $first 根据资源文档的排序获取第一个文档数据。 db.mycol.aggregate([{$group : {_id : “$by_user”, first_url : {$first : “$url”}}}]) $last 根据资源文档的排序获取最后一个文档数据 db.mycol.aggregate([{$group : {_id : “$by_user”, last_url : {$last : “$url”}}}]) 管道管道在Unix和Linux中一般用于将当前命令的输出结果作为下一个命令的参数。 MongoDB的聚合管道将MongoDB文档在一个管道处理完毕后将结果传递给下一个管道处理。管道操作是可以重复的。 表达式：处理输入文档并输出。表达式是无状态的，只能用于计算当前聚合管道的文档，不能处理其它的文档。 这里我们介绍一下聚合框架中常用的几个操作： $project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。 $match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。 $limit：用来限制MongoDB聚合管道返回的文档数。 $skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。 $unwind：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。 $group：将集合中的文档分组，可用于统计结果。 $sort：将输入文档排序后输出。 $geoNear：输出接近某一地理位置的有序文档。 $math 这个相当于where语句，用来过滤文档的 这个位置是非常重要的，如果在$group之前就是where子句，如果在之后，那么相当于`having子句` db.user.aggregate([{$match:{name:&quot;Jack&quot;}},{$group:{_id:null,count:{$sum:1}}}]) ： 统计name=Jack的人数 这个命令相当于SQL中的select count(*) from user where name=&quot;Jack&quot; 我们可以使用db.user.find({name:&quot;Jack&quot;}).count()同样可以查询、 db.user.aggregate([{$match:{age:{$gt:20}}},{$group:{_id:&quot;$name&quot;,sum_age:{$sum:&quot;$age&quot;}}}]) 相当于SQL中的select _id,sum(age) as sum_age from user where age&gt;20 group by name db.user.aggregate([{$group:{_id:&quot;$name&quot;,sum_age:{$sum:&quot;$age&quot;}}},{$match:{sum_age:{$gte:75}}}]) select _id,sum(age) as sum_age from user group by name having sum_age&gt;=75 db.user.aggregate([{$match:{name:&quot;Tom&quot;}},{$group:{_id:&quot;$name&quot;,sum_age:{$sum:&quot;$age&quot;}}},{$match:{sum_age:{$gte:75}}}]) select _id,sum(age) as sum_age from user where name=&quot;Tom&quot; group by name having sum_age&gt;=75 $limit 控制显示的条数，因为使用聚合之后，不能再使用limit()方法来限制 db.user.aggregate([{$group:{_id:&quot;$name&quot;,sum_age:{$sum:&quot;$age&quot;}}},{$limit:1}]) ： 根据姓名分组之后显示一条数据 相当于 select _id,sum(age) as sum_age from user group by name limit 0,1 db.user.aggregate([{$match:{name:&quot;Tom&quot;}},{$group:{_id:&quot;$name&quot;,sum_age:{$sum:&quot;$age&quot;}}},{$match:{sum_age:{$gte:75}}},{$skip:0},{$limit:1}]) select _id ,sum(age) as sum_age from user where name=&quot;Tom&quot; group by name having age&gt;=75 limit 0,1 $sort 排序输出 db.collection.aggregate([{},{},{},......,{$sort:{key:1}}]) db.user.aggregate([{$match:{name:&quot;Tom&quot;}},{$group:{_id:&quot;$name&quot;,sum_age:{sum:&quot;age&quot;}}},{$match:{sum_age:{$gte:75}}},{$sort:{sum_age:1}},{$skip:0},{$limit:1}]) select _id ,sum(age) as sum_age from user where name=&quot;Tom&quot; group by name having age&gt;=75 order by sum_age asc limit 0,1 总结 常用的格式： db.collection.aggregate([{$match:{key:value,...},{$group:{_id:value,..}},{$match:{key:value,....}},{$sort:{key:1,key2:-1}},{$skip:num},{$limit:num}]) 对应SQL中的语句为：select _id,key1,key2 from collection where group by order by limit n,m]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git使用总结]]></title>
      <url>%2F2018%2F06%2F26%2FGit%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Git使用总结开发策略 在实际开发的时候一定要在分支上开发，修复问题，开发完成之后再合并到主分支(master)上，这样可以保证在不损坏主分支的情况下删除或者撤销内容 解决冲突冲突产生 假设现在有一个master分支，其中有一个提交之后的文件demo.txt，那么我们使用git checkout -b dev创建一个新的分支并且切换到这个dev分支 echo chenjiabing &gt;&gt; demo.txt：在文件的末尾追加一个文件 git add file.txt : 添加到暂存区 git commit -m &quot;this is at dev：提交 git checkout master : 切换到主分支 echo 陈加兵 &gt;&gt;demo.txt ： 切换到主分支，在主分支中在文件的末尾追加陈加兵，(这里一定要在文件末尾，因为在dev分支中修改的位置就是文件末尾) git add demo.txt : 添加到暂存区 git commit -m &quot;this is at master&quot; : 提交 git merge dev ：快速合并分支dev到master分支上，那么现在将会出现版本冲突的问题，不能合并成功。此时的demo.txt的文件内容为： 123456789Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD陈加兵=======chenjiabing&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev 冲突解决 此时在master分支中修改demo.txt中的内容，直到满意为止即可 git add demo.txt : 添加 git commit -m &quot;this is finally&quot; :提交 分支管理策略 通常，合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 git merge --no-ff -m &quot;merge with no-ff&quot; dev Bug分支(git stash) Bug分支 git stash 将当前的工作现场存储起来 git stash list ： 列出所有的工作现场 git stash pop : 回复当前分支的工作现场，并且还删除了stash中的内容 添加公钥到Github中 如果你没有在git中配置邮箱和用户名，那么需要先配置 git config --global user.name &quot;CSDN id&quot; git config --global user.email &quot;your email&quot; cd ~/.ssh： 进入主目录的ssh文件夹中，查看是否已经存在秘钥文件id_rusa.pub，如果不存在，那么需要生成秘钥 ssh-keygen -t rsa -C &quot;your email&quot; ： 生成公钥 此时在~/.ssh文件夹下就有了id_rusa.pub文件夹，那么将其中的内容全部复制到github中的SSH中 注意： 添加远程仓库的时候一定要使用ssh形式，否则将会要求输入密码 git remote add git@github.com:chenjiabing666/LearnGit.git 远程仓库的使用常用命令 git clone git@github.com:chenjiabing666/LearnGit.git ：直接clone远程仓库到本地仓库，此时的本地仓库也有了push的权利，不过只能看到一个主分支master ，但是这个远程仓库还有dev分支和Bug分支 git checkout -b dev orgin/dev : 直接在本地创建一个分支dev并且和远程仓库的分支关联起来，那么就可以获取远程dev分支上的文件了 git remote : 查看远程仓库的名称，这个只显示名称，使用git clone的方法关联远程仓库，默认的名字为orgin git remote -v : 显示远程仓库的名称和链接 git remote add shortName url : 添加一个新的远程仓库 git remote add learn git@github.com:chenjiabing666/LearnGit.git git remote rename 旧名称 新名称 ： 修改远程仓库的名称 git remote rename orgin demo git remote remove 名称 ： 删除远程仓库 git remote remvoe orgin git push 仓库名称 [分支名称] ： 将提交的文件推送到远程仓库 git push orgin : 将文件推送到远程仓库的主分支master 假设我们新建了一个dev分支 使用命令git checkout -b dev ,那么我们需要将这个dev分支推送到远程仓库中的dev分支上，使用git push orgin dev 。需要注意的是必须在当前的本地仓库的dev分支才能推送,并且这个本地仓库的名称要和远程仓库一样 git pull : 从远程仓库中拉取本地仓库分支中没有的文件并且合并到当前分支 假设小明在master分支上提交了一个file.txt文件，但是小李的本地仓库中并没有file.txt这个文件，此时小李就需要从远程仓库中把这个文件拉取到自己的本地仓库的master分支上 git checkout master : 切换到主分支 git pull : 拉取远程仓库的最新文件 远程分支推送分支 git push 名称 分支名称 ： 推送分支到远程仓库中 git push orgin Bug : 推送本地的分支Bug推送到远程仓库中，那么仓库中默认的分支名就是Bug 对于一些需要合作完成的分支需要推送到远程仓库，并不是所有的分支都需要推送到远程仓库的 抓取分支 在多人协作完成项目的时候，都需要向主分支master和dev分支上面推送各自的修改 我们使用git clone一个远程仓库的时候，默认情况下只能看到master分支，我们可以使用git branch查看分支。此时我们需要在dev分支上面操作，那么就必须将远程仓库中的dev分支创建到本地，我们可以使用git checkout -b dev orgin/dev ，那么远程仓库的中的dev分支就创建到本地了，那么此时我们就可以在dev分支上面操作了 git push orgin dev : 修改完成之后推送到远程仓库中 建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name 如果远程仓库中有一个demo分支，本地也有一个demo分支，但是这个本地的demo分支并不是使用git checkout -b demo orgin/demo检出的，而是直接创建的，那么我们此时需要使用git pull拉取远程仓库中demo分支中的文件到本地的demo分支就会发现出现错误，因为没有与远程的demo分支关联，此时我们就需要使用git branch --set-upstream demo orgin/demo 总结因此，多人协作的工作模式通常是这样： 首先，可以试图用git push origin &lt;branch-name&gt;推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！ 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;。 标签的使用创建标签 git tag v1.0 : 在当前分支上添加一个标签 git tag -a v1.0 -m &quot;备注信息&quot; ： 添加一个标签并且备注信息 git tag : 列出当前分支上面的所有标签 操作标签 git tag -d v1.0 : 删除指定的标签 git push origin v1.0 : 推送标签到远程仓库，因为标签的创建不会自动推送到远程，必须手动推送 git push orgin --tags : 一次性推送全部的标签 删除远程标签 先删除本地标签 : git tag -d v1.0 使用push删除远程标签 ： git push orgin :refs/tags/v1.0 添加所有文件 git add -A 之后直接提交即可 : git commit -m &quot;&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo使用总结]]></title>
      <url>%2F2018%2F06%2F26%2FDubbo%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Dubbo常见问题官方文档 中文文档 启动检查 Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check=&quot;true&quot;可以通过 check=&quot;false&quot; 关闭检查，比如，测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动。 另外，如果你的 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请关闭 check，否则服务临时不可用时，会抛出异常，拿到 null 引用，如果 check=&quot;false&quot;，总是会返回引用，当服务恢复时，能自动连上 如果在服务提供者没有上线的情况下，我们需要提前将消费者上线，那么就可以关闭启动检查，这样当消费者启动但是不调用服务的情况下不会报错，保证正常启动 配置方式关闭某个服务的检查 &lt;dubbo:reference id=&quot;helloService&quot; interface=&quot;cn.tedu.service.IHelloService&quot; check=&quot;false&quot;/&gt; ：关闭某个服务的启动时检查 这个只会关闭当前的服务器的检查，还是会检查其他的服务 在没有对应服务提供者的情况下如果调用这个服务那么将会报错 在消费者中配置 123456789public class TestDubbo &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext("appliactionContext.xml"); IHelloService helloService=context.getBean("helloService",IHelloService.class); //现在没有调用服务的情况下不会报错，但是如果调用了HelloService中的方法，那么将会报错// helloService.sayHello(); context.close(); &#125;&#125; 如果没有关闭检查，那么会出现如下的错误 123456789101112131415Exception in thread "main" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'helloService': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalStateException: Failed to check the status of the service cn.tedu.service.IHelloService. No provider available for the service cn.tedu.service.IHelloService from the url zookeeper://39.105.123.197:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-consum01&amp;dubbo=2.5.3&amp;interface=cn.tedu.service.IHelloService&amp;methods=sayHello&amp;pid=10974&amp;revision=0.0.1&amp;side=consumer&amp;timestamp=1529667926718 to the consumer 10.18.236.4 use dubbo version 2.5.3 at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:175) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103) at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1634) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:254) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1086) at TestDubbo.main(TestDubbo.java:9)Caused by: java.lang.IllegalStateException: Failed to check the status of the service cn.tedu.service.IHelloService. No provider available for the service cn.tedu.service.IHelloService from the url zookeeper://39.105.123.197:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-consum01&amp;dubbo=2.5.3&amp;interface=cn.tedu.service.IHelloService&amp;methods=sayHello&amp;pid=10974&amp;revision=0.0.1&amp;side=consumer&amp;timestamp=1529667926718 to the consumer 10.18.236.4 use dubbo version 2.5.3 at com.alibaba.dubbo.config.ReferenceConfig.createProxy(ReferenceConfig.java:420) at com.alibaba.dubbo.config.ReferenceConfig.init(ReferenceConfig.java:300) at com.alibaba.dubbo.config.ReferenceConfig.get(ReferenceConfig.java:138) at com.alibaba.dubbo.config.spring.ReferenceBean.getObject(ReferenceBean.java:65) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:168) ... 6 more 关闭所有服务的检查 关闭所有服务的检查 在消费者的配置文件中配置即可 &lt;dubbo:consumer check=&quot;false&quot; /&gt; 关闭注册中心启动时检查 注册订阅失败的时候报错 &lt;dubbo:registry check=&quot;false&quot; /&gt; dubbo.properties 在src/main/resource文件夹下新建dubbo.properties 在其中添加如下内容 1234dubbo.reference.com.foo.BarService.check=falsedubbo.reference.check=falsedubbo.consumer.check=falsedubbo.registry.check=false 只需要添加这个文件即可，会自动设置 负载均衡策略 这个在集群部署的时候会用到，比如多台机器提供的是同一个服务，那么当浏览器请求服务的时候到底该调用哪台机器上的服务才会更好，此时就需要用到负载均衡策略 优秀博文 多协议 在dubbo中存在8中不同的协议，这些协议的作用都是不同的，此时我们需要根据服务的功能来使用不同的协议，比如我们需要上传文件，那么就需要能够传输大文件的协议 默认是dubbo协议，也是用的最多的协议 不同服务不同协议123456789&lt;!-- 多协议配置 --&gt; &lt;dubbo:protocol name="dubbo" port="20880" /&gt; &lt;dubbo:protocol name="rmi" port="1099" /&gt; &lt;!-- 使用dubbo协议暴露服务，直接使用protocol关键词引用上面配置的协议 --&gt; &lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" protocol="dubbo" /&gt; &lt;!-- 使用rmi协议暴露服务 --&gt; &lt;dubbo:service interface="com.alibaba.hello.api.DemoService" version="1.0.0" ref="demoService" protocol="rmi" /&gt; 多协议暴露服务123456&lt;!-- 多协议配置 --&gt; &lt;dubbo:protocol name="dubbo" port="20880" /&gt; &lt;dubbo:protocol name="hessian" port="8080" /&gt; &lt;!-- 使用多个协议暴露服务 --&gt; &lt;dubbo:service id="helloService" interface="com.alibaba.hello.api.HelloService" version="1.0.0" protocol="dubbo,hessian" /&gt; 多版本 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。可以按照以下的步骤进行版本迁移： 在低压力时间段，先升级一半提供者为新版本 再将所有消费者升级为新版本 然后将剩下的一半提供者升级为新版本 直接使用version指定版本即可 实现 我们有一个HelloService接口，但是有两个实现类，分别为HelloServiceImpl1,HelloServiceImpl2 123456789101112131415public class HelloServiceImpl1 implements IHelloService &#123; public void sayHello() &#123; System.out.println("say helloService1"); &#125;&#125;public class HelloServiceImpl2 implements IHelloService &#123; public void sayHello() &#123; System.out.println("say helloservice2"); &#125;&#125; 配置服务提供者，需要根据版本的不同提供服务 123456789101112131415161718&lt;!-- 配置应用名字，用来标识每一个应用，这里的name最好和工程名字一样 --&gt; &lt;dubbo:application name="dubbo-provider01"&gt;&lt;/dubbo:application&gt; &lt;!-- 使用zookeeper注册中心暴露服务 --&gt; &lt;dubbo:registry address="zookeeper://39.105.123.197:2181" /&gt; &lt;!-- 配置服务的接口实现类，这样当提供服务调用的接口的时候才能找到对应的实现类 --&gt; &lt;bean id="helloService1" class="cn.tedu.servivceImpl.HelloServiceImpl1"&gt;&lt;/bean&gt; &lt;!-- 配置服务的接口实现类，这样当提供服务调用的接口的时候才能找到对应的实现类 --&gt; &lt;bean id="helloService2" class="cn.tedu.servivceImpl.HelloServiceImpl2"&gt;&lt;/bean&gt; &lt;!-- 配置服务提供者,版本为1.0，使用的是helloService1实现类 --&gt; &lt;dubbo:service interface="cn.tedu.service.IHelloService" ref="helloService1" version="1.0"&gt;&lt;/dubbo:service&gt; &lt;!-- 配置服务提供者,版本为2.0，使用的是helloService2实现类 --&gt; &lt;dubbo:service interface="cn.tedu.service.IHelloService" ref="helloService2" version="2.0"&gt;&lt;/dubbo:service&gt; 配置服务消费者，需要指定版本号区分调用的服务 根据版本号区分调用哪个服务 12345&lt;!--调用2.0版本的服务--&gt;&lt;dubbo:reference id="helloService2" interface="cn.tedu.service.IHelloService" version="2.0"/&gt;&lt;!--调用1.0版本的服务--&gt;&lt;dubbo:reference id="helloService1" interface="cn.tedu.service.IHelloService" version="1.0"/&gt; 服务分组 当一个接口有多种实现的时候，我们可以使用分组区分调用的服务功能 假设一个支付的接口PayService，其中实现的类有微信支付WeChatPayServiceImpl和支付宝支付AliPayServiceImpl,那么我们可以使用分组进行区分两种服务 服务 在服务提供者的配置文件中定义 1234567&lt;bean id="aliPayServiceImpl" class="cn.tedu.serviceImpl.AliPayServiceImpl"&gt;&lt;/bean&gt;&lt;bean id="weChatPayServiceImpl" class="cn.tedu.serviceImpl.WeChatPayServiceImpl"&gt;&lt;/bean&gt;&lt;!--使用group区分不同的服务功能 --&gt;&lt;dubbo:service group="alipay" interface="cn.tedu.service.PayService" ref="aliPayServiceImpl" /&gt;&lt;dubbo:service group="weChatPay" interface="cn.tedu.service.PayService" ref="weChatPayServiceImpl" /&gt; 引用 在消费者的配置文件中配置即可，使用group指定需要引用的服务 123&lt;dubbo:reference id="alipayService" interface="cn.tedu.service.PayService" group="alipay"/&gt;&lt;dubbo:reference id="weChatPayService" interface="cn.tedu.service.PayService" group="weChatPay"/&gt; 令牌验证通过令牌验证在注册中心控制权限，以决定要不要下发令牌给消费者，可以防止消费者绕过注册中心访问提供者，另外通过注册中心可灵活改变授权方式，而不需修改或升级提供者 可以全局设置开启令牌验证： 12&lt;!--随机token令牌，使用UUID生成--&gt;&lt;dubbo:provider interface="com.foo.BarService" token="true" /&gt; 或 12&lt;!--固定token令牌，相当于密码--&gt;&lt;dubbo:provider interface="com.foo.BarService" token="123456" /&gt; 也可在服务级别设置： 12&lt;!--随机token令牌，使用UUID生成--&gt;&lt;dubbo:service interface="com.foo.BarService" token="true" /&gt; 或 12&lt;!--固定token令牌，相当于密码--&gt;&lt;dubbo:service interface="com.foo.BarService" token="123456" /&gt; 还可在协议级别设置： 12&lt;!--随机token令牌，使用UUID生成--&gt;&lt;dubbo:protocol name=&quot;dubbo&quot; token=&quot;true&quot; /&gt; 或 12&lt;!--固定token令牌，相当于密码--&gt;&lt;dubbo:protocol name=&quot;dubbo&quot; token=&quot;123456&quot; /&gt; dubbo控制台的安装部署 下载dubbo-admin.war : 链接：https://pan.baidu.com/s/1ggeIIHX 密码：ck4h 优秀博文 线程模型如果事件处理的逻辑能迅速完成，并且不会发起新的 IO 请求，比如只是在内存中记个标识，则直接在 IO 线程上处理更快，因为减少了线程池调度。 但如果事件处理逻辑较慢，或者需要发起新的 IO 请求，比如需要查询数据库，则必须派发到线程池，否则 IO 线程阻塞，将导致不能接收其它请求。 如果用 IO 线程处理事件，又在事件处理过程中发起新的 IO 请求，比如在连接事件中发起登录请求，会报“可能引发死锁”异常，但不会真死锁。 因此，需要通过不同的派发策略和不同的线程池配置的组合来应对不同的场景: 1&lt;dubbo:protocol name="dubbo" dispatcher="all" threadpool="fixed" threads="100" /&gt; Dispatcher all 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。 direct 所有消息都不派发到线程池，全部在 IO 线程上直接执行。 message 只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO 线程上执行。 execution 只请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行。 connection 在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。 ThreadPool fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省) cached 缓存线程池，空闲一分钟自动删除，需要时重建。 limited 可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。 eager 优先创建Worker线程池。在任务数量大于corePoolSize但是小于maximumPoolSize时，优先创建Worker来处理任务。当任务数量大于maximumPoolSize时，将任务放入阻塞队列中。阻塞队列充满时抛出RejectedExecutionException。(相比于cached:cached在任务数量超过maximumPoolSize时直接抛出异常而不是将任务放入阻塞队列) 多注册中心Dubbo 支持同一服务向多注册中心同时注册，或者不同服务分别注册到不同的注册中心上去，甚至可以同时引用注册在不同注册中心上的同名服务。另外，注册中心是支持自定义扩展的 1。 多注册中心注册比如：中文站有些服务来不及在青岛部署，只在杭州部署，而青岛的其它应用需要引用此服务，就可以将服务同时注册到两个注册中心。 123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="world" /&gt; &lt;!-- 多注册中心配置 --&gt; &lt;dubbo:registry id="hangzhouRegistry" address="10.20.141.150:9090" /&gt; &lt;dubbo:registry id="qingdaoRegistry" address="10.20.141.151:9010" default="false" /&gt; &lt;!-- 向多个注册中心注册 --&gt; &lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" registry="hangzhouRegistry,qingdaoRegistry" /&gt;&lt;/beans&gt; 不同服务使用不同注册中心比如：CRM 有些服务是专门为国际站设计的，有些服务是专门为中文站设计的。 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="world" /&gt; &lt;!-- 多注册中心配置 --&gt; &lt;dubbo:registry id="chinaRegistry" address="10.20.141.150:9090" /&gt; &lt;dubbo:registry id="intlRegistry" address="10.20.154.177:9010" default="false" /&gt; &lt;!-- 向中文站注册中心注册 --&gt; &lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" registry="chinaRegistry" /&gt; &lt;!-- 向国际站注册中心注册 --&gt; &lt;dubbo:service interface="com.alibaba.hello.api.DemoService" version="1.0.0" ref="demoService" registry="intlRegistry" /&gt;&lt;/beans&gt; 多注册中心引用比如：CRM 需同时调用中文站和国际站的 PC2 服务，PC2 在中文站和国际站均有部署，接口及版本号都一样，但连的数据库不一样。 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="world" /&gt; &lt;!-- 多注册中心配置 --&gt; &lt;dubbo:registry id="chinaRegistry" address="10.20.141.150:9090" /&gt; &lt;dubbo:registry id="intlRegistry" address="10.20.154.177:9010" default="false" /&gt; &lt;!-- 引用中文站服务 --&gt; &lt;dubbo:reference id="chinaHelloService" interface="com.alibaba.hello.api.HelloService" version="1.0.0" registry="chinaRegistry" /&gt; &lt;!-- 引用国际站站服务 --&gt; &lt;dubbo:reference id="intlHelloService" interface="com.alibaba.hello.api.HelloService" version="1.0.0" registry="intlRegistry" /&gt;&lt;/beans&gt; 如果只是测试环境临时需要连接两个不同注册中心，使用竖号分隔多个不同注册中心地址： 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="world" /&gt; &lt;!-- 多注册中心配置，竖号分隔表示同时连接多个不同注册中心，同一注册中心的多个集群地址用逗号分隔 --&gt; &lt;dubbo:registry address="10.20.141.150:9090|10.20.154.177:9010" /&gt; &lt;!-- 引用服务 --&gt; &lt;dubbo:reference id="helloService" interface="com.alibaba.hello.api.HelloService" version="1.0.0" /&gt;&lt;/beans&gt; 分组聚合按组合并返回结果 1，比如菜单服务，接口一样，但有多种实现，用group区分，现在消费方需从每种group中调用一次返回结果，合并结果返回，这样就可以实现聚合菜单项。 配置搜索所有分组 1&lt;dubbo:reference interface="com.xxx.MenuService" group="*" merger="true" /&gt; 合并指定分组 1&lt;dubbo:reference interface="com.xxx.MenuService" group="aaa,bbb" merger="true" /&gt; 指定方法合并结果，其它未指定的方法，将只调用一个 Group 123&lt;dubbo:reference interface="com.xxx.MenuService" group="*"&gt; &lt;dubbo:method name="getMenuItems" merger="true" /&gt;&lt;/dubbo:service&gt; 某个方法不合并结果，其它都合并结果 123&lt;dubbo:reference interface="com.xxx.MenuService" group="*" merger="true"&gt; &lt;dubbo:method name="getMenuItems" merger="false" /&gt;&lt;/dubbo:service&gt; 指定合并策略，缺省根据返回值类型自动匹配，如果同一类型有两个合并器时，需指定合并器的名称 2 123&lt;dubbo:reference interface="com.xxx.MenuService" group="*"&gt; &lt;dubbo:method name="getMenuItems" merger="mymerge" /&gt;&lt;/dubbo:service&gt; 指定合并方法，将调用返回结果的指定方法进行合并，合并方法的参数类型必须是返回结果类型本身 123&lt;dubbo:reference interface="com.xxx.MenuService" group="*"&gt; &lt;dubbo:method name="getMenuItems" merger=".addAll" /&gt;&lt;/dubbo:service&gt; 配置文件覆盖策略 消费者中的相同的配置将会覆盖提供者的配置 回声测试 回声测试用于检测服务是否可用，回声测试按照正常请求流程执行，能够测试整个调用是否通畅，可用于监控。所有服务自动实现 EchoService 接口，只需将任意服务引用强制转型为 EchoService，即可使用。 Spring 配置： 1&lt;dubbo:reference id="memberService" interface="com.xxx.MemberService" /&gt; 代码： 123456789// 远程服务引用MemberService memberService = ctx.getBean("memberService"); EchoService echoService = (EchoService) memberService; // 强制转型为EchoService// 回声测试可用性String status = echoService.$echo("OK"); assert(status.equals("OK")); 上下文信息 RpcContext是一个 ThreadLocal的临时状态记录器，当接收到 RPC 请求，或发起 RPC 请求时，RpcContext 的状态都会变化。比如：A 调 B，B 再调 C，则 B 机器上，在 B 调 C 之前，RpcContext 记录的是 A 调 B 的信息，在 B 调 C 之后，RpcContext 记录的是 B 调 C 的信息。 RpcContext的状态是随时变化的，只会存储最近调用的信息 服务消费方123456789101112131415161718public class TestDubbo &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext("appliactionContext.xml"); IHelloService helloService=context.getBean("helloService",IHelloService.class); //执行服务，只有执行服务才会认定为消费端 helloService.sayHello(); //测试是否是消费者 Boolean flag=RpcContext.getContext().isConsumerSide(); System.out.println(flag); //获取提供者的ip地址 String ip=RpcContext.getContext().getRemoteHost(); System.out.println(ip); //获取调用者的名称，这里的application是&lt;dubbo:application&gt;标签中的名字 String parameters=RpcContext.getContext().getUrl().getParameter("application"); System.out.println(parameters); context.close(); &#125;&#125; 服务提供方123456789101112131415public class XxxServiceImpl implements XxxService &#123; public void xxx() &#123; // 本端是否为提供端，这里会返回true boolean isProviderSide = RpcContext.getContext().isProviderSide(); // 获取调用方IP地址 String clientIP = RpcContext.getContext().getRemoteHost(); // 获取当前服务配置信息，所有配置信息都将转换为URL的参数 String application = RpcContext.getContext().getUrl().getParameter("application"); // 注意：每发起RPC调用，上下文状态会变化 yyyService.yyy(); // 此时本端变成消费端，这里会返回false boolean isProviderSide = RpcContext.getContext().isProviderSide(); &#125; &#125; 隐式参数 可以通过 RpcContext 上的 setAttachment 和 getAttachment 在服务消费方和提供方之间进行参数的隐式传递。 1 在服务消费方端设置隐式参数 setAttachment 设置的 KV 对，在完成下面一次远程调用会被清空，即多次远程调用要多次设置。 123RpcContext.getContext().setAttachment("index", "1"); // 隐式传参，后面的远程调用都会隐式将这些参数发送到服务器端，类似cookie，用于框架集成，不建议常规业务使用xxxService.xxx(); // 远程调用// ... 在服务提供方端获取隐式参数1234567public class XxxServiceImpl implements XxxService &#123; public void xxx() &#123; // 获取客户端隐式传入的参数，用于框架集成，不建议常规业务使用 String index = RpcContext.getContext().getAttachment("index"); &#125;&#125; 注意：path, group, version, dubbo, token, timeout 几个 key 是保留字段，请使用其它值。 ↩ 异步调用基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小。 1 在 consumer.xml 中配置： 123456&lt;dubbo:reference id="fooService" interface="com.alibaba.foo.FooService"&gt; &lt;dubbo:method name="findFoo" async="true" /&gt;&lt;/dubbo:reference&gt;&lt;dubbo:reference id="barService" interface="com.alibaba.bar.BarService"&gt; &lt;dubbo:method name="findBar" async="true" /&gt;&lt;/dubbo:reference&gt; 调用代码: 123456789101112131415161718// 此调用会立即返回nullfooService.findFoo(fooId);// 拿到调用的Future引用，当结果返回后，会被通知和设置到此FutureFuture&lt;Foo&gt; fooFuture = RpcContext.getContext().getFuture(); // 此调用会立即返回nullbarService.findBar(barId);// 拿到调用的Future引用，当结果返回后，会被通知和设置到此FutureFuture&lt;Bar&gt; barFuture = RpcContext.getContext().getFuture(); // 此时findFoo和findBar的请求同时在执行，客户端不需要启动多线程来支持并行，而是借助NIO的非阻塞完成// 如果foo已返回，直接拿到返回值，否则线程wait住，等待foo返回后，线程会被notify唤醒Foo foo = fooFuture.get(); // 同理等待bar返回Bar bar = barFuture.get(); // 如果foo需要5秒返回，bar需要6秒返回，实际只需等6秒，即可获取到foo和bar，进行接下来的处理。 你也可以设置是否等待消息发出： 2 sent=&quot;true&quot; 等待消息发出，消息发送失败将抛出异常。 sent=&quot;false&quot; 不等待消息发出，将消息放入 IO 队列，即刻返回。 1&lt;dubbo:method name="findFoo" async="true" sent="true" /&gt; 如果你只是想异步，完全忽略返回值，可以配置 return=&quot;false&quot;，以减少 Future 对象的创建和管理成本： 1&lt;dubbo:method name="findFoo" async="true" return="false" /&gt; 2.0.6 及其以上版本支持 ↩ 异步总是不等待返回 ↩ 本地存根 dubbo的本地存根的原理是：远程服务后，客户端通常只剩下接口，而实现全在服务器端，但提供方有些时候想在客户端也执行部分逻辑，那么就在服务消费者这一端提供了一个Stub类，然后当消费者调用provider方提供的dubbo服务时，客户端生成 Proxy 实例，这个Proxy实例就是我们正常调用dubbo远程服务要生成的代理实例，然后消费者这方会把 Proxy 通过构造函数传给 消费者方的Stub ，然后把 Stub 暴露给用户，Stub 可以决定要不要去调 Proxy。会通过代理类去完成这个调用，这样在Stub类中，就可以做一些额外的事，来对服务的调用过程进行优化或者容错的处理。附图： 总结：如果消费者想用在调用远程服务的同时还想在之前或者之后实现自己的部分逻辑，那么就需要在消费者端定义一个代理类，其实在消费者调用服务的时候，实际上是调用的代理类。不过其中代理类返回的数据是可以传递给服务提供者的 实现步骤 1. 定义一个服务接口和服务实现类 123456public interface UserInterface &#123; public User getUserById(Integer id) ;&#125; 12345678910public class UserService implements UserInterface &#123; public User getUserById(Integer id) &#123; User user = new User() ; user.setId(id); user.setName("hu"); return user; &#125; &#125; 服务分布配置 1234&lt;dubbo:service interface="org.huxin.dubbo.test.user.service.UserInterface" ref="userService" protocol="dubbo" retries="0"/&gt; &lt;bean id="userService" class="org.huxin.dubbo.test.user.service.impl.UserService" /&gt; 3.服务消费者的Stub类 123456789101112131415161718192021222324252627282930public class UserServiceStub implements UserInterface &#123; //必须定义这个接口，以便接收dubbo在调用远程服务生成的服务代理类 private UserInterface userLocalService ; //这个构造函数必须要提供，dubbo框架会在消费者这一方调用这个方法 public UserServiceStub(UserInterface userLocalService ) &#123; this.userLocalService = userLocalService ; &#125; public User getUserById(Integer id) &#123; User user = null ; try &#123; if (id == 1) &#123; user = this.userLocalService.getUserById(id) ; &#125;else &#123; user = new User(); user.setName("系统用户"); &#125; &#125;catch(Exception e) &#123; user = new User(); user.setName("异常用户"); &#125; return user ; &#125;&#125; 服务消费方的配置 12&lt;dubbo:reference id="userService" interface="org.huxin.dubbo.test.user.service.UserInterface" stub="org.huxin.dubbo.test.UserServiceStub" protocol="dubbo"/&gt; 5.测试代码 12345678@Test public void testGetUserById()&#123; Integer id = 2 ; UserInterface userService = context.getBean(UserInterface.class) ; User user = userService.getUserById( id) ; System.out.println(user.getName()); &#125; 总结 实际上调用getUserById(id)这个方法是代理类UserServiceStub的方法，返回的User对象也是这个这个方法返回的 本地伪装 本地伪装 延迟暴露 延迟暴露 并发控制 并发控制 连接控制 限制连接个数 连接控制 延迟连接 延迟连接 粘滞连接粘滞连接用于有状态服务，尽可能让客户端总是向同一提供者发起调用，除非该提供者挂了，再连另一台。 粘滞连接将自动开启延迟连接，以减少长连接数。 1&lt;dubbo:protocol name="dubbo" sticky="true" /&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring整合Redis]]></title>
      <url>%2F2018%2F06%2F26%2FSpring%E6%95%B4%E5%90%88Redis%2F</url>
      <content type="text"><![CDATA[Spring - Data - Redis添加依赖 需要spring的版本为4.xxx 12345678910111213&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.8.9.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置RedisTemplate 在/src/main/resource文件夹下新建一个redis.properties文件，其中设置redis的配置信息 12345678910111213hostName=39.105.123.197 port=6379timeout=15000usePool=truemaxIdle=80minIdle=80maxWaitMillis=500minEvictableIdleTimeMillis=300000numTestsPerEvictionRun=3timeBetweenEvictionRunsMillis=60000testOnBorrow=truetestOnReturn=falsetestOnCreate=false 在src/main/resource文件夹下新建一个文件spring-redis.xml 创建连接池JedisPoolConfig 创建连接工厂JedisConnectionFactory 配置RedisTemplate，用于操作Redis数据库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;!-- 加载redis.properties,其中定义了数据库的配置信息 --&gt; &lt;util:properties id="redisConfig" location="classpath:redis.properties" /&gt; &lt;!-- 配置Redis的连接池 --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;!-- 配置最大空闲连接数，当空闲连接超过该值时就挨个关闭多余的连接，但不能小于minldle --&gt; &lt;property name="maxIdle" value="#&#123;redisConfig.maxIdle&#125;"&gt;&lt;/property&gt; &lt;!-- 配置最小空闲连接数 --&gt; &lt;property name="minIdle" value="#&#123;redisConfig.minIdle&#125;"&gt;&lt;/property&gt; &lt;!-- 验证连接是否有效 --&gt; &lt;!-- 设置获取连接的时候测试连接是否可用，默认为false --&gt; &lt;property name="testOnBorrow" value="#&#123;redisConfig.testOnBorrow&#125;"&gt;&lt;/property&gt; &lt;!-- 新建连接的时候测试连接是否可用，默认为false --&gt; &lt;property name="testOnCreate" value="#&#123;redisConfig.testOnCreate&#125;"&gt;&lt;/property&gt; &lt;!-- 将连接释放回连接池的时候测试连接 默认为false --&gt; &lt;property name="testOnReturn" value="#&#123;redisConfig.testOnReturn&#125;"&gt;&lt;/property&gt; &lt;!-- 设置等待获取连接池连接的时间，一旦超过这个时间，抛出异常 单位毫秒 --&gt; &lt;property name="maxWaitMillis" value="#&#123;redisConfig.maxWaitMillis&#125;"&gt;&lt;/property&gt; &lt;!-- 连接空闲多久从池中去除，单位为毫秒 &lt;=0表示禁用 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="#&#123;redisConfig.minEvictableIdleTimeMillis&#125;"&gt;&lt;/property&gt; &lt;!-- 设置每次测试多少空闲连接 &lt;=0表示禁用 --&gt; &lt;property name="numTestsPerEvictionRun" value="#&#123;redisConfig.numTestsPerEvictionRun&#125;"&gt;&lt;/property&gt; &lt;!-- 设置定时测试时间，单位毫秒 &lt;=0表示禁用 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="#&#123;redisConfig.timeBetweenEvictionRunsMillis&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="jedisConnFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;!-- 设置是否使用连接池，默认为true --&gt; &lt;property name="usePool" value="#&#123;redisConfig.usePool&#125;" /&gt; &lt;!-- 设置连接池，使用上面配置好的连接池jedisPoolConfig --&gt; &lt;property name="poolConfig" ref="jedisPoolConfig"&gt;&lt;/property&gt; &lt;!-- 设置远程的IP地址 --&gt; &lt;property name="hostName" value="#&#123;redisConfig.hostName&#125;" /&gt; &lt;!-- 设置端口号，默认为6379 --&gt; &lt;property name="port" value="#&#123;redisConfig.port&#125;"&gt;&lt;/property&gt; &lt;!-- 设置获取连接的超时时间 --&gt; &lt;property name="timeout" value="#&#123;redisConfig.timeout&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置 StringRedisSerializer序列化 --&gt; &lt;bean id="stringRedisSerializer" class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt; &lt;bean id="jdkSerializationRedisSerializer" class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer" /&gt; &lt;!-- 配置RedisTemplate，其中封装了操作Redis的各种方法 --&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;!-- 配置Jedis的连接工厂，引用上面 --&gt; &lt;property name="connectionFactory" ref="jedisConnFactory" /&gt; &lt;!-- 配置key的序列化 一般都会使用stringRedisSerializer，默认使用的是JdkSerializationRedisSerializer --&gt; &lt;property name="keySerializer" ref="stringRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 配置JdkSerializationRedisSerializer序列化 --&gt; &lt;property name="valueSerializer" ref="jdkSerializationRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 配置hashkey的序列化，就是field --&gt; &lt;property name="hashKeySerializer" ref="stringRedisSerializer"&gt;&lt;/property&gt; &lt;!-- 配置hashvalue的值的序列化 --&gt; &lt;property name="hashValueSerializer" ref="jdkSerializationRedisSerializer"&gt;&lt;/property&gt; &lt;/bean&gt; 序列化问题 Spring Data Redis提供了对Key-Value的序列号，在使用RedisTemplate对象是默认使用JdkSerializationRedisSerializer实现。还提供了其它的序列化实现如：Jackson2JsonRedisSerializer，JacksonJsonRedisSerializer，GenericToStringSerializer，StringRedisSerializer，OxmSerializer。 各种序列化的方式有各种的优点，需要自己权衡使用 上面我们使用的是JdkSerializationRedisSerializer，但是我们的key使用的是StringRedisSerializer RedisTemplate 这个封装了redis中的所有命令，只需要我们调用即可 API文档 常用的类 Key类型操作 ValueOperations Redis String/Value 操作 ListOperations Redis List 操作 SetOperations Redis Set 操作 ZSetOperations Redis Sort Set 操作 HashOperations Redis Hash 操作 Value约束操作 BoundValueOperations Redis String/Value key 约束 BoundListOperations Redis List key 约束 BoundSetOperations Redis Set key 约束 BoundZSetOperations Redis Sort Set key 约束 BoundHashOperations Redis Hash key 约束 文档 RedisTemplate API 优质博文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis主从复制]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
      <content type="text"><![CDATA[Redis主从复制 本章介绍Redis的一个强大功能–主从复制。一台master主机可以拥有多台slave从机。而一台slave从机又可以拥有多个slave从机。如此下去，形成强大的多级服务器集群架构（高扩展）。可以避免Redis单点故障，实现容灾恢复效果（高可用）。读写分离的架构，满足读多写少的并发应用场景。 作用 主从复制，读写分离，容灾恢复。一台主机负责写入数据，多台从机负责备份数据。在高并发的场景下，即便是主机挂了，可以用从机代替主机继续工作，避免单点故障导致系统性能问题。读写分离，让读多写少的应用性能更佳。 搭建前的准备 因为服务器有限，因此我们只能在一台服务器上模拟操作，实际工作中都是在不同的机器上 cd /etc : 进入etc目录 cp redis.conf redis6380.conf : 复制一份redis的配置文件 cp redis.conf redis6381.conf : 复制一份redis的配置文件 修改新建的配置文件中的内容，只需要三份配置文件中的前四项不同即可 port ： 端口号 pidfile ： pid的文件名 logfile ： 日志的文件名 dbfilename ： 修改持久化的文件名称 daemonize ： 设置为守护线程启动，yes redis-server redis.conf : 启动端口为6379的redis redis-server redis6380.conf : 启动端口为6380的redis redis-server redis6381.conf : 启动端口为6381的redis redis-cli -h 127.0.0.1 -p 6379 : 连接端口为6379的redis redis-cli -h 127.0.0.1 -p 6380 : 连接端口为6380的redis redis-cli -h 127.0.0.1 -p 6381 : 连接端口为6381的redis 主从节点关系 一个主节点可以有多个从节点，但是一个从节点(slaver)只能有一个主节点(master) 查看复制信息 info replication 初始状态没有建立复制的时候，使用info replication，输出以下信息 12345678# Replicationrole:master # 角色，默认是主节点connected_slaves:0 master_repl_offset:37617 # 自身复制偏移量repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:17378 建立主从复制之后，从节点复制信息如下 123456789101112131415role:slave # 角色为从节点master_host:127.0.0.1 # 主节点ip地址master_port:6381 # 端口master_link_status:up # 是否已经连接上 up表示连接上，down表示没有连接master_last_io_seconds_ago:3master_sync_in_progress:0slave_repl_offset:37688slave_priority:100slave_read_only:1 # 从节点设置只读，不能写connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:17378 建立复制动态配置 直接在redis中敲命令设置主从节点，一旦重启之后会恢复原型 slaveof ip port : 建立复制，在哪个redis中执行这条语句，那么哪个redis就作为从节点 slaveof 127.0.0.1 6381 : 6381端口开启的redis作为主节点 配置文件配置 我们可以在配置文件中配置，大概在配置文件中的210行左右，有一个# slaveof &lt;masterip&gt; &lt;masterport&gt;，我们可以在这个地方配置slaveof 127.0.0.1 6381 一旦配置完成之后，redis启动将会建立主从复制 操作 建立了主从关系之后，将会自动执行全量复制，即是主节点中的内容将会更新到从节点中 从节点此时只能执行只读命令，比如get key,不能执行set ke偶们y value 主节点的操作会同步更新到从节点中，比如在主节点中执行set name 陈加兵,那么在从节点中就会出现name这个key 断开复制 slaveof no one : 断开复制 在从节点中执行slaveof no one，那么将会断开和主节点的关系，此时的从节点将会成为主节点，可以使用info replication查看 断开主从复制关系并不会抛弃原有的数据，只是不会接收主节点的数据变化而已 切主 通过slaveof命令还可以实现切主操作,所谓切主是指把当前从节点对主节点的复制切换到另一个主节点。执行slaveof{newMasterIp}{newMasterPort}命令即可,例如把6380节从原来的复制6379节点变为复制6381节点 执行流程 断开与旧主节点复制关系。 与新主节点建立复制关系。 删除从节点当前所有数据。 对新主节点进行复制操作。 提示 切主后从节点会清空之前所有的数据,线上人工操作时小心slaveof在错误的节点上执行或者指向错误的主节点。 安全性 对于数据比较重要的节点,主节点会通过设置requirepass参数进行密码验证,这时所有的客户端访问必须使用auth命令实行校验。从节点与主节点的复制连接是通过一个特殊标识的客户端来完成,因此需要配置从节点的masterauth参数与主节点密码保持一致,这样从节点才可以正确地连接到主节点并发起复制流程。 只读 默认情况下,从节点使用slave-read-only=yes配置为只读模式。由于复制只能从主节点到从节点,对于从节点的任何修改主节点都无法感知,修改从节点会造成主从数据不一致。因此建议线上不要修改从节点的只读模式。 传输延迟 主从节点一般部署在不同机器上,复制时的网络延迟就成为需要考虑的问题,Redis为我们提供了repl-disable-tcp-nodelay参数用于控制是否关闭TCP_NODELAY，默认关闭,说明如下: 当关闭时,主节点产生的命令数据无论大小都会及时地发送给从节点,这样主从之间延迟会变小,但增加了网络带宽的消耗。适用于主从之间的网络环境良好的场景,如同机架或同机房部署。 当开启时,主节点会合并较小的TCP数据包从而节省带宽。默认发送时间间隔取决于Linux的内核,一般默认为40毫秒。这种配置节省了带宽但增大主从之间的延迟。适用于主从网络环境复杂或带宽紧张的场景,如跨机房部署。 提示 部署主从节点时需要考虑网络延迟、带宽使用率、防灾级别等因素,如要求低延迟时,建议同机架或同机房部署并关闭repl-disable-tcp-nodelay;如果考虑高容灾性,可以同城跨机房部署并开启repl-disable-tcp-nodelay 一主一从 一主一从结构是最简单的复制拓扑结构,用于主节点出现宕机时从节点提供故障转移支持。当应用写命令并发量较高且需要持久化时,可以只在从节点上开启AOF,这样既保证数据安全性同时也避免了持久化对主节点的性能干扰。但需要注意的是,当主节点关闭持久化功能时,如果主节点脱机要避免自动重启操作。因为主节点之前没有开启持久化功能自动重启后数据集为空,这时从节点如果继续复制主节点会导致从节点数据也被清空的情况,丧失了持久化的意义。安全的做法是在从节点上执行slaveof no one断开与主节点的复制关系,再重启主节点从而避免这一问题。 一主多从 一主多从结构(又称为星形拓扑结构)使得应用端可以利用多个从节点实现读写分离。对于读占比较大的场景,可以把读命令发送到从节点来分担主节点压力。同时在日常开发中如果需要执行一些比较耗时的读命令,如:keys、sort等,可以在其中一台从节点上执行,防止慢查询对主节点造成阻塞从而影响线上服务的稳定性。对于写并发量较高的场景,多个从节点会导致主节点写命令的多次发送从而过度消耗网络带宽,同时也加重了主节点的负载影响服务稳定性。 树状主从结构 树状主从结构(又称为树状拓扑结构)使得从节点不但可以复制主节点数据,同时可以作为其他从节点的主节点继续向下层复制。通过引入复制中间层,可以有效降低主节点负载和需要传送给从节点的数据量。数据写入节点A后会同步到B和C节点,B节点再把数据同步到D和E节点,数据实现了一层一层的向下复制。当主节点需要挂载多个从节点时为了避免对主节点的性能干扰,可以采用树状主从结构降低主节点压力。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis的管道Pipeline]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%E7%9A%84%E7%AE%A1%E9%81%93Pipeline%2F</url>
      <content type="text"><![CDATA[Redis的管道(Pipeline)为什么使用管道 其中redis的执行一条命令可以分为四个步骤 发送命令 命令排队 命令执行 返回结果 其中1-4之间所需要的时间称为往返时间(RTT) Redis提供了批量操作命令(例如mget、mset等),有效地节约RTT。但大部分命令是不支持批量操作的,例如要执行n次hgetall命令,并没有mhgetall命令存在,需要消耗n次RTT。Redis的客户端和服务端可能部署在不同的机器上。例如客户端在北京,Redis服务端在上海,两地直线距离约为1300公里,那么1次RTT时间=1300×2/(300000×2/3)=13毫秒(光在真空中传输速度为每秒30万公里,这里假设光纤为光速的2/3),那么客户端在1秒内大约只能执行80次左右的命令,这个和Redis的高并发高吞吐特性背道而驰。 Pipeline(管道)机制能改善上面这类问题,它能将一组Redis命令进行组装,通过一次RTT传输给Redis,再将这组Redis命令的执行结果按顺序返回给客户端 客户端使用管道执行命令 使用的是Jedis 我们模拟批量删除所有的键，在redis中并没有提供这种方法，我们只能一个个的删除 12345678910@Testpublic void testPipeline()&#123; Jedis jedis=new Jedis("localhost", 6379); Pipeline pipeline=jedis.pipelined(); //获取管道连接对象 Set&lt;String&gt; keys=jedis.keys("*"); //获取所有的key for (String key : keys) &#123; pipeline.del(key); //删除key，这里并不是真正的删除，只是将命令排入管道中 &#125; pipeline.sync(); //执行管道命令&#125; API 所有的命令都可以使用管道连接，只是通过Pipeline对象调用而已 pipeline.set() ：添加字符串 pipeline.get() ：获取字符串 pipeline.sync() : 执行管道命令，不返回其中命令执行的结果 pipeline.syncAndReturnAll() ： 执行其中的命令，并且将每条命令执行的结果存在List中，我们可以接收并且输出查看]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis持久化]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
      <content type="text"><![CDATA[Redis持久化RDB (默认使用) RDB持久化是把当前进程数据生成快照保存到硬盘的过程,触发RDB持久化过程分为手动触发和自动触发。 手动触发 (bgsave) 执行bgsave命令,Redis父进程判断当前是否存在正在执行的子进程,如RDB/AOF子进程,如果存在bgsave命令直接返回。 父进程执行fork操作创建子进程,fork操作过程中父进程会阻塞,通过info stats命令查看latest_fork_usec选项,可以获取最近一个fork操作的耗时,单位为微秒。 父进程fork完成后,bgsave命令返回“Background saving started”信息并不再阻塞父进程,可以继续响应其他命令 子进程创建RDB文件,根据父进程内存生成临时快照文件,完成后对原有文件进行原子替换。执行lastsave命令可以获取最后一次生成RDB的时间,对应info统计的rdb_last_save_time选项。 进程发送信号给父进程表示完成,父进程更新统计信息,具体见info Persistence下的rdb_*相关选项。 自动触发 执行debug reload命令重新加载Redis时,也会自动触发save操作。 默认情况下执行shutdown命令时,如果没有开启AOF持久化功能则自动执行bgsave。 使用save相关配置,如“save m n”。表示m秒内数据集存在n次修改时,自动触发bgsave。 这个在配置文件redis.conf中配置 默认的配置如下 123save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存 stop-writes-on-bgsave-error ：默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了 rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。 rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。 dbfilename ：设置快照的文件名，默认是 dump.rdb dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。默认是和当前配置文件保存在同一目录。 也就是说通过在配置文件中配置的 save 方式，当实际操作满足该配置形式时就会进行 RDB 持久化，将当前的内存快照保存在 dir 配置的目录中，文件名由配置的dbfilename决定。 备份的文件位置 在redis.conf中修改 dbfilename ：设置快照的文件名，默认是 dump.rdb dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。默认是和当前配置文件保存在同一目录。 RDB的优缺点优点 RDB是一个紧凑压缩的二进制文件,代表Redis在某个时间点上的数据快照。非常适用于备份,全量复制等场景。比如每6小时执行bgsave备份,并把RDB文件拷贝到远程机器或者文件系统中(如hdfs),用于灾难恢复。 Redis加载RDB恢复数据远远快于AOF的方式。 缺点 RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程,属于重量级操作,频繁执行成本过高。 RDB文件使用特定二进制格式保存,Redis版本演进过程中有多个格式的RDB版本,存在老版本Redis服务无法兼容新版RDB格式的问题。 针对RDB不适合实时持久化的问题,Redis提供了AOF持久化方式来解决。 AOF 开启AOF功能需要设置配置:appendonly yes,默认不开启。AOF文件名通过appendfilename配置设置,默认文件名是appendonly.aof。保存路径同RDB持久化方式一致,通过dir配置指定。AOF的工作流程操作:命令写入(append)、文件同步(sync)、文件重写(rewrite)、重启加载(load) AOF 工作流程 所有的写入命令会追加到aof_buf(缓冲区)中。 AOF缓冲区根据对应的策略向硬盘做同步操作(同步策略) 随着AOF文件越来越大,需要定期对AOF文件进行重写,达到压缩的目的 当Redis服务器重启时,可以加载AOF文件进行数据恢复。 开启 在redis.conf文件中 在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相较RDB会慢一些 1appendonly yes # 开启 开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改： 1appendfilename appendonly.aof 文件同步 在redis.conf配置文件中配置即可 Redis提供了多种AOF缓冲区同步文件策略,由参数appendfsync控制，可以在配置文件中配置，三种策略如下： appendfsync always 每次写入都要同步AOF文件,在一般的SATA硬盘上,Redis只能支持大约几百TPS写入,显然跟Redis高性能特性背道而驰,不建议配置。 每次写入都需要同步，最安全也是最慢的 appendfsync everysec 是建议的同步策略,也是默认配置,做到兼顾性能和数据安全性。理论上只有在系统突然宕机的情况下丢失1秒的数据。 每秒同步一次，默认的配置 appendfsync no 由于操作系统每次同步AOF文件的周期不可控,而且会加大每次同步硬盘的数据量,虽然提升了性能,但数据安全性无法保证 不主动同步，而是交由操作系统来做(每30秒同步一次) 文件重写 随着命令不断写入AOF,文件会越来越大,为了解决这个问题,Redis引入AOF重写机制压缩文件体积。AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程。 文件变小的原因 进程内已经超时的数据不再写入文件。 旧的AOF文件含有无效命令,如del key1、hdel key2、srem keys、seta111、set a222等。重写使用进程内数据直接生成,这样新的AOF文件只保留最终数据的写入命令。 多条写命令可以合并为一个,如:lpush list a、lpush list b、lpush listc可以转化为:lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢出,对于list、set、hash、zset等类型操作,以64个元素为界拆分为多条 手动触发 直接调用bgrewriteaof命令。 自动触发 根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。 auto-aof-rewrite-min-size:表示运行AOF重写时文件最小体积,默认为64MB。 auto-aof-rewrite-percentage:代表当前AOF文件空间(aof_current_size)和上一次重写后AOF文件间(aof_base_size)的比值。 性能优化fork操作问题 每次执行持久化的时候都需要fork一个子进程，同时也会阻塞命令的执行 当Redis做RDB或AOF重写时,一个必不可少的操作就是执行fork操作创建子进程,对于大多数操作系统来说fork是个重量级错误。虽然fork创建的子进程不需要拷贝父进程的物理内存空间,但是会复制父进程的空间内存页表。例如对于10GB的Redis进程,需要复制大约20MB的内存页表,因此fork操作耗时跟进程总内存量息息相关,如果使用虚拟化技术,特别是Xen虚拟机,fork操作会更耗时。 对于高流量的Redis实例OPS可达5万以上,如果fork操作耗时在秒级别将拖慢Redis几万条命令执行,对线上应用延迟影响非常明显。正常情况下fork耗时应该是每GB消耗20毫秒左右。可以在info stats统计中查latest_fork_usec指标获取最近一次fork操作耗时,单位微秒。 优化 优先使用物理机或者高效支持fork操作的虚拟化技术,避免使用Xen。 控制Redis实例最大可用内存,fork耗时跟内存量成正比,线上建议每个Redis实例内存控制在10GB以内。 合理配置Linux内存分配策略,避免物理内存不足导致fork失败 降低fork操作的频率,如适度放宽AOF自动触发时机,避免不必要的全量复制等。 文件恢复 如果需要恢复数据，只需要将备份的文件放在redis的安装目录即可，那么当redis重启加载的时候就会自动恢复数据]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis客户端操作]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[Redis客户端Jedis远程连接 yum install redis : 安装redis 开启6379端口 在自己的阿里云的控制台上开启防火墙6379 firewall-cmd --zone=public --add-port=6379/tcp 如果显示firewall not running start firewalld.service 解决拒绝连接问题 redis默认只能允许本地连接，因为在redis.conf定义了bind 127.0.0.1 vi /etc/redis.conf : 打开配置文件 修改bind 127.0.0.1为bind 0.0.0.0即可 添加依赖123456&lt;!-- jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/dependency&gt; 测试1234567891011121314151617181920212223242526272829303132333435//操作String类型的数据@Testpublic void testString()&#123; Jedis jedis=new Jedis("47.104.192.157",6379); //创建jedis对象，其中的参数是IP地址，如果是本地写localhost jedis.set("name", "chenjiabing"); //添加一个String 类型的数据 key为name jedis.get("name"); //获取key为name的值 jedis.del("name"); //删除key为name的数据 jedis.close(); &#125;//测试Hash类型@Testpublic void testHa shSet()&#123; Jedis jedis=new Jedis("localhost"); jedis.hset("user", "name","陈加兵"); //添加一个key为user的Hash类型的数据 jedis.hset("user", "age", "22"); //添加age jedis.hincrBy("user", "age", 200); //年龄增加200 String name=jedis.hget("user", "name"); //获取name的值 Integer age=Integer.parseInt(jedis.hget("user", "age")); //获取age的值，转换为Integer类型 System.out.println(name); System.out.println(age); jedis.close(); &#125;//测试List类型@Testpublic void testList()&#123; Jedis jedis=new Jedis("localhost"); jedis.lpush("list", "陈加兵"); //从左侧添加一个值 System.out.println(jedis.llen("list")); //获取长度 jedis.lpush("list", "1","2","TOM"); //左侧存放多个值 System.out.println(jedis.rpop("list")); //从右侧取出 jedis.close();&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis常用命令]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[Redis常用命令Redis全局命令 keys * : 查看所有的key，这个会遍历所有的键,复杂度为O(n)，因此当存在了大量的key，应该禁止使用这个命令 dbsize ：查看键key的个数，这个是直接获取内置的键总数变量，因此复杂度为O(1) exists key : 检查键值是否存在，存在返回1，否则返回0 del key ： 删除指定的键值 del a : 删除一个键 del a b c : 同时删除多个键 expire key seconds : 设置键的过期时间，单位为秒，超过过期时间会自动删除该键 ttl key： 查看键的剩余过期时间 大于0的整数： 剩余过期时间 -1 ：没有设置过期时间 -2 ： 该键不存在 type key ： 查看key的类型，如果不存在返回none 内部编码String 类型 字符串类型的内部编码有3种: int: 8个字节的长整型。 embstr：小于等于39个字节的字符串。 raw : 大于39个字节的字符串。 Redis会根据当前值的类型和长度决定使用哪种内部编码实现 比如set age 1,此时的编码就是int，可以使用object encoding age查看 Hash 哈希 ziplist (压缩列表):当哈希类型元素个数小于hash-max-ziplist-entries配置(默认512个)、同时所有值都小于hash-max-ziplist-value配置(默认64字节)时,Redis会使用ziplist作为哈希的内部实现,ziplist使用更加紧凑的结构实现多个元素的连续存储,所以在节省内存方面比hashtable更加优秀。 hashtable(哈希表):当哈希类型无法满足ziplist的条件时,Redis会使用hashtable作为哈希的内部实现,因为此时ziplist的读写效率会下降,而hashtable的读写时间复杂度为O(1)。 慢查询命令 config set slowlog-log-slower-than 20000 : 设置预设阀值，单位为毫秒，当命令执行的时间查过这个时间，那么将会被记录到慢查询日志中 config set slowlog-max-len：慢查询日志最多存储的条数，慢查询日志使用的是队列存储的，先进先出，如果超过这个数，那么最先添加的日志将会被清除 config rewrite : 将配置持久化到本地配置文件中 slowlog get [n]: 返回慢查询的日志信息，其中对应的属性为id,发生时间戳、命令耗时、执行命令和参数 slowlog len : 慢查询日志数量 slowlog reset : 慢查询日志重置 事务 multi ： 开启事务 exec ：结束事务 出现语法错误的异常事务将会回滚 出现运行的异常，那么事务将不会回滚 discard ： 中断事务 watch key ..... : 在事务开始之前监视key，如果这个key对应的值在当前客户端开始事务之前被另外一个客户端修改了，那么当前客户端的事务将会失败 12345678## 开启事务multi ## 添加信息，语法正确sadd user:1 user1## 语法错误sdd user:1 user2 ## 结束事务，执行语句，出现语法错误信息，事务回滚exec 如果我们将上面的sdd user:1 user2，修改成zdd user:1 10 user2,那么语法是正确的，但是会出现运行时异常，这个时候事务将不会回滚，第一条执行的语句将会生效]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis使用场景]]></title>
      <url>%2F2018%2F06%2F26%2FRedis%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
      <content type="text"><![CDATA[Redis使用场景缓存 缓存机制几乎在所有的大型网站都有使用,合理地使用缓存不仅可以加快数据的访问速度,而且能够有效地降低后端数据源的压力。Redis提供了键值过期时间设置,并且也提供了灵活控制最大内存和内存溢出后的淘汰策略。可以这么说,一个合理的缓存设计能够为一个网站的稳定保驾护航。第 排行榜系统 排行榜系统几乎存在于所有的网站,例如按照热度排名的排行榜,按照发布时间的排行榜,按照各种复杂维度计算出的排行榜,Redis提供了列表和有序集合数据结构,合理地使用这些数据结构可以很方便地构建各种排行榜系统。 计数器应用 计数器在网站中的作用至关重要,例如视频网站有播放数、电商网站有浏览数,为了保证数据的实时性,每一次播放和浏览都要做加1的操作,如果并发量很大对于传统关系型数据的性能是一种挑战。Redis天然支持计数功能而且计数的性能也非常好,可以说是计数器系统的重要选择。 社交网络 赞/踩、粉丝、共同好友/喜好、推送、下拉刷新等由于社交网站访问量通常比较大,而且传统的关系型数据不太适合保存这种类型的数据,Redis提供的数据结构可以相对比较容易地实现这些功能。 消息队列系统 消息队列系统可以说是一个大型网站的必备基础组件,因为其具有业务解耦、非实时业务削峰等特性。Redis提供了发布订阅功能和阻塞队列的功能,虽然和专业的消息队列比还不够足够强大,但是对于一般的消息队列功能基本可以满足。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[二分查找]]></title>
      <url>%2F2018%2F06%2F14%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
      <content type="text"><![CDATA[二分查找算法 对一个有序数组的查找 准备 使用冒泡排序算法对数组排序 12345678910111213//冒泡排序 , 从小到大public void bubbleSort(Integer[] array)&#123; //外层遍历n-1次 for (int i = 0; i &lt; array.length-1; i++) &#123; for(int j=array.length-1;j&gt;i;j--)&#123; if (array[j]&lt;array[j-1]) &#123; Integer t=array[j]; array[j]=array[j-1]; array[j-1]=t; &#125; &#125; &#125;&#125; 非递归实现 传入的数组是一个从小到大的数组 123456789101112131415161718192021222324252627/** * 二分查找算法 * @param array 数组，必须是从小到大有序的 * @param key 查找的关键字 * @return 如果成功查找到，那么返回索引，否则返回-1 */ public Integer binarySearch(Integer[] array,Integer key)&#123; int low=0; //最前面的索引默认是0 int high=array.length-1; //最后面的索引默认为最后一个 //从小到大的数组，low&gt;high判断数组中是否有元素 if (key&lt;array[low]||key&gt;array[high]||low&gt;high) &#123; return -1; &#125; while(low&lt;=high)&#123; int middle=(low+high)/2; //左右索引的中间值 //如果要查找的数据大于中间值，表示 if (key&gt;array[middle]) &#123; low=middle+1; //那么查找右半部分 &#125;else if (key&lt;array[middle]) &#123; //如果查找的数据小于中间值，那么查找左半部分 high=middle-1; &#125;else &#123; //如果key==middle,那么直接返回middle即可 return middle; &#125; &#125; return -1; //没有找到，返回-1 &#125; 递归实现12345678910111213141516171819202122/** * 递归的二分查找 * @param array 从小到大的有序数组 * @param key 需要查找的数 据 * @param low 左边的索引 初始值为0 * @param high 右边的索引 初始值为array.length-1 * @return 查找成功返回索引，否则返回-1 */public Integer recursionBinarySearch(Integer[] array,Integer key,Integer low,Integer high)&#123; //从小到大的数组，low&gt;high判断数组中是否有元素 if (key&lt;array[low]||key&gt;array[high]||low&gt;high) &#123; return -1; &#125; Integer middle=(low+high)/2; //中间索引 if (key&gt;array[middle]) &#123; return recursionBinarySearch(array, key, middle+1, high); &#125;else if(key&lt;array[middle])&#123; return recursionBinarySearch(array, key, low, middle-1); &#125;else &#123; return middle; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis总结]]></title>
      <url>%2F2018%2F06%2F06%2FRedis%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Redis 中文文档 数据库的分类 关系型数据库 存储表 使用SQL 也称为结构化数据库 常见产品 MySQL Oracle SQL Server DB2 非关系型数据库 泛指不使用SQL操作的数据库 文档数据库 存储文档 MogoDB，用于存储JSON文档 Key_Value数据库 核心原理就是散列表(hash) 查询性能奇高，经常作为数据库的缓存使用 常见产品 MemoryCache Redis what 一种非关系型Key_Value数据库 特点 是内存型数据库，同时提供了磁盘持久存储功能 Redis采用散列表技术，查询性能高，可以达到千万级并发，Mysql的并发是千级并发 Redis经常作为关系型数据库的缓存使用 Redis支持5种数据类型 Redis安装第一种 yum 安装 yum -y install redis 常用命令 systemctl start redis.service ps -A | grep redis ： 查看redis进程 systemctl restart redis.service systemctl stop redis.service 编译安装 下载地址 安装教程 配置环境变量 export PATH=/usr/local/redis/bin:$PATH redis-server : 启动redis 启动客户端 redis-cli，默认端口为6379 Redis 提供了5中数据类型 Redis为每种数据类型提供的对应的一组操作命令 String Hash List Set Sorted Set 除了5中类型的命令，还提供了其他的命令 都是指存储到数据库中的value的类型，key的类型永远都是字符串 keys * 获取所有的key String类型命令 可以存储字符串，也可以存储数字(字符串形式)，并且其中对数字的处理也提供了一些命令，便于我们操作数字 SET set key value : 设置key的值为value，如果已经有值了，那么就会覆盖旧值 set message &quot;hello world&quot; set key value EX seconds 设置key的值，并且过期时间为秒 set message &quot;beijing&quot; EX 10 ： 10秒之后过期 get get key : 获取指定key的值 get message del del key : 删除指定的key append append key value : 在指定的key后面追加值 decr decr key : 如果key中存储的是一个数字，那么这个值将会减一，如果不是数字报错 set a &quot;10&quot;,desr a: 执行这两个命令之后，a的值就是&quot;9&quot;、 decrby decrby key number : 减少number decrby a 10 incr incr key : 如果key中存储的是一个数据，那么值将会加一 incr a incrby incrby key number : 如果key中存储的数据是一个整型数据，那么增加number incrby a 10 : a对应的整型数据+10 incrbyfloat incrbyfloat key number : 增加浮点数 incrbyfloat a 10.4 ：增加10.4 incrbyfloat a -10.5 : 减少10.5 strlen str key : 获取指定key的长度 mset mset a &quot;cen&quot; b &quot;ceg&quot;：同时设置多个key-value mget megt key1 key2 .......... : 同时获取多个key的值 Hash类型 key是字符串的类型，其中的value是Hash类型，形式如下： 简单的理解就是每一个key中对应的值相当于Java中的对象，其中的value就是成员变量的字段和对应的值 hset hset key field value : 为指定的key设置其中的域为field的值为value hset user name &quot;chenjiabing&quot; : 设置key为user的name域的值为chenjiabing hset user age &quot;22&quot; hset user password &quot;123456&quot; 形象的输出就好像是javascript中的对象，如下： 12345user=&#123; "name":"chenjiabing", "age":"22", "password":"123456"&#125; hget hget key field : 获取指定key中的域为field的值 hget user name : 获取name的值 hdel hdel key field : 删除指定的域 hdel user name : 删除user中的name域 List 列表 实际上是一个双向队列，可以在左侧插入，左侧取出，右侧插入，右侧取出 lpush lpush key value ..... : 从左侧插入一个或者多个value lpush list 1 32 3 &quot;chenjiabing&quot; ： 在左侧插入4个value LPOP lpop key ： 从左侧取出一个值，那么此时的list的长度就会减一 lpop list : 取出一个值 rpush rpush key value ..... : 从右侧插入一个或者多个值 rpush list 1 3 4 rpop rpop key : 从右侧取出一个值 rpop list ： 从右侧取出一个值，那么长度减一 LLEN LLEN key ： 查看长度 LLEN list BRPOP BRPOP key timeout :阻塞从右侧取值， 从右侧取出数据，如果其中的数据为空，那么等待timeout秒，如果其中一旦插入数据就会立即返回 BROP list 60 : 从右侧取出list中的数据，如果list中没有数据那么等待60s，如果一旦其中插入了数据，会立即返回数据 BLPOP BLPOP key timeout : 阻塞从左侧取值 BLPOP list 60 Set 集合 不重复 SortedSet 有序集合Java 操作 Redis添加依赖 Jedis 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 测试 开启6379端口 firewall-cmd --zone=public --add-port=6379/tcp 如果显示firewall not running start firewalld.service 测试如下 Jedis中的方法名和Redis中的命令是一样的 1234567891011121314151617181920212223242526272829303132333435//操作String类型的数据@Testpublic void testString()&#123; Jedis jedis=new Jedis("47.104.192.157"); //创建jedis对象，其中的参数是IP地址，如果是本地写localhost jedis.set("name", "chenjiabing"); //添加一个String 类型的数据 key为name jedis.get("name"); //获取key为name的值 jedis.del("name"); //删除key为name的数据 jedis.close();&#125;//测试Hash类型@Testpublic void testHashSet()&#123; Jedis jedis=new Jedis("localhost"); jedis.hset("user", "name","陈加兵"); //添加一个key为user的Hash类型的数据 jedis.hset("user", "age", "22"); //添加age jedis.hincrBy("user", "age", 200); //年龄增加200 String name=jedis.hget("user", "name"); //获取name的值 Integer age=Integer.parseInt(jedis.hget("user", "age")); //获取age的值，转换为Integer类型 System.out.println(name); System.out.println(age); jedis.close(); &#125;//测试List类型@Testpublic void testList()&#123; Jedis jedis=new Jedis("localhost"); jedis.lpush("list", "陈加兵"); //从左侧添加一个值 System.out.println(jedis.llen("list")); //获取长度 jedis.lpush("list", "1","2","TOM"); //左侧存放多个值 System.out.println(jedis.rpop("list")); //从右侧取出 jedis.close();&#125; Redis解决Session共享 当浏览器登录，Nginx会分发请求给应用服务器，此时的这个服务器中保存了该用户的session，但是可能再次请求的时候，Nginx会把请求分发给另外一个应用服务器，那么又需要重新登录一次。我们可以使用Nginx的ip_hash策略解决这个问题，但是我们也可以使用Redis解决 我们将session id存放在Redis中，每一个应用服务器都从Redis中获取Session id 需要一个远程数据库Redis，并且所有的应用服务器(Tomcat)共享这个远程数据库，那么Redis中的sessionId才能实现共享存取 Session管理器 Redis Session Manage for Apache Tomcat 参考文章 下载jar包 tomcat-redis-session-manager-VERSION.jar jedis-2.5.2.jar commons-pool2-2.2.jar 将下载的jar包放在每个应用服务器的Tomcat中 不适用于Tomcat8.* 这里是要修改每一台应用服务器上面的Tomcat内容，这样才能实现多台应用服务器中的SessionId共享 将jar包放在Tomcat目录中的lib文件夹下 修改Tomcat目录下的conf/context.xml中添加如下内容 123456&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt;&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" host="47.104.192.157" &lt;!-- 服务器的IP，这个是Redis数据库所在服务器的IP --&gt; port="6379" &lt;!-- 端口 "6379" --&gt; database="0" &lt;!-- optional: defaults to "0" --&gt; maxInactiveInterval="60" /&gt; &lt;!-- 失效时间 "60" (in seconds) --&gt; 参考文档 http://redisdoc.com/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx总结]]></title>
      <url>%2F2018%2F06%2F06%2FNginx%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Nginx什么是Nginx 是俄罗斯程序员开发的一款高性能的web服务器 Nginx可以承受高并发，可以同时承受近百万请求 利用Nginx和Tomcat(应用服务器)组合搭建反向代理服务器集群，可以解决WEB的高并发问题 WEB 服务器 凡是能够处理Http协议的服务器统称为web服务器 Nginx Apache Tomcat JBOSS Weblogic WebSpare 安装Nginxyum 安装 yum -y install nginx nginx 启动 nginx -s stop 关闭 启动命令 systemctl start nginx.service systemctl stop nginx.service systemctl restart nginx.service systemctl enable nginx.service systemctl disable nginx.service ps -A | grep nginx : 检查 启动之后在浏览器直接输入http://IP地址即可访问到主页，这里的端口号默认是80 配置文件 /etc/nginx/nginx.conf web目录 /usr/share/nginx/html 安装包安装 安装地址 Nginx 配置文件 位置 ： /etc/nginx/nginx.conf （yum安装的路径） 内容结构 12345678910111213141516worker_processes 1; //worker进程，一般是电脑几核处理器就写几events&#123; worker_connections 1024; //一个worker进程能够承受多少线程&#125;http&#123; http协议通用参数 server&#123; 虚拟主机参数 &#125; server&#123; 虚拟主机参数 &#125;&#125; nginx -t -c /etc/nginx/nginx.conf 修改完成之后执行该命令，测试配置文件，热加载(不停机)配置文件 nginx -s reload : 重新启动nginx 虚拟主机的三种方式 基于端口的虚拟主机，80,8080，需要使用80以外的其他端口，客户端使用不方便 基于IP虚拟机，一个服务器可以绑定多个IP 基于域名的虚拟主机，共享一个IP，共享一个80端口 外网配置### 前提 我们的服务器Ｃｅｎｔｏｓ７ 使用yum install nginx安装了Nginx，那么这个Nginx的web目录就在/usr/share/nginx/html 配置文件的路径为： /etc/nginx/nginx.conf 有自己的域名 配置开始 申请自己的域名： 比如chenjiabing.org，并且将自己的域名解析绑定在服务器的ip地址上 比如将下面需要用到的t1.chenjiabing.org和t2.chenjiabing.org解析在上面，那么我们在访问t1.chenjiabing.org的时候才能找到ip，随之找到自己的服务器，之后再根据在Nginx中配置的虚拟主机访问到对应的页面 在/etc/nginx/nginx.conf的配置文件中只需要配置虚拟主机即可，这里我们配置两个虚拟主机 123456789101112131415161718192021222324252627282930313233343536373839404142 # 自己配置的虚拟主机 server&#123; listen 80; # nginx的端口 server_name t1.chenjiabing.org; # 访问的地址 location / &#123; root t1; # 这个虚拟主机对应的web目录，这里设置的路径为/usr/share/t1 index index.html; # 默认显示的首页 &#125;&#125;# 自己配置的虚拟主机 server&#123; listen 80; server_name t2.chenjiabing.cn; # 访问的地址 location / &#123; # /usr/share/nginx/t2 root t2; # 这个虚拟主机的web目录 index index.html; # 显示的首页 &#125;&#125;# nginx默认的虚拟主机server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # 默认的web目录，其实这里可以写 html 是一样的 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; 配置上面的两个虚拟主机之后，我们需要配置对应的web目录，我们只需要在/usr/share/nginx/这个目录中新建t1和t2两个文件夹作为两个虚拟主机的web目录，之后，在其中创建index.html作为显示的主页即可 测试启动Nginx: nginx -t -c /etc/nginx/nginx.conf 重新启动nginx ： nginx -s reload 之后在浏览器中输入t1.chenjiabing.org,那么浏览器就会自动访问到/usr/share/nginx/t1/index.html显示首页内容，同样的输入http://t2.chenjiabing.org 内网配置前提 没有自己的域名，但是我们想要使用域名访问服务器上的Nginx的内容，比如，我们输入t1.tedu.cn就想要访问到服务器地址为：47.104.192.157中Nginx配置的虚拟主机 使用的是Linux，hosts文件所在目录为/etc/hosts 使用的是windows，那么hosts文件所在的目录为C:\Windows\System32\Drivers\etc\hosts 本地配置 我们需要在/etc/hosts中添加对应需要的域名和服务器的IP地址 sudo vi /etc/hosts ,输入以下内容 12347.104.192.157 t1.tedu.cn ## 前面是服务器的IP地址，后面是需要访问的域名，这个是没有申请的域名，可以直接写47.104.192.157 t2.tedu.cn 配置完成之后，使用ping t1.tedu.cn查看是否能够找到对应的IP地址47.104.192.157 服务器配置虚拟主机 和上面的配置一样，不过是这次配置的域名是t1.tedu.cn 123456789101112131415161718192021222324252627282930313233343536373839404142 # 自己配置的虚拟主机 server&#123; listen 80; # nginx的端口 server_name t1.tedu.org; # 访问的地址 location / &#123; root t1; # 这个虚拟主机对应的web目录，这里设置的路径为/usr/share/t1 index index.html; # 默认显示的首页 &#125;&#125;# 自己配置的虚拟主机 server&#123; listen 80; server_name t2.tedu.cn; # 访问的地址 location / &#123; # /usr/share/nginx/t2 root t2; # 这个虚拟主机的web目录 index index.html; # 显示的首页 &#125;&#125;# nginx默认的虚拟主机server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # 默认的web目录，其实这里可以写 html 是一样的 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; 同样的创建t1和t2的web目录 测试加载，重启 在本地机器的浏览器中输入t1.tedu.cn即可访问到，不过这次只能在配置hosts的本地机器使用，如果该机器没有配置这个hosts文件，那么是不能访问的 搜索过程 在本地配置过的hosts文件的机器的浏览器中输入http://t1.tedu.cn,那么浏览器会查找本地的hosts文件中是否存在对应的IP地址 查找到对应的IP地址之后，会向服务器发出请求，此时服务器端就会根据浏览器发出的域名在Nginx的虚拟主机中查找匹配server_name,然后找到响应的页面 ping 判断域名能够解析成对应的IP 判断IP地址是否能够访问 HTTPSwhat 基于SSL加密的HTTP通讯 底层是SSL加密的TCP协议 应用层还是传统的HTTP编程 默认的通讯端口是 443 需要去CA申请证书，配置到服务器上 配置HTTPS证书前提 远程服务器上的Nginx使用yum -y install nginx安装的，那么这个路径就是确定了 并且下载了证书，总共两个文件 内网配置 我们在aliyun.com中使用tom.canglaoshi.org这个域名申请了HTTPS证书 因为我们没有域名和自己的服务器IP地址绑定在一起，因此我们使用内网配置 在本地的机器的/etc/hosts文件中添加对应的服务器的IP地址 tom.canglaoshi.org 这里的服务器的IP地址是远程服务器的地址，等会我们需要在远程服务器中配置Nginx 147.104.192.157 tom.canglaoshi.org # 服务器IP地址 域名 在远程服务器的Ngix配置文件中/etc/nginx/ngxin.conf添加一个虚拟主机server， 我们可在其中添加一个include tom.conf;这句话，那么我们再在/etc/nginx创建一个tom.conf配置文件即可，这样看的更加清除，其实就是使用了引入文件 tom.conf的内容如下，下面的路径都是使用的相对路径 http协议默认访问的是80端口，因此假如我们在浏览器中输入http://tom.canglaoshi.org那么将不会显示安全证书，因为https协议使用的是443端口，但是我们可以添加一个监听80端口的虚拟主机，设置server_name为tom.canglaoshi.org，同时使用301重定向到https://tom.canglaoshi.org，那么当在浏览器中输入http://tom.canglaoshi.org的时候就会自动跳转到https://tom.canglaoshi.org 12345678910111213141516171819202122server&#123; liseten 80; # 默认端口，使用的http协议 server_name tom.canglaoshi.org; return 301 https://tom.canglaoshi.org; # 这里定义的是重定向，如果使用http://tom.canglaoshi.org ，那么就会重定向到https://tom.canglaoshi.org&#125;server &#123; listen 443; # 端口号 必须开启,必须使用Https协议才能访问到 server_name tom.canglaoshi.org; # 开启证书的域名，这个域名不能改变，因为我们就是使用这个域名开启证书的 ssl on; ssl_certificate cert/214462831460580.pem; # 这个是开启证书的时候下载的文件，放在/etc/nginx/cert文件中 ssl_certificate_key cert/214462831460580.key; # 这个是开启证书的时候下载的文件，放在/etc/nginx/cert文件中 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; root tom; # 这个是访问域名的时候显示的web目录，这需要自己在/usr/share/nginx中创建 index index.html; # 这个是显示的首页 &#125;&#125; 我们将开启证书的时候下载的两个文件，分别为214462831460580.key和214462831460580.pem放到/etc/nginx/cert文件中，当然这个cert文件需要我们自己创建 至此就配置完成 测试Nginx : nginx -t -c /etc/nginx/ngxin.conf 重启nginx ： nginx -s reload 此时在本地配置的机器的浏览器中输入https://tom.canglaoshi.org访问即可，我们将会看见地址栏中将会出现安全两个字，那么证书就配置上了 这里使用的403端口，必须使用https访问 外网配置 我们有自己的域名chenjiabibing.org和自己的服务器IP绑定在一起，那么我们可以直接在远程服务器中配置 使用tom.chengjiabing.org这个子域名申请证书，下载两个文件 不需要在本地机器配置了，直接从上面的远程服务器的步骤开始配置 Nginx反向代理集群what 通过互联网访问远程的服务器，Nginx分发请求给各种web容器(Tomcat…..)处理就叫反向代理 内网模拟 我们需要5台电脑，一台是本地的，使用浏览器访问域名为http://tts.tedu.cn,一台远程服务器(IP地址:47.104.192.157)，这台远程服务器使用Nginx分发请求给另外的三台，另外的三台使用的是Tomcat处理Nginx分发的请求，IP地址为：192.168.0.231，192.168.0.176，，192.168.0.174 必须确保三台的Tomcat容器都是开启的状态，我们可以在本地使用http://192.168.0.231:8080/访问看看是否能够访问到该机器的Tomcat 因为没有申请域名，这个tts.tedu.cn没有和远程服务器的IP绑定，因此需要在本地机器配置/etc/hosts文件中配置才可以用浏览器访问 在/etc/hosts文件中添加47.104.192.157 tts.tedu.cn即可 使用ping tts.tedu.cn查看能够成功 此时我们在远程服务器中配置另外三台的集群信息即可。 在/etc/nginx/nginx.conf添加一句include tts.conf 那么我们只需要将自己的集群配置信息文件tts.conf放在/etc/nginx/文件夹下即可 tts.conf配置文件如下： 12345678910111213141516171819202122232425262728upstream toms &#123; server 192.168.0.231:8080; # 配置三台tomcat的处理器，端口是8080，因为tomcat的默认端口 server 192.168.0.176:8080; server 192.168.0.174:8080;&#125;server &#123; listen 80; # 监听的是80端口，浏览器默认使用80，当在本地机器上输入`http://tts.tedu.cn` server_name tts.tedu.cn; ## 对应的域名 location / &#123; proxy_pass http://toms; # 这里的toms就是上面定义的集群信息 proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; &#125;&#125; 此时我们配置成功 测试配置 重启Nginx 在配置/etc/hosts的本地机器上输入http://tts.tedu.cn即可访问，我们看到Nginx是将请求均匀分发到不同的集群机器上进行处理 Nginx集群的负载均衡策略轮训策略 默认策略 可以增加权重 weight 对于一些应用服务器的性能可能不一样，我们需要给性能更好的应用服务器分配更多的请求处理，因此这里就涉及到权重问题 直接在后面添加权重即可，如下 12345upstream toms &#123; server 192.168.0.231:8080 weigth 10 ; # 配置三台tomcat的处理器，端口是8080，因为tomcat的默认端口 server 192.168.0.176:8080 weight 20; server 192.168.0.174:8080 weight 30;&#125; 可以配合Redis实现session共享问题 ip_hash ip 散列 根据用户的Ip地址映射到固定的服务器 如果用户登录网站，那么在当前的服务器中已经保存了session的信息，此时就不需要重新登录了，但是可能当再次请求的时候，Nginx又将其分发到其他的应用服务器中了，但是这个应用服务器没有当前当前用户登录的session信息，此时就需要重新登录，这个就是问题所在 原理 就是根据用户的IP地址通过散列算法每次请求都保证Nginx将对应的Ip分发到同一台应用服务器 ip散列可以和轮训策略结合使用 直接添加一个ip_hash即可 123456upstream toms &#123; ip_hash; server 192.168.0.231:8080 weigth 10 ; # 配置三台tomcat的处理器，端口是8080，因为tomcat的默认端口 server 192.168.0.176:8080 weight 20; server 192.168.0.174:8080 weight 30;&#125; url_hash 根据url映射到固定的服务器 服务器的临时下线 如果服务器需要更新升级，我们需要将应用服务器临时下线维护，我们可以将其删除，或者添加一个down即可，比如server 192.168.0.174:8080 weight 30 down就表示该服务器下线了 MySQL远程连接 前提是远程的服务器需要开启3306端口，这个在阿里云的服务器开启即可 grant all privileges on *.* to 用户名@&quot;IP地址&quot; identified by &quot;密码&quot; grant all privileges on tedu_store.* to tedu@&quot;%&quot; identified by &quot;tedu&quot;; 连接远程数据库tedu_store，用户名为tedu,用户密码为tedu 在本地连接远程数据库 mysql -h IP地址 -u 用户名 -p mysql -h 47.104.152.197 -u tedu -p，之后直接输入密码即可，那么连接的就是远程数据库 远程数据库开启之后，我们就可以在自己的项目中配置数据库的连接url为远程数据库了，那么就可实现多个应用服务器共享一个数据库，实现数据的共享了，不会导致数据错乱了 项目集群部署需求 一台Nginx服务器分发请求，部署反向集群 多台应用服务器处理请求(Tomcat) 一台MySQL数据库服务器，存储项目数据 一台Redis服务器，实现session共享，实现Redis缓存 总结 Nginx只是起到分发请求的作用，具体的处理是在应用服务器中，比如Tomcat，Nginx根据不同的策略将请求分发给不同应用服务器处理 这些不同的应用服务器可以连接同一个远程数据库，那么就可以实现数据共享，不会导致数据错乱]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux使用总结]]></title>
      <url>%2F2018%2F05%2F27%2FLinux%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Liunx使用命令管道连接 | 命令管道符合为|,可以将两个命令进行连接，连接后第一个命令的输出结果作为第二个命令的输入信息 比如 ls /ect | more -10 分屏显示etc文件夹下的10行数据 Linux文件系统结构 / : 根目录 /home： 主文件夹，登录用户的主文件夹 /etc ：操作系统配置文件的保存位置 /usr : 用于添加的程序文件，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。 root : 超级用户的目录 改变当前工作目录命令 cd 目标目录 cd 没有参数的时候直接返回用户主目录 cd /etc : 使用绝对路径切换当前的工作目录 cd .. : 返回上一级 cd 目录 ：使用相对路径其切换，前提是当前的目录中有这个目录 显示当前的工作目录 pwd 文件或文件夹的操作(mkdir/touch) mkdir 文件夹名称 创建文件夹 mkdir demo/file 在demo文件夹下新建一个文件加file，如果这个demo文件夹不存在，那么将会报错 mkdir -p 文件夹名称 递归创建文件夹 mkdir -p demo/file :如果demo文件夹不存在，那么会自动创建出来 touch 新文件名 : 创建文件 ，比如touch file.txt touch 已经存在的文件名或者文件夹名 ： 修改文件或者文件夹的创建时间，但是并不是重新创建一个，里面的内容的不会清空 改名或者移动(mv) mv 参数1 参数2 mv 已存在的文件夹/文件 新文件夹/文件 ：修改名称 比如 ：mv file.txt a.txt mv 已存在的文件夹/文件 目标文件夹 ： 将文件或者文件夹移动到目标文件夹中 mv file.txt /tmp/dmeo 将当前文件夹的file.txt移动到/tmp/demo文件夹中 mv demo/file.txt . 将 demo文件夹下的file.txt移动到当前文件夹 mv file.txt ../ 将当前文件file.txt 移动到上一级目录 复制文件或者文件夹(cp) cp 存在的文件/文件夹 新文件/新文件夹 进行改名复制 cp a.txt /tmp/file.txt 将当前文件夹中的a.txt文件复制到/tmp文件夹中，改名为file.txt cp 存在文件 已存在的文件夹 将文件复制一份到已存在文件夹中，并且文件名和源文件的名一样 cp a.txt /tmp 将当前文件a.txt复制到tmp文件夹中，并且名称还是a.txt cp -i ... 提示是否覆盖的信息 cp -f 强制覆盖，不给出提示 cp -r 存在的文件夹 目标文件夹 复制文件夹 比如：cp -r file /tmp/demo复制当前文件夹file和其中的所有内容到/tmp/demo`文件夹下 删除文件或者文件夹(rm) rm 文件名 删除文件 rm a.txt 删除当前文件夹中的a.txt文件 rm /tmp/demo/a.txt 删除/tmp/demo文件夹下的a.txt文件 rm -r 存在的文件夹 ： 删除文件夹及文件夹下的全部内容 rm -r demo 删除文件夹demo rm -f 强制删除文件，不提示 rm -rf :强制删除文件夹 远程登录服务器SSH 客户端输入：ssh 用户名@服务器IP/域名 ssh soft01@192.168.7.36 第一输入需要确认证书： 选择yes 输入password SFTP传输文件 sftp 用户名@主机/IP 确认证书 ：yes 输入密码 ： 盲敲 进入ftp，其中的提示符号变成&gt; 常用命令 ls 显示当前远程服务器的目录内容 lls : 显示本地目录内容 pwd : 显示当前远程服务器目录的路径 lpwd ：显示本地目录的路径 get 远程文件 : 获取远程文件,只能是压缩文件，比如.tar.gz get demo.txt 获取远程文件的demo.txt put 本地文件 ：上传本地文件到远程服务器 ，只能是压缩文件，比如.tar.gz push abc.txt : 上传本地当前文件abc.txt到远程服务器 exit : 退出 windows 操作Linux pyttty 开源软件 Linux打包命令 tar -czvf 包文件.tar.gz 文件夹1 文件夹2 .... ： tar czvf demo.tar.gz demo/ 打包当前的demo文件夹 -c : create创建包 ，建议使用后缀 .tar -z : 表示打包后录用gzip算法进行压缩,后缀需要写.gz -v : 显示打包的过程，哪些文件被打包了 -f ： 指定打包以后包的文件名 ，放在最后，如：czvf 解压缩包的命令后缀为 tar.gz tar -xzvf 包名.tar.gz -x : 释放，将包进行释放操作 -z ： 先使用gzip解压缩，一般对应的后缀.gz -v : 表示显示解包的过程 -f ： 指定包的文件名 后缀为 zip 如果没有unzip命令，可以命令行安装即可 yum -y install unzip unzip 文件 下载命令wget 安装该命令：yum -y install wget wget 下载地址 ： 这个命令将会从互联网自动下载所需要的资源 购买云服务器 地域： 国内配置域名的时候必须备案，国外服务器无需备案 配置： x86服务器，1G内存 1CPU 镜像： 公共镜像，Centos 7.4 网络： 1M 安全组(防火墙)：开放端口 80,443,22 注意： 没有开放8080，需要以后配置 设置密码 设置服务器名 PATH变量的作用 操作系统可执行命令的搜索路径，操作系统在执行密令的时候，会在PATH变量一系列路径中逐一查找命令程序，如果找到就执行这个程序，否则将报出命令没有找到的错误 echo $PATH : 回显PATH的值 export PATH=... : 在终端直接输入的PATH，只会在当前的终端不关闭的情况才会生效，如果这个终端窗口关闭了，那么就会失效 export PATH=/usr/local/java/jdk1.8/bin:$PATH,这个命令是将java的jdk的路径添加到当前PATH路径的前面，不过这个只是临时的，当终端退出，那么就会失效 如果想要这个PATH永久起作用，那么需要在/etc/profile文件中添加，这个文件会在开机启动的时候就解析加载 如果我们使用的安装包安装的话，那么默认的启动命令是只能在当前安装包的bin中才能执行启动命令，如果我们想要在任何位置打开终端都能启动这个软件，那么我们可以将其配置在PATH中，我们只需要在/etc/profile文件中添加：export PATH=文件位置:$PATH 使用 VIM 编辑文本文件 基于命令行的全屏幕可视化编辑器 安装 vim yum -y install vim :安装vim 常用命令 在命令状态下 yy ： 复制当前行到剪切板 P：复制剪切板的内容到当前行之前 p： 复制剪切板的内容到当前行之后 nyy ： 复制当前行和后面的n行数据到剪切板 5yy dd ：删除当前行（其实是剪切），可以使用P或者p再次复制回去 ndd ： 删除当前行的后面n行数据，实际上是剪切 10dd ?正则 ： 向前查找 ?System /正则 ：向后查找 n 查找下一个 先使用?正则或者\正则查找之后，然后按n将会查找下一个结果 u ：撤销，可撤销多次 配置JDK环境 下载jdk 解压缩在/usr/local/java中 tar -xzvf ...... 配置环境变量 先复制一个/etc/profile ,避免错改造成系统崩溃 cp /etc/profile profile_1 vi /etc/profile 在末尾输入 1234export JAVA_HOME=/usr/local/java/jdk1.8.0_172 ## jdk的路径export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 执行source /etc/profile 在终端输入java -version判断是否配置成功 重启机器 安装配置Tomcat第一种yum yum -y install tomcat 安装以后的安装位置在/usr/share/tomcat/,这个是默认安装位置 启动和关闭 systemctl start tomcat.service ： 启动 systemctl stop tomcat.service : 关闭 systemctl restart tomcat.service : 重启 systemctl enable tomcat.service : 设置自动启动 systemctl disable tomcat.service : 关闭自动启动 第二种使用原厂的包安装 下载tomcat ： tomcat.apache.org 或者使用wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-7/v7.0.88/bin/apache-tomcat-7.0.88.zip 如果没有wget，那么使用yum -y install wget即可 解压：unzip 文件名 将解压之后的文件夹移动到/usr/local下即可：mv apache-tomcat-7.0.88 /usr/local/ 设置启动脚本的执行权限： cd /usr/local/apache-tomcat-7.0.88/bin ：进入到bin目录 添加执行权限： chmod +x *.sh ：为.sh脚本添加执行权限 启动和关闭tomcat 在bin文件夹下 输入： ./startup.sh即可启动 输入ps -A | grep java : 检查是否启动 开放防火墙 ： firewall-cmd --permanent --add-port=8080/tcp 如果显示防火墙显示not runing，那么使用service firewalld start开启防火墙 在bin文件夹下输入 ：./shutdown.sh 即可关闭 最后在浏览器输入http://ip:8080即可访问 云服务器需要开启8080端口 自己的服务器 —- &gt; 管理 —&gt; 本例安全组 —-&gt; 配置规则 —- &gt; 添加安全组规则 —-&gt; 添加端口范围 8080/8080 安装MySQL Mariadb和Mysql是一样的，不过mariadb现在是开源免费的。mysql以后的版本都是收费的 yum -y install mariadb mariadb-server ： 使用此命令安装即可 安装了两个组件，客户端mariadb 启动： systemctl start mariadb.service 关闭：systemctl stop mariadb.service 重新启动： systemctl restart mariadb.service 开机启动： systemctl enable mariadb.service 取消开机启动：systemctl disable mariadb.service 连接mariadb mysql -u root： 初始安装没有密码 设置mysql密码 set password=password(“密码”); flush privileges; 设置完成之后使用mysql -u root -p输入密码进入即可 mysql 解决中文乱码 show variables like &#39;%char%&#39;; 查看自己的编码是否是utf8 在/etc/my.cnf添加如下代码即可 123456[mysqld]character-set-server=utf8 [client]default-character-set=utf8 [mysql]default-character-set=utf8 数据库迁移【Import】 意思就是将本地的数据库迁移到远程服务器中。不需要在远程服务器中重新创建和插入数据了 步骤 导出(备份)数据库 mysqldump -u root -p密码 数据库名字 &gt; 文件名.sql 比如 :mysqldump -u root -proot tedu_store&gt;tedu_store.sql;，导出的tedu_store.sql就会在当前目录中，这个命令不需要登录mysql即可完成 将tedu_store.sql上传到远程服务器中 sftp 用户名@IP： 登录远程服务器的上传下载功能 put tedu_store.sql: 上传 在远程服务器中创建数据库 create database tedu_store; 导入数据： use tedu_store source tedu_store.sql 即可，这里需要指定路径 部署项目在远程服务器上步骤 导出一个war包，比如Tedu_store.war 项目右击 — &gt; Export —- &gt; WAR File —-&gt; 选择位置 ——-&gt; Finish 导出的Tedu_store.war上传到远程服务器 放在tomcat中的webapps包下 我们将Tedu_store.war放在webapps下，那么会自动生成一个Tedu_store，这个就是我们的项目 修改数据库的连接参数 第一种：在本地电脑打包的时候就修改成远程服务器的数据库的连接参数 第二种： 在远程服务器中修改 进入到项目的WEB-INF/classes下，其中有一个db.properties文件，其中就是配置数据库的信息，我们可以使用vi编辑器修改 重启tomcat，我们使用zip安装方式安装的，因此需要在Tomcat的bin下执行： ./shutdown.sh 关闭 ./start.sh启动 接下来就是访问即可 http://ip:8080/Tedu_store/..... 查看错误信息 进入到Tomcat的安装目录的logs目录，下面有一个catalina.out，这里面存储的就是项目的运行信息，我们可以在其中查找项目的错误信息 输出重定向 将一个命令的输出目标从标准控制台(标出输出)重新定向到其他设备(一般是一个文件) &gt;: 生成一个新文件 &gt;&gt;：不生成一个新文件，在文件后面追加 比如cat file.txt&gt;demo.txt, : 将显示的file.txt文件内容重定向到deom.txt文件中，如果`demo.txt不存在，那么会被新建，如果存在，那么将会覆盖其中的内容。 cat file.txt&gt;&gt;demo.txt : 将显示的file.txt文件的内容在demo.txt后面追加，如果demo.txt不存在就新建，如果存在，那么在其内容的后面追加 作用 记录命令的执行日志 tar -czvf file.tar.gz file&gt;file.log : 将这个执行语句的日志记录到file.log中 快速生成文本文件 echo &quot;hello World&quot; &gt;hello.txt 文件权限 chmod -rw-rw-r : 文件拥有者、群组、其他 为所有用户设置权限 x :执行权限，如果一个文件夹没有执行权限，那么我们使用cd 文件夹名是不允许进入查看内容的 chmod +x file : 为file文件夹添加执行权限 chmod -x file: 为file文件夹删除执行权限 r ： 可读权限 chmod -r file.txt : 删除file.txt文件的可读权限 chmod +r file.txt : 添加可读权限 w: 可写权限 chmod -w file.txt chmod +w file.txt 为不同的用户设置权限 chmod u+x,g-x,o-x file : 表示文件拥有者添加执行权限，群组用户删除执行权限，其他用户删除执行权限 chmod g+x file : 为群组添加执行权限 使用数字代表权限 r : 4 w : 2 x : 1 rwx : 4+2+1=7 rw- : 4+2 =6 --x : 1 r-x : 4+1=5 chmod 664 file.txt : 为文件拥有这设置rw-权限，为群组设置rw-权限，为其他用户设置r--权限 可以执行的文件 文件是可执行的二进制程序或者文件是可执行的脚本程序 文件具有可以执行的权限 可执行的脚本 可执行的脚本，也是称为shell脚本，是一个文本文件，文件的每一行都是可以执行的shell命令，如果有执行权限，这个文件就可以执行，执行时候批量执行文件中的每个命令，经常用于自动化运维]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[监听器获取spring配置文件创建的对象]]></title>
      <url>%2F2018%2F05%2F27%2F%E7%9B%91%E5%90%AC%E5%99%A8%E8%8E%B7%E5%8F%96spring%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%9B%E5%BB%BA%E7%9A%84%E5%AF%B9%E8%B1%A1%2F</url>
      <content type="text"><![CDATA[监听器获取spring配置文件创建的对象前提 我们在使用监听器的时候，会用到spring配置文件创建的对象，那么我们不能像其他的类中直接使用@Resource或者@AutoWired自动注入对象，那么我们如何获取对象呢 比如我们在缓存数据的时候，就是在容器启动的时候读取数据库中的信息缓存在ServletContext中，那么我们肯定需要调用Service中的对象来获取数据库中的信息，此时我们就需要获取spring配置文件配置的业务层的对象 准备 前提是你的spring的配置文件是使用的spring监听器ContextLoaderListener加载的，而不是一起在springMVC的前端控制器中加载，比如你在web.xml配置如下 12345678910&lt;!--配置spring配置问文件的路径--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!--使用通配符指定多个配置文件，比如 spring-service.xml，spring-dao.xml--&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--spring监听器--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; 实现 我们先创建一个ServletContext上下文监听器，在其中使用WebApplicationContextUtils类获取WebApplicationContext对象，之后即可获取其中spring创建的bean 1234567891011121314public class InitCompontServletContextListener implements ServletContextListener, ServletContextAttributeListener &#123; private BlogIndex blogIndex; //spring配置创建的对象 private IBlogService blogService; //spring配置创建的对象 /** * web容器初始化的时候就会调用 */ public void contextInitialized(ServletContextEvent contextEvent) &#123; ServletContext context=contextEvent.getServletContext(); //获取上下文对象 WebApplicationContext applicationContext=WebApplicationContextUtils.getRequiredWebApplicationContext(context); blogIndex=applicationContext.getBean("blogIndex",BlogIndex.class); //加载BlogIndex对象 blogService=applicationContext.getBean("blogServiceImpl",IBlogService.class); //加载IBlogService对象 &#125; 参考文章 http://www.cnblogs.com/Joke-Jay/p/6507171.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SSM整合]]></title>
      <url>%2F2018%2F05%2F27%2FSSM%E6%95%B4%E5%90%88%2F</url>
      <content type="text"><![CDATA[Spring + SpringMVC + Mybatis整合依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;!-- SpringMVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring-JDBC,要和spring-webmvc的版本一致 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Spring 整合jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL驱动jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.28&lt;/version&gt; &lt;/dependency&gt; &lt;!-- DBCP连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加jackson，自动转换为JSON数据 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加jstl标签库 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入aspectj依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.8.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.13&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入spring的aop --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加文件上传的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; 配置数据库连接信息 — db.properties文件123456url=jdbc:mysql://localhost:3306/db_blog3?useUnicode=true&amp;characterEncoding=utf8driver=com.mysql.jdbc.Driveruser=rootpassword=rootinitSize=2maxSize=10 Mybatis和Spring整合 — spring-dao.xml 读取db.properties文件配置DBCP连接池创建数据源 使用上面的数据源配置SqlSessionFactoryBean 配置组件扫描Mybatis的接口mapper的包，用于创建mapper接口对象 配置批量扫描Mybatis的XXMapper.xml文件的MapperScannerConfigurer 配置事务管理器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:util="http://www.springframework.org/schema/util" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.2.xsd"&gt; &lt;!-- 组件扫描 用于自动创建mapper包下的所有接口的对象，否则将不能使用@Resource注解的方式注入接口对象 --&gt; &lt;context:component-scan base-package="cn.tedu.blog.mapper" /&gt; &lt;!-- 配置MapperScannerConfigurer --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 用于配置持久层接口在哪里，指定mapper的包 --&gt; &lt;property name="basePackage" value="cn.tedu.blog.mapper" /&gt; &lt;/bean&gt; &lt;!-- 加载db.properties,其中定义了数据库的配置信息 --&gt; &lt;util:properties id="dbConfig" location="classpath:db.properties" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="url" value="#&#123;dbConfig.url&#125;" /&gt; &lt;property name="driverClassName" value="#&#123;dbConfig.driver&#125;" /&gt; &lt;property name="username" value="#&#123;dbConfig.user&#125;" /&gt; &lt;property name="password" value="#&#123;dbConfig.password&#125;" /&gt; &lt;property name="initialSize" value="#&#123;dbConfig.initSize&#125;" /&gt; &lt;property name="maxActive" value="#&#123;dbConfig.maxSize&#125;" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactoryBean --&gt; &lt;bean class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 用于配置数据库连接池 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 用于配置持久层映射文件在哪里,所有的xml文件，使用通配符 --&gt; &lt;property name="mapperLocations" value="classpath:mappers/*.xml" /&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!-- 注入数据源，这里使用的是上面配置好的DataSource --&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 开启事务注解 ,transaction-manager指定的是上面配置的事务管理器的id--&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;&lt;/beans&gt; Spring与SpringMVC不需要整合 我们只需要创建一个springMVC.xml文件即可 扫描controller包下，组件扫描，自动创建对象 配置视图解析器 配置注解驱动 配置拦截器 配置上传文件的解析器 ………………… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:util="http://www.springframework.org/schema/util" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.2.xsd"&gt; &lt;!-- 组件扫描 自动创建对象 --&gt; &lt;context:component-scan base-package="cn.tedu.blog.controller" /&gt; &lt;!-- 配置ViewResolver视图解析器 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt; &lt;!-- 配置驱动，用于@ResponseBody的使用 --&gt; &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!-- 配置拦截器的路径 --&gt; &lt;mvc:mapping path="/blogger/*" /&gt; &lt;mvc:mapping path="/blogType/*" /&gt; &lt;!-- 配置不拦截的路径 --&gt; &lt;mvc:exclude-mapping path="/blogger/showLogin.do"&gt;&lt;/mvc:exclude-mapping&gt; &lt;mvc:exclude-mapping path="/blogger/login.do"&gt;&lt;/mvc:exclude-mapping&gt; &lt;mvc:exclude-mapping path="/blogger/showInfo.do"&gt;&lt;/mvc:exclude-mapping&gt; &lt;bean class="cn.tedu.blog.interceptor.LoginInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; &lt;!-- 上传组件的解析器 --&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!-- 上传文件大小 --&gt; &lt;property name="maxUploadSize" value="10000000"&gt;&lt;/property&gt; &lt;!-- 请求的编码格式，必须和jSP的pageEncoding属性一致，以便正确读取表单的内容，默认为ISO-8859-1 --&gt; &lt;property name="defaultEncoding" value="utf-8"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 业务层的配置文件 – spring-service.xml 配置组件自动扫描业务层的类，自动创建对象 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:util="http://www.springframework.org/schema/util" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.2.xsd"&gt; &lt;!-- 组件扫描 --&gt; &lt;context:component-scan base-package="cn.tedu.blog.service" /&gt;&lt;/beans&gt; 配置 web.xml 文件 配置POST中文乱码过滤器 配置Spring的监听器ContextLoaderListener，用于在容器启动的时候就加载spring的配置文件 配置SpringMVC的前端控制器DispatcherServlet，其中指定的是springMVC的配置文件springMVC.xml 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- 解决POST提交方式的中文乱码的过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 配置SpringMVC的前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- springmvc的配置文件 --&gt; &lt;param-value&gt;classpath:springMVC.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 使用ContextLoaderListener配置spring的监听器，主要是在启动的时候加载spring的配置文件 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- 指定所有的spring配置文件，这里使用 * 通配符 --&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; 包的结构]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene全文检索]]></title>
      <url>%2F2018%2F05%2F27%2FLucene%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%2F</url>
      <content type="text"><![CDATA[Lucene 全文检索Field域 Field是文档中的域，包括Field名和Field值两部分，一个文档可以包括多个Field，Document只是Field的一个承载体，Field值即为要索引的内容，也是要搜索的内容。 是否分词 分词就是对文件的内容或者其他的属性进行分割形成一个一个的语汇单元，分词的过程就是将一些动词，定冠词，不定冠词等内容去掉，保留名词。比如文件的内容，商品的介绍，这些内容都是需要用户输入关键词来查询的，因此这个必须分词 但是对于商品的id，订单号，身份证号这些是不用分词的，这个是必须全局匹配才会找到相关的内容 是否索引 索引的目的就是为了将来作为查询条件来搜索，比如商品的名称，商品的介绍，文章的内容，这些内容需要输入关键词搜索的，我们必须进行索引，如果不索引将会不能爱按照这些内容搜索。 不索引： 商品的id，图片的路径等这个是不需要作为查询条件的，因此不需要索引 是否存储 将Field值存储在文档中，存储在文档中的Field才可以从Document中获取。 比如：商品名称、订单号，凡是将来要从Document中获取的Field都要存储。 否：不存储Field值，不存储的Field无法通过Document获取 比如：商品简介，内容较大不用存储。如果要向用户展示商品简介可以从系统的关系数据库中获取商品简介。 如果需要商品描述，则根据搜索出的商品ID去数据库中查询，然后显示出商品描述信息即可。 ​ Field的常用类型 Field改进 图书id 是否分词：不用分词，因为不会根据商品id来搜索商品 是否索引：不索引，因为不需要根据图书ID进行搜索 是否存储：要存储，因为查询结果页面需要使用id这个值。 图书名称： 是否分词：要分词，因为要将图书的名称内容分词索引，根据关键搜索图书名称抽取的词。 是否索引：要索引。 是否存储：要存储。 图书价格 是否分词：要分词，lucene对数字型的值只要有搜索需求的都要分词和索 引，因为lucene对数字型的内容要特殊分词处理，本例子可能要根据价格范 围搜索，需要分词和索引。 是否索引：要索引 是否存储：要存储 图书图片地址： 是否分词：不分词 是否索引：不索引 是否存储：要存储，因为只有根据图片地址才能找到对应的图片 图书描述： 是否分词：要分词 是否索引：要索引 是否存储：因为图书描述内容量大，不在查询结果页面直接显示，不存储。 不存储是来不在lucene的索引文件中记录，节省lucene的索引文件空间， 如果要在详情页面显示描述，思路： 从lucene中取出图书的id，根据图书的id查询关系数据库中book表 得到描述信息。 添加依赖 这里使用的IKAnalyzer这个中文分词器 1234567891011121314151617181920212223242526272829303132333435363738&lt;!-- 添加lucene支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- IK分词器 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.janeluo&lt;/groupId&gt; &lt;artifactId&gt;ikanalyzer&lt;/artifactId&gt; &lt;version&gt;2012_u6&lt;/version&gt; &lt;/dependency&gt; 添加IK中文分词器的扩展 只需要将这些文件下载下载出来，然后添加到src/main/resource路径下即可 Lucene的工具类 其中自己封装了一些方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Lucene的工具类 * @author chenjiabing */public class LuceneUtils &#123; /** * 获取IndexWriter 用于创建索引库 * @return IndexWriter对象 * @throws Exception */ public static IndexWriter getIndexWriter() throws Exception&#123; //创建索引库存放的位置 Directory directory=FSDirectory.open(new File("/home/chenjiabing/Documents/Lucene")); //使用IK中文分词器 IKAnalyzer ikAnalyzer=new IKAnalyzer(true); //创建IndexWriteConfig对象，其中传入的是分析器对象 IndexWriterConfig indexWriterConfig=new IndexWriterConfig(Version.LATEST, ikAnalyzer); //创建索引，其中的变量是索引库的位置，索引配置对象 IndexWriter indexWriter=new IndexWriter(directory, indexWriterConfig); return indexWriter; &#125; /** * 获取IndexSearcher，用于查询 * @return IndexSearcher对象 * @throws Exception */ public static IndexSearcher getIndexSearcher()throws Exception&#123; //创建Directory对象，指定索引库的位置 Directory directory=FSDirectory.open(new File("/home/chenjiabing/Documents/Lucene")); //创建IndexReader对象 IndexReader indexReader=DirectoryReader.open(directory); //创建IndexSearcher对象 IndexSearcher indexSearcher=new IndexSearcher(indexReader); return indexSearcher; &#125; /** * 根据查询语句，打印结果 * @param indexSearcher IndexSearch对象 * @param query 查询对象 * @param n 显示结果数量 * @throws IOException */ public static void doSearch(IndexSearcher indexSearcher,Query query,Integer n) throws IOException&#123; //执行查询 TopDocs topDocs=indexSearcher.search(query, n); //返回查询结果 ScoreDoc[] scoreDocs=topDocs.scoreDocs; //遍历查询结果 for (ScoreDoc scoreDoc : scoreDocs) &#123; int doc=scoreDoc.doc; //返回文档的编号 //根据编号查询文档 Document document=indexSearcher.doc(doc); //输出文档中定义的域 System.out.println(document.get("fileName")); /*System.out.println(document.get("fileSize")); System.out.println(document.get("fileContent")); System.out.println(document.get("filePath"));*/ &#125; &#125;&#125; 创建索引库12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 创建索引 @Test public void testIndex() throws Exception &#123; IndexWriter indexWriter=LuceneUtils.getIndexWriter(); //创建File对象,这里是需要索引的文件 File file=new File("/home/chenjiabing/Documents/Blog"); //获取文件夹下的所有文件 File[] files=file.listFiles(); //遍历所有的文件，取出相关 的内容 for (File f : files) &#123; Document document=new Document(); //创建文档对象 //获取文件名 String fileName=f.getName(); //创建域 文件名 分词，索引 存储 Field fieldName=new TextField("fileName", fileName, Store.YES); //获取文件大小 Long fileSize=FileUtils.sizeOf(f); //创建文件大小的域，分词，索引，存储 Field fieldSize=new LongField("fileSize", fileSize, Store.YES); //获取文件路径 String filePath=f.getPath(); //创建文件路径的域 不分词，不索引 但是必须存储，用来找到指定的文件 Field fieldPath=new StoredField("filePath", filePath); //获取文件内容 String fileContent=FileUtils.readFileToString(f); //创建文件内容的域，分词，索引，存储 Field fieldContent=new TextField("fileContent", fileContent,Store.YES); //将分出的这些域添加到文档中 document.add(fieldContent); document.add(fieldName); document.add(fieldPath); document.add(fieldSize); //将文档写入索引库 indexWriter.addDocument(document); &#125; //关闭IndexWriter对象 indexWriter.close(); &#125; Query 搜索TermQuery 这个是精确搜索 TermQuery项查询，TermQuery不使用分析器，搜索关键词作为整体来匹配Field域中的词进行查询，比如订单号、分类ID号等。 这个查询的方式不会通过分词器进行分词查询，而是整个内容匹配。比如其中的查询条件为文件的名称：springmvc拦截器，那么只有当名称为...springmvc拦截器.....这样整个词语连接在一起的时候才会查询到 `TermQuery(new Term(&quot;域名&quot;,&quot;搜索的词语&quot;)) : 这里的域名是创建Field的时候指定的：new Field(&quot;域名&quot;,值) 123456789101112@Test public void testTermQuerySearch() throws Exception&#123; //获取IndexSearcher IndexSearcher indexSearcher=LuceneUtils.getIndexSearcher(); //创建一个TermQuery对象，指定查询的域和需要查询的词 TermQuery query=new TermQuery(new Term("fileName","springmvc拦截器")); System.out.println(query); //打印查询结果 LuceneUtils.doSearch(indexSearcher, query, 10); //关闭IndexReader indexSearcher.getIndexReader().close(); &#125; NumericRangeQuery 指定数字范围查询. 适合查询价格等数字类型的 其中有许多创建查询范围的静态方法，适合多种数据类型的查询 123456789101112131415161718@Test public void testNumericRangeQuery() throws Exception&#123; IndexSearcher indexSearcher=LuceneUtils.getIndexSearcher(); /** * 这里是查询文件大小的域：fileSize * 第一个参数： 域名 * 第二个参数：最小值 * 第三个参数： 最大值 * 第四个参数： 是否包含最小值 * 第五个参数： 是否包含最大值 */ Query query=NumericRangeQuery.newLongRange("fileSize", 1000L, 2000L, true, true); //输出查询条件：fileSize:[1000 TO 2000] System.out.println(query); LuceneUtils.doSearch(indexSearcher, query, 10); //关闭IndexReader indexSearcher.getIndexReader().close(); &#125; BooleanQuery BooleanQuery，布尔查询，实现组合条件查询。 Occur.MUST : 当前的查询条件必须满足 Occur.SHOULD ： 当前的查询条件可满足可不满足，相当于or MUST_NOT：查询条件不能满足，相当于NOT非+ 12345678910111213141516171819202122@Test public void testBooleanQuery() throws Exception&#123; IndexSearcher indexSearcher=LuceneUtils.getIndexSearcher(); //第一个查询条件 根据fileName域查询 Query query1=new TermQuery(new Term("fileName", "springmvc")); //第二个查询条件，根据fileSize查询 Query query2=NumericRangeQuery.newLongRange("fileSize", 1000L, 2000L, true, true); //创建BooleanQuery BooleanQuery query=new BooleanQuery(); //添加查询条件，这个条件是必须满足的 ：Occur.MUST query.add(query1,Occur.MUST); //添加第二个查询条件，这个条件可满足可不满足，相当于or query.add(query2,Occur.SHOULD); System.out.println(query); //执行查询 LuceneUtils.doSearch(indexSearcher, query, 10); indexSearcher.getIndexReader().close(); &#125; MatchAllDocsQuery 查询所有 返回的是索引库中所有的文件信息 123456789//查询所有 @Test public void testMatchAllDoc() throws Exception&#123; IndexSearcher indexSearcher=LuceneUtils.getIndexSearcher(); Query query=new MatchAllDocsQuery(); System.out.println(query); LuceneUtils.doSearch(indexSearcher, query, 10); indexSearcher.getIndexReader().close(); &#125; QueryParser [常用] 通过QueryParser也可以创建Query，QueryParser提供一个Parse方法，此方法可以直接根据查询语法来查询 12345678910111213141516171819@Test public void testQueryParser() throws Exception&#123; IndexSearcher indexSearcher=LuceneUtils.getIndexSearcher(); /** * 第一个参数：指定了默认的查询的域名 * 第二个参数： 指定了分词器 */ QueryParser parser=new QueryParser("fileName",new IKAnalyzer()); /** * 其中的字符串的形式为： *:* * 查询所有： *:* * 根据默认域名查询直接写一个查询内容即可： "springmvc" * 根据指定域名查询： "fileContent:springmvc" */ Query query=parser.parse("fileContent:拦截器"); System.out.println(query); LuceneUtils.doSearch(indexSearcher, query, 50); indexSearcher.getIndexReader().close(); &#125; MultiFieldQueryParser 通过MultiFieldQueryParser对多个域查询。 123456789101112131415161718192021@Test public void testMulitFiledQueryParser() throws Exception&#123; IndexSearcher indexSearcher=LuceneUtils.getIndexSearcher(); //指定默认查询的域名 String[] fields=&#123;"fileName","fileContent"&#125;; /** * 创建对象 * 第一个参数： 指定默认域名的数组 * 第二参数： 指定分词器，这里使用中文分词器 */ MultiFieldQueryParser parser=new MultiFieldQueryParser(fields, new IKAnalyzer()); //这里没有指定域名，因此使用上面指定的两个默认的域名进行查询，这两个默认域名之间是or关系，只要满足就查询返回 //Query query=parser.parse("springmvc"); //指定filePath域名中搜索 Query query=parser.parse("filePath:/home/chenjiabing"); System.out.println(query); LuceneUtils.doSearch(indexSearcher, query, 50); indexSearcher.getIndexReader().close(); &#125; 索引维护 每个document代表一个索引，维护索引其实就是对document的增删改查 添加索引 如果数据库系统做了变更，那么我们需要添加索引，那么此时就需要添加索引 indexWriter.addDocument（doc) 这个就像是创建索引库的时候，其实就是在添加索引 删除索引指定条件删除 根据Term项删除索引，满足条件的将全部删除。 Term是索引域中最小的单位。根据条件删除时，建议根据唯一键来进行删除。在solr中就是根据ID来进行删除和修改操作的。 writer.deleteDocuments(new Term(&quot;域名&quot;,&quot;值&quot;)); 123456789101112131415161718@Testpublic void deleteIndex() throws Exception &#123; // 创建分词器，标准分词器 Analyzer analyzer = new IKAnalyzer(); // 创建IndexWriter IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_4_10_3, analyzer); Directory directory = FSDirectory .open(new File("E:\\11-index\\hcx\\")); // 创建IndexWriter IndexWriter writer = new IndexWriter(directory, cfg); // Terms writer.deleteDocuments(new Term("id", "1")); writer.close();&#125; 删除全部 将索引目录的索引信息全部删除，直接彻底删除，无法恢复。慎用！ 12345678910111213141516// 删除索引@Testpublic void deleteIndex() throws Exception &#123; // 1、指定索引库目录 Directory directory = FSDirectory.open(new File("E:\\11-index\\0720")); // 2、创建IndexWriterConfig IndexWriterConfig cfg = new IndexWriterConfig(Version.LATEST, new StandardAnalyzer()); // 3、 创建IndexWriter IndexWriter writer = new IndexWriter(directory, cfg); // 4、通过IndexWriter来删除索引 // a)、删除全部索引 writer.deleteAll(); // 5、关闭IndexWriter writer.close();&#125; 修改索引 更新索引是先删除再添加，建议对更新需求采用此方法并且要保证对已存在的索引执行更新，可以先查询出来，确定更新记录存在执行更新操作。 123456789101112131415161718192021222324@Testpublic void updateIndex() throws Exception &#123; // 创建分词器，标准分词器 Analyzer analyzer = new StandardAnalyzer(); // 创建IndexWriter IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_4_10_3, analyzer); Directory directory = FSDirectory .open(new File("E:\\11-index\\hcx\\")); // 创建IndexWriter IndexWriter writer = new IndexWriter(directory, cfg); // 第一个参数：指定查询条件 // 第二个参数：修改之后的对象 // 修改时如果根据查询条件，可以查询出结果，则将以前的删掉，然后覆盖新的Document对象，如果没有查询出结果，则新增一个Document // 修改流程即：先查询，再删除，在添加 Document doc = new Document(); doc.add(new TextField("name", "lisi", Store.YES)); writer.updateDocument(new Term("name", "zhangsan"), doc); writer.close();&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring之AOP之底层实现]]></title>
      <url>%2F2018%2F05%2F21%2FSpring%E4%B9%8BAOP%E4%B9%8B%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[Spring之AOP之底层实现静态代理实现 定义IStudnetService接口 12345678/** * IStudentService的接口 * @author chenjiabing */public interface IStudentService &#123; void add();&#125; 定义StudentServiceImpl实现方法 1234567@Servicepublic class StudentServiceImpl implements IStudentService &#123; public void add() &#123; System.out.println("StudentService的add方法"); &#125;&#125; 定义StudentAop切面类 12345678910111213141516171819202122232425262728293031/** * 切面类 * @author chenjiabing */@Componentpublic class StudentAOP &#123; //之前执行 public void before()&#123; System.out.println("StudentAOP.before...."); &#125; //之后执行 public void after()&#123; System.out.println("StudentAOP.after"); &#125; //在之后执行，只在没有出现异常的时候执行 public void afterReturning()&#123; System.out.println("StudentAOP.afterReturning"); &#125; //之后执行，但是只在出现异常的时候执行 public void afterThrowing()&#123; System.out.println("StudentAOP.throwing"); &#125; //环绕方法 public void arounding()&#123; System.out.println("StudentAOP.arounding"); &#125;&#125; 定义StudentProxy代理类 12345678910111213141516171819202122232425/** * 静态代理类 * @author chenjiabing */@Componentpublic class StudentProxy implements IStudentService &#123; @Resource private StudentAOP studentAOP; //依赖注入切面对象 @Resource private IStudentService studentService; //目标对象 public void add() &#123; try &#123; studentAOP.arounding(); //执行环绕方法 studentAOP.before(); //执行切面类的方法 studentService.add(); //执行目标对象的方法 studentAOP.after(); //执行切面的after方法 studentAOP.afterReturning(); //执行切面类afterReturning的方法 &#125; catch (Exception e) &#123; studentAOP.afterThrowing(); //执行切面类的方法，在出现异常之后执行 &#125;finally&#123; studentAOP.arounding(); //执行环绕方法 &#125; &#125;&#125; 测试方法 12345678910@Testpublic void test1() &#123; // 加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-dao.xml", "spring-service.xml","spring-aop.xml"); //创建Service，其中使用的是动态代理类 IStudentService studentService=ac.getBean("studentProxy",IStudentService.class); studentService.add();&#125; 动态代理实现 代理类实现java.lang.reflect.InvocationHandler接口 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 动态代理的类 * * @author chenjiabing */@Component // 创建对象public class ProxyHandler implements InvocationHandler &#123; private Object object; // 目标对象 @Resource private StudentAOP studentAOP; // 注入切面类 // 获取动态代理类的对象 public Object getObject(Object object)&#123; this.object=object; /** * 第一个参数：目标类的类加载器 * 第二个参数：目标类的接口 * 第三个参数：动态代理的实例 */ return Proxy.newProxyInstance(object.getClass().getClassLoader(), object.getClass().getInterfaces(), this); &#125; /** * @param proxy ：被代理的对象 * @param method : 要调用的方法 * @param args : 方法调用的时候所需要的参数 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; studentAOP.before(); //调用切面的before方法 //通过反射调用目标类的方法 Object result=method.invoke(object, args); //调用目标类的方法 studentAOP.after(); //调用切面的after方法 return result; &#125;&#125; 测试方法 1234567891011121314@Testpublic void test2() &#123; // 加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-dao.xml", "spring-service.xml","spring-aop.xml"); //获取动态代理类的对象 ProxyHandler proxyHandler=ac.getBean("proxyHandler",ProxyHandler.class); //获取代理类的对象 IStudentService studentService=(IStudentService) proxyHandler.getObject(new StudentServiceImpl()); studentService.add(); &#125; 参考文档 JDK代理和Cglib代理的实现]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring之AOP]]></title>
      <url>%2F2018%2F05%2F21%2FSpring%E4%B9%8BAOP%2F</url>
      <content type="text"><![CDATA[Spring之AOPSpring框架两大核心内容IOC （ＤＩ） ＩＯＣ：控制反转 将创建和管理对象全部交给框架完成 DI : 依赖注入 为成员变量赋值 其中有不同的方法赋值，但是我们推荐使用set方法注入或者注解方式 AOP 面向切面编程，是面向对象编程的重要组成部分，在不改变业务逻辑功能的基础上，对横切逻辑进行扩展 aspectj框架是aop编程思想的体现，spring-aop对aspectj又进一步的封装 Aop的实现原理是jdk的动态代理和Cglib代理 如果IOC容器组件实现接口使用JDK动态代理，如果没有实现接口使用Cglib代理 实现步骤依赖jar包 aspectjweaver aspectjrt spring-aop 这个是spring对aspectj的封装，因此我们使用起来更加简单 添加依赖 在pom.xml中添加如下依赖 12345678910111213141516171819&lt;!-- 导入aspectj依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.8.13&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.13&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 导入spring的aop --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 创建一个aop的实现类 创建类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Component //spring自动创建对象@Aspect //表示当前类是一个切面类public class DemoAop &#123; /** * @Before("bean(bean的名称)") 表示该方法在这个bean中的所有方法执行之前执行 * 其中可以使用通配符，比如bean("*ServiceImpl") 表示全部的service类，比如userServiceImpl */ @Before("bean(userServiceImpl)")//方法执行之前 public void before()&#123; System.out.println("方法执行之前..............."); &#125; /** * 在方法之后执行 */ @After("bean(*ServiceImpl)") public void after()&#123; System.out.println("在方法执行之后执行"); &#125; /** * 在业务方法没有异常的时候才会执行，并且实在@After之后执行 * 如果业务方法有异常，那么不会执行 */ @AfterReturning("bean(*ServiceImpl)") public void afterReturning()&#123; System.out.println("方法在after之后执行，并且这个业务方法没有出现异常"); &#125; /** * 在业务方法发生异常才会执行，并且在@After之后执行 * 如果没有发生异常，不会执行 */ @AfterThrowing("bean(*ServiceImpl)") public void afterThrowing()&#123; System.out.println("方法发生异常执行...."); &#125; /** * 环绕通知 * @param jp * @throws Throwable */ @Around("bean(*ServiceImpl)") public Object test(ProceedingJoinPoint jp) throws Throwable&#123; System.out.println("环绕通知 .....之前"); //调用业务层的方法,其中的Object是接收业务层方法的返回值 Object object =jp.proceed(); System.out.println("环绕通知..........之后"); return object; //这里的返回值必须返回，否则在业务层将不会获取到 &#125; &#125; 定义配置文件 配置注解扫描(spring-aop.xml) 12345&lt;!-- 定义spring组件扫描componet --&gt;&lt;context:component-scan base-package="cn.tedu.store.aop" /&gt;&lt;!-- 解析切面注解 --&gt;&lt;aop:aspectj-autoproxy /&gt; 通知(5种) @Before（前置通知）：在业务方法执行之前调用 @After（后置通知）：在方法之后执行 @AfterReturning(正常返回通知)：在方法之后执行，只有在业务方法没有出现异常的时候才会执行 @AfterThrowing(异常通知) ： 在方法之后执行，只有在业务方法出现异常的时候才会执行 @Around （环绕通知）：在业务方法执行之前和之后执行，即是在@Before之前执行，在@After之后执行，必须又返回值，这里的返回值就是业务层方法的返回值，如果不返回，那么业务层方法就获取不到返回值 连接点 业务层的所有方法，叫做连接点 业务类中可以被增强的方法都叫做连接点 切点 能切入切面逻辑的方法，叫做切点 实际被增强的方法叫做切入点 ，其他的那些没有被增强的方法(连接点)不是切点 切面 定义了增强方法的类就叫做切面 定义切点第一种方式(基于spring创建的bean) bena的切点定义 ： (bean(&quot;userServiceImpl&quot;)),这个是作用到该业务类中的所有方法上，并不能定义到某一个方法上 bean(&quot;*ServiceImpl&quot;)：作用到多个业务层，比如：userServiceImpl,addressServiceImpl bean(&quot;userServiceImpl&quot;)||bean(&quot;addressServiceImpl&quot;)： 只作用到当前的两个业务层 第二种方式(基于类的) (within(&quot;全类名&quot;))： 其中写的是全类名 (within(&quot;cn.tedu.store.service.UserServiceImpl&quot;))：作用于UserServiceImpl这个业务层中的所有方法 (within(&quot;cn.tedu.store.service.*ServiceImpl&quot;)): 使用*通配符，作用到全部的业务层 第三种方式(基于方法的) (&quot;execution(* cn.tedu.store.service.UserServiceImpl.login(..))&quot;) ：第一个*表示方法的返回类型，一般使用*表示，其中的形式是全类名.方法名(..) (&quot;execution(* cn.tedu.store.service.UserServiceImpl.get*(..))&quot;):这个将作用于UserServiceImpl这个业务类中的所有以get开头的方法 (&quot;execution(* cn.tedu.store.service.*ServiceImpl.login(..))&quot;): 这个将作用于所有的业务类中的所有以get开头的方法 (&quot;execution(* cn.tedu.store..get*(..))&quot;) :这个将作用于cn.tedu.store这个包和其子包下的所有类中的所有以get开头的方法 123456789101112131415161718192021222324@Component@Aspectpublic class TestAop &#123; /** 在调用UserServiceImpl中的login()方法之前执行这个方法 */ @Before("execution(* cn.tedu.store.service.UserServiceImpl.login(..))") public void test()&#123; System.out.println("TestAop.text"); &#125; /** * 测试登录的业务方法的性能 */ @Around("execution(* cn.tedu.store.service.UserServiceImpl.login(..))") public Object test1(ProceedingJoinPoint jp) throws Throwable&#123; Long before=System.currentTimeMillis(); //获取执行之前的系统时间 Object object=jp.proceed(); //调用业务层的方法 Long after=System.currentTimeMillis(); //获取执行之后的系统时间 System.out.println(after-before); return object; &#125;&#125; 使用场景 测试系统性能 打印日志 事务处理 …………………………………… 实现原理 基于动态代理完成 Aop的实现原理是jdk的动态代理和Cglib代理 cglib代理使用的是继承，动态代理使用的是接口，如果需要添加横切逻辑的类没有接口，那么使用的是cglib代理，如果有接口，使用的是jdk的动态代理 JDK的动态代理的原理是代理类实现目标类的接口，但是Cglib代理原理是继承，因此如果目标有接口那么使用的是动态代理。 spring-aop是对aspectj的进一步封装 Spring-aop 处理事务处理的前提 默认发生RuntimeException或者其子类类型异常时，spring-aop会捕获异常，并且处理事务 配置文件 创建事务管理器对象 开启基于注解的事务管理 12345678&lt;!-- 配置事务管理器 --&gt;&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!-- 注入数据源，这里使用的是上面配置好的DataSource --&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 开启事务注解 ,transaction-manager指定的是上面配置的事务管理器的id--&gt;&lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; 注解配置事务@Transactional 可以在service的实现类上添加，那么所有的实现方法都会被事务管理器管理 可以在某一个方法上添加，那么只有配置了注解的方法才会被事务管理器管理 可以在Service的接口上添加注解，那么所有的接口方法都会被事务管理器管理 我们推荐在Service的接口类上添加注解,并且在只涉及到查询语句的方法中设置传播行为为只读@Transactional(readOnly=true) Spring事务的传播属性 名称 值 解释 PROPAGATION_REQUIRED 0 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是Spring默认的事务的传播。 PROPAGATION_SUPPORTS 1 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 2 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 3 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 4 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 5 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 6 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 Spring事务的隔离级别 名称 值 解释 ISOLATION_DEFAULT -1 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别。另外四个与JDBC的隔离级别相对应 ISOLATION_READ_UNCOMMITTED 1 这是事务最低的隔离级别，它充许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻读。 ISOLATION_READ_COMMITTED 2 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。 ISOLATION_REPEATABLE_READ 4 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻读。 ISOLATION_SERIALIZABLE 8 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻读。 配置须知 我们知道其实只有在涉及到数据库的修改才应该被事务管理，查询不需要被事务管理，但是一旦我们在一个Service接口上添加了@Transactional这个注解，那么默认这个接口中所有的方法都会被事务管理，因为这些方法都使用了默认的传播属性PROPAGATION_REQUIRED，我们可以在只涉及到查询语句的方法上添加@Transactional(readyOnly=true)，这样可以优化事务管理 实例 接口上一旦添加了事务的注解，那么所有的方法都会被管理，但是我们可以设置只涉及到查询语句的方法传播属性为只读 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * 博客的业务层接口 * @author chenjiabing */@Transactional //在接口中添加事务管理，那么其中的所有方法都被事务管理了public interface IBlogService &#123; /** * 获取当前用户的所有博客分类 * @param bloggerId 博主id * @return */ @Transactional(readOnly=true) //设置传播属性为只读，因为其中只涉及了查询语句 List&lt;BlogType&gt; getBlogTypeList(Integer bloggerId); /** * 添加博客 * @param blog Blog对象，其中封装了需要添加的内容 */// @Transactional(propagation=Propagation.REQUIRED) //这个是默认的，可以不用定义，因为在接口上已经定义了 void addBlog(Blog blog); /** * 分页获取博客总数 * @param bloggerId * @param offest * @param count * @return */ @Transactional(readOnly=true) List&lt;Blog&gt; getBlogList(Integer bloggerId,Integer offest,Integer count); /** * 获取博客总数 * @param bloggerId * @return */ @Transactional(readOnly=true) Integer getBlogCount(Integer bloggerId,String title,Integer typeId); /** * 批量删除博客 * @param ids */ void moveBlogByIdsBatch(Integer[] ids); /** * 根据id查询博客信息 * @param id 主键id * @return 返回Blog对象，其中封装了需要的信息 */ @Transactional(readOnly=true) Blog getBlogById(Integer id); /** * 根据日期分类 * @param bloggerId * @return */ @Transactional(readOnly=true) List&lt;Blog_Count_ReleaseDateStr_Vo&gt; getBlogGroupByReleaseDateStr(Integer bloggerId); /** * 按照博客分类来获取博客信息 * @param typeId 分类id * @return */ @Transactional(readOnly=true) List&lt;Blog&gt; getBlogByTypeId(Integer typeId,Integer offest,Integer count); /** * 按照日期分类获取博客信息 * @param bloggerId 博主id * @param releaseDateStr 日期 * @param offest 偏移量 * @param count 数量 * @return */ @Transactional(readOnly=true) List&lt;Blog&gt; getBlogByreleaseDateStr(@Param("bloggerId")Integer bloggerId,@Param("releaseDateStr")String releaseDateStr,@Param("offest")Integer offest,@Param("count")Integer count); /** * 按照日期查询博客数量 * @param bloggerId 博主id * @param releaseDateStr 日期 * @return */ @Transactional(readOnly=true) Integer getBlogCount(Integer bloggerId,String releaseDateStr); /** * 修改博客的点击次数 * @param id * @param clickHit */ void modifyclickHit(Integer id,Integer clickHit);&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis之使用总结]]></title>
      <url>%2F2018%2F05%2F21%2FMybatis%E4%B9%8B%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Mybatis之使用总结多表连接查询 如果需要使用多表连接查询，使用resultMap对应表与实体类的对应关系太麻烦，我们可以定义一个值对象，其中封装了多表连接查询返回的字段，我们直接使用值对象接收返回的结果即可 比如我们在商城网站上的显示购物车的模块，使用的CartVo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 购物车的值对象 * 用于接收多表连接查询的结果 * @author chenjiabing */public class CartVo implements Serializable &#123; private static final long serialVersionUID = 8904622535687816912L; private Integer id; //主键 购物车表中的主键 private String goodsId; //商品的id private Integer uid; //用户id private String image; //图片地址 private String title; //商品标题 private Integer price; //商品价格 private Integer num; //加入购物车的商品数量 public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getGoodsId() &#123; return goodsId; &#125; public void setGoodsId(String goodsId) &#123; this.goodsId = goodsId; &#125; public Integer getUid() &#123; return uid; &#125; public void setUid(Integer uid) &#123; this.uid = uid; &#125; public String getImage() &#123; return image; &#125; public void setImage(String image) &#123; this.image = image; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public Integer getPrice() &#123; return price; &#125; public void setPrice(Integer price) &#123; this.price = price; &#125; public Integer getNum() &#123; return num; &#125; public void setNum(Integer num) &#123; this.num = num; &#125; @Override public String toString() &#123; return "CartVo [id=" + id + ", goodsId=" + goodsId + ", uid=" + uid + ", image=" + image + ", title=" + title + ", price=" + price + ", num=" + num + "]"; &#125; &#125; 表与实体类中的字段不对应 一般在数据库中定义字段的格式是使用下划线_连接的，但是在java中定义是使用驼峰式的命名风格，因此难免会出现字段不一样的情况，我们一般可以使用resultMap实现其的对应关系，或者在查询的时候，使用别名即可 Mapper方法中参数问题 默认的mapper接口中的方法只能有一个参数，但是我们可以使用@Param(&quot;&quot;)这个注解来新增加参数 批量删除 批量删除mapper接口中方法传入的是数组，必须使用@Param()标记，否则将不能识别 使用的sql语句： delete from 表名 where id in (.....) 我们可以在&lt;delete&gt;节点中使用&lt;forEach&gt;标签来遍历传入的数组 123456789101112131415161718192021&lt;!-- void deleteCartById(Integer[] ids); 批量删除 --&gt; &lt;delete id="deleteCartById" parameterType="java.lang.Integer"&gt; delete from t_cart where id in &lt;!-- 遍历数组ids collection:需要遍历的数组 item: 数组中的每一个值 open ： 开始的内容 close: 结束的内容 separator ：每个元素的分割符 最后拼接的就是 (id,id,id,id,id) --&gt; &lt;foreach collection="ids" item="id" open="(" separator="," close=")"&gt; #&#123;id&#125; &lt;/foreach&gt; &lt;/delete&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc之文件上传和下载]]></title>
      <url>%2F2018%2F05%2F21%2FSpringmvc%E4%B9%8B%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD%2F</url>
      <content type="text"><![CDATA[Springmvc之文件上传和下载前提 在上传和下载之前需要在对应的根目录下创建对应的文件夹，比如我们在webApp下创建upload文件夹下 添加依赖 commons-io commons-fileupload 123456789101112&lt;!-- 添加文件上传的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; 在配置文件中配置(spring-mvc.xml) id的名称一定是multipartResolver，不能任意指定 12345678&lt;!-- 上传组件的解析器 --&gt;&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!-- 上传文件大小 单位是字节--&gt; &lt;property name="maxUploadSize" value="10000000"&gt;&lt;/property&gt; &lt;!-- 请求的编码格式，必须和jSP的pageEncoding属性一致，以便正确读取表单的内容，默认为ISO-8859-1 --&gt; &lt;property name="defaultEncoding" value="utf-8"&gt;&lt;/property&gt;&lt;/bean&gt; 制作上传表单 表单的提交方式一定为POST 必须追加enctype=&quot;multipart/form-data&quot; 12345&lt;form action="$&#123;pageContext.request.contextPath &#125;/upload/upload.do" method="POST" enctype="multipart/form-data"&gt; file: &lt;input type="file" name="file" value="上传"&gt; &lt;br&gt; &lt;input type="submit" value="上传"&gt;&lt;/form&gt; 完成controller 上传的参数一定为MultipartFile file 123456789@RequestMapping("/upload.do") public String uplaod(MultipartFile file) throws IllegalStateException, IOException&#123; String fileName=file.getOriginalFilename(); //获取文件名 Long fileSize=file.getSize(); //获取文件大小 //上传 参数是文件上传后储存的路径，最终的文件上传后的文件路径为/home/chenjiabing/Documents/Blog/fileName file.transferTo(new File("/home/chenjiabing/Documents/Blog",fileName)); //重定向到首页 return "redirect:../main/showIndex.do"; &#125; 异步上传文件定义表单 设置onchange事件，只要input的改变了，那么就上传文件 1&lt;input type="file" name="file" value="" id="iconPic" onchange="getImageFun()"&gt; 定义Controller 其中的参数最好定义映射关系@RequestParam(&quot;file&quot;)，否则有时候会出现不对应的情况 数据库中保存的文件的路径不需要保存项目路径，只需要保存项目的文件路径即可，比如/upload/文件名，那么我们使用http://localhost:8080/TeduStore/upload/文件名就能访问到 1234567891011121314151617181920212223242526272829303132333435363738394041@RequestMapping("/getImage.do")@ResponseBodypublic ResponseResult&lt;Void&gt; getImage(@RequestParam("file")MultipartFile file,HttpSession session) throws IllegalStateException, IOException&#123; ResponseResult&lt;Void&gt; result = new ResponseResult&lt;Void&gt;(); // 如果文件不为空 if (!file.isEmpty()) &#123; String originalFilename = file.getOriginalFilename(); // 获取初始的文件名称 UUID uuid = UUID.randomUUID(); // 使用随机算法生成文件名称，保证文件名称不冲突 String fileName = uuid.toString() + originalFilename.substring(originalFilename .lastIndexOf(".")); // 获取文件在项目中的上传路径 String filePath = session.getServletContext().getRealPath( "/upload/"); // 创建文件的存储路径 File f1 = new File(filePath, fileName); // 判断项目中这个upload文件夹是否存在 if (!f1.getParentFile().exists()) &#123; f1.getParentFile().mkdirs(); // 创建 &#125; // 保存文件 try &#123; file.transferTo(f1); // 存储到数据库中的路径 String fileToDatabase = "/upload/" + fileName; Integer id=this.getId(session); bloggerService.modifyImage(id, fileToDatabase); result.setState(1); result.setMessage("头像上传成功"); &#125; catch (Exception e) &#123; result.setState(0); result.setMessage("头像上传失败"); &#125; &#125; return result;&#125; AJAx异步提交 必须设置contentType:false,processData:false 使用FormData对象保存数据，当然处理文件类型(File类型)的，我们也可以存储键值对，比如formdata.append(&quot;username&quot;,&quot;jack&quot;),最后一起提交即可 1234567891011121314151617181920//上传文件的方法function getImageFun()&#123; var file=document.getElementById("iconPic").files[0]; //获取当前的file // 创建FormData对象 var formData=new FormData(); formData.append("file",file); //将文件放入formData中 $.ajax(&#123; "url":"$&#123;pageContext.request.contextPath&#125;/user/getImage.do", "data":formData, "type":"post", "dataType":"json", //返回数据类型 "contentType":false, //不设置上传文件类型 ，因为上传的文件有多种类型的 "processData":false, //不处理数据 "success":function(obj)&#123; alert(obj.message); var url=window.URL.createObjectURL(file); //获取上传的的本地路径 $("#icon").attr("src",url); //将上面的头像显示为当前选择的图片 &#125; &#125;)&#125; 文件下载### 第一种方式 直接在输入地址即可，比如：http://localhost:8080/TeduStore/upload.do/download.do?fileName=1.jpg 1234567891011121314151617181920212223/** * 文件下载 * @param fileName 文件名 * @param request * @throws IOException */ @RequestMapping("/download.do")public ResponseEntity&lt;byte[]&gt; download(@RequestParam("fileName")String fileName,HttpServletRequest request) throws IOException&#123; //获取下载文件的路径，在文件中的真实路径 String path=request.getServletContext().getRealPath("/upload/"); //下载文件的全路径 File file=new File(path+File.separator+fileName); HttpHeaders headers = new HttpHeaders(); //下载显示的文件名，解决中文名称乱码问题 String downloadFielName = new String(fileName.getBytes("UTF-8"),"iso-8859-1"); //通知浏览器以attachment（下载方式）打开图片 headers.setContentDispositionFormData("attachment", downloadFielName); //application/octet-stream ： 二进制流数据（最常见的文件下载）。 headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); return new ResponseEntity&lt;byte[]&gt;(FileUtils.readFileToByteArray(file), headers, HttpStatus.CREATED); &#125; 第二种方式 controller方法返回byte[] 使用@ResponseBody注解 设置请求头的ContentType类型为下载文件的类型 设置请求头的ContentDisposition 下载图片 只需要在浏览器中输入 ：http://localhost:8080/Project/download/download.do?filename=1.png.就会下载项目路径下的文件夹upload中文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445@RequestMapping("/download.do") @ResponseBody public byte[] download(HttpServletResponse response,HttpServletRequest request,String filename) throws IOException &#123; // 转换编码格式为iso-8859-1 filename = URLEncoder.encode(filename, "utf-8"); // 设置响应头 contentType,这里是下载图片 因此写的是 image/png response.setContentType("image/png"); // 设置响应头Content-Disposition,使用转义双引号 response.setHeader("Content-Disposition", "attachment;filename=\"" + filename + "\""); return getImage(filename, request); &#125; /** * 返回需要下载图片的byte数组 * @param filename 图片的名称 * @param request HttpServletRequest对象，需要获取下载图片的项目路径 * @return byte数组 * @throws IOException */ public byte[] getImage(String filename,HttpServletRequest request) throws IOException&#123; //获取图片文件存放的位置，在项目的upload文件夹下 String projectPath=request.getServletContext().getRealPath("/upload/"); //获取需要下载的图片的路径 File file=new File(projectPath+File.separator+filename); //创建输入流，读取图片 InputStream inputStream=new FileInputStream(file); //创建内存操作流 ByteArrayOutputStream out=new ByteArrayOutputStream(); byte[] b=new byte[1000]; //创建一个缓冲数组 int len=0; //读取字节流，读入到byte数组中 while((len=inputStream.read(b))!=-1)&#123; out.write(b,0,len); //写入byte数组输入流 &#125; inputStream.close(); out.close(); return out.toByteArray(); &#125; 导出Excel文件 改变请求头中的contentType类型为excel类型的即可 12345678910111213141516171819202122232425262728293031323334353637@RequestMapping("/export.do") @ResponseBody public byte[] export(HttpServletResponse response) throws IOException &#123; String filename="excel表格.xlsx"; // 转换编码格式为iso-8859-1 filename = URLEncoder.encode(filename, "utf-8"); // 设置响应头 contentType,这里是下载excel response.setContentType("application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"); // 设置响应头Content-Disposition response.setHeader("Content-Disposition", "attachment;filename=\"" + filename + "\""); return createExcel(); &#125; //创建excel表格，变成byte数组 private byte[] createExcel() throws IOException&#123; //使用POI生成Excel XSSFWorkbook workbook=new XSSFWorkbook(); //生成工作簿 XSSFSheet sheet = workbook.createSheet("第一张表"); //在工作簿中创建一个工作表 XSSFRow row = sheet.createRow(0); //创建行 行号从0开始 XSSFCell cell = row.createCell(0); //在行中创建单元格，从0开始，一行中包括多个单元格 cell.setCellValue("第一行第一个单元格"); //在单元格中添加数据 ByteArrayOutputStream outputStream=new ByteArrayOutputStream(); workbook.write(outputStream); //写入ByteOutputStream流中 workbook.close(); outputStream.close(); return outputStream.toByteArray(); &#125; 导出数据库中的信息 我们可以使用上面的方式，将数据库中的信息写入到excel文件中，然后用户点击链接直接下载即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring之密码加密]]></title>
      <url>%2F2018%2F05%2F21%2FSpring%E4%B9%8B%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%2F</url>
      <content type="text"><![CDATA[密码加密消息摘要(数据的指纹)定义 对不固定的消息（字符串，一段文本，一个文件），通过一种特定的算法，得到一个固定长度的文本，固定长度的文本叫做消息摘要 比如我是程序员经过特定的算法之后，得到了消息摘要为：adaf02515dfds7885csdfcdsc 作用 数据完整性的检验技术，我们将文本转换为消息摘要，然后比较消息摘要的值是否相等，如果相等那么表示两种文本相同 特性 不可逆的，不能从消息摘要再得到原来的文本 特定的算法 MD5 SHA 实现步骤添加依赖jar包 commons-codec 12345&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt;&lt;/dependency&gt; 测试MD5Hex 得到的是32位的16进制的字符串 1234567891011121314@Test public void test1()&#123; String str1="你们好，未来的程序员!"; String strMessageString=DigestUtils.md5Hex(str1); System.out.println(strMessageString); &#125; //读取文件 @Test public void test2() throws IOException&#123; InputStream inputStream=new FileInputStream(new File("/home/chenjiabing/Documents/Blog/AOP.md")); String message=DigestUtils.md5Hex(inputStream); System.out.println(message); &#125; 密码加密 避免在数据库中明文保存密码，通过消息摘要技术对密码进行加密 明文 没有加密的文字(字符串)，能看懂的文字 密文 经过加密后的文字(字符串)，看不出来明文的意思 ### 加盐处理 salt 为了提高密码的安全性 就是在用户的密码之后随便添加一个字符串，然后连接在一起生成摘要，那么即使获取摘要，也不会被破解 1234567@Testpublic void test3()&#123; String str1="123456"; String salt="这个是加盐处理"; //需要加盐，随便定义一个字符串 String message=DigestUtils.md5Hex(str1+salt); //获取加盐之后的消息摘要 System.out.println(message);&#125; 实例密码的安全性处理 涉及到密码： 登录，注册，修改密码 实现 创建一个MD5Password工具类，用于加密密码 12345678910111213141516/** * 密码加密的类 * @author chenjiabing */public class MD5Password &#123; private final static String SALT="加油,骚年!"; //加盐处理 /** * 获取加密之后的密码 * @param password 用户输入的密码 * @return 加密之后的密码 */ public static String getMd5Password(String password)&#123; return DigestUtils.md5Hex(password+SALT); //使用了加盐处理 &#125;&#125; 在注册的时候对输入的密码进行加密存储到数据库中 12345678910111213141516171819/** * 注册 * 1. 调用selectUserByUserName(User user)方法判断用户名是否存在，返回对象u * 2. 判断u是否为null， * 3. 如果为null，调用insertUser(user)方法添加 * 4. 如果不为null，抛出异常提示controller用户名存在(UserNameAlreadyExistException) */ public void register(User user) throws UserNameAlreadyExistException &#123; User u=userMapper.selectUserByUserName(user.getUsername()); //调用usermapper中的方法 if (u!=null) &#123; //如果u不为null，表示用户名已经存在与数据库中，不可以再次注册了，因此抛出异常 throw new UserNameAlreadyExistException("用户名已经存在，请重新输入!!!"); &#125;else &#123; //如果u==null，表示用户名不存在，可以添加 //获取加密之后的密码 String md5Password=MD5Password.getMd5Password(user.getPassword()); //将加密之后的密码设置到user中，保存到数据库中 user.setPassword(md5Password); userMapper.insertUser(user); //直接调用持久层方法插入数据即可 &#125; &#125; 在登录的时候，将用户输入的密码进行加密获取到加密之后的密码，然后和数据库中的密码比较 1234567891011121314151617181920212223242526272829/** * 登录方法 * 1. 通过selectUserByUserName返回user对象 * 2.判断user是否为null * 3.如果user=null，抛出UserNotFoundException异常 * 4.如果user！=null，那么验证其中的密码是否正确 * 5.如果密码不匹配，抛出PassWordNotMatchException异常 * 6. 如果密码匹配，那么返回user对象 * @throws UserNotFoundException * @throws PassWordNotMatchException */ public User login(String userName, String passWord) throws UserNotFoundException, PassWordNotMatchException &#123; User user=userMapper.selectUserByUserName(userName); //根据用户名查询，返回user对象 if (user==null) &#123; //user为null，表示用户名不存在 throw new UserNotFoundException("用户名不存在"); &#125;else &#123; //如果用户名存在，验证密码 //获取加密之后的密码，实际是一个消息摘要 String md5Password=MD5Password.getMd5Password(passWord); //使用加密之后获取的消息摘要和数据库中对应的密码比较 if (md5Password.equals(user.getPassword())) &#123; //如果密码匹配 return user; //返回user对象即可 &#125;else &#123; //如果密码不相同，那么直接抛出密码不匹配的异常即可 throw new PassWordNotMatchException("密码不匹配"); &#125; &#125; &#125; 在修改中，将旧密码加密后和数据库中的密码比较，并且将新密码加密更新到数据库中 12345678910111213141516171819202122232425262728293031/** * 修改密码 * 1. 根据id查询用户信息，返回user * 2. 如果user=null,抛出用户不存在的异常 * 3. 如果user！=null，比较user中的密码和用户输入的旧密码oldPassword是否相同 * 4. 如果密码不相同，抛出密码不匹配的异常 * 5. 如果密码相同，表示用户输入的旧密码是正确的，那么更新密码即可 */ public void updatePassword(Integer id, String oldPassword, String newPassword) throws UserNotFoundException, PassWordNotMatchException &#123; User user=userMapper.seletUserById(id); //根据id查询，返回user对象 if (user==null) &#123; //如果用户不存在 throw new UserNotFoundException("当前登录的用户不存在"); //抛出用户不存在的异常 &#125;else &#123; //如果当前登录的用户存在 //获取旧密码的加密之后的密码 String oldMd5Password=MD5Password.getMd5Password(oldPassword); //使用加密之后的密码和数据库中的密码比较 if (!user.getPassword().equals(oldMd5Password)) &#123; //如果返回的user对象中的密码和用户输入的旧密码不匹配 throw new PassWordNotMatchException("输入的旧密码不匹配"); &#125;else &#123; //如果输出的旧密码正确 User u1=new User(); //创建User对象，封装修改所需的参数 //获取加密之后的新密码 String newMd5Password=MD5Password.getMd5Password(newPassword); u1.setPassword(newMd5Password); //封装新密码，其中是加密之后的密码 u1.setId(id); //封装id userMapper.update(u1); //调用修改的方法 &#125; &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc拦截器拦截Ajax请求]]></title>
      <url>%2F2018%2F05%2F21%2F%E6%8B%A6%E6%88%AA%E5%99%A8%E6%8B%A6%E6%88%AAAjax%E8%AF%B7%E6%B1%82%2F</url>
      <content type="text"><![CDATA[拦截器拦截Ajax请求## 问题 如果我们在拦截器中定义了拦截器的路径为/user/*这个地址,并且拦截器拦截器之后，如果没有登录，那么重定向到登录界面。但是我们在未登录的前提下使用Ajax异步请求了/user/addUser.do这个地址，出现了拦截器是拦截了，但是并没有重定向到登录界面。 原因 可以参照这篇文章 ：http://www.cnblogs.com/dudu/p/ajax_302_found.html 解决第一种 我们可以使用$.ajax中的error中的方法内直接重定向 1234567891011121314$.ajax(&#123; url:url, type:"GET", data:d, dataType:"json", success:function()&#123; alert(data.message); &#125;, //一旦拦截器拦截url的请求，那么会执行error中的回调方法 //这个是失败的执行的回调方法，我们可以在其中重定向到登录界面 error:function()&#123; window.location="$&#123;pageContext.request.contextPath&#125;/user/showLogin.do"; &#125; &#125;)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[选择排序]]></title>
      <url>%2F2018%2F05%2F09%2F%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
      <content type="text"><![CDATA[选择排序思想(从小到大) 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕 分析 假设数组中有个n元素 第一趟：在整个数组中选择出最小的元素，和数组中的第一个元素交换位置，那么此时的第一个元素就是最小的 第二趟： 从第二个元素开始再次查找剩余数组中最小的元素，和数组中的第二个元素交换位置，那么此时的第一个和第二个元素就是最小的 第三趟： 从第三个元素开始再次查找剩余数组中最小的元素，和数组中的第三个元素交换位置，那么此时的前三个就是从小到大的排序 第四趟………………………….第n-1趟 实现12345678910111213141516171819202122232425/** * 思想： 从第一个开始取值和后面的元素开始比较，如果有比它小的，那么就交换元素值 * 外层循环从第一个元素开始，内层循环保证了从外层循环的后面一个元素开始，这样就是保证了比较 * @param arrary 待排序的数组 */public static void selectSort(int[] arrary)&#123; //外层循环，从第一个元素开始直到倒数第二个元素 for (int i = 0; i &lt; arrary.length-1; i++) &#123; int k=i; //这个是保存最小元素的下标，初始化是i //内层循环，从i+1个元素开始直到最后一个元素 for (int j = i+1; j &lt; arrary.length; j++) &#123; //如果下标为j的元素比下标为k的元素小，那么k=j if (arrary[j]&lt;arrary[k]) &#123; k=j; //记录此时的最小的下标 &#125; &#125; //如果此时的k改变了，即是不等于初始值i了，那么表示找到比初始值更小的了，则交换位置 if (k!=i) &#123; //arrary[k]和arrary[i]交换位置，因为最小的放在前面 int temp=arrary[i]; arrary[i]=arrary[k]; arrary[k]=temp; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[插入排序算法]]></title>
      <url>%2F2018%2F05%2F09%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[插入排序算法思想 我们以从小到大的排序进行讲解 插入排序就是将一个元素插入到一个已经是有序的序列中， 通过遍历比较这个待插入元素和有序的序列元素之间的大小，来比较需要插入的位置，使其仍然是一个有序的数组。 数组插入的算法：向后移动元素给待插入的数据位置 详解 第一趟：假设我们需要排序的数组大小为n，一般的思想是先假设第一个元素是有序的，即是已经排序好的，那么第二个元素此时就是待插入的元素，我们拿这个待插入的元素和第一个元素比较大小，如果小的话，那么就将其插入到第一个元素的前面，此时待插入元素就变成了第一个，如果大于的话，就不需要改变位置。那么此时这个数组的前两个元素就是有序的 第二趟： 经过第一趟的，前面两个元素已经是有序的，那么此时的第三个元素就是待插入元素，这个待插入元素先和第二个元素进行比较，如果大于的话，那么就不需要再和第一个元素比较了，当前位置不用改变就可以维持前面三个元素是有序的。如果是小于的话，此时的第二个元素就需要向后移动位置，因为这里可以肯定的是这个待插入元素一定是在其前面插入的，具体的位置没有确定而已。第二个元素向后移动之后，那么此时就需要和第一个元素比较，如果大于的话，那么就插在第一个和第二个元素之间成为当前数组的第二个元素即可，如果小于的话，那么就插入到第一个元素之前，同样的是第一个元素要向后移动为其腾出位置。 第三趟…………………………………第n-1趟 算法分析 平均时间复杂度：O(n2) 空间复杂度：O(1) (用于记录需要插入的数据) 稳定性：稳定 算法实现 — java 需要注意的是判断条件一定是j&gt;=0&amp;&amp;insertNode&lt;array[j]，因为如果调换顺序的话，那么会造成数组下标越界 12345678910111213141516171819202122/** 这个是从小到大的插入排序* @Param array 待排序的数组*/public static void insertSort(int[] array)&#123; //我们假设第一个元素已经是有序的，因此从第二个开始遍历，总共需要遍历n-1次 for (int i = 1; i &lt; array.length; i++) &#123; int insertNode=array[i]; //这个就是待插入的数，需要和在之前的元素比较 int j=i-1; //这个的初始值是待插入数字的前一个数字 //如果待插入的数字比前面的元素小并且此时的j没有到达第一个元素(j&gt;=0) //循环结束的条件是insertNode&gt;=array[j],那么此时的insertNode需要插入的位置就是array[j+1]这个位置了 //需要注意的是&amp;&amp;是短路与的判断，因此需要将j&gt;=0放在前面，否则如果是insertNode&lt;array[j]&amp;&amp;j&gt;=0的形式，那么当j=-1的时候就会造成下标数组越界 while(j&gt;=0&amp;&amp;insertNode&lt;array[j])&#123; array[j+1]=array[j]; //元素后移，以便插入 j--; //比较的元素的下标此时需要前移，和待插入的数据进行比较 &#125; array[j+1]=insertNode; //这个位置就是待插入元素需要插入的位置 &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JQuery实现AJAX异步提交]]></title>
      <url>%2F2018%2F05%2F09%2FJQuery%E5%AE%9E%E7%8E%B0AJAX%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4%2F</url>
      <content type="text"><![CDATA[JQuery实现AJAX异步提交准备 点击下载JQurery的文件 添加JQuery的文件： &lt;script type=&quot;text/javascript&quot; src=&quot;文件路径&quot;&gt;&lt;/script&gt; $.ajax({})格式 其中的url，type等 前面的key可以不用加双引号，也可以加上 1234567$.ajax(&#123; url: '/path/to/file', //请求的路径 type: 'default GET (Other values: POST)', //请求方式，默认为get dataType: 'default: Intelligent Guess (Other values: xml, json, script, or html)', //响应的回来的数据类型，如果指定了json，那么就不需要将返回转换为JSON数据了 data: &#123;param1: 'value1'&#125;, //请求数据，无论是get还是post都是这种形式的 success: function(obj)&#123;&#125; //响应成功调用的方法，obj是返回的数据 &#125;) 实例 在前面博文中的Springmvc响应Ajax请求(@ResponseBody)，我们使用$.ajax({})来发出请求获取City集合 12345678910111213141516171819202122232425262728293031323334353637//根据选择的省份获取市function getCity()&#123; var province=$("#province").val(); //获取下拉菜单的值，这里返回的是省份的编号 var url="&lt;%=request.getContextPath()%&gt;/menu/getCity.do"; //异步请求的url var d=&#123;"province":province&#125;; //将省份的编号传入 //每次都要清空之前的城市 $("#city").html("&lt;option value='-1'&gt;请选择市&lt;/option&gt;"); //如果用户点击了请选择省，那么返回的值就是-1，此时不需要发出异步请求 if(province==-1)&#123; return; &#125; //使用Post请求发出AJAX请求，返回的是一个集合，因此转换为JSON数据的obj是一个数组 $.ajax(&#123; url: url, //请求的路径 type:"POST", // 请求方式，默认为get dataType: "json", //响应的回来的数据类型，如果指定了json，那么就不需要将返回转换为JSON数据了 data:d, //请求数据 success: function(obj)&#123; //响应成功调用的方法，obj是返回的数据 //如果返回的是一个空的，直接返回即可，不需要后续的操作 if(obj.lengt==0)&#123; return; &#125; //循环遍历返回的JSON数组 for(var i=0;i&lt;obj.length;i++)&#123; //创建option，用于插入节点 var option="&lt;option value=" + obj[i].code + "&gt;"+obj[i].name+"&lt;/option&gt;"; //将option插入到下拉列表中 $("#city").append(option); &#125; &#125; &#125;);&#125; $.get() 只适用于GET的异步请求 格式12345678910/* url :请求路径，其中参数必须封装在其中，比如 : http://lcoalhost:8080/web1/regist?name=chenjiabing&amp;age=1 function（data,status,xhr）：这个是回调函数 data：请求返回的数据 status : 请求的状态，其中的有success,error xhr: 这个是XMLHttpRequest对象*/$.get('url', function(data,status,xhr) &#123; &#125;); 实现12345678910111213$(function()&#123; $("#btn").click(function()&#123; var url="http://localhost:8080/web1/user/regist.do?username=chenjiabing&amp;password=12345" ; //请求的url $.get(url,function(data,status)&#123; //如果响应成功，输出返回的数据 if(status=="success") &#123; alert(data); &#125;else&#123; alert("响应失败"); &#125; &#125;); &#125;);&#125;); $.post 只适用于POST请求 格式12345678910/* url ： 异步请求的路径，其中不用封装数据 function（data,status,xhr） :回调函数 data： 请求返回的数据 status：请求的状态，其中的值有success，error xhr: XMLHttpRequest对象*/$.post('url', &#123;param1: 'value1'&#125;, function(data, status, xhr) &#123; /*optional stuff to do after success */ &#125;); 实现1234567891011121314$(function()&#123; $("#btn") .click(function()&#123; var url="http://localhost:8080/web1/user/regist.do; //请求路径 var d=&#123;"username":"陈加兵","password":"123456"&#125;; //发送的请求参数 $.post(url,d,function(data,status,xhr)&#123; if(status=="success")&#123; alert(data); &#125;else &#123; alert("响应失败"); &#125; &#125;) &#125;);&#125;);]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc中的转发重定向和拦截器]]></title>
      <url>%2F2018%2F05%2F09%2FSpringmvc%E4%B8%AD%E7%9A%84%E8%BD%AC%E5%8F%91%E9%87%8D%E5%AE%9A%E5%90%91%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
      <content type="text"><![CDATA[Springmvc中的转发重定向和拦截器可变参数 可变参数在设计方法时，使用数据类型...来声明参数类型，例如：public static void function(int... numbers)在实现方法体时，可变参数是作为数组来处理 12345678910111213141516public class Test &#123; public static void main(String[] args) &#123; System.out.println(Test.sum(1,2,3)); System.out.println(Test.sum(1,2,3,4,54)); &#125; public static int sum(int... numbers)&#123; int sum=0; for(int i=0;i&lt;numbers.length;i++)&#123; sum+=numbers[i]; &#125; return sum; &#125;&#125; 注意： 每个方法中，最多只允许存在1个可变参数，并且，如果存在可变参数,那么必须是最后一个参数 转发和重定向 在控制器内部处理请求的方法中，默认返回字符串时的处理方式是转发，转发的值是view组件的名称，比如return &quot;login&quot;，实质上会根据视图解析器(ViewResolver)得到最终负责显示的页面，而通过return redirect:路径这样的语法表示重定向，在redirect:右侧的内容是路径，这个路径通常使用相对的路径，是以当前客户端的地址栏中的路径为标准进行参考，例如当前的地址为：http://localhost:8080/Project/user/reg.do，然后return &quot;redirect:login.do&quot;,则会重定向到http://localhost:8080/Project/user/login.do,如果return &quot;redirect:/main/index.do&quot;或者return &quot;redirect:../main/index.do&quot;，则会重定向到http://localhost:8080/Project/main/index.do forward: 不添加任何字段，那么spring中默认的是转发，比如return login,那么这个会经过视图解析器进行解析，跳转到指定的视图。但是如果添加了forward，那么就不经过视图解析器，而是直接进行跳转，我们一般都是转发到controller中的方法，比如return forward:../user/showLogin.do redirect: 重定向 ： return &quot;redirect:login.do&quot; 返回的是一个Controller方法的路径，而不是一个view，这个不会经过视图解析器，而是直接跳转 实例1234567891011121314151617@RequestMapping(value="/handle_reg.do", method=RequestMethod.POST) public String handleReg(User user,ModelMap map) &#123; try &#123; userService.reg(user); System.out.println("注册成功！"); return "redirect:login.do"; //重定向到login.do这个控制方法，login.do对应的就是转发到login.jsp &#125; catch (UsernameConflictException e) &#123; System.out.println(e.getMessage()); map.put("errorMessage", e.getMessage()); return "error"; &#125; &#125; @RequestMapping(value="login.do") public String handleLogin() &#123; return "login"; &#125; 拦截器基本概念 拦截器(interceptor)是springmvc中的一个组件，是运行在DispatcherServlet之后，运行在Controller之前的 拦截器可以决定对某些符合条件的进行拦截或者放行，所以，通常用于对一些具有相同运行条件的功能进行约束 使用拦截器自定义拦截器类 创建一个拦截类(DemoInterceptor)，实现HandlerInterceptor接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DemoInterceptor implements HandlerInterceptor &#123; /** * 处理器执行之前调用 * @param request HttpServletRequest对象，可以获取请求参数等等 * @param response HttpServletResponse对象 * @param Handler 拦截器的Controller对象 * @return 如果返回false，就会中断处理流程，不会处理后续的拦截器和Controller。如果返回true，则会执行后续的拦截器和处理器 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("DemoInterceptor的PreHandler执行"); return true; &#125; /** * 处理器执行之后调用,跳转到指定视图之前调用 * @param request HttpServletRequest对象 * @param response HttpServletResponse对象 * @param Handler 拦截器的Controller对象 * @param modelAndView ModelAndView对象，其中存放的是处理结果和视图的信息 */ public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; /** * 1. 可以自己设计逻辑，例如某些情况下返回false，返回true * 2. 返回true表示执行后续的处理器和拦截器，返回false会中断处理流程 */ System.out.println("handler:"+handler); System.out.println("DemoInterceptor的PostHandler执行"); //设置视图的名称，那么执行完成之后就会条跳转到index.jsp页面 //modelAndView.setViewName("index"); &#125; /** * 请求处理完成之后调用 */ public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("DemoInterceptor的afterCompletion执行"); &#125;&#125; 在springmvc的配置文件中配置 配置拦截的路径：&lt;mvc:mapping path=&quot;&quot;/&gt; 可以使用通配符* 比如：/**匹配所有的路径，/user/*只能匹配/user的子路径 配置不拦截的路径 ： &lt;mvc:exclude-mapping path=&quot;&quot;/&gt; 可以配置多个 配置拦截器类(bean) : &lt;bean class=&quot;&quot;&gt; 配置 必须按照上面的顺序配置，否则将会报错 123456789101112131415161718192021 &lt;!-- 配置拦截器,其中可以配置多个拦截器 --&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!-- 配置拦截器的拦截路径，拦截/user下的全部处理器方法映射 比如：http://localhost:8080/Springmvc/user/login.do这个请求就会被拦截 --&gt; &lt;mvc:mapping path="/user/*"/&gt; &lt;!-- 配置不被该拦截器拦截器的controller方法,这个是可选配置 比如：http://localhost:8080/Springmvc/user/index.do将不会被拦截器 --&gt; &lt;mvc:exclude-mapping path="/user/index.do"/&gt; &lt;mvc:exclude-mapping path="/user/login.do"/&gt; &lt;!-- 配置拦截器的bean，指定的是全类名 --&gt; &lt;bean class="cn.tedu.spring.interceptor.DemoInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 其中实现的方法 public boolean preHandle(HttpServletRequest request,HttpServletResponse response, Object handler) 该方法在controller处理请求之前执行 如果返回的false，则会中断处理流程，不会执行后续的拦截器和处理器，返回true会执行后续的拦截器和处理器 可以自行设计逻辑返回false或者true public void postHandle(HttpServletRequest request,HttpServletResponse response, Object handler,ModelAndView modelAndView) 处理器执行之后，视图处理之前调用，此时可以通过对ModelAndView对数据和视图进行处理 当然需要prehandler方法返回true才会执行 public void afterCompletion(HttpServletRequest request,HttpServletResponse response, Object handler, Exception ex) 所有的请求处理完毕之后调用，比如性能监控中，我们可以在此记录结束时间和消耗时间，还可以进行一些资源处理 当然需要prehandler方法返回true才会执行 演示登录检查 登录检查： 当涉及到用户信息的修改，查看什么的，必须要验证是否登录，因此需要设计拦截器验证登录 先设定登录数据，即： 在login.jsp中添加登录按钮，登录完成之后，需要自己定义一个标记存储在session中，比如用户的id或者用户的对象 我们使用用户的id作为标记验证是否已经的登录，如果用户登录成功，会在session中添加一个uid的属性 用户退出登录使用session.invalidate();清除session，并且重定向到登录界面 自定义拦截器(LoginInterceptor) 具体流程在prehandler方法中写的很清楚 12345678910111213141516171819202122232425262728293031public class LoginInterceptor implements HandlerInterceptor&#123; /* * 在处理器执行之前调用(non-Javadoc) * 1. 获取session * 2. 读取session中的uid的值 * 如果为null，表示没有登录，那么直接重定向到登录界面，同时返回false，不需要执行后面的流程了 * 如果不为null，表示已经登录了，那么直接返回true，继续执行后面的拦截器或者处理器 */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; HttpSession session=request.getSession(); //获取session Object uid=session.getAttribute("uid"); //读取session中的对象 //如果uid存在，那么即可登录完成 if (uid!=null) &#123; return true; //返回true，登录成功就需要执行后续的流程 &#125; response.sendRedirect(request.getContextPath()+"/user/login.do"); //重定向到登录界面 return false; //返回false，后面的流程也不用执行了，直接中断 &#125; public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; springmvc中配置拦截器 由于这里只是跳转到用户中心需要验证登录，那么只是匹配了user_center.do 1234567&lt;!-- 配置拦截器,其中可以配置多个拦截器 --&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/user/user_center.do"/&gt; &lt;bean class="cn.tedu.spring.interceptor.LoginInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 多个拦截器的执行顺序 根据在springmvc配置文件中配置的顺序执行，即是在&lt;mvc:interceptors&gt;下配置的拦截器的顺序，如果对同一个路径进行了拦截器，那么先配置的先拦截 拦截器和过滤器的区别(主要的区别) 拦截器是springmvc中，仅仅当使用springmvc才可以使用拦截器，过滤器是Java EE体系中的，无论使用哪种框架都可以使用过滤器 拦截器在DispatcherServlet之后，在处理器之前执行，过滤器在DispatcherServlet之前执行 过滤器会在所有的servlet之前执行(所有的请求都会执行)，而拦截器会在springmvc中DispatcherServlet之后执行，所以过滤器在项目中可以过滤任何请求（只要是配置了对应的路径），而拦截器只会在DispatcherServlet处理的请求的基础之上进行拦截 总结 当多种请求都需要做相同或者极为相似的任务时，可以使用拦截器 开发好拦截器，那么需要在springmvc的配置文件中配置 在&lt;mvc:interceptors&gt;可以有如果若干个&lt;mvc:interceptor&gt;,即是配置若干个拦截器，配置的多个拦截器将会形成拦截器链，如果配置多个拦截器对同一个路径都会拦截，那么会按照配置的节点顺序执行。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc解决中文乱码问题]]></title>
      <url>%2F2018%2F05%2F09%2FSpringmvc%E8%A7%A3%E5%86%B3%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[Springmvc解决中文乱码问题POST 在表单提交的时候，如果遇到中文乱码的情况，springmvc提供了一个CharacterEncodingFilter过滤器，我们只需要在web.xml文件中配置即可 注意 表单的提交方式必须是post 在web.xml中配置CharacterEncodingFilter编码格式要和JSP页面的编码格式一致 解决中文乱码必须使用过滤器(在DispatcherServlet之前执行)，而不能使用springmvc的拦截器，因为过滤器在DispatcherServlet之前，所以设置好编码后，DispatcherServlet和Controller都可以获取到正确的数据，而拦截器运行在DispatcherServlet之后，也即是意味着DispatcherServlet获取的数据已经是乱码，那么在拦截器中调整乱码是没有意义的 在web.xml配置12345678910111213141516 &lt;!-- 配置 CharacterEncodingFilter解决中文乱码问题--&gt;&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 配置编码格式为UTF-8 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; GET 即使配置了中文乱码过滤器CharacterEncodingFilter，但是这个只会针对POST请求才会起作用，如果我们在使用GET请求的时候携带的参数有中文的话，那么服务器接收的时候就会产生中文乱码。 我们在eclipse中修改Tomcat的server.xml文件中的内容参数即可，如下： 我们只需要在&lt;connector connectionTimeout=&quot;20000&quot;......&gt;在这个最后加上URIEncoding=&quot;UTF-8&quot;即可 总结 那么以后创建项目时候的完整的web.xml如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;Springmvc&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 配置前端控制器DispatcherServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置springMVC配置文件的路径，这里如果想要使用默认的可以不用配置 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- classpath表示根路径，这里找的项目根路径下的applicationContext.xml --&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 当tomcat启动的时候就加载，设置启动的优先级 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;!-- 配置分发规则，这个是用来控制所有的请求,只要是请求后缀为.do的都会拦截分发 --&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 配置 CharacterEncodingFilter解决中文乱码问题--&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 配置编码格式为UTF-8 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis之增删改查]]></title>
      <url>%2F2018%2F05%2F04%2FMybatis%E4%B9%8B%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%2F</url>
      <content type="text"><![CDATA[Mybatis的增删改查增加数据 在增加数据的时候，mybatis默认返回的是受影响的行数，因此不需要指定ResultType指定返回类型 在UserMapper.java接口中添加方法 1234/** @param user User对象*/Integer reg(User user); UserMapper.xml文件中添加&lt;insert&gt;节点 #{}中填写的是User对象的属性名称 ​ 1234567891011121314&lt;!-- 节点名称取决于需要执行的操作 --&gt; &lt;!-- 例如增加操作应该使用insert节点 --&gt; &lt;!-- id属性(*)的值是Java接口中的方法名称 --&gt; &lt;!-- parameterType属性的值是参数类型 --&gt; &lt;!-- 节点中间编写SQL语句 --&gt; &lt;insert id="reg" parameterType="cn.tedu.spring.entity.User"&gt; INSERT INTO user ( username, password ) VALUES ( #&#123;username&#125;, #&#123;password&#125; ) &lt;/insert&gt; 测试 1234567891011121314151617181920212223242526@Test public void testReg() &#123; //加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); //获取UserMapper的bean，这个是spring通过扫描mapper.xml文件自动为mybatis自动创建的，首字母小写 UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); //新建User对象 User user = new User(); user.setUsername("Tom1"); user.setPassword("123456"); //调用reg(user)，进行添加，返回的是受影响的行数 Integer affectedRows = userMapper.reg(user); System.out.println( "affectedRows=" + affectedRows); ac.close(); &#125; 在Mybatis中增加数据时获取自增主键的id 首先mybatis在处理增加数据的功能时，只是返回受影响的行数，所以在持久层中并不会返回新增加的 如果需要获取自增主键Id，首先，在XML映射的&lt;insert&gt;节点中需要添加2个属性 useGeneratedKeys ：设置是否返回自增主键，如果为true则返回，默认为false keyProperty ： 配置自增主键在表中对应的字段 ，因为有时候在表中的自增主键的字段可能不是id，因此需要指定 123456789101112131415&lt;!-- 节点名称取决于需要执行的操作 --&gt;&lt;!-- 例如增加操作应该使用insert节点 --&gt;&lt;!-- id属性(*)的值是Java接口中的方法名称 --&gt;&lt;!-- parameterType属性的值是参数类型 useGeneratedKeys: 指定是否返回自增主键，默认为false keyProperty:配置自增主键在表中对应的字段 --&gt;&lt;insert id="reg" parameterType="cn.tedu.spring.entity.User" useGeneratedKeys="true" keyProperty="id"&gt; INSERT INTO user ( username, password ) VALUES ( #&#123;username&#125;, #&#123;password&#125; )&lt;/insert&gt; 此时的mybatis执行insert方法之后，即是调用reg(user)，返回的还是受影响的行数，并不是此时的自增主键id的值。而是在调用这个方法的时候将id封装到指定的方法参数中，即是封装到user中了，因此只有调用者才可以获取id，而持久层无法获取 12345678910111213141516171819202122232425262728@Testpublic void testReg() &#123; //加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); //获取UserMapper的bean，这个是spring通过扫描mapper.xml文件自动为mybatis自动创建的，首字母小写 UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); //新建User对象，此时并没有设置id的值 User user = new User(); user.setUsername("Tom1"); user.setPassword("123456"); //调用reg(user)，进行添加，返回的是受影响的行数，但是此时已经将id封装到参数User对象中了 Integer affectedRows = userMapper.reg(user); System.out.println( "affectedRows=" + affectedRows); //直接获取Uesr对象中的id值，这个是自增主键返回的值 System.out.println("id = "+user.getId()); ac.close();&#125; 删除数据 在删除数据的时候，自动会返回受影响的行数，不需要在delete节点中定义返回类型，只有在查询数据的时候才会定义返回类型 在UserMapper.java中添加一个接口方法 12//根据id删除数据，返回受影响的行数，返回1，如果删除失败返回0Integer deleteUserById(int id); 在UserMapper.xml中配置&lt;delete&gt;节点 1234567&lt;!-- 删除用户数据根据id Integer deleteUserById(int id) parameterType: 指定参数类型，这里也可以不需要指定 --&gt;&lt;delete id="deleteUserById" parameterType="int"&gt; delete from user where id=#&#123;id&#125;&lt;/delete&gt; 删除数据是不可逆的，通常不会真正的删除数据，我们会使用备份，日志等手段来保存数据，在许多软件上看到的删除也许都是修改操作，通常在表中有一个字段is_deleted标记是否删除，如果执行删除，那么就会设置其值为true表示已经删除了，那么此时将不会显示在客户端，让客户以为已经被删除了 Mybaits参数规则 mybatis默认支持一个参数，即是定义的接口方法中只能有一个参数 如果需要支持多个参数，那么需要使用@Param()注解 如果接口方法中的参数类型是基本类型的可以不用parameterType指定类型，如果不是基本类型的，规范要求需要使用parameterType指定类型，但是可以不写 @Param() mybatis默认支持一个参数，即是定义的接口方法中只能有一个参数 在设计java接口方法时，如果需要指定多个参数，那么必须使用@Param() 如果想要支持多个参数，需要使用@Param()来指定参数，比如Integer ChangePassword(@Param(&quot;id&quot;)Integer id,@Param(&quot;newPassword&quot;)String newPassword); 其中@Param(&quot;key&quot;)中的value在配置增删改查的时候是使用#{key}表达式取出的 mybaits在处理过程中，本质上是使用了Map对参数进行了封装的。即是@Param(&quot;&quot;)注解中给出的参数值是Map中的key，调用方法时给出的参数值是Map中的value值，而最终在XML文件中使用#{}获取值，其实是使用Map中的get(key)方法获取的 修改数据 在修改数据的时候，mybatis自动返回受影响的行数，因此我们不需要定义返回类型，默认的返回数据就是受影响的行数 在UserMapper.java接口中定义根据id修改数据的方法 使用@Param()注解来标记多个参数 ​ 1234567/** * 修改密码 * @param id id * @param newPassword 新密码 * @return 受影响的行数 */Integer ChangePassword(@Param("id")Integer id,@Param("newPassword")String newPassword); 在UserMapper.xml中添加&lt;update&gt;节点 其中#{}表达式中的字段为@Param(&quot;value&quot;)中的value ​ 123456&lt;!-- 修改密码 Integer ChangePassword(@Param("id")Integer id,@Param("newPassword")String newPassword); --&gt;&lt;update id="ChangePassword"&gt; update user set password=#&#123;newPassword&#125; where id=#&#123;id&#125;&lt;/update&gt; 测试方法 1234567891011121314151617@Testpublic void testChangePassword() &#123; //加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); //获取UserMapper的bean，这个是spring通过扫描mapper.xml文件自动为mybatis自动创建的，首字母小写 UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); //调用删除的方法 int affectRow=userMapper.ChangePassword(3, "12345895"); System.out.println(affectRow); ac.close();&#125; 案例：修改用户密码用户提供数据 旧密码：oldPassword 新密码：newPassword 步骤 通过id查找用户信息 不可以使用select * from user where id=? and password=?,因为这个是不区分大小写的,我们应该先根据id获取用户信息，再比较password 在UserserviceImpl中完成验证逻辑，如果用户不存在，那么抛出用户不存在的异常，如果存在就验证原密码和是否匹配 用户信息存在，那么就要验证用户输入的oldPassword和用户信息中的原密码是否相同了，如果不相同，抛出密码不匹配的异常，如果相同，那么就可以修改密码 修改密码 实现 我们编写了一个UserService中编写逻辑 1234567891011121314public void ChangePasssword(Integer id, String oldPassword, String newPassword) throws UserNotFoundException, PasswordNotMatchException&#123; User user=this.findUserById(id); //获取用户信息 if (user==null) &#123; //如果用户信息不存在 throw new UserNotFoundException("操作失败，用户信息不存在"); &#125;else &#123; //用户存在，则判断原密码 if (user.getPassword().equals(oldPassword)) &#123;//如果密码匹配 userMapper.ChangePassword(id, newPassword); //修改密码 &#125;else &#123; //原密码不匹配 throw new PasswordNotMatchException("操作失败，原密码不正确"); &#125; &#125;&#125; 那么在Controller中如果要调用这个ChangePasssword将会通过处理异常来判断哪里是出错了，并给出友好的提示 查询数据单条数据的查询 根据id的查询返回的查询结果就是单条数据，比如：select * from user where id=1 单条记录的查询在编写接口方法的时候，只需要返回一个实体类对象即可 123456/** * 根据id查询用户信息 * @param id 用户id * @return 返回User对象 */User findUserById(Integer id); 在UserMapper.xml中配置&lt;select&gt;节点 需要使用resultType指定返回的类型，因为参数是基本类型，因此不需要使用parameterType指定参数类型 123&lt;select id="findUserById" resultType="cn.tedu.spring.entity.User"&gt; select * from user where id=#&#123;id&#125;&lt;/select&gt; 多条记录的查找 有些查找语句返回的是多条记录，那么我们可以使用List&lt;&gt;集合来接收返回的结果，不能直接使用实体类对象来接收 在UserMapper.java中定义接口方法 123456/** * 根据密码查找用户 * @param password 用户密码 * @return 返回的是一个用户的集合 */List&lt;User&gt; findUserByPassword(String password); 在UserMapper.xml中添加&lt;select&gt;节点 这里的resultType虽然返回的是User集合，但是这里的类型还是需要写User类型 由于参数是基本类型，因此不需要使用parameterType 12345678&lt;!-- List&lt;User&gt; findUserByPassword(String password); resultType: 虽然返回的是User集合，但是这里的类型还是需要写User类型 --&gt; &lt;select id="findUserByPassword" resultType="cn.tedu.spring.entity.User"&gt; select * from user where password=#&#123;password&#125; &lt;/select&gt; 测试 1234567891011121314151617@Testpublic void testFindUserByPassword() &#123; //加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); //获取UserMapper的bean，这个是spring通过扫描mapper.xml文件自动为mybatis自动创建的，首字母小写 UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); //获取User集合 List&lt;User&gt; users=userMapper.findUserByPassword("12345895"); System.out.println(users); ac.close();&#125; 总结 xxMapper.xml中配置的节点的id要和xxMapper.java中的方法名相同 mybatis默认支持一个参数，但是我们可以使用@Param(&quot;&quot;)指定多个参数，不过在使用#{}取值的时候要和@Param(&quot;&quot;)中的参数一致 获取自增主键并不是作为方法的返回值，而是在调用方法的时候将自增主键的值设置在方法参数的对象中，那么此时的调用者就可以获取到自增主键的值 增加，修改，删除，方法返回的永远是受影响的行数 在定义实体类属性的时候，尽量使用包装类，比如Integer age 只要是&lt;select&gt;节点，那么必须写返回类型resultType，无论是基本型还是其他类型]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[快速排序算法]]></title>
      <url>%2F2018%2F05%2F04%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[快速排序算法思想(从小到大排序) 快速排序是使用分治法来完成的 基本思想就是先从其中选取一个基准值，然后从数组的两端开始移动查找，在右边移动查找到比基准值小的数据停止移动，此时在左边查找到比基准值大的数据也停止查找，交换这两个查找到的数据，交换完成之后两端继续移动查找，如果左边找到比基准值大的，右边找到比基准值小的数据，再次交换。直到查找到同一个数据上(相遇)或者”擦肩而过”。那么将基准值与相遇的那个值交换，此时就能够保证在基准值左边的都是比基准值小的，在其右边的都是比其大的数，此时一轮查找结束。接下来这个基准值将一个数组分成了两半，左边的是小的，右边是大的，那么我们再分别对左边和右边的数据进行相同的操作，直至不可拆分成新的子序列为止。 快速排序的最坏运行时间是O(n2)，但期望的运行时间是O(nlgn)。 选取数组的第一个数为基准值 我们选取数组的第一个元素作为基准值 此时先从数组的最右边开始查找，如果找到比基准值小的停止查找，再从最左边开始查找，直至找到比基准值大的，那么两边就交换，交换完成之后，最右边再次开始查找，找到就等待左边找到数交换，直至双方相遇。那么把相遇的那个点的数据和基准值交换即可，那么现在在基准值左边的都是小的，在右边的都是大的，此时的基准值将数组分成了两个子序列，再对子序列进行重复的操作，直到不可拆分成子序列。 实现的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static void quickSort(int[] arr,int low,int high)&#123; //递归结束的条件，如果此时的子序列只有一个元素就是low=high，就不用排序了 if(low&gt;=high)&#123; return; &#125; int i=low; //i从最左边开始查找 int j=high; //i从最右边开始查找 int temp = arr[low]; //设置基准值为第一个元素，temp //如果此时的i和j没有相遇，一直进行下去 while (i&lt;j) &#123; //先从右边开始查找，如果没有找到比基准值小的并且没有相遇，那么继续向右查找 while (temp&lt;=arr[j]&amp;&amp;i&lt;j) &#123; j--; //向左移动 &#125; //再从左边开始查找，如果没有找到比基准值大的并且没有相遇，那么继续向左查找 while (temp&gt;=arr[i]&amp;&amp;i&lt;j) &#123; i++; // 向右移动 &#125; //代码能够运行到这里，那么表示已经找到了右面小于基准值的，左面大于基准值的，那么就可以交换数据了 //这里的i&lt;j用于控制在最后相遇的时候还要交换数据，不必交换了，可以省去一次的交换 if (i&lt;j) &#123; //交换数据 int t = arr[j]; arr[j] = arr[i]; arr[i] = t; &#125; &#125; //最后将基准为与i和j相等位置的数字交换 arr[low] = arr[i]; //第一个元素设置为i和j相遇的那个值 arr[i] = temp; //相遇的那个地方设置为基准值 //递归调用左半数组，以基准值为中心切割 quickSort(arr, low, j-1); //递归调用右半数组 quickSort(arr, j+1, high); &#125; 测试 123456int[] array=&#123; 9,7,4,67,45,2,24,33,22,45,88,12,1,0,25&#125;;quickSort(array, 0, array.length-1);for (int i = 0; i &lt; array.length; i++) &#123; System.out.print(array[i]+"\t");&#125; 另外一种方式123456789101112131415161718192021222324252627282930313233343536373839404142public static int partition(int[] array,int low,int high)&#123; int i=low; int j=high; int temp=array[low]; //选取第一个为基准数 //如果此时的还没有相遇，表示没有结束 while(i&lt;j)&#123; //因为基准数是最左面的，因此从最右面开始查找 //当当前的值比基准值大，并且i和j不相等，即是没有相遇 while(temp&lt;array[j]&amp;&amp;i&lt;j)&#123; j--; //向左移动，继续查找 &#125; //从左面开始查找，如果查找到的数据array[i]小于基准值并且i和j没有相遇，那么继续向右移动查找 while(array[i]&lt;temp&amp;&amp;i&lt;j)&#123; i++; //继续向右移动查找 &#125; //代码能够运行到这里，那么表示已经找到了右面小于基准值的，左面大于基准值的，那么就可以交换数据了 if (i&lt;j) &#123; int t = array[j]; array[j] = array[i]; array[i] = t; &#125; &#125; low=i; high=j; return j ; //返回当前的基准值在数组中的索引，用于分割子序列 &#125; public static void quickSort1(int[] arrary,int low,int high)&#123; //停止条件，如果low&gt;high表示相遇，那么停止递归 if(low&gt;high)&#123; return; &#125; int index=partition(arrary, low, high); //获取基准值的位置 quickSort1(arrary, low, index-1); //左边的 quickSort1(arrary,index+1,high); //右边的 &#125; 为什么从最右边开始查找 如果从最左边开始查找，那么有可能某一次查找到了比基准值大的数，停止查找，等待最右边查找到比基准值小的数，但是此时最右边一直在查找，直到和其相遇都没有查找到比基准值小的数据，那么此时的的基准值就需要和这个比它还大的值交换，那么出现的结果就是此时的数组的第一个数是比基准值大的，违背了左边都是比基准值小的，右边都是比基准值大的。 如果从最右边开始查找，即使当某一个时刻查找到了比基准值小的数据，停止查找，等待左边查找到比基准值大的数据。但是左边没有找到，直至相遇，那么此时相遇的这个数任然是比基准值小的，因此和基准值交换是没有问题的 参考文章https://blog.csdn.net/as02446418/article/details/47395867]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[冒泡排序算法]]></title>
      <url>%2F2018%2F05%2F04%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[冒泡排序算法原理 比较相邻的两个数，将值较大的元素放在最前面，由于较小的数字像泡泡一样浮上来，因此取名为冒泡 从后向前比较(小的数上浮) 第一趟：从数组的最后一个元素和倒数第二个元素比较，小的上浮(交换)，之后倒数第二个和倒数第三个数字比较，小的上浮(交换)，直至第二个数字和第一个数字比较，小的上浮,那么经过一趟排序之后，此时的第一个元素就是最小的 第二趟： 经过第一趟之后，第一个就是最小的数字，因此第二趟就不比较第一个和第二个数字了。从最后一个元素和倒数第二个元素比较，小的上浮，直至第三个元素和第二个元素比较，小的上浮，那么此时的第二个就是仅次于第一个的小的元素 第三趟：和前面一样的比较，不过就是不用比较第二个和第三个元素了，因为经过第一趟和第二趟之后，数组中的第一个和第二个元素已经是最小的两个了。经过第三趟比较，第三个元素是仅次于第一个和第二个元素小的元素 第四趟，第五趟……………………………… 从上面我们可以得出，假设数组中有n个元素，那么需要经过n-1趟排序才可以完成全部的比较，最后一趟可以比较出倒数第一个和倒数第二个元素的大小 实现123456789101112131415161718192021/** * 冒泡排序算法之从后向前比较排序 * @param a 需要排序的数组 */public static void bubbleSort(int[] a) &#123; // 外层循环控制排序的趟数，总共需要n-1趟排序 for (int i = 0; i &lt; a.length - 1; i++) &#123; //内层循环控制的是每一趟排序需要比较的次数，j=a.length-1 表示从最后一个元素开始比较，j&gt;i是用于控制每趟之后比较的次数 //比如，经过第一趟之后，那么第一个元素肯定是最小的，因此就不需要将第二个元素和其比较了，第二趟之后第二个元素第一个和第二个元素就是最小的，都需要比较了 for(int j=a.length-1;j&gt;i;j--)&#123; //比较大小，较小的就上浮 if(a[j]&lt;a[j-1])&#123; //交换位置 int temp=a[j]; a[j]=a[j-1]; a[j-1]=temp; &#125; &#125; &#125;&#125; 从前向后比较(大的数字下沉) 第一趟：从第一个元素和第二个元素进行比较，较大的下沉(交换)，然后第二个元素和第三个元素比较，较大的下沉，直至倒数第二个和最后一个比较，大的下沉，那么此时的最后一个数就是最大的 第二趟： 从第一个元素和第二个元素进行比较，较大的下沉，然后第二个和第三个比较，直至倒数第三个和倒数第二个比较，大的下沉，那么此时的倒数第二个数是仅次于最后一个数小的元素。因为经过第一趟之后，最后一个元素已经是最大的，因此不需要比较了 第三趟： 经过第二趟之后，倒数第二个仅次于最后一个元素小的元素了，因此在第三趟中只需要比较到倒数第四个和倒数第三个元素的大小即可，大的下沉，那么此时的倒数第三个元素又是前面所有元素中最大的，因此在第四趟排序就不需要和其比较了。 第四趟…………………………………………………… 从上面我们可以得出结论： 假设有n个元素，那么总共需要进行n-1趟排序 实现1234567891011121314151617181920/** * 冒泡排序算法之从前向后比较排序 * @param a 需要排序的数组 */ public static void bubbleSort(int[] a) &#123; // 外层循环控制排序的趟数，总共需要n-1趟排序 for (int i = 0; i &lt; a.length - 1; i++) &#123; //内层循环控制每趟循环比较的次数，j=0表示从第一个元素开始进行比较，j&lt;a.length-1-i用来控制每趟循环之后不用再比较的元素索引 //比如第一趟循环之后，最后一个元素就是最大的，那么在第二趟循环就不需要和其比较了 for (int j = 0; j &lt; a.length - 1 - i; j++) &#123; //相邻的元素进行比较，如果前面的大于后面的就交换位置 if (a[j] &gt; a[j + 1]) &#123; int temp = a[j]; a[j] = a[j + 1]; a[j + 1] = temp; &#125; &#125; &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSON]]></title>
      <url>%2F2018%2F05%2F04%2FJSON%2F</url>
      <content type="text"><![CDATA[JSON定义 数据组织的一种方式 格式 key-value形式的组织 JSON对象 对象保存在{}中，并且以key-value的形式存储 其中的key必须是加上双引号，不能是单引号 {&quot;key1&quot;,value1,&quot;key2&quot;,value2,..........} 其中的value可以是任意类型的，比如整数，字符串等 {&quot;name&quot;:&quot;Jack&quot;,&quot;age&quot;:22}，这个是简单的对象 对象之中还可以嵌套（对象之中嵌套对象） 12345678910&#123; "name":"Jack", "age":22 "data":&#123; "name":"admin", "age":33, "telephone":"1235488", "password":"12345686" &#125;&#125; JSON数组 使用[]保存数组 独立的数组：[&quot;admin&quot;,&quot;Tom&quot;,&quot;JACk&quot;] 数组中包含对象 12345[ &#123;"name":"Jack","age":22&#125;, &#123;"name":"Tom","age":33&#125;, "date":"2012-12-12"] 在对象中也是可以包含JSON数组 123456789&#123; "employees": [ &#123; "firstName":"John" , "lastName":"Doe" &#125;, &#123; "firstName":"Anna" , "lastName":"Smith" &#125;, &#123; "firstName":"Peter" , "lastName":"Jones" &#125; ], "name":"JACK", "age":22&#125; 访问JSON对象 定义一个JSON对象并且获取 12345678910111213141516var obj = &#123; "name":"Jack", "age":22 "data":&#123; "name":"admin", "age":33, "telephone":"1235488", "password":"12345686" &#125;&#125;;var name=obj.name;var age=obj.age;var dataName=obj.data.name;var dataAge=obj.data.age; 访问JSON数组 定义并且访问 我们定义一个对象，其中包含一个JSON数组employees 123456789101112131415161718function testJSON()&#123; //定义一个对象，其中包含JSON数组employees var obj = &#123; "employees": [ &#123; "firstName":"John" , "lastName":"Doe" &#125;, &#123; "firstName":"Anna" , "lastName":"Smith" &#125;, &#123; "firstName":"Peter" , "lastName":"Jones" &#125; ], "name":"JACK", "age":22 &#125;; //遍历其中的JSON数组employees for(var i=0;i&lt;obj.employees.length;i++)&#123; console.log(obj.employees[i].firstName+"-----"+obj.employees[i].lastName); &#125; &#125; JSON.parse(str) 将字符串形式的JSON对象转换成为JSON对象，即是去掉引号 12345678var p='&#123;"name":"陈加兵","age":22&#125;'; //这个是json字符串//这样取值肯定不行，因为此时的p并不是JSON对象，而是一个字符串形式的JSON对象alert(p.name+"---&gt;"+p.age); var obj = JSON.parse(p); //将字符串形式的json对象转换成真正的JSON对象alert(obj.name + "---&gt;" + obj.age); //此时就可以取出其中的值了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[javascript实现Ajax]]></title>
      <url>%2F2018%2F05%2F04%2Fjavascript%E5%AE%9E%E7%8E%B0Ajax%2F</url>
      <content type="text"><![CDATA[javascript实现Ajax定义 异步的javascript和XML，实现异步提交功能的技术(XMLHttpRequest) 不响应页面的前提下，服务器可以响应其中的一小部分数据到页面上 实现的步骤创建XMLHttpRequest 解决浏览器兼容问题 12345678910111213function getXHR()&#123; var xmlhttp; //判断当前浏览器是否识别XMLHttpRequest if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125; else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject("Microsoft.XMLHTTP"); &#125; return xmlhttp; &#125; 打开1234//第一个参数：请求的方式//第二： 请求的url//第三个：是否为异步，true表示异步，false表示同步xhr.open("GET","Url",true); 发送请求1xhr.send(); 接收服务器响应数据 xhr.onreadystatechange : 表示从发送请求到响应请求的状态变化，根据状态的变化，处理数据5种状态 xhr.readyState ： 获取状态值 0 : 表示xhr对象创建，但是还未初始化 1 ：初始化完成，发送请求 2 ： 接收服务器的响应 3：解析服务器断响应的数据 4： 响应数据 xhr.status : 获取响应状态码 200 ：表示ok if(xhr.status==200) xhr.responseText : 获取文本数据 123456789//用于监听 xhr.onreadystatechange=function()&#123; //如果数据响应成功，并且状态码为200 if (xhr.readyState==4&amp;&amp;xhr.status==200) &#123; //处理数据 var text=xhr.responseText; //获取文本数据 &#125; &#125; 实例 请求本地的file.text文件 123456789101112131415161718192021222324252627function LoadText()&#123; var xhr; //判断当前浏览器是否识别XMLHttpRequest if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xhr=new XMLHttpRequest(); &#125; else &#123;// code for IE6, IE5 xhr=new ActiveXObject("Microsoft.XMLHTTP"); &#125; //用于监听 xhr.onreadystatechange=function()&#123; //如果数据响应成功，并且状态码为200 if (xhr.readyState==4&amp;&amp;xhr.status==200) &#123; //处理数据 var text=xhr.responseText; //获取文本数据 alert(text); &#125; &#125; //异步请求 xhr.open("GET","file.text",true); xhr.send(); //发送请求&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mybatis配置事务管理器]]></title>
      <url>%2F2018%2F05%2F04%2FMybatis%E9%85%8D%E7%BD%AE%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%99%A8%2F</url>
      <content type="text"><![CDATA[Mybatis配置事务管理器 数据库中的事务可以保证在连续执行的多条写操作(增删改)时，这多条操作要么成功，要么全部失败，以保证数据和逻辑的完整及严谨 在使用mybatis时，无需考虑事务如何创建，如何提交等，只需要配置好事务管理器 配置事务管理器(DataSourceTransactionManager) 在spring的配置文件中配置即可 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!-- 加载db.properties --&gt; &lt;util:properties id="dbConfig" location="classpath:db.properties" /&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="url" value="#&#123;dbConfig.url&#125;" /&gt; &lt;property name="driverClassName" value="#&#123;dbConfig.driver&#125;" /&gt; &lt;property name="username" value="#&#123;dbConfig.user&#125;" /&gt; &lt;property name="password" value="#&#123;dbConfig.password&#125;" /&gt; &lt;property name="initialSize" value="#&#123;dbConfig.initSize&#125;" /&gt; &lt;property name="maxActive" value="#&#123;dbConfig.maxSize&#125;" /&gt; &lt;/bean&gt; &lt;!-- 配置MapperScannerConfigurer,自动扫描整个包，并且spring会自动创建UserMapper接口对象--&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 配置接口文件所在的包 --&gt; &lt;property name="basePackage" value="cn.tedu.spring.mapper" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactoryBean --&gt; &lt;bean class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 配置数据源：如何连接数据库等 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 配置XML文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath:mappers/UserMapper.xml" /&gt; &lt;/bean&gt; &lt;!--配置事务管理器，需要用到前面配置的数据源datasource--&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; 开启事务注解 直接在spring配置文件中配置即可 12&lt;!-- 开启事务注解 ,transaction-manager指定的是上面配置的事务管理器的id--&gt;&lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; 在需要使用事务的方法上添加@Transactional注解(或者是Service类上) 如果添加在类上，那么类中的全部方法都会被事务管理器管理 如果添加在方法上，那么只有这个方法会被管理 事务只发生在service的 在方法上添加注解 12345678910111213141516@Transactionalpublic void ChangePasssword(Integer id, String oldPassword, String newPassword) throws UserNotFoundException, PasswordNotMatchException&#123; User user=this.findUserById(id); //获取用户信息 if (user==null) &#123; //如果用户信息不存在 throw new UserNotFoundException("操作失败，用户信息不存在"); &#125;else &#123; //用户存在，则判断原密码 if (user.getPassword().equals(oldPassword)) &#123;//如果密码匹配 User user1=new User(); user1.setPassword(newPassword); userMapper.update(user1); &#125;else &#123; //原密码不匹配 throw new PasswordNotMatchException("操作失败，原密码不正确"); &#125; &#125;&#125; 在service类上添加@Transactional注解，那么类中的整个方法都会被管理 1234567@Service @Transactional //配置事务管理public class UserServiceImpl implements IUserService &#123; @Resource private UserMapper userMapper;&#125; 开启组件扫描 在spring-service.xml中开启组件扫描service即可 12&lt;!-- 组件扫描 --&gt;&lt;context:component-scan base-package="cn.tedu.spring.service" /&gt; 事务如何处理 在spring处理事务时，如果遇到RuntimeException就会自动回滚 完整的spring配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!-- 加载db.properties --&gt; &lt;util:properties id="dbConfig" location="classpath:db.properties" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="url" value="#&#123;dbConfig.url&#125;" /&gt; &lt;property name="driverClassName" value="#&#123;dbConfig.driver&#125;" /&gt; &lt;property name="username" value="#&#123;dbConfig.user&#125;" /&gt; &lt;property name="password" value="#&#123;dbConfig.password&#125;" /&gt; &lt;property name="initialSize" value="#&#123;dbConfig.initSize&#125;" /&gt; &lt;property name="maxActive" value="#&#123;dbConfig.maxSize&#125;" /&gt; &lt;/bean&gt; &lt;!-- 配置MapperScannerConfigurer,自动扫描整个包，并且spring会自动创建UserMapper接口对象--&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 配置接口文件所在的包 --&gt; &lt;property name="basePackage" value="cn.tedu.spring.mapper" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactoryBean --&gt; &lt;bean class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 配置数据源：如何连接数据库等 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 配置XML文件的位置,其中的值是一个数组 --&gt; &lt;property name="mapperLocations"&gt; &lt;array&gt; &lt;value&gt;classpath:mappers/UserMapper.xml&lt;/value&gt; &lt;value&gt;classpath:mappers/DormitoryMapper.xml&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!-- 配置数据源 --&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 开启事务注解 ,transaction-manager指定的是上面配置的事务管理器的id--&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis之动态sql]]></title>
      <url>%2F2018%2F05%2F04%2F%E5%8A%A8%E6%80%81sql%2F</url>
      <content type="text"><![CDATA[动态sqlif子句格式 &lt;if test=&quot;&quot;&gt; test中填写的是判断条件 实例更新密码或者年龄 首先在UserMapper.java中添加抽象方法 因为要一个方法兼具更新密码或者更新年龄的功能，那么我们直接使用一个实体类对象作为方法参数即可 123456/** * 更新数据，比如密码或者年龄 * @param user User对象，其中封装了用户密码或者用户的年龄 * @return 受影响的行数，成功返回1，否则返回0 */Integer update(User user); 在UserMapper.xml中配置&lt;update&gt;节点 只能修改密码或者年龄，不能同时修改，因为如果同时修改拼接而成的sql语句将会少了一个逗号, 1234567891011&lt;update id="update" parameterType="cn.tedu.spring.entity.User"&gt; update user set &lt;if test="password!=null"&gt; password=#&#123;password&#125; &lt;/if&gt; &lt;if test="age!=null"&gt; age=#&#123;age&#125; &lt;/if&gt; where id=#&#123;id&#125;&lt;/update&gt; 测试 修改年龄age，因此只需要在新建的User对象中添加age的值即可，那么此时password的值不能设置 同时要设置id的值 1234567891011121314151617181920@Testpublic void testUpdate() &#123; //加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); //获取UserMapper的bean，这个是spring通过扫描mapper.xml文件自动为mybatis自动创建的，首字母小写 UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); //新建一个User对象 User user=new User(); user.setId(3); //设置id user.setAge(33); //设置年龄 int affectRows=userMapper.update(user); System.out.println(affectRows); ac.close();&#125; 根据用户名或者用户id查询信息 在UserMpper.java中添加接口方法 123456/** * 查找用户信息，根据用户名或者用户id查询 * @param user User对象，其中封装了用户名或者用户id * @return 用户对象 */User findUser(User user); 在UserMapper.xml中配置 12345678910111213141516&lt;!-- User findUser(User user); 不能同时查询，缺少连接符号 and or --&gt; &lt;select id="findUser" parameterType="cn.tedu.spring.entity.User" resultType="cn.tedu.spring.entity.User"&gt; select * from user where &lt;if test="id!=null"&gt; id=#&#123;id&#125; &lt;/if&gt; &lt;if test="username!=null"&gt; username=#&#123;username&#125; &lt;/if&gt; &lt;/select&gt; 测试方法 12345678910111213141516171819@Test public void testFind() &#123; //加载Spring的配置文件 AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); //获取UserMapper的bean，这个是spring通过扫描mapper.xml文件自动为mybatis自动创建的，首字母小写 UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); //新建一个User对象 User user=new User(); user.setId(3); //设置id //根据id查找 System.out.println(userMapper.findUser(user)); ac.close(); &#125; choose【了解】 相当于java中的switch，通常与when搭配使用 123456789101112&lt;select&gt; select * from user where &lt;choose&gt; &lt;when test="password!=null"&gt; password=#&#123;password&#125; &lt;/when&gt; &lt;otherwise&gt; id=#&#123;id&#125; &lt;/otherwise&gt; &lt;/choose&gt;&lt;/select&gt; where元素问题 我们使用动态sql语句构建的语句如下 123456789101112&lt;select id="findUser" parameterType="cn.tedu.spring.entity.User" resultType="cn.tedu.spring.entity.User" &gt; select * from user where &lt;if test="password!=null"&gt; password=#&#123;password&#125; &lt;/if&gt; &lt;if test="username!=null"&gt; and username=#&#123;username&#125; &lt;/if&gt; &lt;/select&gt; 如果传入的参数User对象中只是设置了username的值，那么此时的sql语句将会变成select * from user where and username=#{username},很明显多了一个and 作用 &lt;where&gt;标签主要是用于简化where子句的编写，&lt;where&gt;可以替代sql语句中的where，而且还可以将后面多余的and或者or去掉 格式1234select 字段 from 表名 &lt;where&gt; ..... &lt;/where&gt; 解决问题 我们使用&lt;where&gt;标签解决上面的问题 12345678910111213&lt;select id="findUser" parameterType="cn.tedu.spring.entity.User" resultType="cn.tedu.spring.entity.User" &gt; select * from user &lt;where&gt; &lt;if test="password!=null"&gt; and password=#&#123;password&#125; &lt;/if&gt; &lt;if test="username!=null"&gt; and username=#&#123;username&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 如果此时在User对象中只是设置了一个username的值，那么会去掉前面的and关键字，并且此时的sql语句会变成：select * from user where username=#{username} set元素问题 我们使用动态sql构建一个更新语句，如下： 1234567891011121314151617&lt;update id="update" parameterType="cn.tedu.spring.entity.User"&gt; update user set &lt;if test="password!=null"&gt; password=#&#123;password&#125;, &lt;/if&gt; &lt;if test="age!=null"&gt; age=#&#123;age&#125;, &lt;/if&gt; &lt;if test="username!=null"&gt; username=#&#123;username&#125; &lt;/if&gt; where id=#&#123;id&#125; &lt;/update&gt; 从上面的&lt;update&gt;中可以看出，如果我们在User对象中没有设置password,age,username的值，那么构建出来的sql语句变成了update user set where id=#{id}，很明显是一个错误的语句。 如果在User对象中值设置了password的值，那么这里的sql语句变成了update user set password=#{password}, where id=#{id},很明显，这个sql多了一个逗号 解决 我们可以使用&lt;set&gt;,可以在&lt;set&gt;元素所在位置输出一个set关键字，而且可以去除内容结尾中无关的逗号，有了&lt;set&gt;元素，那么我们可以动态的修改字段 格式1234update table_name &lt;set&gt; ...... &lt;/set&gt; 实例 解决上面的问题 1234567891011121314151617&lt;update id="update" parameterType="cn.tedu.spring.entity.User"&gt; update user &lt;set&gt; &lt;if test="password!=null"&gt; password=#&#123;password&#125;, &lt;/if&gt; &lt;if test="age!=null"&gt; age=#&#123;age&#125;, &lt;/if&gt; &lt;if test="username!=null"&gt; username=#&#123;username&#125; &lt;/if&gt; &lt;/set&gt; where id=#&#123;id&#125; &lt;/update&gt; where 元素作用 使用动态sql可以解决SQL语句中代码复用问题，即2处或者多处高度相似的代码，在使用动态SQL之后，1个方法和1个映射就可以解决 forEach持久层 根据传入的id批量删除商品，用sql语句如下：delete from t_cart where id in (1,2,3,4,4),因此参数应该是一个数组 接口中定义方法 数组必须使用@Param()来指定 123456789/** * 根据id删除购物车中的商品 * @param ids */ void deleteCartById(@Param("ids")Integer[] ids); 配置文件中配置 使用遍历数组中的元素 123456789101112131415161718192021&lt;!-- void deleteCartById(@Param("ids")Integer[] ids); 批量删除 --&gt; &lt;delete id="deleteCartById" parameterType="java.lang.Integer"&gt; delete from t_cart where id in &lt;!-- 遍历数组ids collection:需要遍历的数组 item: 数组中的每一个值 open ： 开始的内容 close: 结束的内容 separator ：每个元素的分割符 最后拼接的就是 (id,id,id,id,id) --&gt; &lt;foreach collection="ids" item="id" open="(" separator="," close=")"&gt; #&#123;id&#125; &lt;/foreach&gt; &lt;/delete&gt; 总结 虽然在动态sql中，有很多标签可以实现对SQL语句的编程，但是，使用动态SQL的原则应该是希望代码复用，而不是编程，更不要用动态sql解决业务方法的问题]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis入门程序]]></title>
      <url>%2F2018%2F05%2F04%2FMyBatis%E5%85%A5%E9%97%A8%E7%A8%8B%E5%BA%8F%2F</url>
      <content type="text"><![CDATA[MyBatis入门程序设计案例实现向tedu_ums数据库的t_users数据表中插入数据。 开发步骤1 创建项目DAY07-MyBatis-Sample，生成web.xml，在web.xml中配置（2项），添加spring-webmvc依赖，复制Spring配置文件，添加Tomcat运行环境； 2 添加新的依赖：mybatis、mybatis-spring、spring-jdbc： 123456789101112131415161718&lt;!-- Spring-JDBC --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 以上依赖中，spring-jdbc的版本需与spring-webmvc保持一致！（同一个项目中，以spring-作为前缀的依赖都应该使用相同版本） 3 创建实现类cn.tedu.spring.entity.User，在该类中声明Integer id、String username、String password属性，及相关方法； 4 设计持久层接口：创建cn.tedu.spring.mapper.UserMapper接口，并在接口中添加抽象方法： 1Integer reg(User user); 注意：增删改操作固定返回受影响的行数，在设计方法时，可以将返回值声明为Integer类型，或使用void表示无返回值也可以。 5 从FTP下载mybatis.zip文件，将解压得到的EmpMapper.xml重命名为UserMapper.xml（推荐这样命名），然后在项目的src\main\resource新建文件夹mappers，将UserMapper.xml复制到mappers文件夹中； 6 编辑UserMapper.xml文件： ​ 123456789101112131415161718192021&lt;!-- MyBatis的接口映射文件，根节点是mapper --&gt;&lt;!-- 接口映射文件是与Java接口文件(interface)相对应的 --&gt;&lt;!-- 根节点的namespace属性用于指定Java接口文件 --&gt;&lt;mapper namespace="cn.tedu.spring.mapper.UserMapper"&gt; &lt;!-- 节点名称取决于需要执行的操作 --&gt; &lt;!-- 例如增加操作应该使用insert节点 --&gt; &lt;!-- id属性(*)的值是Java接口中的方法名称 --&gt; &lt;!-- parameterType属性的值是参数类型 --&gt; &lt;!-- 节点中间编写SQL语句 --&gt; &lt;insert id="reg" parameterType="cn.tedu.spring.entity.User"&gt; INSERT INTO t_users ( username, password ) VALUES ( #&#123;username&#125;, #&#123;password&#125; ) &lt;/insert&gt; &lt;/mapper&gt; 7 添加依赖：mysql-connector-xxxx、dbcp、junit； 8 在src\main\resources下配置db.properties； 9 从此前的项目中复制spring-dao.xml，在该配置文件中，至少配置了：加载db.properties、BasicDataSource 10 在spring-dao.xml中，配置： 12345678910111213141516&lt;!-- 配置MapperScannerConfigurer ，扫描mapper的配置在哪里--&gt;&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 配置接口文件所在的包 --&gt; &lt;property name="basePackage" value="cn.tedu.spring.mapper" /&gt;&lt;/bean&gt;&lt;!-- 配置SqlSessionFactoryBean --&gt;&lt;bean class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 配置数据源：如何连接数据库等 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 配置XML文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath:mappers/UserMapper.xml" /&gt;&lt;/bean&gt; 11 编写测试类，添加测试方法： 123456789101112131415161718192021@Testpublic void testReg() &#123; AbstractApplicationContext ac = new ClassPathXmlApplicationContext( "spring-mvc.xml", "spring-dao.xml"); UserMapper userMapper = ac.getBean( "userMapper", UserMapper.class); User user = new User(); user.setUsername("Tom1"); user.setPassword("123456"); Integer affectedRows = userMapper.reg(user); System.out.println( "affectedRows=" + affectedRows); ac.close();&#125; 总结 在spring中配置mybatis的步骤： 配置扫描xxmapper.xml的MapperScannerConfigurer 配置SqlSessionFactoryBean，需要用到数据库连接池的数据源datasource 完整的依赖文件pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;dependencies&gt; &lt;!-- SpringMVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring-JDBC,要和spring-webmvc的版本一致 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.28&lt;/version&gt; &lt;/dependency&gt; &lt;!-- DBCP --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 完整的db.properties文件 123456url=jdbc:mysql://localhost:3306/mybatis?useUnicode=true&amp;characterEncoding=utf8driver=com.mysql.jdbc.Driveruser=rootpassword=rootinitSize=5maxSize=10 完整的spring-dao.xml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:util="http://www.springframework.org/schema/util" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.2.xsd"&gt; &lt;!-- 加载db.properties --&gt; &lt;util:properties id="dbConfig" location="classpath:db.properties" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="url" value="#&#123;dbConfig.url&#125;" /&gt; &lt;property name="driverClassName" value="#&#123;dbConfig.driver&#125;" /&gt; &lt;property name="username" value="#&#123;dbConfig.user&#125;" /&gt; &lt;property name="password" value="#&#123;dbConfig.password&#125;" /&gt; &lt;property name="initialSize" value="#&#123;dbConfig.initSize&#125;" /&gt; &lt;property name="maxActive" value="#&#123;dbConfig.maxSize&#125;" /&gt; &lt;/bean&gt; &lt;!-- 配置MapperScannerConfigurer,自动扫描整个包，并且spring会自动创建UserMapper接口对象--&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 配置接口文件所在的包 --&gt; &lt;property name="basePackage" value="cn.tedu.spring.mapper" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactoryBean --&gt; &lt;bean class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 配置数据源：如何连接数据库等 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 配置XML文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath:mappers/UserMapper.xml" /&gt; &lt;/bean&gt;&lt;/beans&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc响应Ajax请求(@ResponseBody)]]></title>
      <url>%2F2018%2F05%2F04%2FSpringmvc%E5%93%8D%E5%BA%94Ajax%E8%AF%B7%E6%B1%82-ResponseBody%2F</url>
      <content type="text"><![CDATA[Springmvc响应Ajax请求(@ResponseBody)创建工程 创建maven project 选择war包 自动生成web.xml Target Runtime 选择 Tomcat 添加依赖pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;dependencies&gt; &lt;!-- SpringMVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring-JDBC,要和spring-webmvc的版本一致 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;3.2.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Spring 整合jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.28&lt;/version&gt; &lt;/dependency&gt; &lt;!-- DBCP --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置前端控制器和解决中乱码的过滤器(web.xml) 12345678910111213141516171819202122232425262728293031&lt;!--配置中文乱码的过滤器--&gt;&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;!--配置前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!--加载spring配置文件--&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 配置spring-mvc.xml 要想使用@ResponseBody这个注解来接收Ajax发送过来的请求，必须加上注解驱动&lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; 123456789101112&lt;!-- 组件扫描 --&gt;&lt;context:component-scan base-package="cn.tedu.spring.controller" /&gt;&lt;!-- 配置ViewResolver --&gt;&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/web/" /&gt; &lt;property name="suffix" value=".jsp" /&gt;&lt;/bean&gt;&lt;!-- 配置注解扫描，用于ajax的注解扫描 --&gt;&lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; 编写前端表单 其实并不是使用表单提交的，可以不使用表单 12345&lt;form action="" method="post"&gt; 姓名： &lt;input type="text" name="name" id="name" onblur="checkName()"&gt;&lt;span id="nameSpan"&gt;&lt;/span&gt;&lt;br&gt; 密码:&lt;input type="password" name="pwd" id="pwd"&gt;&lt;span id="pwSpan"&gt;&lt;/span&gt;&lt;br&gt; &lt;input type="submit" value="注册"&gt;&lt;/form&gt; 效果和实现(@RequestBody)用户名文本框失去焦点，异步检测用户 用户名文本框失去焦点发生请求处理方法，检测用户名 请求方式POST 返回的值不再是视图的名称，而是处理请求的结果，即使返回给Ajax请求的数据 12345678@RequestMapping("/checkName.do")@ResponseBody //使用@ResponseBody，表示这个是处理ajax的请求public String checkName(@RequestParam("name")String name)&#123; if ("admin".equals(name)) &#123; return "0"; //表示admin这个用户名不能使用，已经存在 &#125; return "1"; //表示此时的用户名不存在，可以使用&#125; 前端编写Ajax请求（JQUERY） 使用JQuery中的Ajax请求 12345678910111213141516171819202122232425262728&lt;!-- 添加jquery文件 --&gt;&lt;script type="text/javascript" src="&lt;%=request.getContextPath() %&gt;/web/jquery-3.2.1.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt; function checkName()&#123; var name=$("#name").val(); //获取用户名 if(name=="")&#123; alert("用户名不能为空"); return; &#125; var url="&lt;%=request.getContextPath()%&gt;/user/checkName.do"; // 请求的url $.post(url,&#123;'name':name&#125;,function(responseData,status,xhr)&#123; //如果状态码正确 if(status=="success")&#123; if(responseData=="0")&#123; //为节点添加提示内容 $("#nameSpan").text("用户名已经存在，请重新输入"); $("#nameSpan").css("color","red"); //设置颜色为红色 &#125;else&#123; $("#nameSpan").text("用户名不存在，可以使用"); $("#nameSpan").css("color","green"); &#125; &#125; &#125;) &#125;`&lt;/script&gt; 使用javascript发出Ajax请求 GET请求 ：xhr.open(&quot;GET&quot;,&quot;&lt;%=request.getContextPath()%&gt;/user/checkName.do?name=&quot;+name,true); POST请求需要将数据封装到xhr.send(data)中 12345678910111213141516171819202122232425262728//使用POST请求function checkNameFun()&#123; var xhr=getXHR(); //获取XHR //监听状态改变 xhr.onreadystatechange=function()&#123; if(xhr.readyState==4&amp;&amp;xhr.status==200)&#123; var text=xhr.responseText; //获取返回的数据 if(Text=="0")&#123; alert("用户名已经存在，请重新输入"); &#125;else&#123; alert("用户名不存在，可以使用"); &#125; &#125; &#125; var name=$("#name").val(); //获取name文本框中的值 if(name=="")&#123; alert("用户名不能为空"); return; &#125; //编写请求 xhr.open("POST","&lt;%=request.getContextPath()%&gt;/user/checkName.do",true); //在open之后，send之前添加请求头信息 xhr.setRequestHeader("content-type","application/x-www-form-urlencoded"); //在send之中添加请求信息 xhr.send("name="+name); //发送请求&#125; @ResponseBody 配置注解驱动支持该注解的使用，直接在spring-mvc.xml中配置即可&lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; 添加jackson的依赖，处理json数据 我们需要三个jar包，我们只需要添加jackson-databind即可，就会自动的导入其他的两个 ​ 123456&lt;!-- 添加jackson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; 用于响应Ajax请求 使用@ResponseBody标记的Controller方法的返回值，不再是返回的视图名称,而是返回的给Ajax的请求结果，可以是String，List,Map,单个对象等 返回单个值 返回的单个值，比如String，int，boolean 直接使用上面的例子即可 12345678@RequestMapping("/checkName.do")@ResponseBody //使用@ResponseBody，表示这个是处理ajax的请求public String checkName(@RequestParam("name")String name)&#123; if ("admin".equals(name)) &#123; return "0"; //表示admin这个用户名不能使用，已经存在 &#125; return "1"; //表示此时的用户名不存在，可以使用&#125; 返回Map 这里我们返回的是一个Map&lt;String,Object&gt; 使用了JackSon，spring会将Map自动转换成JSON对象，那么我们在JSP中就可以用JSON来获取数据即可 编写Controller方法，使用@ResponseBody注解 12345678910111213141516171819@RequestMapping("/testMap.do")@ResponseBody //使用注解public Map&lt;String,Object&gt; testMap(@RequestParam("name")String name,@RequestParam("age")Integer age)&#123; System.out.println(name+"---"+age); //接收请求参数 Map&lt;String, Object&gt; map=new HashMap&lt;String, Object&gt;(); //新建一个Map //新建User对象 User user1=new User(); user1.setName("JACK"); user1.setAge(22); User user2=new User(); user2.setAge(33); user2.setName("Tom"); //将上面的User对象添加到map中 map.put("u1",user1); map.put("u2",user2); return map;&#125; 在jsp页面中添加一个方法，用于发出Ajax请求 使用返回的数据(JSON对象)，直接使用data.key的形式即可取出Map中的值 12345678910111213//Ajax请求testMap.dofunction testMap()&#123; var url="&lt;%=request.getContextPath()%&gt;/user/testMap.do"; // 请求的url var d=&#123;'name':'陈加兵','age':22&#125;; //需要发出请求的参数 $.post(url,d,function(responseData,status,xhr)&#123; //如果状态码正确 if(status=="success")&#123; var user1=responseData.u1; //取出key为u1的值，是一个user对象 var user2=responseData.u2; //取出key为u2的值，是一个user对象 alert("u1 = "+user1.name+"---"+user1.age); //打印出u1中的name，age的值 &#125; &#125;)&#125; 返回List 这里的返回值是List&lt;Object&gt; JackSon会自动将List转换成JSON数组，在JSP页面就可以使用JSON的方式来获取数据 比如：[{&quot;name&quot;:&quot;JACK&quot;,&quot;age&quot;:22},{&quot;name&quot;:&quot;Tom&quot;,&quot;age&quot;:33},10]，这个是一个JSON数组的形式，因此我们在js中需要遍历这个数组 Controller中方法如下： 12345678910111213141516171819@RequestMapping("/testList.do")@ResponseBodypublic List&lt;User&gt; testList(@RequestParam("name") String name, @RequestParam("age") Integer age) &#123; System.out.println(name + "---" + age); // 接收请求参数 List&lt;User&gt; list = new ArrayList&lt;User&gt;(); // 新建User对象 User user1 = new User(); user1.setName("JACK"); user1.setAge(22); User user2 = new User(); user2.setAge(33); user2.setName("Tom"); //将数据添加到其中 list.add(user1); list.add(user2); return list;&#125; jsp中使用发出Ajax请求 此时返回的是数组，因此需要循环遍历 123456789101112131415//Ajax请求testList.dofunction testList()&#123; var url="&lt;%=request.getContextPath()%&gt;/user/testList.do"; // 请求的url var d=&#123;'name':'陈加兵','age':22&#125;; //需要发出请求的参数 $.post(url,d,function(responseData,status,xhr)&#123; //如果状态码正确 if(status=="success")&#123; //此时返回的是一个数组，因此我们需要循环遍历这个数组，但是其中的元素是一个User对象，因此可以使用key-value的形式取出其中的值 for(var i=0;i&lt;responseData.length;i++)&#123; //将数据输出到控制台 console.log(responseData[i].name+"-----&gt;" + responseData[i].age); &#125; &#125; &#125;)&#125; 返回单个对象 返回的是一个对象，比如一个User对象，JackSon会将其转换成为JSON对象返回给浏览器 返回的是对象，那么我们在js中可以直接使用key-value的形式取出其中的值 Controller中的方法 12345678910@RequestMapping("/testObject.do")@ResponseBodypublic User testObject(@RequestParam("name") String name, @RequestParam("age") Integer age) &#123; System.out.println(name + "---" + age); // 接收请求参数 User user=new User(); user.setName("JACK"); user.setAge(22); return user;&#125; 发出Ajax请求，并且接收数据 直接使用取值即可 1234567891011//Ajax请求testObject.dofunction testObject()&#123; var url="&lt;%=request.getContextPath()%&gt;/user/testObject.do"; // 请求的url var d=&#123;'name':'陈加兵','age':22&#125;; //需要发出请求的参数 $.post(url,d,function(responseData,status,xhr)&#123; //如果状态码正确 if(status=="success")&#123; console.log(responseData.name+"----"+responseData.age); &#125; &#125;)&#125; 练习省市二级菜单联动 前端使用下拉菜单&lt;select&gt;实现 加载页面完成之后，发送一个异步请求，请求所有的省份,在省的下拉菜单中显示出来 当用户选择了某个省之后，那么发送一个异步请求，获取当前省的所有市的信息，并且显示在市的下拉菜单中 在省的下拉菜单中需要使用onchange监听选项的改变，只要选项改变了就要发出异步请求，返回对应城市的信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869省：&lt;select name="province" id="province" onchange="getCity()"&gt; &lt;option value="-1"&gt;请选择省&lt;/option&gt;&lt;/select&gt;市：&lt;select name="city" id="city"&gt; &lt;option value="-1"&gt;请选择市&lt;/option&gt;&lt;/select&gt;&lt;!--加载jquery--&gt;&lt;script type="text/javascript" src="&lt;%=request.getContextPath() %&gt;/web/jquery-3.2.1.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt; //只要页面加载完成之后就会执行其中的逻辑 $(function()&#123; getProvince(); //页面加载完成就调用这个方法发出异步请求 &#125;); //获取省份的方法 function getProvince()&#123; var url="&lt;%=request.getContextPath()%&gt;/menu/getProvince.do"; //异步请求的url var d=&#123;&#125;; //没有数据提交 $.post(url,d,function(data,status,xhr)&#123; if(status=="success")&#123; //循环遍历返回的JSON数组 for(var i=0;i&lt;data.length;i++)&#123; //创建option，用于插入节点 var option="&lt;option value=" + data[i].code + "&gt;"+data[i].name+"&lt;/option&gt;"; //将option插入到下拉列表中 $("#province").append(option); &#125; &#125; &#125;); &#125; //根据选择的省份获取市 function getCity()&#123; var province=$("#province").val(); //获取下拉菜单的值，这里返回的是省份的编号 var url="&lt;%=request.getContextPath()%&gt;/menu/getCity.do"; //异步请求的url var d=&#123;"province":province&#125;; //将省份的编号传入 //每次都要清空之前的城市 $("#city").html("&lt;option value='-1'&gt;请选择市&lt;/option&gt;"); //如果用户点击了请选择省，那么返回的值就是-1，此时不需要发出异步请求 if(province==-1)&#123; return; &#125; //发出异步请求 $.post(url,d,function(data,status,xhr)&#123; if(status=="success")&#123; //如果返回的是一个空的，直接返回即可，不需要后续的操作 if(data.lengt==0)&#123; return; &#125; //循环遍历返回的JSON数组 for(var i=0;i&lt;data.length;i++)&#123; //创建option，用于插入节点 var option="&lt;option value=" + data[i].code + "&gt;"+data[i].name+"&lt;/option&gt;"; //将option插入到下拉列表中 $("#city").append(option); &#125; &#125; &#125;); &#125;&lt;/script&gt; 在Controller编写方法 展示页面的方法(showMenu.do) 返回省份信息的方法 返回城市信息方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//显示页面@RequestMapping("/showMenu.do")public String showMenu() &#123; return "menu";&#125;//异步请求返回省份的信息@RequestMapping("/getProvince.do")@ResponseBodypublic List&lt;Province&gt; getProvince()&#123; Province p1=new Province(); p1.setName("江苏"); p1.setCode(1001); Province p2=new Province(); p2.setName("山东"); p2.setCode(1002); List&lt;Province&gt; provinces=new ArrayList&lt;Province&gt;(); provinces.add(p1); provinces.add(p2); return provinces;&#125;//异步获取城市信息的方法，这里没有操作数据库，仅仅是模拟，因此只要返回数据即可@RequestMapping("/getCity.do")@ResponseBodypublic List&lt;City&gt; getCity(@RequestParam("province") Integer code)&#123; System.out.println(code); List&lt;City&gt; cities=new ArrayList&lt;City&gt;(); /** * 如果这里涉及到数据库操作 * 1. 调用service的方法查询，service调用dao的方法查询 * 2. dao中的查询： 根据code查询出对应的城市即可，当然是联表查询 * 3. select c.name,c.code from city c join province p on c.provice_id=p.id; * 4. mybatis调用第三步的查询语句，直接返回的就是List&lt;City&gt;集合 */ //这里省略if的判断，主要是看效果 City c1=new City(); c1.setName("南京"); c1.setCode(123); City c2=new City(); c2.setName("淮安"); c2.setCode(1223); cities.add(c1); cities.add(c2); return cities; //返回集合&#125; 总结 springmvc会通过jackson将返回给ajax请求的对象自动封装成JSON对象，那么在JSP页面我们就可以使用JSON的读取方式获取返回的数据即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring配置DBCP连接池]]></title>
      <url>%2F2018%2F05%2F04%2FSpring%E9%85%8D%E7%BD%AEDBCP%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[Spring配置DBCP连接池建立数据库配置文件jdbc.properties 在resource文件下新建一个jdbc.properties文件，内容如下 在每一个键值对的后面不可以有空格，将光标移动到后面，如果紧贴着即可 ​ 123456url=jdbc:mysql://localhost:3306/tedu_ums?useUnicode=true&amp;characterEncoding=utf8driver=com.mysql.jdbc.Driveruser=rootpassword=rootinitSize=5 maxSize=10 在spring配置文件中配置DBCP数据源 直接使用spring的表达式获取文件中的值即可 ​ 12345678910111213141516171819202122&lt;!-- 加载db.properties --&gt; &lt;util:properties id="dbConfig" location="classpath:jdbc.properties" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="url" value="#&#123;dbConfig.url&#125;" /&gt; &lt;property name="driverClassName" value="#&#123;dbConfig.driver&#125;" /&gt; &lt;property name="username" value="#&#123;dbConfig.user&#125;" /&gt; &lt;property name="password" value="#&#123;dbConfig.password&#125;" /&gt; &lt;!--初始化链接数量--&gt; &lt;property name="initialSize" value="#&#123;dbConfig.initSize&#125;" /&gt; &lt;!--最大链接数量--&gt; &lt;property name="maxActive" value="#&#123;dbConfig.maxSize&#125;" /&gt; &lt;/bean&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc处理异常]]></title>
      <url>%2F2018%2F05%2F04%2FSpringmvc%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%2F</url>
      <content type="text"><![CDATA[Spring MVC处理异常关于异常 异常的体系结构： 12345678910111213Throwable Error OutOfMemoryError（OOM） Exception RuntimeException NullPointerException：某个为null的对象调用了属性或方法 ClassCastException：强制转换为不匹配的数据类型 ClassNotFoundException：尝试加载的类不存在 IndexOutOfBoundsException：使用List集合时使用了越界的索引 ArrayIndexOutOfBoundsException：使用Array时使用了越界的索引 SQLException：数据库相关异常 IOException：输入输出（读写）异常 FileNotFoundException：文件找不到 在Spring MVC中处理异常 在Spring MVC中，提供了一种统一处理某种异常的机制，例如通过配置，可以对整个项目中的NullPointerException进行处理，那么，无论是项目的哪个环节出现该异常，都会自动按照配置的方式进行处理，而不用每个方法中逐一编写相关代码。 准备演示案例 创建项目DAY07-SpringMVC-Exception，设计请求路径： http://SERVER:PORT/PROJECT/ex1.do http://SERVER:PORT/PROJECT/ex2.do 以上3个请求将分别由ex1.jsp、ex2.jsp页面显示。 使用SimpleMappingExceptionResolver 在Spring MVC中，有SimpleMappingExceptionResolver类，用于配置异常与View组件的映射关系，如果确定某种异常出现后都会显示某个View组件，则在Spring的配置文件中： 12345678910&lt;bean class="xx.xx.SimpleMappingExceptionResolver"&gt; &lt;property name="exceptionMappings"&gt; &lt;props&gt; &lt;prop key="异常类的全名"&gt;View组件名&lt;/prop&gt; &lt;prop key="异常类的全名"&gt;View组件名&lt;/prop&gt; &lt;prop key="异常类的全名"&gt;View组件名&lt;/prop&gt; &lt;props&gt; &lt;/property&gt;&lt;/bean&gt; 经过以上配置后，整个项目运行到任何位置，一旦出现以上配置过的异常，都会转发到匹配的View组件，在项目的各个方法中，不必再处理已经配置过的异常！ 这种做法的不足在于：只要是同一种异常，都是转发到同一个View组件，无法根据实际运行状态进行更加细化的处理，例如无法提示是哪个值错误或者某些原因导致的异常。 使用@ExceptionHandler注意：使用SimpleMappingExceptionResolver处理异常时，不可以使用@ExceptionHandler！ 当需要统一处理异常时，可以在控制器类中自定义方法（方法名称自定义），并在方法上方添加@ExceptionHandler，与处理请求的方法类似，可以按需添加方法的参数，需要注意的，必须有Exception参数： 1234567891011121314@ExceptionHandlerpublic String handleException( HttpServletRequest request, Exception ex) &#123; System.out.println(ex.getClass()); if (ex instanceof NullPointerException) &#123; return "error1"; &#125; else if (ex instanceof ArrayIndexOutOfBoundsException) &#123; return "error2"; &#125; else &#123; return "error3"; &#125;&#125; 这种做法，是作用于当前控制器类内部的所有请求的处理！对其它控制器类中的异常是没有影响的！ Spring MVC小结 解决MVC中V与C的关系的，即如何接收请求并响应； 在Spring的配置文件中，最主要的配置是组件扫描和ViewResolver； 重点掌握@RequestMapping注解，还有@RequestParam注解； 掌握在处理请求时，如何获取请求参数（2种）和封装转发数据（ModelMap）； 理解转发和重定向； 学会使用Interceptor； 学会处理异常。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc之向JSP页面提供数据(request，session)]]></title>
      <url>%2F2018%2F04%2F26%2FSpringmvc%E4%B9%8B%E5%90%91JSP%E9%A1%B5%E9%9D%A2%E6%8F%90%E4%BE%9B%E6%95%B0%E6%8D%AE-request%EF%BC%8Csession%2F</url>
      <content type="text"><![CDATA[Springmvc之向JSP页面提供数据(request，session)准备 Springmvc默认就是转发,因此可以在request域中共享数据 表单提交，注册 123456&lt;form action="&lt;%=request.getContextPath()%&gt;/user/login.do" method="post"&gt; username:&lt;input type="text" name="username"&gt; &lt;br&gt; password:&lt;input type="text" name="password"&gt; &lt;br&gt; age:&lt;input type="text" name="age"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; User类 12345678910111213141516171819202122232425262728public class User &#123; private String username; private String password; int age; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override public String toString() &#123; return "User [username=" + username + ", password=" + password + "]"; &#125;&#125; 使用HttpServletRequest转发 直接使用HttpServletRequest中的setAttribute(key,value)即可添加属性值request域中，那么在JSP页面即可使用EL表达式获取 12345678910/** * @param user 接收请求参数 * @param request 添加属性值request域中 */@RequestMapping(value = "/login.do")public String login(User user,HttpServletRequest request,HttpServletResponse response) &#123; System.out.println(user); request.setAttribute("user", user); return "error";&#125; 【不常用】使用ModelAndView转发 ModelAndView中本身就是用来存储数据和视图的，因此我们可以使用ModelAndView来传值 ModelAndView会利用HttpServletRequest中的setAttribute(key,value)将数据存储在requst域中 Model表示的就是转发的数据，可以通过ModelAndView(String viewName,Map&lt;String,?&gt; map)构造方法封装Model，其中Model的类型就是Map&lt;String,?&gt; 12345678910@RequestMapping(value = "/login.do")public ModelAndView login(User user) &#123; System.out.println(user); //创建一个Map，存储数据 Map&lt;String, User&gt; map=new HashMap&lt;String, User&gt;(); //将获取的user对象存储进去 map.put("user", user); //返回一个ModelAndView对象，第一个参数是视图，第二个是Map存储数据 return new ModelAndView("error", map);&#125; 【推荐使用】使用ModelMap转发 利用HttpServletRequest中的setAtttibute()添加数据到request域中 直接在处理请求的方法中，添加ModelMap类型的参数，当需要转发数据时，调用它的addAttribute方法封装数据，如果需要封装多条，多次调用即可 1234567@RequestMapping(value = "/login.do")public String login(User user,ModelMap map) &#123; System.out.println(user); //将数据存储在ModelMap中 map.addAttribute("user", user); return "error";&#125; 拓展 从源代码可以看出，ModelMap实际上是实现了Map接口，因此我们也可以直接使用Map传值 直接在方法的参数中声明即可，spring会自动注入 1234567@RequestMapping(value = "/login.do")public String login(User user,Map&lt;String, Object&gt; map) &#123; System.out.println(user); //将数据存储在ModelMap中 map.put("user", user); return "error";&#125; Session 浏览器关闭或者在session的指定时间内没有操作，那么session会自动关闭 通常会把访问的用户的唯一标识（用户的ID或用户名，邮箱等）和使用频率使用较高的数据（用户名，昵称，头像）存储在Session中。 使用HttpSession123456@RequestMapping(value = "/login.do")public String login(User user,HttpSession session) &#123; //将id存储在session中 session.setAttribute("uid", "9527"); return "error";&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc之接受请求参数]]></title>
      <url>%2F2018%2F04%2F26%2FSpringmvc%E4%B9%8B%E6%8E%A5%E5%8F%97%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%2F</url>
      <content type="text"><![CDATA[Springmvc之接受请求参数准备工作 新建一个表单提交 请求地址： http://localhost:8080/ProjectName/user/login.do 123456&lt;form action="&lt;%=request.getContextPath()%&gt;/user/login.do" method="post"&gt; username:&lt;input type="text" name="username"&gt; &lt;br&gt; password:&lt;input type="text" name="password"&gt; &lt;br&gt; age:&lt;input type="text" name="age"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; 【不推荐】HttpServletRequest 直接使用HttpServeletRequest作为方法参数，spring会自动为其注入 需要手动转换参数的类型 12345678@RequestMapping(value="/login.do")public String login(HttpServletRequest request,HttpServletResponse response)&#123; String username=request.getParameter("username"); String password=request.getParameter("password"); int age=Integer.parseInt(request.getParameter("age")); //转换类型 System.out.println(username+"---&gt;"+password); return "success";&#125; 直接在方法中声明对应的参数(name的属性必须和方法参数一致) 表单中的name属性要和方法中的参数一致 涉及到类型转换，直接在方法中申明不同类型的参数即可 优点： 方便，并且可以使Springmvc自动处理数据类型 12345@RequestMapping(value = "/login.do")public String login(String username,String password,Integer age) &#123; System.out.println(username + "---&gt;" + password+"-----&gt;"+age); return "success";&#125; 【推荐】@RequestParam 使用该注解可以获取请求参数，方法中的参数可以与表单中的name属性不一致 使用@RequestParam这个获取的值必须包含在请求参数中，否则报错，除非设置required属性为false 1234567891011/** * 使用@RequestParam获取请求参数 * @RequestParam()中的value属性为form表单中对应的name属性 * 自动转换数据类型，只需要定义方法参数为所需的数据类型即可，spring会为我们自动转换 */@RequestMapping(value = "/login.do")public String login(@RequestParam(value = "username") String name, @RequestParam("password") String pwd,@RequestParam("age") Integer age) &#123; System.out.println(name + "---&gt;" + pwd+"-----&gt;"+age); return "success";&#125; 属性 value 指定请求中对应的属性名称，这个就像表单中定义的name属性 required指定是否这个参数必须包含在请求地址中，默认是true，即是如果不包含这个参数那么就会报错。 defaultValue 指定默认的值，如果设置了required=false，并且没有设置这个值，那么默认的是null，但是也是可以使用这个属性来设置参数默认的值。当然对于设置了int类型的参数，那么并没有指定其值，那么将会报错，因为int类型没有null，只有Integer类型的才有，因此需要设置成Integer 123456789101112/* * 这里的获取请求参数中的username，age的值 * 其中username的这个注解默认的是required=true，因此这个是不可以没有的 * age的这个注解设置了required=false，表示可以没有这个参数，但是如果没有这个参数，那么默认的是null，但是int类型的没有null，因此也会是报错的，有两种解决方式： * 1) 通过defalutValue设置其默认的值 * 2) 如果我们就想要设其为null，可以使用封装类Integer类型即可 */@RequestMapping(value = "/testRequestParams")public String testRequestParams(@RequestParam(value="username") String username,@RequestParam(value="age",required=false) int age) &#123; System.out.println("username,age "+ username+" , "+age); return SUCCESS;&#125; 【推荐】使用自定义数据类型(JavaBean) 如果传过来的请求参数很多，那么我们使用上面的方法获取请求参数，需要申明很多的方法参数。但是我们可以将传递过来的请求参数封装成一个JavaBean，那么我们直接传入一个JavaBean对象即可接收全部的请求参数。 声明一个User类，其中必须为每一个属性添加 set方法，并且其中的变量名要和表单中的name属性一致 12345678910111213141516171819202122232425262728public class User &#123; private String username; private String password; private int age; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override public String toString() &#123; return "User [username=" + username + ", password=" + password + "]"; &#125;&#125; 那么我们此时的UserController中的login方法如下： 12345@RequestMapping(value = "/login.do") public String login(User user) &#123; System.out.println(user); return "success"; &#125; 总结 以上的所有方法并不冲突，可以混合使用 12345678/** * 混合使用案例*/@RequestMapping(value = "/login.do")public String login(User user,@RequestParam("gender")String gender) &#123; System.out.println(user); return "success";&#125; 不建议使用HttpServletRequest方法获取，另外的方法都是非常好用的方法，根据实际情况进行选取即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc之RequestMapping]]></title>
      <url>%2F2018%2F04%2F26%2FSpringmvc%E4%B9%8BRequestMapping%2F</url>
      <content type="text"><![CDATA[Springmvc之RequestMappingRequestMapping 标记客户的请求与哪一个类和方法对应 使用@RequestMapping同时对类和方法进行注解，相当于最终将这两处的注解路径拼接起来，比如类上使用@RequestMapping(&quot;/user&quot;),在方法上使用@RequestMapping(&quot;/login.do&quot;),那么拼接时访问的路径为http://localhost:8080/ProjectName/user/login.do 属性 value ： 默认的属性，表示映射的地址，如果只有这一个属性，那么默认可以不写value，比如@RequestMapping(&quot;/login.do&quot;)和@RequestMapping(value=&quot;/login.do&quot;)是一样的效果 method：指定是请求的方式，我们知道请求的方式有post,get,put,delete。一般常用的是post,get，一旦我们在其中定义这个method属性，那么如果请求的方式不是这个method指定的属性值，那么就不会访问到这个方法。 其实只要不指定这个method属性，无论是post还是get方式的都会执行这个方法，只有当其设置了method属性才会做限定 比如我们使用了 @RequestMapping(value=&quot;login.do&quot;,method=RequestMethod.GET)，但是我们使用表单提交的是&lt;form action=&quot;&lt;%=request.getContextPath%&gt;/project/user/login.do&quot; method=&quot;post&quot;&gt;&lt;/form&gt;,那么这个表单的请求就不会对应上面的注解的方法，因为表单的提交方式是post，但是RequestMapping定义的是method是get方式,会响应405错误 params ： params是用来指定请求中包含的参数，其中的值是一个字符串数组的形式，并且这个还支持简答的表达式 param: 表示请求参数中必须包含param这个参数至于为其赋予的值可以随便，但是必须包含这个字段 param!=value： 表示请求参数中必须包含param这个参数，但是为其赋予的值不能等于value这个值，其他的什么值都是可以的 !param ：表示请求参数中一定不能包含这个param字段，如果包含这个字段，那么将不能映射到这个地址 {“param1”，“param2”} ： 指定请求参数中必须包含着两个请求参数，至于为其赋什么值随便 12345678/* * 请求的参数中必须不能包含name属性，age必须不能等于12，必须包含sex，address必须等于xuzhou */@RequestMapping(value="/testParams",params=&#123;"!name","age!=12","sex","address=xuzhou"&#125;) public String testParams()&#123; System.out.println("testParams"); return SUCCESS; &#125; headers : headers和params同样是支持简单的表达式，同样是一个字符串数组，这里一样的是适用于上面的表达式 123456789/* * 请求的参数中必须不能包含name属性，age必须不能等于12，必须包含sex，address必须等于xuzhou * 请求头中的Accept-Language不能等于zh-CN,zh;q=0.8 */@RequestMapping(value="/testParams",params=&#123;"!name","age!=12","sex","address=xuzhou"&#125;,headers=&#123;"Accept-Language!=zh-CN,zh;q=0.8"&#125;)public String testParams()&#123; System.out.println("testParams"); return SUCCESS;&#125; RequestMapping支持Ant风格的通配符 在学习struts2中的时候也是支持通配符调用的，比如_等。现在springmvc中也是支持通配符风格的，但是只支持Ant风格的，如下： ？： 表示一个任意的字符 springmvc/testAnt?可以使用springmvc/testAnta`这个地址来访问，其中最后一个a可以替换成任意的字符 * : 表示支持多个任意的字符 /spingmvc/testAnt/* 可以使用springmvc/testAnt/aaaaa这个地址来访问，其中最后一层的路径可以使用任意的字符串替换 ** : 匹配多层路径 /springmvc/testAnt/** 可以使用/springmvc/testAnt/user/test这个来访问，当然也可以是多层的路径 123456789/* * 这里的* 表示支持任意多个字符，因此这里可以使用:springmvc/testAnt/user这个地址来访问，其中最后一层use可以写成任意的字符串即可 * */ @RequestMapping(value="/testAnt/*",method=RequestMethod.GET) public String testAnt()&#123; System.out.println("testAnt"); return SUCCESS; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Springmvc入门]]></title>
      <url>%2F2018%2F04%2F24%2FSpringmvc%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[Springmvc入门作用 解决V(View)和C(Controller)的交互问题,即解决了Controller如果接收了用户的请求，并将结果响应给用户的问题 springmvc约定了一套处理用户请求的流程 Springmvc的核心组件 DispatcherServlet ：前端控制器，请求入口 HandlerMapping ： 控制器，其中存放着处理请求的组件，请求派发 Controller ：控制器，处理请求 ModelAndView ：模型，封装业务处理结果和视图 ViewResolver : 视图解析器，显示视图 springmvc处理流程 用户发出请求，请求交给前端控制器(DispatcherServlet)处理 DispatcherServlet通过HandlerMapping找到Controller中相对应的组件处理请求 执行Controller组件约定方法处理请求，在约定方法调用模型组件(Service,Dao)完成业务逻辑,约定方法返回一个ModelAndView对象，封装了处理结果和视图名称信息 控制器接收了ModelAndView之后，调用视图解析器(ViewResolver)组件，定位到指定的View(JSP)并且传递处理结果，生成响应界面结果 创建一个Springmvc项目 创建maven项目 导入web.xml 配置tomact项目运行环境(项目右击 --&gt; properties - &gt; Target Runtimes) 配置pom.xml依赖 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.12.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加springmvc的配置文件在resource目录下(applicationContext.xml) 开启组件扫描 配置视图解析器，用来定义跳转的视图，在视图解析中，最后的jsp文件在 perfix + controller中返回的字符串 + suffix 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:util="http://www.springframework.org/schema/util" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.2.xsd"&gt; &lt;!-- 开启组件扫描 --&gt; &lt;context:component-scan base-package="cn.tedu.springmvc"&gt;&lt;/context:component-scan&gt; &lt;!-- 配置视图解析器: prefix:表示前缀 suffix：表示后缀 如果controller中返回的是success这个字符串，那么对应的视图是/WEB-INF/JSP/success.jsp这个视图 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/JSP/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt;&lt;/beans&gt; 配置前端控制器(DispatcherServlet),在web.xml中配置 12345678910111213141516171819202122&lt;!-- 配置前端控制器DispatcherServlet --&gt;&lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置springMVC配置文件的路径，这里如果想要使用默认的可以不用配置 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- classpath表示根路径，这里找的项目根路径下的applicationContext.xml --&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 当tomcat启动的时候就加载，设置启动的优先级 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;!-- 配置分发规则，这个是用来控制所有的请求,只要是请求后缀为.do的都会拦截分发--&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 在cn.tedu.springmvc.controller包中创建一个UserController类 12345678910@Controller@RequestMapping("/user")public class UserController &#123; @RequestMapping("/hello.do") public String testHello()&#123; System.out.println("Hello World"); return "success"; //返回视图，这里通过视图解析器之后对应的是 /WEB-INF/JSP/success.jsp &#125;&#125; 在 WEB-INF/JSP/中创建一个success.jsp页面，添加一个&lt;h1&gt;Hello World&lt;/h1&gt; 此时启动项目，打开浏览器输入http://localhost:8080/Springmvc_01/user/hello.do，那么就会看见成功跳转到success.jsp页面，显示文字]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring注解的使用和组件扫描]]></title>
      <url>%2F2018%2F04%2F24%2FSpring%E6%B3%A8%E8%A7%A3%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E7%BB%84%E4%BB%B6%E6%89%AB%E6%8F%8F%2F</url>
      <content type="text"><![CDATA[Spring注解的使用和组件扫描【非常重要】 组件扫描(Component-Scan) 通过配置组件扫描，可以使得spring自动扫描package，而不必在spring的配置文件中逐一声明各个&lt;bean&gt; 在配置组件扫描时，指定的包是“根包”，即例如指定了cn.tedu.spring,spring不只会扫描这个包，还会扫描它的各个层级子包，例如：cn.tedu.spring.dao 直接在spring的配置文件中开启组件扫描即可 &lt;context:component-scan base-package=&quot;cn.tedu.spring&quot;&gt;&lt;/context:component-scan&gt; 注意： 仅仅开启组件扫描spring是不会自动管理bean的，而是自动的扫描package，要想自动管理bean，那么还需要配置注解 注解 在类的声明上方添加@Component注解，可以是的spring知道这个类是一个组件，需要进行管理，所以如过某个类需要被Spring管理，应该将这个类放在被扫描的包中，并且添加注解 由Spring扫描到的组件(由@Component注解标记的类)，会由Spring自动设置Bean Id，值为将类名首字母小写的名称，例如组件类的名称是UserDao，则配置的Bean的id是userDao，如果需要自定义Bean，那么可以直接在注解中设置，比如@Component(&quot;id&quot;) 前提 一定要是在开启组件扫描的包下使用注解，否则将不会扫描到配置的注解 常用注解 可以混用，暂时这几个注解没有差异，完全功能相同，但是我们还是要根据规则使用 @Component ： 通用注解 @Service ： 用于对业务逻辑类的注解(Service层) @Controller ： 用于对控制器类的注解 @Repository ：用于对持久层处理类的注解(Dao层) @Named ：通用注解(不用) 以上5个注解从实现目标和效果是等效的，但是基于方便理解代码的目的，应该按需使用，了；例如对名为UserService类的，应该使用@Service 其他注解@Scope 在类的声明语句上方添加这个注解，用于设置bean的作用域,比如@Scope(&quot;prototype&quot;)表示非单例，默认是单例 @Lazy 在单例模式下设置是否懒加载，例如@Lazy(&quot;true&quot;)用于设置成懒加载 在类的声明语句上方添加 前面之前已经说过，在创建Bean的时候默认使用的是单例模式下的饿汉式的创建，即是在spring配置文件加载的时候创建 @PostConstruct 将方法设置为生命周期的初始化方法 设置初始化方法，直接在初始化方法的声明语句中添加即可 1234567/** * 初始化方法： 应该是public的，无返回参数，无参数的 */@PostConstruct //定义初始化方法，在构造方法之后执行public void init()&#123; System.out.println("初始化方法");&#125; @PreDestroy(单例模式下才会销毁) 在方法的声明语句上方使用，可以将这个方法设置为生命周期的销毁方法 1234@PreDestroy //定义销毁方法 public void destroy()&#123; System.out.println("销毁方法"); &#125; 注入值@Autowired （不推荐使用） 在类中，在声明属性的上方添加@Autowired，用于标记该属性是自动装配值 这种自动装配默认按照类型(byType)实现自动装配 如果需要按照名称(byName)来自动装配,还需要使用@Qualifier(&quot;userDao&quot;)来组合使用，注解中配置的名称是需要注入的值的Bean-Id UserDao 123456@Repository(&quot;userDao&quot;)public class UserDaoImpl implements UserDao&#123; public void reg() &#123; System.out.println(&quot;reg&quot;); &#125;&#125; UserService 123456789@Servicepublic class UserService &#123; @Autowired @Qualifier("userDao") private UserDao userDao; public void reg()&#123; userDao.reg(); &#125;&#125; @Resource (推荐使用) 在需要注入的属性的上方添加该注解 默认先按照名称来自动装配的(byName),如果名称对应不上，那么按照类型(byType)进行匹配 12@Resource //这里会先自动匹配和属性名一样的Bean Id，如果没有匹配到，那么就按照类型进行匹配private UserDao userDao; 如果使用@Resource(name=&quot;userDaoImpl&quot;)，name属性指定的是Bean Id,添加了name属性，那么只是按照名称来装配，如果这个名称对应的Bean不存在，那么就注入失败 12@Resource(name="userDaoImpl") //这里只会匹配Bean Id为userDaoImpl的，如果匹配不上，那么报异常private UserDao userDao; @Value 使用@Value注解添加在属性的声明的上方，可以对属性注入值 直接注入值 12@Value("陈加兵")private String name; 在使用@Value(&quot;#{beanId.属性名}&quot;)的注解时还可以使用Spring表达式 12@Value(#&#123;jdbc.url&#125;)private String url;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring表达式和自动装配]]></title>
      <url>%2F2018%2F04%2F24%2FSpring%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
      <content type="text"><![CDATA[Spring表达式和自动装配【重要】spring表达式作用 通过spring表达式可以在配置Y节点时，如果Y的某些属性需要注入值，可以是已经配置的好的X类的节点中的值 直接使用#{id.属性名} 前提 必须为每个属性都要设置set方法 实现 新建两个类 Message 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Message &#123; private String name; private List&lt;String&gt; cities; //城市 。List集合 private Set&lt;String&gt; friend; //Set集合 private Map&lt;Integer,String&gt; bookes; //Map集合 private Properties properties; //Properties集合 private String[] names; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String[] getNames() &#123; return names; &#125; public void setNames(String[] names) &#123; this.names = names; &#125; public List&lt;String&gt; getCities() &#123; return cities; &#125; public void setCities(List&lt;String&gt; cities) &#123; this.cities = cities; &#125; public Set&lt;String&gt; getFriend() &#123; return friend; &#125; public void setFriend(Set&lt;String&gt; friend) &#123; this.friend = friend; &#125; public Map&lt;Integer, String&gt; getBookes() &#123; return bookes; &#125; public void setBookes(Map&lt;Integer, String&gt; bookes) &#123; this.bookes = bookes; &#125; public Properties getProperties() &#123; return properties; &#125; public void setProperties(Properties properties) &#123; this.properties = properties; &#125;&#125; ValueBean的类 123456789101112public class ValueBean &#123; private String username; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125;&#125; 获取不是集合类型的值 在sprig的配置文件中配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;util:list id="cities"&gt; &lt;value&gt;徐州&lt;/value&gt; &lt;value&gt;无锡&lt;/value&gt; &lt;value&gt;常州&lt;/value&gt;&lt;/util:list&gt;&lt;util:set id="friends"&gt; &lt;value&gt;Jack&lt;/value&gt; &lt;value&gt;Tom&lt;/value&gt; &lt;value&gt;陈加兵&lt;/value&gt;&lt;/util:set&gt;&lt;util:map id="bookes"&gt; &lt;entry key="1001" value="java编程基础"&gt;&lt;/entry&gt; &lt;entry key="1002" value="java编程思想"&gt;&lt;/entry&gt;&lt;/util:map&gt;&lt;!-- 引入外部的Properties文件，location指定的就是位置 --&gt;&lt;util:properties id="properties" location="classpath:jdbc.properties"&gt;&lt;/util:properties&gt;&lt;bean id="message" class="cn.tedu.spring.beans.Message"&gt; &lt;property name="name" value="陈加兵"&gt;&lt;/property&gt; &lt;!-- List集合的注入 ref指定的上面定义的List的id --&gt; &lt;property name="cities" ref="cities"&gt;&lt;/property&gt; &lt;!-- Set集合的注入 --&gt; &lt;property name="friend" ref="friends"&gt;&lt;/property&gt; &lt;!-- Map集合的注入 --&gt; &lt;property name="bookes" ref="bookes"&gt;&lt;/property&gt; &lt;!-- properties的集合的注入 --&gt; &lt;property name="properties" ref="properties"&gt;&lt;/property&gt; &lt;!-- 为数组赋值 --&gt; &lt;property name="names"&gt; &lt;array&gt; &lt;value&gt;Alex&lt;/value&gt; &lt;value&gt;Billy&lt;/value&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置ValueBean --&gt;&lt;bean id="valueBean" class="cn.tedu.spring.beans.ValueBean"&gt; &lt;!-- value的值是使用spring表达式获取的，形式为：#&#123;前面定义好的id.属性名&#125; --&gt; &lt;property name="username" value="#&#123;message.name&#125;"&gt;&lt;/property&gt;&lt;/bean&gt; 引用数组集合或者List的值 直接使用 #{bean的id.数组名[index]} 12345&lt;!-- 配置ValueBean --&gt;&lt;bean id="valueBean" class="cn.tedu.spring.beans.ValueBean"&gt; &lt;!-- value的值是使用spring表达式获取的，形式为：#&#123;前面定义好的id.属性名&#125; --&gt; &lt;property name="username" value="#&#123;message.names[0]&#125;"&gt;&lt;/property&gt;&lt;/bean&gt; ValueBean的name属性设置为Person中的Address对象的city值 #{person.address.city} Person类中有一个成员变量是Address类的对象 这里不再写这三个类了，直接在spring中配置 123456789101112131415161718&lt;!-- 创建一个Address的实例 --&gt; &lt;bean id="address" class="cn.tedu.spring.beans.Address"&gt; &lt;property name="city" value="无锡"&gt;&lt;/property&gt; &lt;property name="pro" value="江苏"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="person" class="cn.tedu.spring.beans.Person"&gt; &lt;property name="name" value="陈加兵"&gt;&lt;/property&gt; &lt;property name="age" value="22"&gt;&lt;/property&gt; &lt;!-- 引用上面address --&gt; &lt;property name="address" ref="address"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置ValueBean --&gt; &lt;bean id="valueBean" class="cn.tedu.spring.beans.ValueBean"&gt; &lt;!-- value的值是使用spring表达式获取的，形式为：#&#123;前面定义好的id.属性名&#125; --&gt; &lt;property name="username" value="#&#123;person.address.city&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; 引用Map集合中的某个value #{id.Map名称.key名称} #{id.Map名称[&#39;key名称&#39;]} 【了解】spring表达式支持方法的调用【了解】 自动装装配(autowire) &lt;bean id=&quot;&quot; class=&quot;&quot; autowire=&quot;&quot;&gt; 自动装配表现为不需要配置&lt;property&gt;节点来注入，spring会自动的为属性注入值 在bean节点中添加autowire属性以配置自动装配，当值为byName，表示根据名称自动装配，即spring会检查这个bean的所有属性名称，然后在搜平日那个管理的所有Bean中查找bean-id一致的Bean对象，如果找到，则自动赋值 当取值为byType时，表示根据类型自动装配，及自动化赋值的标准是找数据类型匹配的Bean对象，需要注意的是：如果根据类型装配，必须保证可以匹配上的，由spring自动管理的Bean只有一个，如果有2个或者更多，会导致异常 实例 UserDao 12345public class UserDao()&#123; public void reg()&#123;&#125;&#125; UserService 123456public class UserService&#123; private UserDao userDao; private void reg()&#123; userDao.reg();&#125;&#125; spring 的配置文件 1234&lt;bean id="userDao" class="cn.tedu.spring.UserDao"/&gt;&lt;!--这里不需要配置property节点来ref上面定义的bean，只需要使用自动装配即可--&gt;&lt;bean id="userService" class="cn.tedu.spring.UserService" autowire="byName"&gt; @Value() 使用这个注解为成员变量赋值 1234Class Person()&#123; @Value("陈加兵") //直接为其赋值 private String name;&#125; 可以使用这个注解读配置文件中的值并未成员变量赋值： @Value(#{dbConfig.url})，这个是读取spring-dao.xml中的中的key为url的值]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring依赖注入]]></title>
      <url>%2F2018%2F04%2F24%2FSpring%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%2F</url>
      <content type="text"><![CDATA[Spring依赖注入【了解】Spring管理对象的生命周期(只有在单例的模式有意义，这个是默认的) 由spring管理的对象可以有生命周期方法，这些生命周期方法是开发人员自定义的，方法名自定义，无参数 由spring管理的对象的类可以有初始化和销毁这两种生命周期方法，按需设计即可。 因为是spring自己调用的，因此要设置为无参数，无返回值的方法。 为单个bean指定生命周期方法 实例： 1234567891011public class Person &#123; private String name; private int age; //person类的初始化方法 public void init()&#123; System.out.println("初始化方法"); &#125; public void destory()&#123; System.out.println("销毁方法"); &#125;&#125; 在spring配置文件中配置 12345&lt;!-- init-method ： 定义初始化方法，直接写上方法名称即可 destroy-method： 定义销毁方法，直接写上方法名即可 --&gt;&lt;bean id="" class="cn.tedu.spring.beans.Person" init-method="init" destroy-method="destory"&gt;&lt;/bean&gt; 为容器中所有的bean指定生命周期方法 可以在顶级节点中添加default-init-method指定初始化方法和添加default-destroy-method指定销毁方法 123&lt;beans default-init-method="init" default-destroy-method="destroy"&gt; &lt;bean id="person" class="cn.tedu.spring.bean.Person"&gt;&lt;/bean&gt;&lt;/bean&gt; 【重要】注入属性值实现目标 由spring管理的对象，其属性值可以为其中的某些属性注入值，是的最终获取对象时，属性就已经有值了 Setter注入前提 必须为每一个属性添加set方法 基本数据类型变量的注入实现 新建一个Person的实体类如下： 12345678910111213141516public class Person &#123; private String name; private int age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 在配置文件中配置bean 123456789&lt;bean id="person" class="cn.tedu.spring.beans.Person"&gt; &lt;!-- 直接使用property配置参数 name：指定属性的字段，这个是set方法后面的单词首字母小写的值，比如SetUsername()，那么此时的name值为username value： 指定属性的值 ref : 指定前面定义的bean的id，用于设置引用类型的参数值 --&gt; &lt;property name="name" value="陈加兵"&gt;&lt;/property&gt; &lt;property name="age" value="22"&gt;&lt;/property&gt;&lt;/bean&gt; 注意： 在配置XML文件时，节点中的name属性的值其实是Java代码中Set方法名称中除去set单词并且将首字母小写后的名称，例如Set方法的名称为setAge，那么其中的name属性的值就是age。所以这个name属性的值并不是java代码中的属性名称，只不过通常在java代码中，基于代码规范，这里的name属性值也是java代码中的属性名称。 引用类型的属性注入 引用类型即是在一个类中包含另外一个类的对象，即是一个类的成员变量是另外一个类的对象 实现 新建一个Address类 12345678910111213141516public class Address &#123; private String city; //城市 private String pro ; //省份 public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getPro() &#123; return pro; &#125; public void setPro(String pro) &#123; this.pro = pro; &#125;&#125; 新建一个Person类，其中包含了Address这个类的对象 1234567891011121314151617181920212223242526272829public class Person &#123; private String name; private int age; private Address address; // Address的对象作为成员变量 public Address getAddress() &#123; return address; &#125; public void setAddress(Address address) &#123; this.address = address; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 在配置文件中配置实例 12345678910111213&lt;!-- 创建一个Address的实例 --&gt;&lt;bean id="address" class="cn.tedu.spring.beans.Address"&gt; &lt;property name="city" value="无锡"&gt;&lt;/property&gt; &lt;property name="pro" value="江苏"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="person" class="cn.tedu.spring.beans.Person"&gt; &lt;property name="name" value="陈加兵"&gt;&lt;/property&gt; &lt;property name="age" value="22"&gt;&lt;/property&gt; &lt;!-- 这里的ref引用的是上面配置的Address的实例中的id值 --&gt; &lt;property name="address" ref="address"&gt;&lt;/property&gt;&lt;/bean&gt; 【了解】构造器注入(无参，有参) 在前面已经讲过了无参构造注入，直接使用&lt;bean id=&quot;&quot; class=&quot;&quot;&gt;即可 前提 有一个构造有参构造方法 实现 创建一个Person类 12345678910111213141516171819202122232425public class Person &#123; private String name; private int age; //构造方法 public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 配置spring的配置文件 12345678910&lt;bean id="person" class="cn.tedu.spring.beans.Person"&gt; &lt;!-- name: 这个相当于index，也是指定参数列表的属性，不过这里是直接使用参数列表中的变量名 value: 为参数设置的值 index: 构造方法的参数列表的索引，从0开始 ref:引用类型的值，这里的值应该是上面已经定义好的bean的id值 --&gt; &lt;constructor-arg index="0" value="陈加兵"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="1" value="22"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 注入基本型 在spring注入值时，如果值的类型是String或者java中的基本数据类型，都称之为基本型，而其他的都是”非基本型“的数据 注入非基本型(ref) 前面所说的引用类型的注入就是基本型的注入，这里不再详细的讲述 注入集合 集合类型有List，Set，Map，Properties 实现 创建一个Message类，其中定义了各种集合类型的成员属性，并且添加了set方法 123456789101112131415161718192021222324252627282930public class Message &#123; private List&lt;String&gt; cities; //城市 。List集合 private Set&lt;String&gt; friend; //Set集合 private Map&lt;Integer,String&gt; bookes; //Map集合 private Properties properties; //Properties集合 public List&lt;String&gt; getCities() &#123; return cities; &#125; public void setCities(List&lt;String&gt; cities) &#123; this.cities = cities; &#125; public Set&lt;String&gt; getFriend() &#123; return friend; &#125; public void setFriend(Set&lt;String&gt; friend) &#123; this.friend = friend; &#125; public Map&lt;Integer, String&gt; getBookes() &#123; return bookes; &#125; public void setBookes(Map&lt;Integer, String&gt; bookes) &#123; this.bookes = bookes; &#125; public Properties getProperties() &#123; return properties; &#125; public void setProperties(Properties properties) &#123; this.properties = properties; &#125;&#125; 在spring的配置文件中配置注入 1234567891011121314151617181920212223242526272829303132333435&lt;bean id="message" class="cn.tedu.spring.beans.Message"&gt; &lt;!-- List集合的注入 --&gt; &lt;property name="cities"&gt; &lt;list&gt; &lt;value&gt;徐州&lt;/value&gt; &lt;value&gt;无锡&lt;/value&gt; &lt;value&gt;常州&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- Set集合的注入 --&gt; &lt;property name="friend"&gt; &lt;set&gt; &lt;value&gt;Jack&lt;/value&gt; &lt;value&gt;Tom&lt;/value&gt; &lt;value&gt;陈加兵&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!-- Map集合的注入 --&gt; &lt;property name="bookes"&gt; &lt;map&gt; &lt;entry key="1001" value="java编程基础"&gt;&lt;/entry&gt; &lt;entry key="1002" value="java编程思想"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;!-- properties的集合的注入 --&gt; &lt;property name="properties"&gt; &lt;props&gt; &lt;prop key="username"&gt;root&lt;/prop&gt; &lt;prop key="password"&gt;root&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; 测试方法 123456789101112131415161718@Test public void test2() &#123; // spring的配置文件 String conf = "applicationContext.xml"; // 获取spring容器 AbstractApplicationContext context = new ClassPathXmlApplicationContext( conf); Message message=(Message) context.getBean("message"); List&lt;String&gt; cities=message.getCities(); Set&lt;String&gt; friends=message.getFriend(); Map&lt;Integer, String&gt; bookes=message.getBookes(); Properties properties=message.getProperties(); System.out.println(cities); System.out.println(friends); System.out.println(bookes); System.out.println(properties); context.close(); &#125; 【重点了解Properties的注入】引用方式注入集合(&lt;util:&gt;) 其中的ref指定的是配置集合的id 使用的还是上面的Message类 在resource中需要新建一个jdbc.properties，我们便可以在spring的配置文件中使用&lt;util:properties id=&quot;&quot; location=&quot;classpath:jdbc.properties&quot;&gt;自动的读取其中的值 1234root=rootpassword=rooturl=jdbc:mysql://localhost:3306/hirbernate?useUnicode=true&amp;characterEncoding=UTF-8driver=com.mysql.jdbc.Driver spring的配置文件中配置bean 123456789101112131415161718192021222324252627282930313233&lt;util:list id="cities"&gt; &lt;value&gt;徐州&lt;/value&gt; &lt;value&gt;无锡&lt;/value&gt; &lt;value&gt;常州&lt;/value&gt;&lt;/util:list&gt;&lt;util:set id="friends"&gt; &lt;value&gt;Jack&lt;/value&gt; &lt;value&gt;Tom&lt;/value&gt; &lt;value&gt;陈加兵&lt;/value&gt;&lt;/util:set&gt;&lt;util:map id="bookes"&gt; &lt;entry key="1001" value="java编程基础"&gt;&lt;/entry&gt; &lt;entry key="1002" value="java编程思想"&gt;&lt;/entry&gt;&lt;/util:map&gt;&lt;!-- 引入外部的Properties文件，location指定的就是位置 --&gt;&lt;util:properties id="properties" location="classpath:jdbc.properties"&gt;&lt;/util:properties&gt;&lt;bean id="message" class="cn.tedu.spring.beans.Message"&gt; &lt;!-- List集合的注入 ref指定的上面定义的List的id --&gt; &lt;property name="cities" ref="cities"&gt;&lt;/property&gt; &lt;!-- Set集合的注入 --&gt; &lt;property name="friend" ref="friends"&gt;&lt;/property&gt; &lt;!-- Map集合的注入 --&gt; &lt;property name="bookes" ref="bookes"&gt;&lt;/property&gt; &lt;!-- properties的集合的注入 --&gt; &lt;property name="properties" ref="properties"&gt;&lt;/property&gt;&lt;/bean&gt; 【了解】其他类型的注入为数组注入值 新添加一个数组的属性 12345678private String[] names; public String[] getNames() &#123; return names; &#125; public void setNames(String[] names) &#123; this.names = names; &#125; spring配置文件 1234567&lt;!-- 为数组赋值 --&gt;&lt;property name="names"&gt; &lt;array&gt; &lt;value&gt;Alex&lt;/value&gt; &lt;value&gt;Billy&lt;/value&gt; &lt;/array&gt;&lt;/property&gt; 甚至在配置XML时，&lt;List&gt;和&lt;array&gt;可以随意挑选使用，即为List类型的数据注入值时，既可以使用&lt;List&gt;节点，也可以使用&lt;array&gt;节点，反之为数组类型的数据值也是一样 注入空字符串 设置的value直接为&quot;&quot; 为引用类型的数据注入null值123&lt;property name="xxx"&gt; &lt;null/&gt;&lt;/property&gt; 显示的确定数据类型123&lt;property name="xxx"&gt; &lt;value type="数据类型"&gt;值&lt;/value&gt;&lt;/property&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring入门]]></title>
      <url>%2F2018%2F04%2F24%2FSpring%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[spring_day01SSM框架 Spring + springMVC + mybatis 作用 管理对象： 当开发人员需要某一个类的对象时，不需要自行new对象，而是通过spring直接获取即可 使用【掌握】通过spring获取存在无参构造方法类的对象 创建Maven Project 当项目创建好之后，生成web.xml，解决默认提示错误 选择tomcat, 项目右击 - &gt; properties -&gt; Target Runtimes 打开 http://mvnrepository.com，搜索springwebmvc，在结果中找到的Group是org.springframework,选择版本，并且复制xml代码 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.12.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置spring的配置文件(applicationContext.xml) 1234&lt;!-- id： 自定义名称 class : 需要spring管理的类的路径 --&gt; &lt;bean id="date" class="java.util.Date"&gt;&lt;/bean&gt; 测试 12345678910111213141516import java.util.Date;import org.springframework.context.support.AbstractApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TestDemo1 &#123; public static void main(String[] args) &#123; //spring的配置文件 String conf="applicationContext.xml"; //获取spring容器 AbstractApplicationContext context=new ClassPathXmlApplicationContext(conf); //获取配置文件中指定的bean，参数是自定义的id Date date=(Date) context.getBean("date"); //打印出日期，对象创建成功 System.out.println(date); context.close(); &#125;&#125; 内存泄露或者内存溢出 当需要释放某个对象所占用的内存空间时，如果对象没有正确关闭，将导致无法释放，由于这个对象可能已经没有了引用，这个对象再也无法使用，却一直被误认为被使用，就会变成长期存在于内存中的垃圾数据，就是内存泄露 其实少量的内存泄露是灭有危害的。但是如果存在大量的内存泄露，就可导致可用内存明显变少，计算机的运行性能就会下降，当内存泄露到极点的时候，就会溢出。尽管少量的内存泄露是没有危害的，但是应该严谨的编程，尽量不要出现内存泄露 【了解】通过spring获取类中不存在无参构造方法，但是存在静态工厂方法类的对象 我们使用spring获取java.util.Calendar的对象 factory-method ： 这个属性指定的静态工厂方法 在spring的配置文件中配置这个对象 123456&lt;!-- 通过静态工厂方法创建对象 id ： 自定义的名称 class： 类的全路径 factory-method ： 静态工厂方法 --&gt;&lt;bean id="calendar" class="java.util.Calendar" factory-method="getInstance"&gt;&lt;/bean&gt; 测试 12345678910111213@Test public void testStatice() &#123; // spring的配置文件 String conf = "applicationContext.xml"; // 获取spring容器 AbstractApplicationContext context = new ClassPathXmlApplicationContext( conf); // 获取配置文件中指定的bean，参数是自定义的id Calendar calendar=(Calendar) context.getBean("calendar"); // 打印出日期，对象创建成功 System.out.println(calendar.getTime()); context.close(); &#125; 【了解】类中不存在无参构造方法，也没有静态工厂方法，但是存在实例工厂方法实例工厂方法 实例工厂方法： 指另一个类中有工厂方法，可以获取目标类型的对象，即X类中有工厂方法(非静态的)可以获取Y类的对象 实例 假设存在PhoneFactory类中，该类中有非静态方法getPhone()可以获取Phon类型的对象，并且Phone没有无参构造方法 Phone 123456public class Phone &#123; public String name; public Phone(String name) &#123; this.name=name; &#125;&#125; PhoneFactory 12345public class PhoneFactory &#123; public Phone getPhone() &#123; return new Phone("小米6"); &#125;&#125; spring配置文件 factory-bean ： 是工厂类的id factory-method ： 工厂类获取Phone对象的非静态的方法 12345678&lt;!-- 配置工厂类 --&gt; &lt;bean id="phoneFactory" class="cn.tedu.spring.beans.PhoneFactory"&gt;&lt;/bean&gt; &lt;!-- 配置Phone类的对象 factory-bean ： 是工厂类的id factory-method ： 工厂类获取Phone对象的非静态的方法 --&gt; &lt;bean id="phone" class="cn.tedu.spring.beans.Phone" factory-bean="phoneFactory" factory-method="getPhone"&gt;&lt;/bean&gt; Bean的作用域(Scope) 默认情况下，由spring配置的对象是单例的 在配置时，在&lt;bean&gt;节点添加scope属性即可调整，当该属性为singleton时是单例的，当属性为prototype为非单例的 1234&lt;!-- id： 自定义名称 class : 需要spring管理的类的路径 --&gt;&lt;bean id="date" class="java.util.Date" scope="prototype"&gt;&lt;/bean&gt; 单例(Singleton)懒加载 在默认情况下，spring创建对象的是使用饿汉式，即是在spring配置文件开始加载的时候就创建对象，但是我们可以使用lazy-init取值我true的时候，就会使用懒加载(懒汉式) 1&lt;bean id="date" class="java.util.Date" scope="singleton" lazy-init="true"&gt;&lt;/bean&gt; prototype 一个Bean定义对应多个对象实例 request 在一次Http请求中，一个Bean只创建一个实例，仅限于web环境 session 在一个HttpSession中，一个Bean定义对应一个实例 globalSession 在一个全局的HttpSession中，一个bean定义对应一个实例 Bean的延迟初始化 在spring创建Bean的实例的时候默认是使用单例，并且是饿汉式加载，即是在spring的配置文件在开始加载的时候就创建bean的实例对象 但是我们可以使用lazy-init来延迟初始化，使用懒加载即可，当lazy-init为true的时候便是延迟加载 1&lt;bean id="date" class="java.util.Date" lazy-init="true"&gt;&lt;/bean&gt; 我们还可以在&lt;beans&gt;根节点中添加一个default-lazy-init，可以为容器中的所有bean设置为懒加载 1&lt;beans default-lazy-init="true"&gt;&lt;/beans&gt; spring配置文件的全部约束12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:util="http://www.springframework.org/schema/util" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.2.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.2.xsd"&gt;&lt;/beans&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet和JSP总结]]></title>
      <url>%2F2018%2F04%2F24%2FServlet%E5%92%8CJSP%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Servlet和JSP总结B/S和C/S BS: Browser Server 浏览器和服务器 特点： 跨平台，功能升级比较方便，加载数据慢，用户体验稍差 CS： Client Server 客户端和服务器 特点： 功能升级 需要下载新版本客户端，用户交互界面炫酷，体验度高，需要开发多个平台的版本，开发成本高 总结： 两种架构各有优缺点，以后工作都有可能涉及到 什么是服务器 服务器实际上就是一台高配置的电脑，通常配置内存8g以上，cpu8核以上，硬盘T级别 web服务器： 电脑上安装了web服务器软件，提供复杂的数据及文件共享功能 邮件服务器： 电脑上安装了邮件服务器，提供了收发邮件的功能 数据库服务器： 电脑上安装了数据库软件(mysql oracle) 提供了数据的增删改查 ftp服务器：电脑上安装了ftp服务软件，提供了文件上传下载功能 什么是web服务器 电脑中得到任何资源（数据或者文件）被远程计算机访问，都必须有一个与之对应的网络通信程序，当有用户来访问时，此程序负责建立网络连接，读取相关资源，并把资源发送给用户，此程序负责底层的网络通讯处理http协议，使用此类型程序，程序猿只需要把精力放在具体的业务逻辑上即可 通过scoket实现web服务器 练习： 请求http://localhost:8080 返回一个网页 火狐浏览器执行，chrome不支持，windows下不执行可能原因是防火墙 1234567891011121314151617181920212223242526272829303132import java.io.FileInputStream;import java.io.IOException;import java.io.OutputStream;import java.net.ServerSocket;public class Socket &#123; public static void main(String[] args) throws IOException &#123; //创建服务器socket，并指定端口号 ServerSocket serverSocket=new ServerSocket(8888); System.out.println("服务器已经启动"); //循环接收新的socket while(true)&#123; //得到链接进来的socket对象 java.net.Socket socket=serverSocket.accept(); //构建数据发送通道 OutputStream outputStream=socket.getOutputStream(); //得到文件的输入流 FileInputStream inputStream=new FileInputStream("/home/chenjiabing/文档/a.html"); //把文件数据读取到，然后写出 int len=0; while((len=inputStream.read())!=-1)&#123; outputStream.write(len); &#125; //关闭流 outputStream.close(); inputStream.close(); &#125; &#125;&#125; 市面上常见的web服务器 webSphere : 是IBM公司产品，闭源收费 应用场景：IBM的操作系统+DB2+WebSphere Tomcat： apache的产品，属于开源免费应用在中小型网站中 web学习阶段使用的服务器 weblogic : BEA公司的产品 闭源收费 静态资源和动态资源 静态资源：任何用户 任何时间访问 内容都一样 动态资源： 不同的用户访问显示的内容可能会不一样，通过计算生成的网页 Servlet 介绍 因为web服务器本身只提供了静态资源访问，而具体的业务需求存在着动态资源，servlet就是用来扩展web服务器功能，tomcat属于web容器，而servlet属于存在于容器中的组件，Servlet本身是一个组件规范。 如何创建Servlet 创建一个Class，继承HttpServlet 编译 打包并发布（把servlet添加到tomcat中的webapps目录下） WEB-INF 这个文件夹里面的资源不能直接访问 classess (.class文件) lib (存放第三方的jar包) web.xml （部署描述文件） 运行tomact服务器 创建Servlet第一个程序 创建maven项目 把默认的jar改成war 把package Explorer改成 project Explorer 在工程根目录的第一个文件上右键点击最长的那一个选项(默认工程中没有web.xml文件，这个操作会自动创建web.xml) 创建一个类，继承HttpServlet 可能你会发现没有这个HttpServlet类，因为这里我们还需要一个jar包，我们在项目上右击选择properties，然后选择Targeted Runtime选择你自己的Tomcat，ok 1234567891011121314151617181920212223import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class HelloServlet extends HttpServlet &#123; //这个方法可以处理任何的请求，get.post delete put 并且可以在适当的时候调用处理请求类型的各种方法 @Override protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //设置响应的数据类型 response.setContentType("text/html"); //设置响应编码格式为UTF-8，否则将会出现中文乱码 response.setCharacterEncoding("UTF-8"); //得到输出对象 PrintWriter writer=response.getWriter(); //返回数据，这里是向浏览器中写入数据 writer.write("&lt;h1&gt;Hello World--你好世界&lt;/h1&gt;"); //关闭输出流 writer.close(); &#125;&#125; 接下来在web.xml中配置Servlet的映射地址，在web-app的目录下写上如下内容 12345678910111213&lt;servlet&gt; &lt;!-- 自己定义的名字，任意 --&gt; &lt;servlet-name&gt;HelloWorld&lt;/servlet-name&gt; &lt;!-- 指定Servlet的全类名 --&gt; &lt;servlet-class&gt;cn.tedu.HelloServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;!-- 指定Servlet的映射关系 --&gt;&lt;servlet-mapping&gt; &lt;!-- 这个是上面定义的Servlet的名字 --&gt; &lt;servlet-name&gt;HelloWorld&lt;/servlet-name&gt; &lt;!-- 指定映射的地址： 这里只需要在浏览器中输入http://localhost:8080/helloWorld即可调用这个Servlet --&gt; &lt;url-pattern&gt;/helloWorld&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 在浏览器中输入http://localhost:8080/helloWorld 错误码 404 找不到访问资源 解决： 检查请求地址，检查项目是否部署成功 500 服务器处理出错 - 代码执行中有异常，仔细查看异常提示，看看能否找到解决办法 Servlet响应的过程 浏览器发出请求，会先由浏览器的通讯模块对请求进行打包，打包后把数据传递给tomcat服务器 tomcat由通讯模块接收请求包并且对请求包进行解析，把请求数据封装到Request对象中，并且创建Response对象用于给浏览器返回数据 tomcat通讯模块通过查找web.xml文件和本次请求相对应的Sevlet，通过反射技术创建对象并且调用对象的Service方法并把Request和Response传递到方法中 在service方法中书写各种业务代码，把需要返回的数据交给Respose对象，由Response对象传递给通讯模块，在通讯模块中打包成响应包 把响应包数据发送给浏览器通讯模块 浏览器通讯模块解析数据并且展示返回的数据 ##响应数据乱码-为什么出现乱码,因为输出响应数据默认使用的是iso8859-1 需要把此编码改成utf-8 ##发出请求时传递参数把请求的参数写在请求地址的后面http://localhost:8080/1712ServletDay02_01Hello/hello?name=xiaoming通过request获取请求参数 ##案例:计算 体质率BMI页面中 有两个文本输入框 一个用来获取身高,一个用来获取体重 和一个提交按钮bmi计算公式 bmi = 体重(kg)/身高(m)/身高(m)根据bmi值判断体重是否正常 bmi=19&amp;&amp; bmi&lt;=25 体重正常 bmi&gt;25 该减肥了步骤:1. 创建页面bmi.html 页面中添加两个文本输入框和一个提交按钮 2. 创建BMIServlet在Service方法中写业务逻辑 3. 在web.xml中配置bmiservlet 地址栏中出现中文 乱码解决方案因为浏览器默认会对中进行utf-8编码,但是在Servlet里面8.0以前默认是iso8859-1,8.0以后默认是utf-8,如果使用8.0以前版本解决乱码方案有两种: new String(gender.getBytes(&quot;iso8859-1&quot;),&quot;utf-8&quot;); 在server.xml的配置文件中修改 在server.xml的第65行左右 的&lt;Connector标签中添加以下属性&lt;Connector URIEncoding=&quot;utf-8&quot; HTTP协议(了解)什么是HTTP协议属于一种网络应用层的协议,规定了浏览器与web服务器之间如何通讯,以及数据包的结构 -tcp/ip协议:属于连接协议,规定了两台设备如何建立连接 -http:应用层协议基于tcp/ip协议 http协议,规定了数据包的内容和结构,规定了请求方式等内容 浏览器-&gt;打请求包-&gt;服务器-&gt;服务器解请求包 服务器-&gt;打响应包-&gt;浏览器-&gt;浏览器解响应包 http://locaohost:8888/1712ServletDay02_01Hello/hello?name=abc http请求包数据: GET /1712ServletDay02_01Hello/hello?name=abc HTTP/1.1 Host: localhost:8080 主机地址 Connection: keep-alive 连接状态 Upgrade-Insecure-Requests: 1 //浏览器信息User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8Accept-Encoding: gzip, deflate, sdchAccept-Language: zh-CN,zh;q=0.8 响应数据包 HTTP/1.1(协议版本号) 200(状态码) OK(状态信息) Server: Apache-Coyote/1.1(服务器信息) Content-Type: text/html;charset=utf-8(响应数据类型及字符集) Content-Length: 21(数据长度) Date: Tue, 03 Apr 2018 07:44:01 GMT(当前时间) http请求包中包含:请求头和请求体 http响应包中包含:响应头和响应体 请求方式:GET和POST GET: 请求参数放在请求地址的后面 提交的数据量比较小(大小在2k左右的数据) 不能提交敏感信息因为在地址栏中可能会显示出来,或者某些路由器会保存请求地址中的信息 浏览器什么时候会发出get请求: 在地址栏中发出的请求就是get请求 form表单默认的请求方式就是get 点击超链接所发出的请求也是get POST: 会将请求参数放在请求体里面,没有大小限制 敏感信息相对安全 浏览器什么时候会发出post请求 只有当表单的提交方式修改为post的时候 Servlet中service 和doGet/doPost的关系当Servlet组件被tomcat容器调用执行的时候会先执行service方法,在Service方法中判断请求方式是get就访问doGet 如果是post就访问doPost 获取请求头里面的数据 String uri = request.getRequestURI(); StringBuffer url = request.getRequestURL(); String httpVersion = request.getProtocol(); 设置响应头数据1234//设置响应数据类型和字符集response.setContentType("text/html;charset=utf-8");//设置刷新时间response.setHeader("refresh", "3;info.html"); 乱码响应数据有中文 response.setContentType(&quot;text/html;charset=utf-8&quot;);请求参数有中文 get请求: new String(gender.getBytes(&quot;iso8859-1&quot;),&quot;utf-8&quot;); 修改server配置文件 65左右 &lt;Connector URIEncoding=”utf-8” post: 为什么出现乱码:在post表单提交数据的时候使用当前页面的解码格式进行编码,因为Request对象默认使用iso8859-1解码 所以需要使用以下方式解决乱码问题 解决方案:在获取参数之前添加以下代码request.setCharacterEncoding(&quot;utf-8&quot;); 以后写Servlet代码 需要添加以下两行代码12request.setCharacterEncoding("utf-8");response.setContentType("text/html;charset=utf-8"); 定时刷新及定时跳转 response.setHeader(&quot;refresh&quot;,&quot;2&quot;); response.setHeader(&quot;refresh&quot;,&quot;2;home.html&quot;); 如何隐藏关闭的工程 在左侧边栏右上角的小三角点击 点击 customView -&gt; filters-&gt;closed Project 如何分组显示项目 在左侧边栏右上角的小三角点击 点击Top level Element 选择Working set 然后重新点击小三角 选择select working set 在里面点击new -&gt;Java 给分组起名然后分配工程到此分组里面,也可以不分配之后以拖拽的方式分配项目 重定向 什么是重定向:让浏览器往另外一个地址重新发出请求 实现原理: 重定向命令会给浏览器返回一个302的状态码 和一个location的参数 ,浏览器接收到302状态码后会向location参数的地址发出请求 重定向案例: response.sendRedirect(request.getContextPath()+&quot;/FindAllServlet&quot;); 得到当前工程根路径的方式: request.getContextPath() 路径的匹配两种匹配方式: 精确匹配:web.xml中的url parttern要和请求地址一致 模糊匹配: 通过添加* 的方式让多个请求地址对应一个Servlet /*: *代表一个或多个未知,此地址会对应所有的动态资源地址(servlet地址) /abc /bcd /aaa /a/b/c /x/yhttp://localhost:8080/appname/(内容任意) /user/*:此匹配地址必须要求请求地址中必须是http://localhost:8080/appname/user/(内容任意) 后缀匹配 *.do(*.action)http://localhost:8080/appname/xxxx.do 浏览器输入一个地址查找资源的过程是怎样的?1. 在当前应用的web.xml中查找是否有与之匹配的动态资源路径(Servlet) 2. 如果匹配到则执行相对应的Servlet 3. 如果没有匹配到会使用默认的Servlet查找是否有同名的静态资源 4. 如果有则返回资源文件 5. 如果没有则页面会显示404(找不到资源) 总结:先找动态 然后找静态 都找不到就404 复制工程时注意事项 如果复制工程,需要在工程上右键properties-&gt;web settings修改里面的名称,此时的名称为复制之前工程的名称,修改成新工程的名字 Servlet的生命周期 什么是生命周期: 什么时候实例化 什么时候初始化 什么时候调用方法 什么时候销毁 实例化: 两种情况: 默认什么时候请求 什么时候实例化 web容器启动的时候实例化 需要在Web.xml中进行配置 &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;数值越小 优先级越高 初始化: 当请求地址在web.xml中匹配到相应的Servlet的时候 web容器会通过反射实例化Servlet对象 并且调用有参数的init方法 在有参数的方法中调用了无参的init()如果需要写初始化代码 重写无参的init(); 方法调用: service doget dopost web容器先实例化Servlet然后初始化Servlet 然后web容器调用service方法在Service方法中判断请求方式然后调用doget或doPost方法 销毁: 当工程从web容器(Tomcat)中卸载的时候执行 执行步骤: 实例化-&gt;初始化-&gt;方法调用-&gt;销毁 JSP 什么是JSP: Java Server Page java服务器页面是sun公司提供的一套动态页面规范 虽然直接使用Servlet也可以生成动态页面,但是操作过于繁琐(out.pringtln()),也不利于页面的维护,所以sun公司才提出了jsp规范 jsp实际上就是一个以.jsp结尾的文件,可以在此文件中写html(css/javaScript)也可以写Java代码片段,容器会将此文件转换成Servlet来执行总结:jsp文件的本质就是Servlet 如何创建jsp文件 创建一个file 名称为first.jsp 在jsp文件中可以写以下内容Html(包括css,JavaScript)直接写即可和操作html文件一样Java代码 两种写法: &lt;% java代码 %&gt; 转换成servlet时会直接照搬过去 &lt;%=java表达式 %&gt; 只能输出一行 等效out.println(java表达式)隐含对象 什么是隐含对象 在jsp中不用创建可以直接使用的对象称为隐含对象(比如:out,request,response,servletConfig…) 为什么可以直接用隐含对象 因为把jsp转成servlet的时候会自动生成创建这些对象的代码指令 什么是指令:告诉容器,将jsp转成servlet的时候所做的一些额外操作 比如 import contentType pageEncoding等 pageEncoding指令有些容器在读取磁盘中的jsp文件时默认的解码是iso-8859-1(tomcat默认是utf-8),但是通常jsp文本保存时选择的编码字符集是utf-8,为了保证编码和解码字符集一致所以在页面中通过pageEncoding属性设置解码字符集weblogic bea 收费 默认是iso-8859-1 jsp是如何执行的 容器会将jsp文件转成一个servlet html(css,js)—&gt;在_jspService中 通过out.write &lt;% %&gt; —-&gt; 直接原样照搬到_jspService中 &lt;%= %&gt;—-&gt; 在_jspService中 使用 out.print() 容器和调用其它servlet一样调用此Servlet 练习: 自己写一个jsp 显示当前时间 格式为 2018年10月20日 11点23分44秒 练习: 显示用户表中的所有用户信息 ###cellpadding 内容距td边框的距离 ###cellspacing td边框距table边框的距离 Servlet(显示 业务逻辑)Dao数据访问 JSP(显示 业务逻辑)Dao数据访问 ##三层架构JSP(显示)Servlet(业务逻辑)Dao数据访问案例:查询所有用户 Servlet: 执行查询数据的代码放在Servlet里面 JSP:控制显示的代码##转发一个web组件将未完成的工作交给另外一个web组件 web组件(Servlet和jsp)通常情况下是在Servlet里面获取数据,然后把数据交给Jsp显示浏览器发请求-&gt;Servlet -&gt; Jsp以前请求发送到Servlet或jsp 现在分层之后 先把请求发送到Servlet,在Servlet里面获取数据 然后把数据转发给Jsp显示浏览器发请求-&gt;Servlet浏览器发请求-&gt;Jsp##如何实现转发 把数据绑定到request对象上 可以绑定多个数据 request.setAttribute(“users”, users); 得到转发器 并调用forward方法 RequestDispatcher dispatcher =request.getRequestDispatcher(&quot;userlist3.jsp&quot;); dispatcher.forward(request, response); 注意:转发实际上就是web容器找到相对应的组件并且执行了组件的_jspService方法##转发的特点 转发的目的地有限制只能是应用内部的资源 转发后浏览器的地址栏不变###转发和重定向的区别: 浏览器地址栏有没有变化? -转发没有 -重定向有变化 能否共享Request和Response对象 -转发:可以共享,因为转发只有一次请求web容器只创建了一对Request和Response对象两个组件使用的是相同的 -重定向:不可以共享:因为两次请求,web容器创建了两对Request和Response 每个组件使用的是自己的Request和Response 访问地址有何区别 -转发:只能访问工程内部的资源 -重定向:可以访问任意地址 include 指令 引入一个jsp页面，实现页面复用 &lt;jsp:include page=&quot;file.jsp&quot;&gt; 路径相关问题 转发，重定向，表单提交，超链接 request.getDispatcher(&quot;&quot;) response.sendRedirect(&quot;&quot;) &lt;form action=&quot;&quot;&gt; &lt;a href=&quot;&quot;&gt;&lt;/a&gt; 相对路径 不以/开头的路径就是相对路径，此路径相对于当前组件的位置 如果想要找到上一级的资源需要加上 ../ 访问上上级的a.jsp : ../../a.jsp 绝对路径 假设工程名为web1 获取工程名 : request.getContextPath() 以/开头的路径是绝对路径 转发从工程名之后写 request.getDispatcher(&quot;/jsp/a.jsp&quot;) 直接省略前面的工程名 其他(重定向，超链接，表单提交)从工程名开始写 &lt;a href=&quot;&lt;%=request.getContextPath() %&gt;/jsp/a.jsp&quot;&gt; &lt;form action=&quot;&lt;%=request.getContextPath() %&gt;/jsp/helloServlet&quot;&gt; response.sendRedirect(&quot;&lt;%=request.getContextPath() %&gt;/jsp/a.jsp&quot;) 总结 以后工作中更多的使用的是绝对路径，可维护性和扩展性更好，相对路径可能会出现一个地方更改多个地方出现错误的情况 状态管理（数据管理）什么是状态管理 将浏览器和服务器之间的多次交互建立关系，此时需要数据建立关系，数据保存和修改称为状态管理。状态即是数据 Cookie 把少量数据保存在浏览器(客户端)的一种技术 cookie默认是保存在内存中，浏览器关闭则清除，如果设置了时间为0则立即清除，如果设置时间为正整数，则保存在磁盘中，时间到后自动删除 工作原理： 浏览器访问服务器时，服务器会将一些数据以setCookie的形式把数据存放到响应的消息头中，然后浏览器再次访问服务器时，会将Cookie数据放在请求的消息头中，这样服务器就能够得到之前请求时保存的一些数据，这样多次请求就能建立联系 服务器如何添加cookie： 123456//创建一个cookie对象Cookie cookie= new Cookie("name", "xiaoming");//设置cookie的过期时间，如果设置为0表示立即清除，如果没有设置那么浏览器关闭之后就会清除cookie.setMaxAge(100);//添加到响应头中，并且返回给浏览器response.addCookie(cookie); 此时在浏览器中就可以查看到这个cookie的值了(name属性对应的值) cookie时间： 如果Cookie没有设置时间，时间为负整数，cookie保存在内存中，如果浏览器关闭，则数据清除 如果cookie时间设置为0，是立即清除cookie的意思 如果设置成为大于0 的整数，此时的cookie会保存到磁盘中，当时间到了之后会自动删除 cookie.setMaxAge(100); 单位是秒 获取cookie的值 12345678910// 获取Cookie，返回的是一个数组 Cookie[] cookies = request.getCookies(); //如果Cookies存在，读取 if (cookies != null) &#123; for(Cookie cookie : cookies)&#123; System.out.println(cookie.getName()+" : " + cookie.getValue()); &#125; &#125;else &#123; System.out.println("其中没有cookie"); &#125; cookie的路径 如果不设置路径，默认会以当前组件的路径为准，只有当访问地址为当前组件地址或者组件地址的子地址时才会带上cookie 假设我们添加cookie的servlet为 http://localhost:8080/web1/cookie/setCookieServlet,那么我们的获取添加的cookie的servlet地址只有是http://localhost:8080/web1/cookie这个地址的子地址(后代),比如http://localhost:8080/web1/cookie/user/getCookieServlet 为cookie设置路径 cookie.setPath(“/“); 举例： 如果设置path为 /a /a/servlet1 : yes /b/servlet2 : no cookie的编码问题 cookie只能保存英文，不能保存中文，如果需要保存中文，那么需要编码 中文编码 1234567891011String name="小明";//对中文进行url编码name=URLEncoder.encode(name,"utf-8");//创建一个cookie对象Cookie cookie= new Cookie("name", name);//设置cookie的过期时间，如果设置为0表示立即清除，如果没有设置那么浏览器关闭之后就会清除cookie.setMaxAge(100);System.out.println(cookie.getPath());//添加到响应头中，并且返回给浏览器response.addCookie(cookie); 将获取的中文cookie解码输出 12345678910111213// 获取Cookie，返回的是一个数组Cookie[] cookies = request.getCookies();//如果Cookies存在，读取if (cookies != null) &#123; for(Cookie cookie : cookies)&#123; String value=cookie.getValue(); //把cookie的值取出，然后url解码 value=URLDecoder.decode(value,"utf-8"); System.out.println(cookie.getName()+" : " + value); &#125;&#125;else &#123; System.out.println("其中没有cookie");&#125; cookie的限制 cookie可以被用户禁止 cookie不安全 ，对于敏感信息一定要加密 cookie的数据大小有限制，大约4k左右 cookie总数也有限制，大约200个左右 使用cookie记录客户端访问次数1234567891011121314151617181920212223242526272829@Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; Cookie[] cookies = request.getCookies(); Map&lt;String, String&gt; map = getValues(cookies); //获取map String stringCount = map.get("count"); // 获取指定的value if (stringCount == null) &#123;// 第一次请求 stringCount = "1"; // 设置访问次数为1 &#125; else &#123;// 不是第一次请求 // 请求次数+1 stringCount = "" + (Integer.parseInt(stringCount) + 1); &#125; Cookie cookie = new Cookie("count", stringCount); // 把运行次数放置到cookie中 response.addCookie(cookie); // 添加cookie,如果前面已经存在了，那么相当于更新cookie的值 System.out.println(stringCount); &#125; /** * 将cookie数组中的键值对存放到Map中,这样就能判断出这个cookie中是否含有指定的key */ public Map&lt;String, String&gt; getValues(Cookie[] cookies) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); if (cookies != null) &#123; for (Cookie cookie : cookies) &#123; map.put(cookie.getName(), cookie.getValue()); &#125; &#125; return map; &#125; 使用cookie保存登录的用户名和信息 需求： 当用户选择了记住用户名和密码的选项，那么当用户登录成功的时候，接下来每次请求登录页面的时候浏览器会自动显示之前成功登录的用户名和密码 实现： 一个单选按钮，选择是否记录登录信息，jsp页面 在表单提交给servlet之后，验证用户是否登录成功，如果登录成功了并且还选择了记住用户名和密码，那么就将此时的用户名和密码信息添加到cookie中 在每次跳转到登录页面的时候都需要经过一个Servlet，这个Servlet的作用是获取cookie的值，并且存放在request域中，这样在login.jsp页面中就可以使用这个值 login.jsp 123456789101112131415161718192021222324252627&lt;form action="/Servlet01/RememberLoginServlet" method="post"&gt; &lt;table cellpadding="0" cellspacing="0" border="0" class="form_table"&gt; &lt;tr&gt; &lt;td valign="middle" align="right"&gt;username:&lt;/td&gt; &lt;td valign="middle" align="left"&gt;&lt;input type="text" class="inputgri" name="username" value="&lt;%=request.getAttribute("username") %&gt;" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td valign="middle" align="right"&gt;password:&lt;/td&gt; &lt;td valign="middle" align="left"&gt;&lt;input type="password" class="inputgri" name="password" value="&lt;%=request.getAttribute("password") %&gt;" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td valign="middle" align="left"&gt; &lt;input type="checkbox" name="isRemember"&gt;记住用户名和密码一周 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;p&gt; &lt;input type="submit" class="button" value="Submit &amp;raquo;" /&gt; &lt;/p&gt; &lt;/form&gt; 验证用户，保存信息到cookie中的servlet 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Overrideprotected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; request.setCharacterEncoding("UTF-8"); // 设置中文格式 //设置响应字符集必须写在获取输出对象的前面 response.setContentType("text/html;charset=utf-8"); PrintWriter writer=response.getWriter(); // 获取用户名和密码 String username = request.getParameter("username"); String password = request.getParameter("password"); String isRemeber = request.getParameter("isRemember"); // 登录流程 Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConn(); // 获取连接 String sql = "select count(*) c from user where username=? and password=?"; statement = connection.prepareStatement(sql); //创建预编译对象 //设置占位符的值 statement.setString(1, username); statement.setString(2, password); resultSet = statement.executeQuery(); // 执行查询语句 //遍历查询结果集，如果count&gt;0 表示登录成功，如果=0表示用户名或密码错误 while (resultSet.next()) &#123; int count = resultSet.getInt("c"); // 获取总数 if (count &gt; 0) &#123; System.out.println("登录成功"); // 判断是否记住密码 //如果设置了记住密码，那么就将此时的用户名和密码保存在cookie中 if (isRemeber != null) &#123; //将username和password添加到cookie中 Cookie cookie=new Cookie("loginInfo", username+","+password); cookie.setMaxAge(7*24*3600); //设置时间为一周，单位为秒 response.addCookie(cookie); &#125; //跳转到首页 request.getRequestDispatcher("home.jsp").forward(request, response); &#125; else &#123; System.out.println("登录失败，用户名或密码错误"); response.sendRedirect("/Servlet01/ShowLoginCookieServlet"); //重定向到登录界面 &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); writer.write("服务器出错....."); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 获取cookie值，存放到request域中，便于在login.jsp页面中访问到信息 1234567891011121314151617181920212223242526272829@Overrideprotected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; Cookie[] cookies = request.getCookies(); Map&lt;String, String&gt; map = getValues(cookies); String loginInfo = map.get("loginInfo"); // 获取cookie的值 String username = ""; String password = ""; if (loginInfo != null) &#123; username = loginInfo.split(",")[0]; // 分割字符串，获取信息 password = loginInfo.split(",")[1]; &#125; request.setAttribute("username", username); request.setAttribute("password", password); request.getRequestDispatcher("login.jsp").forward(request, response);&#125;/** * 将cookie数组中的键值对存放到Map中,这样就能判断出这个cookie中是否含有指定的key */public Map&lt;String, String&gt; getValues(Cookie[] cookies) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); if (cookies != null) &#123; for (Cookie cookie : cookies) &#123; map.put(cookie.getName(), cookie.getValue()); &#125; &#125; return map;&#125; Session 服务端为了保存状态（数据）创建的一个特殊的对象，session数据会保存在服务器 工作原理 当浏览器第一次向服务器请求，服务器创建一个session对象，然后把session对象的唯一标识sessionid以cookie的形式返回给浏览器，服务器通过sessionid找到上次保存的session对象，这样的话多次请求只需要把数据保存在session对象中， 如何创建Session对象 HttpSession session=request.getSession(boolean flag) 参数为false，如果不存在这个session，那么就返回一个null 参数为true，会通过cookie中的sessionid获取之前保存的session对象，如果有则返回，如果没有则创建一个新的session，这个是默认的形式（缺省值为true） 添加删除数据 setAttribute(key,value) getAtttribute(key,value) removeAttribute(key) session超时 session默认时间是在服务器保存30分钟 如何修改session存活时间 修改配置文件 在servers中的web.xml中查找如下123&lt;session-config&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt; &lt;/session-config&gt; 通过代码设置时间 session.setMaxInactiveInterval(int mils); 单位为秒 删除session session.invalidate() 删除session中的数据 session.removeAttribute(key) 实现自动登录（Session) 这个在学到过滤器的时候再讲 Base64加密 什么是Base64： 将任意二进制数据转换成字符串（由64个基础字符组成a-z A-Z 0-9 + /),可以将需要加密的字符串转换成二进制数据后再转换成Base64的字符串，也可以把任意文件的二进制数据转换成可见的字符串 123456789String pw="admin";BASE64Encoder encoder=new BASE64Encoder();String newPW=encoder.encode(pw.getBytes("utf-8"));System.out.println(newPW);//解密BASE64Decoder decoder=new BASE64Decoder();String oldPw=new String(decoder.decodeBuffer(newPW),"utf-8");System.out.println(oldPw); 比较cookie和Session cookie： 优点不占用服务器资源，缺点：大小有限制4k 数量限制200左右 内容有限制只能存放字符串，cookie不够安全而且有些浏览器可以模拟cookie数据 Session： 优点:安全（因为数据保存在服务器）大小无限制，保存数据类型丰富，缺点： 占用资源，浏览器关闭后Session则失效,因为session的是状态是存储在cookie中的seessionid决定的。 自动登录加强版 需要自己创建一个cookie 过滤器什么是过滤器 Servlet规范中定义的是一种特殊组件，用来拦截web容器调用Servlet/jsp组件的过程 好处： 可以在不改动Servlet的情况下增加业务功能，可以起到代码复用的作用，因为一个过滤器可以对应拦截多个Servlet 如何创建一个过滤器 new - &gt; Filter 这样就创建一个过滤器，其中的类实现了Filter这个接口 12345678910111213141516171819public class MyFilter implements Filter &#123; public MyFilter() &#123; &#125; public void destroy() &#123; System.out.println("过滤器被销毁"); &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println("过滤器执行"); chain.doFilter(request, response); &#125; public void init(FilterConfig fConfig) throws ServletException &#123; System.out.println("过滤器初始化"); &#125;&#125; 这个类中同样有init和destroy方法，但是实现代码逻辑实在doFilter()这个方法中 在web.xml中配置这个过滤器1234567891011&lt;!-- 配置Filter 的name和class --&gt; &lt;filter&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;filter-class&gt;cn.filter.MyFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;!-- 配置Filter的过滤的url，其中的name是前面定义好的 --&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;!-- /* 拦截所有的Servlet,但是也拦截器了这个路径下的jsp ，如果设置成/MyServlet,那么只拦截这一个Servlet--&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 过滤器的生命周期 创建： 无参构造方法，当web容器启动时，会自动创建过滤器 初始化： init()方法 当过滤器创建后会自动调用 销毁: destroy()方法 当应用程序从web容器中卸载时 doFilter(): 当调用被拦截器的Servlet或者jsp的时候执行，在此方法中执行doFilter方法相当于执行Servlet里面的Service方法，因为过滤器里面的Request和Response对象和Servlet中的是同一对象，所以在Servlet里面做的任何事都可以在过滤器中实现 案例： 实现评论功能 如果出现了敏感字符禁止访问 步骤 准备一个Comment.jsp页面，页面中有一个文本框和一个提交按钮 如果出现敏感信息禁止提交，并跳转到原页面重新填写评论 123456public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest req=(HttpServletRequest)request; //继续执行下面的Filter和Servlet，没有这个方法，那么将不会执行 chain.doFilter(request, response); &#125; 如果配置多个过滤器拦截器同一个请求地址 此时多个过滤器都会响应，哪个先执行，取决于在web.xml中哪个过滤器先配置，先配置的先执行 &lt;init-param&gt;设置初始化值 配置Filter 的初始化值，在web.xml中定义 其中的 12345678&lt;filter&gt; &lt;filter-name&gt;CommentFiletr&lt;/filter-name&gt; &lt;filter-class&gt;cn.filter.CommentFiletr&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;word&lt;/param-name&gt; &lt;param-value&gt;美女,我操&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; 获取其中的值 在init中初始化FilterConfig对象 在doFilter中使用FilterConfig对象获取初始化值即可123456789101112131415161718192021public class CommentFiletr implements Filter &#123; private FilterConfig config; //定义成员变量FilterConfig对象 public CommentFiletr() &#123; &#125; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; String word=this.config.getInitParameter("word"); //获取初始化值 chain.doFilter(request, response); &#125; //初始化方法 public void init(FilterConfig fConfig) throws ServletException &#123; this.config=fConfig; &#125;&#125; ServletContext（上下文） 定义： web服务器启动的时候会为每一个应用创建一个符合ServletContext接口的对象 特点： 唯一性： 整个工程中只有一个 持久性： 只要容器不关闭，整个ServletContext对象就会存在于内存中 应用场景： 负责传递数据（共享数据），任何一个组件往ServletContext对象中保存数据都可以给整个工程的所有Servlet访问 可以在web.xml中获取全局的初始化数据 如何配置参数 在web.xml中配置即可 如果想要配置多个，那么可以定义多个&lt;context-param&gt;即可 1234&lt;context-param&gt; &lt;param-name&gt;name&lt;/param-name&gt; &lt;param-value&gt;陈加兵&lt;/param-value&gt;&lt;/context-param&gt; 在组件中获取ServletContext(在任何组件中都可以获取) 在Servlet中获取 1234protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; ServletContext context=this.getServletContext(); //获取对象 String name=context.getInitParameter("name"); //获取name属性的值&#125; 在Filter中获取 12345//初始化方法public void init(FilterConfig fConfig) throws ServletException &#123; ServletContext context=fConfig.getServletContext(); String name=context.getInitParameter("name");&#125; 添加和获取数据 getAttribute(key) setAttribute(key,value) Request,Session,ServletContex，PageContext作用范围 ServletContext &gt; Session &gt; Request &gt; PageContext 如何选择传递数据的域：符合需求的域中，选择范围最小的 监听器 Listener什么是监听器 Servelt规范中定义的一个特殊组件，用来监听容器内部各组件的事件 组件会有两大类事件 生命周期相关事件(比如session的创建的和销毁) 绑定数据相关事件 如何创建监听器Listener new --- &gt; Listener ---&gt; 类名 ---&gt; next -- &gt; 选择对应的Listener 具体的选项如下图 选项中有三大域的监听器，ServletContext，Session，Request 其中Liftcycle 是 生名周期金监听器 其中可以监听三大域的创建和销毁-Change to Attributes 是三大域绑定删除数据监听器 创建成功之后会在web.xml中自动为我们填上监听器的配置 123&lt;listener&gt; &lt;listener-class&gt;cn.listener.MyListener&lt;/listener-class&gt;&lt;/listener&gt; 统计在线人数 当开始一个会话将会就表示在线人数+1，因此需要监听Session的生命周期 因为我们是统计在线人数，因此我们需要在jsp页面中显示出人数，我们需要将在线人数这个变量存放在ServletContext才能实现共享，这样只有当web容器关闭才会清空其中的在线人数 如果存放在session中，那么当浏览器关闭就会清空session中的数据，或者到了指定的时间也会清空，因此我们不能存放在Session 创建一个监听Session的监听器 1234567891011121314151617181920212223242526272829public class MyListener implements HttpSessionListener &#123; //Session创建时调用的方法 public void sessionCreated(HttpSessionEvent sessionEvent) &#123; System.out.println("会话开始"); // 取出当前在线人数 ServletContext context = sessionEvent.getSession().getServletContext(); // 得到ServletContext Integer count=(Integer) context.getAttribute("count"); //获取当前的在线人数 // 如果count是第一次，那么此时的count就是null，因为这里还没有设置这个上下文参数 if (count == null) &#123; count = 1; &#125; else &#123; count++; &#125; // 将在线人数保存回去 context.setAttribute("count",count); &#125; //Session销毁时调用的方法 public void sessionDestroyed(HttpSessionEvent event) &#123; System.out.println("会话结束"); ServletContext context = event.getSession().getServletContext(); Integer count=(Integer) context.getAttribute("count"); //获取当前的在线人数 count--; // 直接人数-1 // 将此时的人数保存回去 context.setAttribute("count",count); &#125;&#125; 缓存数据练习 创建一ServletContext生命周期监听器，在ServletContext创建的的方法中读取数据库中的数据并将数据保存在ServletContext中，因为ServletContext在容器创建的时候就会创建，因此在web容器开启的时候就会读取数据库中的信息 我们在Servlet中直接读取ServletContext中的数据即可，不同在请求Servlet的时候从数据库中读取，提高Servlet的响应效率 好处 在我们使用同一种数据的时候，并且数据常用，我们可以在web容器启动的时候就加载出来，不用每次用到该数据就请求一次读取数据库一次，提高了效率 代码123456789101112131415public class CacheListener implements ServletContextListener &#123; //ServletContext销毁的时候调用 public void contextDestroyed(ServletContextEvent event) &#123; System.out.println("销毁"); &#125; //ServletContext初始化的时候调用 public void contextInitialized(ServletContextEvent event) &#123; ServletContext context=event.getServletContext(); //获取ServletContext对象 EmpDao empDao=new EmpDao(); //创建Dao对象，用于读取数据库中的信息 List&lt;Emp&gt; emps=empDao.findAll(); //获取所有的数据 context.setAttribute("emps", emps); //添加到ServletContext中 &#125;&#125; 各组件执行顺序 MyServlet、MyListener(监听ServletContext),MyFilter web容器启动 – &gt; MyListener(监听) — &gt; MyFilter实例化 – &gt; 请求 —&gt; MyFilter(doFilter) —&gt; 执行MyServlet Servlet线程安全问题为什么 为什么会有线程安全问题：因为每一个请求 服务器都会开启一条新的线程来执行，这样的话如果请求量比较大出现高并发访问就会出现多条线程同时执行，如果多一条线程执行的过程中，有需要去修改同一份数据，则有可能出现线程安全问题，即一条数据没有处理完，另外一条数据把数据取走 解决方案 通过同步代码块，将可能会出现线程安全的代码包裹起来，这样就可以解决线程安全问题 实例 假设我们的线程不安全的Servlet如下 12345678910111213141516171819public class ThreadSafeServlet extends HttpServlet &#123; private int count = 0; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; System.out.println(Thread.currentThread().getName() + "：开始执行" + count); try &#123; Thread.sleep(5000); //线程睡眠5s &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; count++; System.out.println(Thread.currentThread().getName() + "：执行完毕" + count); &#125;&#125; 我们在浏览器多次请求这个servlet，那么我们可以看到输出的每一个开始执行的count的值都是0，但是我们后面都count++了，从此可以看出线程不安全，那么我们添加一个同步代码块来确保线程安全 123456789101112131415161718192021public class ThreadSafeServlet extends HttpServlet &#123; private int count = 0; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //同步代码块 synchronized (this) &#123; System.out.println(Thread.currentThread().getName() + "：开始执行" + count); try &#123; Thread.sleep(5000); //线程睡眠5s &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; count++; System.out.println(Thread.currentThread().getName() + "：执行完毕" + count); &#125; &#125;&#125; JSP扩展什么是JSP java Server page java服务器页面 jsp文件部署到web容器时会自动转成Servlet组件，添加到容器中 如何写jsp java代码的写法 &lt;% %&gt; 写java代码，任意java代码都行，转化成Servlet的时候直接是写在service方法体中 &lt;%! %&gt; 声明变量或者方法，转换成Servlet的时候直接作为其成员变量或者成员方法 &lt;%= %&gt; java表达式，返回的是一个值 指令 高速容器，将jsp转成Servlet的时候所做的一些额外操作 &lt;%@ page&gt; ： import导包 contentType pageEncoding session的默认值为true，如果值为false，则在java代码中不能使用session隐式对象 errorPage :指定jsp里面出现异常时显示的页面 isErrorPage : 设置当前页面为错误异常页面，默认为false，设置为true之后页面中才可以使用exception获取异常信息 tablib ： 引入标签库 JSP中隐式对象什么是隐式对象 在JSP中可以不用创建，可以直接使用的对象 为什么可以直接使用 因为将JSP转成Servlet类的时候会自动创建的对象 有哪些 （九大隐式对象) 面试中常考 application ： 类型为ServletContext，该实例表示jsp所属的web应用本身，可以用于多个组件间共享或传递数据，常用方法有setAttribute(),getAttribute(),removeAttribute()和getInitParameter() session : 类型为HttpSession，用于在同一个会话中共享数据，常用方法有setAttribute(),getAttribute(),removeAttribute() request ：类型HttpServeltRequest，用于在同一个请求中共享数据，常用方法有setAttribute(),getAttribute(),removeAttribute() pageContext : 用于在同一个jsp中共享数据，常用方法有setAttribute(),getAttribute(),removeAttribute() 12345&lt;%pageContext.setAttribute("name", "陈加兵");%&gt;&lt;h1&gt;&lt;%=pageContext.getAttribute("name") %&gt;&lt;/h1&gt; response : 类型HttpServletResponse,用于处理响应数据和重定向，因为有out，更多使用的是out out ： 类型为JSPWriter，用于输出数据 page ： page就是jsp本身，因为jsp最终会转成Servlet，page相当于this exception : 异常对象，用于获取异常信息，只有当page指令里面添加了isErrorPage=true的时候才能使用 config ： 类型为ServletConfig，用于获取配置文件中初始化参数 JSP的注释 &lt;!--注释内容--&gt; ： 代码会被注释但是代码会被执行 &lt;%-- 注释内容 --%&gt; ： 代码会被注释，不会执行 JSP如何执行的 将JSP转成Servlet 调用Servlet JSP标签和EL表达式什么是jsp标签 是sun公司提供的一套类似于html标签的内容，用于替换jsp中出现的java代码 因为在jsp中写java代码不利于维护，代码的可读性也很差，以后工作时显示相关的内容很可能交给前端工程师或者美工，所以在jsp中尽量不要出现java代码，所以才产生了jsp标签 什么是EL表达式 一套简单的运算规则，用于从域对象中取值，然后给jsp中标签的属性赋值 EL表达式的使用(${}) 访问Bean对象中的属性(属性必须有get方法) ${对象名.属性名},假设一个对象user，访问其中的name属性，我们可以使用 ${user.name}，这个相当于调用了user.getName()方法 EL表达式执行过程 ${user.name} 会先从pageContext域中查找如果有则用，如果没有会到request域中查找，如果没有再到session域中查找，如果没有再到ServletContext中查找 如果找不到直接输出空字符串&quot;&quot;,如果没有获取到对象调用对象的方法不会报空指针异常，仍然输出空字符串 指定域获取 ${requestScope.user.name} 相当于 request.getAttribute(&quot;user&quot;).getName() pageScope requestScope sessionScope applicationScope ${user[&#39;name&#39;]} 个人不推荐使用 使用EL表达式获取请求参数(使用不多，一般都是在Servlet获取) 直接使用${param.请求参数名} 获取指定的请求参数 ${param.name} 相当于request.getParameter(&quot;name&quot;) ${paramValues.参数名[index]} 获取多个同名参数 相当于request.getParameterValues(&quot;参数名&quot;)[index] EL表达式的简单运算 运算结果可以直接给标签的属性赋值 算术运算符 可以直接使用加减乘除 ${1+2},${5/2},${5*3} 注意： +只能做求和运算，不能字符串拼接 逻辑运算符 ${true and false}=false,${true and true}=true,${true or false}=true 关系运算符 使用 ==, != , &gt;=,&lt;, &gt; , &lt;= , &amp;&amp; , || 如： ${age&lt;30} 可以直接在EL表达式比较大小，返回的也是false和true，可以用来判断，如下：${1&lt;2}=false ,${(10*10)&gt;200}=true,${age&gt;11&amp;&amp;age&lt;20} empty 判断是否为空(空字符串或者值为null) 判断字符串为null或者为空字符串 判断数组，值为null和不为null但是数组里面没有数据都会返回true 判断对象为null ${empty str} 判断字符串是否为空 ${empty user} 判断对象user是否为空 jstl java standard tab lib （java标准标签库） jstl是Apache开发的一套jsp标签 如何使用 导入jstljar包,使用maven，在pom.xml中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 通过tablib指定引入标签库 &lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; ， uri：是标签库的命名空间，代表标签库的唯一标识，prefix ：别名或前缀 几个核心标签 if标签， &lt;c:if test=&quot;&quot;&gt; test中填写的是判断条件，使用EL表达式 var ： test中的判断结果，如果test中的判断为真，那么此时var的变量值为true scope ： 将var中的变量存放到指定的域中，便于直接访问12345678910&lt;% request.setAttribute("age", 22);%&gt;&lt;c:if test="$&#123;requestScope.age&gt;20 &#125;"&gt; &lt;h1&gt;&lt;c:out value="年龄大于20"&gt;&lt;/c:out&gt;&lt;/h1&gt;&lt;/c:if&gt;&lt;c:if test="$&#123;requestScope.age&gt;10 &#125;" var="result" scope="session"&gt; &lt;h2&gt;此时的判断结果为 : $&#123;sessionScope.result &#125;&lt;/h2&gt;&lt;/c:if&gt; choose标签 （相当于switch case） 需要和 when，otherwise结合使用1234567891011121314151617&lt;%User user=new User();user.setUsername("libai");user.setPassword("admin");request.setAttribute("user", user);%&gt;&lt;c:choose&gt; &lt;c:when test="$&#123;user.username=='libai' &amp;&amp; user.password=='admin' &#125;"&gt; &lt;h1&gt;登录成功&lt;/h1&gt; &lt;/c:when&gt; &lt;!-- 其他的任何类型的判断，只要不是when中的，都在这里执行，相当于else --&gt; &lt;c:otherwise&gt; &lt;h1&gt;登录失败&lt;/h1&gt; &lt;/c:otherwise&gt;&lt;/c:choose&gt; forEach标签 相当于java中的forEach，由于遍历集合或者数组 items : 需要遍历的集合或者数组 var ：遍历的对象的变量名称，遍历时会把当前遍历的对象绑定在PageContext域中，需要获取遍历对象的内容时直接使用EL表达式从域中获取出来 begin ： 开始的索引 end ： 结束的索引 step ： 指定步长，默认的步长为1 varStatus : 遍历的状态，如果需要得到遍历对象的下标调用index，如果想要得到遍历对象是集合中的第几个调用count 1234567891011121314151617181920212223&lt;table width="500" border="1"&gt; &lt;tr&gt; &lt;th&gt;用户名&lt;/th&gt; &lt;th&gt;密码&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;th&gt;级别&lt;/th&gt; &lt;th&gt;下标&lt;/th&gt; &lt;th&gt;第几个&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach var="user" items="$&#123;requestScope.users &#125;" begin="0" end="19" step="1" varStatus="s"&gt; &lt;c:if test="$&#123;s.index%2==0 &#125;"&gt; &lt;tr id="row1"&gt; &lt;/c:if&gt; &lt;c:if test="$&#123;s.index%2!=0 &#125;"&gt; &lt;tr id="row2"&gt; &lt;/c:if&gt; &lt;td&gt;$&#123;user.username &#125;&lt;/td&gt; &lt;td&gt;$&#123;user.password &#125;&lt;/td&gt; &lt;td&gt;$&#123;user.gender &#125;&lt;/td&gt; &lt;td&gt;$&#123;user.level &#125;&lt;/td&gt; &lt;!-- 下标 --&gt; &lt;td&gt;$&#123;s.index &#125;&lt;/td&gt; &lt;!-- 第几个 --&gt; &lt;td&gt;$&#123;s.count &#125;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt;&lt;/table&gt; 自定义标签 简单标签技术 复杂标签技术：支持标签内部写java代码 简单标签技术(继承SimpleTagSupport) 创建自定义标签的类(继承SimpleTagSupport) get，set方法必须1234567891011121314151617181920212223242526272829303132import java.io.IOException;import java.io.PrintWriter;import javax.servlet.jsp.JspException;import javax.servlet.jsp.JspWriter;import javax.servlet.jsp.PageContext;import javax.servlet.jsp.tagext.SimpleTagSupport;public class HelloTag extends SimpleTagSupport &#123; private int count; //标签的属性count private String msg; //属性msg @Override public void doTag() throws JspException, IOException &#123; PageContext context=(PageContext) this.getJspContext(); //获取PageContext隐式对象 JspWriter out=context.getOut(); //获取JSPWriter对象，用于在JSp页面中输出内容 for(int i=0;i&lt;count;i++)&#123; out.println(msg+"&lt;br/&gt;"); &#125; &#125; public int getCount() &#123; return count; &#125; public void setCount(int count) &#123; this.count = count; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; 定义hello.tld文件(WEB-INF下) 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!-- 约束不用改写，直接copy --&gt;&lt;taglib xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-jsptaglibrary_2_1.xsd" version="2.1"&gt; &lt;!-- 标签库的版本号 --&gt; &lt;tlib-version&gt;1.1&lt;/tlib-version&gt; &lt;!-- 推荐别名 --&gt; &lt;short-name&gt;d&lt;/short-name&gt; &lt;!-- 随便起，只要保证唯一性即可，这个是唯一标识 --&gt; &lt;uri&gt;http://www.tedu.cn/hello&lt;/uri&gt; &lt;tag&gt; &lt;!-- 标签名 --&gt; &lt;name&gt;hello&lt;/name&gt; &lt;!-- 标签的类，自定义的类 --&gt; &lt;tag-class&gt;cn.servlet.HelloTag&lt;/tag-class&gt; &lt;!-- 设置成没有标签体 --&gt; &lt;body-content&gt;empty&lt;/body-content&gt; &lt;!-- 定义标签的属性 --&gt; &lt;attribute&gt; &lt;!-- 属性的名字 --&gt; &lt;name&gt;msg&lt;/name&gt; &lt;!-- 是否设置成必须的 --&gt; &lt;required&gt;true&lt;/required&gt; &lt;!-- 是否运行EL表达式赋值 --&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;attribute&gt; &lt;name&gt;count&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;rtexprvalue&gt;true&lt;/rtexprvalue&gt; &lt;/attribute&gt; &lt;/tag&gt;&lt;/taglib&gt; 在jsp中引入这个标签库 1234&lt;!-- 引入自定义的标签库 --&gt;&lt;%@ taglib prefix="d" uri="http://www.tedu.cn/hello"%&gt;&lt;d:hello count="20" msg="陈加兵"/&gt; &lt;body-content&gt; 其中可以写以下三种内容 JSP ： 有标签体而且标签体内可以写java代码(只有复杂标签技术才支持) empty ：没有标签体 scriptless ： 有标签体，但是标签体内不能写java代码]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate关联查询]]></title>
      <url>%2F2018%2F04%2F24%2FHibernate%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%2F</url>
      <content type="text"><![CDATA[Hibernate关联查询关联查询之延迟加载(lazy)什么是延迟加载 前面单独讲过延迟加载就是在根据id查询获取的对象中只是有一个id的属性值，只有当使用其他属性的时候才会发出sql语句查询数据库，session.load(Class&lt;T&gt; cls,id)就是这个原理 什么是关联查询的延迟加载 简单的说就是在关联关系中，根据id查询对象的时候仅仅发出sql语句查询的是当前的实体类的表，并没有查询另外一张表的数据，只有当需要使用另外一张表的对象中的属性时才会发出sql语句查询另外一张表 一对一 在一对一的关系中默认使用的不是延迟加载，而是饿汉式的加载方式(EAGER),即是查询一个对象，并且也会随之查询另外一个对象的数据，发出的sql语句是左外连接查询 使用懒加载可以减轻数据库服务器的压力，只有当用到数据的时候才会发出select语句查询 我们可以使用@OneToOne(fetch=FetchType.LAZY)其中的fetch有两个值，一个是FetchType.LAZY(懒加载)，一个是FetchType.EAGER(饿汉式) 测试 使用前面讲过的Student和Teacher类 测试默认的情况(饿汉式的加载) 由于是默认的就是饿汉式的查询方式，因此不需要改变实体类 测试方法 我们根据id查询husband的数据，这里发出的sql语句是左外连接语句，相当于：select * from husband h left join wife w on h.wifeid=w.id where h.id=? 123456789101112131415161718192021222324252627@Test public void Test1() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=1的husband数据，这里将会使用左外连接查询数据，直接联表查询 Husband husband=session.get(Husband.class, 1); //获取Husband中的Wife对象属性 Wife wife=husband.getWife(); //输出wife的属性age的值，由于前面已经查询过了，因此这里不再发出sql语句 System.out.println(wife.getAge()); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; 测试懒加载 需要在@OneToOne注解中添加fetch属性，我们测试单向外键关联的懒加载(通过Husband类访问Wife的信息) Husband类，使用懒加载 12345678910111213141516171819202122232425262728293031323334353637383940414243@Entity //指定实体类@Table(name="husband") //指定对应数据库的表名为husbandpublic class Husband &#123; private int id; private String name; private int age; private Wife wife; //Wife对象 @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @OneToOne(fetch=FetchType.LAZY) //设置wife的主键为Husband的外键，默认的对应表中的字段为wife_id @JoinColumn(name="wifeid") // 默认外键的名字为wife_id.我们使用这个注解改变外键的名字为wifeid public Wife getWife() &#123; return this.wife; &#125; public void setWife(Wife wife) &#123; this.wife = wife; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + ", Wife=" + this.wife + "]"; &#125;&#125; 测试方法 12345678910111213141516171819202122232425262728@Test public void Test1() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=1的husband数据，这里使用懒加载，只会查找husband的表，并不会联表查询 Husband husband=session.get(Husband.class, 1); //获取Husband中的Wife对象属性，此处依然没有查询wife表 Wife wife=husband.getWife(); //输出wife的属性age的值，此处发出sql语句查询wife表，验证了只有当用到的wife属性的时候才会发出查询语句 System.out.println(wife.getAge()); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; 总结 默认使用的饿汉式的查询方式，因此在访问数据量过大的时候，我们可以设置懒加载的方式 如果是双向外键关联的关系，我们可以在两个@OneToOne都设置fetch属性的值为懒加载 一对多或者多对一 如果是@ManyToOne的方式，那么默认的就是EAGER方式进行查找。当我们使用get语句查找Many的对象的时候，那么我们会看到发出的select语句其实也在查找作为其属性的One的那一方的信息，但是如果我们设置LAZY,那么使用get语句查找Many的时候将不会直接查找One的一方，而是在用到One的信息的时候才会发出select语句查找One的一方。可以提高性能，使用如下：@ManyToOne(fetch=FetchType.LAZY) 使用@OneToMany默认的fetch是LAZY，即是当查询One的一方的时候只是发出了查找One的一方的select语句。只有当调用其中的Many一方的对象的属性的时候才会发出select语句查询。 多对多 多对多的关联查询默认使用的懒加载(LAZY) 如果想要设置饿汉式加载，可以使用@ManyToMany(fetch=FetchType.EAGER)，这里就不在演示了 如果在双向外键关联中都要饿汉式加载，那么可以在两个@ManyToMany注解中设置属性]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate关联关系]]></title>
      <url>%2F2018%2F04%2F24%2FHibernate%E5%85%B3%E8%81%94%E5%85%B3%E7%B3%BB%2F</url>
      <content type="text"><![CDATA[Hibernate关联关系一对一背景 在中国一个丈夫只能有一个妻子，那么丈夫和妻子的关系就是一对一的关系 准备 创建丈夫和妻子的实体类 丈夫的实体类 1234567891011121314151617181920212223242526272829303132@Entity@Table(name="husband")public class Husband &#123; private int id; private String name; private int age; @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + "]"; &#125;&#125; 妻子的实体类 123456789101112131415161718192021222324252627282930313233@Entity@Table(name="wife")public class Wife &#123; private int id; private String name; private int age; @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + "]"; &#125;&#125;个 单向外键关联 单向外键关联简单的说就是只能通过一张表访问到另外一张表的数据，不能也从另外一张表访问到这张表的数据。 比如：我们可以通过丈夫的信息访问到妻子的信息，那么在丈夫的表中就必须有妻子的外键。同样的，我们也可以通过妻子的信息访问到丈夫的信息，那么在妻子的表中必须有丈夫的外键。 简单的说就是只能单向访问，要么是通过妻子访问丈夫，要么是通过丈夫访问妻子 通过丈夫访问妻子 根据上面的需求，那么此时的妻子的主键将作为丈夫的外键，这样才可以通过丈夫访问到妻子的信息，其实的sql语句是这样的，如下：select * from husband h join wife w on h.wife_id=w.id; 妻子的主键作为丈夫的外键，那么这个是表中的关系，在实体类中的关系就是妻子的对象作为丈夫的实体类的属性，这样丈夫才可以访问到妻子的信息。 完整的Husband实体类的代码 如果使用自动生成表的话，那么默认生成的外键名称为 类名小写_id，但是我们可以使用@JoinColumn(name=&quot;&quot;)改变外键的名称 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;import javax.persistence.Table;@Entity //指定实体类@Table(name="husband") //指定对应数据库的表名为husbandpublic class Husband &#123; private int id; private String name; private int age; private Wife Wife; @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @OneToOne //设置wife的主键为Husband的外键，默认的对应表中的字段为wife_id @JoinColumn(name="wifeid") // 默认外键的名字为wife_id.我们使用这个注解改变外键的名字为wifeid public Wife getWife() &#123; return Wife; &#125; public void setWife(Wife wife) &#123; Wife = wife; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + "]"; &#125;&#125; 实体类Wife的代码不用改变 在核心配置文件hibernate.cfg.xml添加实体类的映射即可 12&lt;mapping class="cn.tedu.bean.Husband"&gt;&lt;/mapping&gt;&lt;mapping class="cn.tedu.bean.Wife"&gt;&lt;/mapping&gt; 启动服务器我们将会看到Hibernate已经为我们创建了两张表husband和wife，其中wife的主键设置为husband的外键了(wifeid) 测试方法 我们知道妻子是作为丈夫的外键，因此这里需要先添加指定的wife数据，才可以添加对应的husband数据，所以下面的测试方法先保存了wife对象。但是在后面讲到级联操作，那么就可以直接保存husband对象便可以一起保存了wife对象数据到数据库中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154import org.hibernate.Session;import org.hibernate.Transaction;import org.junit.Test;import cn.tedu.bean.Husband;import cn.tedu.bean.Teacher;import cn.tedu.bean.Wife;import cn.tedu.utils.HibernateUntil;public class TestOneToOne &#123; /** * 添加数据到husband中 */ @Test public void TestAdd() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //创建wife对象，并且设置属性值，由于主键是自增长的，因此这里不需要自己设置 Wife wife=new Wife(); wife.setAge(22); wife.setName("Marry"); //新建husband对象 Husband husband=new Husband(); husband.setAge(22); husband.setName("陈加兵"); //将Wife的对象添加到Husband中，如果这里设置了级联操作，那么只需要保存husband对象即可完成wife的数据保存 husband.setWife(wife); //由于没有设置级联操作，因此这里需要先保存wife对象，否则将不能在数据库中添加成功 session.save(wife); //保存丈夫的信息 session.save(husband); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; /** * 查询丈夫和对应妻子的信息 * 根据id查询，只要查询到丈夫的对象，那么妻子的信息就会保存在Husband的属性Wife对象中，因此可以通过访问其中的wife属性来获取对应妻子的信息 * 原理：使用session.get(class&lt;T&gt; cls,id)，其实发出的sql语句是外连接语句： * select * from husband h left join wife w on h.wifeid=w.id where h.id=? * 如果能够查找到对应的妻子信息就将其添加到Husband中的wife属性中，如果没有查找到那么设置wife属性为null即可，这个就是外连接 */ @Test public void TestGet() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=1的husband信息 Husband husband=session.get(Husband.class, 1); //获取对应的妻子对象 Wife wife=husband.getWife(); //输出 System.out.println(husband); System.out.println(wife); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; /** * 测试修改操作： 这里我们修改id=1的Husband对应的妻子的信息为id=2,当然前提是id=2的wife信息要存在，否则将不会成功 * 想要修改妻子的数据，直接修改Husband中的wife属性即可 */ @Test public void TestUpdate() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=1的husband信息 Husband husband=session.get(Husband.class, 1); //查询wife的id=2的对象 Wife wife=session.get(Wife.class, 2); //如果这个对象查询到 if (wife!=null) &#123; husband.setWife(wife); //修改Husband对象中的wife属性值即可 &#125; session.update(husband); //执行更新操作 //获取对应的妻子对象 // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; /** * 测试删除wife表中的数据 * 原理： 如果设置了外键关联，那么我们想要删除wife的数据，必须先要删除其中与之外键关联的丈夫的信息，或者设置Husband表中的外键为其他的wife数据 * 两种解决办法： * 1. 先删除对应的丈夫的数据 * 2. 直接将丈夫对应的表的wifeId设置为其他或者为空即可 * * 下面我们使用的是设置丈夫对应的wifeId为空，那么就可以删除其对应的妻子的数据 */ @Test public void TestDelete() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询到id=2的wife数据 Wife wife=session.get(Wife.class,2); //查询其对应的丈夫，这里还没有讲到其他的查询条件，所以我们默认id=2就是wife的id=2的对应的丈夫 Husband husband=session.get(Husband.class, 2); //将wife设置null，表示将wifeId外键设置空，因此就断了外键关联 husband.setWife(null); //删除wife session.delete(wife); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125;&#125; 通过妻子访问丈夫 那么根据需求，此时就是丈夫的主键作为妻子的外键，那么只需要在WIfe的类中添加一个Husband对象属性即可 Wife类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;import javax.persistence.Table;@Entity@Table(name="wife")public class Wife &#123; private int id; private String name; private int age; private Husband husband; @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @OneToOne //设置丈夫的主键为妻子外键 @JoinColumn(name="husbandId") // 外键名称为husbandId public Husband getHusband() &#123; return husband; &#125; public void setHusband(Husband husband) &#123; this.husband = husband; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + "]"; &#125;&#125; Husband的类不用改变，还是如第一个的样子 总结 单向连接就是只能通过一个对象访问另一个对象的属性，只需要在一个实体类中添加另外一个类的对象为成员变量即可，并且在该对象的get方法上添加OneToOne注解即可，就表示这个对象的主键会作为该实体类的外键 双向外键关联(@OneToOne(mappedBy=””) 所谓的双向的外键关联，就是两个实体类可以互相访问对方的属性，那么此时就需要在两个实体类中都要添加对方的对象为成员变量 问题 在两个实体类中都添加对方的对象作为自己的成员变量，那么我们此时就需要在两个实体类中都要使用OneToOne注解，但是我们使用了OneToOne就会在两张表中都会将对方的主键作为自己的外键，显然是没有必要的，冗余。 解决办法 我们在不想作为外键的属性的get方法上添加mappedBy,或者在想要成为对方的外键的类中的对方的对象的get方法中添加即可。 但是我们需要注意的是： mappedBy=”“，其中的值一定要和该类对象对方类中属性的字段相同 实现 我们让Wife作为Husband的外键，所以mappedBy添加到Wife类中的Husband对象的get方法头上即可 Husband实体类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;import javax.persistence.Table;@Entity //指定实体类@Table(name="husband") //指定对应数据库的表名为husbandpublic class Husband &#123; private int id; private String name; private int age; private Wife Wife; //Wife对象 @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @OneToOne //设置wife的主键为Husband的外键，默认的对应表中的字段为wife_id @JoinColumn(name="wifeid") // 默认外键的名字为wife_id.我们使用这个注解改变外键的名字为wifeid public Wife getWife() &#123; return Wife; &#125; public void setWife(Wife wife) &#123; Wife = wife; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + ", Wife=" + Wife + "]"; &#125;&#125; Wife类(添加@oneToOne(mappedBy=”wife”)) 将维护权交给了wife，表示wife作为husband的外键 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;import javax.persistence.Table;@Entity@Table(name="wife")public class Wife &#123; private int id; private String name; private int age; private Husband husband; //Husband对象 @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; /** * mappedBy="对方类中的该类的属性名字"，注意这里的名字和一定要和对方类中的成员变量的字段一样 * 表示将维护权交给对方类中的当前类的对象，就是表示当前类的主键将会作为外键 */ @OneToOne(mappedBy="wife") //设置关联，并且将维护权交给了对方类中的属性wife，因此这里的外键就是wifeId public Husband getHusband() &#123; return husband; &#125; public void setHusband(Husband husband) &#123; this.husband = husband; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Wife [id=" + id + ", name=" + name + ", age=" + age + ", husband=" + husband + "]"; &#125;&#125;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;import javax.persistence.Table;@Entity@Table(name="wife")public class Wife &#123; private int id; private String name; private int age; private Husband husband; //Husband对象 @Id @GeneratedValue //主键生成策略，自增长 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; /** * mappedBy="对方类中的该类的属性名字"，注意这里的名字和一定要和对方类中的成员变量的字段一样 * 表示将维护权交给对方类中的当前类的对象，就是表示当前类的主键将会作为外键 */ @OneToOne(mappedBy="wife") //设置关联，并且将维护权交给了对方类中的属性wife，因此这里的外键就是wifeId public Husband getHusband() &#123; return husband; &#125; public void setHusband(Husband husband) &#123; this.husband = husband; &#125; @Column(length=20) //设置长度为20 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Wife [id=" + id + ", name=" + name + ", age=" + age + ", husband=" + husband + "]"; &#125;&#125; 测试 我们只要查询到Husband对象就可以访问到其中的Wife对象的数据，同样的只要查询到Wife对象就可以访问到其中的Husband对象的数据 这里就不再测试了 一对多 一个宿舍可以被多个学生住，这个就是一对多的关系,其中宿舍是One的一方，学生是Many的一方 准备 Student实体类 12345678910111213141516171819202122232425262728293031323334import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;import javax.persistence.Table;@Entity@Table(name="student")public class Student &#123; private int id; //主键 private String name; private int age; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 宿舍的实体类 1234567891011121314151617181920212223/** * 一个宿舍可以被多个学生住 * 一个学生只能住在一个宿舍 * 学生是One * 宿舍是Many */public class Dormitory &#123; private int id; //主键 private Long number; //宿舍编号 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public Long getNumber() &#123; return number; &#125; public void setNumber(Long number) &#123; this.number = number; &#125;&#125; 前提须知 我们知道无论是一对多还是多对一的关系，在创建表的关联关系的时候，外键总是在多的一方，即是一的一方的主键作为多的一方的外键 单向外键关联 前面已经说过，单向外键关联是只能单向访问，只能一张表访问另外一张表，比如通过One的一方可以访问到Many的一方，也可以通过Many的一方访问到One的一方 从One的一方访问Many的一方(@OneToMany) 即是通过学生查询到其所住的宿舍 想要通过学生查询到所住的宿舍，那么必须在Student的实体类中必须有Dormitory的对象作为其成员变量 Dormitory类(One的一方，使用@OneToMany) 1234567891011121314151617181920212223242526272829303132333435@Entity@Table(name = "dormitory")public class Dormitory &#123; private int id; // 主键 private Long number; // 宿舍编号 private Set&lt;Student&gt; students; @Id @GeneratedValue public int getId() &#123; return id; &#125; @OneToMany //Dormitory是One的一方，Student是Many的一方，因此这里使用OneToMany @JoinColumn(name="dormitory_id") //必须指定外键的名称，否则将会自动创建第三张表来管理关联关系 public Set&lt;Student&gt; getStudents() &#123; return students; &#125; public void setStudents(Set&lt;Student&gt; students) &#123; this.students = students; &#125; public void setId(int id) &#123; this.id = id; &#125; public Long getNumber() &#123; return number; &#125; public void setNumber(Long number) &#123; this.number = number; &#125;&#125; Student类(Many的一方，不变) 测试 添加： 在为Many的一方(Student)添加宿舍信息的时候，这个宿舍的信息一定是在数据库中的，因为添加外键相当于必须这个外键存在才能添加 删除： 在删除的One的一方的时候，一定要确保Many的一方没有与其外键关联，否则将会删除失败，除非设置了级联删除，那么会连同外键关联的数据一起删除（以后再讲） 123456789101112131415161718192021222324252627282930313233@Testpublic void TestGet() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); Dormitory dormitory=new Dormitory(); dormitory.setNumber(10011L); //创建一个Set集合存储Student对象 Set&lt;Student&gt; students=new HashSet&lt;Student&gt;(); for(int i=0;i&lt;5;i++)&#123; Student student=new Student(); student.setAge(10*i); student.setName("name_"+i); session.save(student); students.add(student); // 添加到集合中 &#125; dormitory.setStudents(students); //将学生信息添加到宿舍对象中 session.save(dormitory); //保存宿舍信息 // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session != null) &#123; session.close(); &#125; &#125;&#125; 从Many的一方查询One的一方(@ManyToOne) 即是通过学生对象查询到宿舍信息，因此需要在学生的实体类中添加宿舍的实体类对象 Student实体类（使用＠ManyToOne) 12345678910111213141516171819202122232425262728293031323334353637@Entity@Table(name="student")public class Student &#123; private int id; //主键 private String name; private int age; private Dormitory dormitory; //添加Dormitory对象，因为是One的一方，因此不用Set集合存储 @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @ManyToOne //使用@ManyToOne，因为Student是Many的一方 @JoinColumn(name="dormitory_id") //设置外键的字段值 public Dormitory getDormitory() &#123; return dormitory; &#125; public void setDormitory(Dormitory dormitory) &#123; this.dormitory = dormitory; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; Dormitory实体类，不用改变，还是和前面的最初的实体类一样 双向外键关联 即是通过One的一方可以访问到Many的一方，也可以通过Many的一方访问到One的一方。简单的说就是可以互相访问对方的数据。 要想实现双向外键关联，必须是两个实体类对象互为对方的成员属性 问题并解决 因为是双向关联，因此这里的要设置双向关联的主导对象（mappedBy），否则将会出现两张表的外键都是对方的主键，这显然是冗余的，因此我们需要设置一个主导的。我们这里应该选择多的一方为主导位置的，因此需要在一的这一方使用mppedBy指定主导对象。因此我们只需要在@OneToMany上加上mappedBy属性即可。 由于无论是一对多还是多对一的关系，外加都是One一方的主键，因此要将维护权交给One的一方，因此只需要在@OneToMany这个注解中添加mappedBy这个属性即可 由于外键是在One的一方添加的，即是外键在student的表中，因此只有在Student的实体类中可以使用@JoinColumn()设置外键的字段名 实现 Student实体类(Many的一方，因此使用@ManyToOne) 12345678910111213141516171819202122232425262728293031323334353637@Entity@Table(name="student")public class Student &#123; private int id; //主键 private String name; private int age; private Dormitory dormitory; //添加Dormitory对象，因为是One的一方，因此不用Set集合存储 @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @ManyToOne //使用@ManyToOne，因为Student是Many的一方 @JoinColumn(name="dormitory_id") //设置外键的字段值,因为外键是在student表中添加的，因此只能在这个地方设置外键的字段名 public Dormitory getDormitory() &#123; return dormitory; &#125; public void setDormitory(Dormitory dormitory) &#123; this.dormitory = dormitory; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; Dormitory实体类（One的一方，使用@OneToMany) 1234567891011121314151617181920212223242526272829@Entity@Table(name = "dormitory")public class Dormitory &#123; private int id; // 主键 private Long number; // 宿舍编号 private Set&lt;Student&gt; students; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; //仍然需要注意的是mappedBy的值必须是对方类中该类对象的一样的字段 @OneToMany(mappedBy="dormitory") //添加注解，由于是双向外键关联，必须添加mappedBy,由于外键就是One的一方的主键，因此这里的只需要在OneToMany中添加即可 public Set&lt;Student&gt; getStudents() &#123; return students; &#125; public void setStudents(Set&lt;Student&gt; students) &#123; this.students = students; &#125; public Long getNumber() &#123; return number; &#125; public void setNumber(Long number) &#123; this.number = number; &#125;&#125; 总结 无论是一对多还是多对一的关系，在建立表的时候总是在Many的一方添加One的一方的外键 在单向外键关联中，如果通过One的一方获取Many的一方数据，那么需要在One的实体类中添加Many的实体类的对象为其成员变量，同时在这个成员变量的get方法上方使用@OneToMany这个注解。如果想要通过Many的一方获取One的数据，那么需要在Many的实体类中添加One的实体类的对象为其成员变量，同时在这个成员变量的get方法上使用@ManyToOne这个注解 在双向外键关联，那么我们在使用@JoinColumn改变外键的字段名，那么必须在One的实体类中使用，因为外键是设置在One的一方的表中 双向外键关联必须使用@OneToMany(mappedBy=)设置主导地位的表，如果不设置这个mappedBy，那么就会出现双向外键，出现了冗余 多对一 一对多和多对一是相对的，因此这里的使用和一对多是一样的，不再反复的讲述了 多对多背景 一个老师可以教多个学生，一个学生可以被多个老师教，那么老师和学生的关系就是多对多的关系 准备 老师的实体类(Teacher) 12345678910111213141516171819202122232425262728293031323334import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;import javax.persistence.Table;@Entity@Table(name="teacher")public class Teacher &#123; private int id; //主键 private String name; private int age; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 学生的实体类(Student) 12345678910111213141516171819202122232425262728293031323334import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;import javax.persistence.Table;@Entity@Table(name="student")public class Student &#123; private int id; //主键 private String name; private int age; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 前提须知 我们在处理多对多的关系，在建立表的时候使用的是第三张表来维护外键，如下： 单向外键关联(@ManyToMany)通过学生访问老师的信息 根据需求我们必须在Student的类中将Teacher类的对象声明为成员变量，多对多的关系，因此使用的是Set集合来存储 Student的实体类 123456789101112131415161718192021222324252627282930313233343536373839@Entity@Table(name="student")public class Student &#123; private int id; //主键 private String name; private int age; private Set&lt;Teacher&gt; teachers; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @ManyToMany //指定第三张表的名称，如果默认的是student_teacher,joinColumns指定的是当前的实体类的外键名称，inverseJoinColumns指定的是另外一个实体类的外键名称 //如果不指定外键的名称，那么默认的是student_id,和teacher_id @JoinTable(name="stu_tea",joinColumns=@JoinColumn(name="st_id"),inverseJoinColumns=@JoinColumn(name="t_id")) public Set&lt;Teacher&gt; getTeachers() &#123; return teachers; &#125; public void setTeachers(Set&lt;Teacher&gt; teachers) &#123; this.teachers = teachers; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; @JoinTable 在多对多的关系中，默认创建第三张表的名称为 ： 表名_表名，但是我们可以使用@JoinTable这个注解来修改第三张表的名称 其中的name属性可以修改 @ManyToMany 在多对多的关系中使用，在实体类对象的get方法上面使用 joinColumns指定的是当前的实体类对应的外键名称，其中的值使用的@JoinColumn注解 inverseJoinColumns指定的是另外一个实体类的外键名称，其中的值使用的是@JoinColumn注解 通过老师访问学生的信息 那么需要在Teacher类中添加一个成员变量的类型为Student对象，并且在该成员变量的get方法上使用@ManyToMany 这个就不在演示了，和上面很相似 双向外键关联(@ManyToMany(mappedBy=””)) 如果老师想要知道自己教的学生的信息，学生也想知道老师的信息，那么就需要使用多对多双向关联，在两个实体类中都要定义对方的实体类的对象，因此这样就可以访问到对方的信息了。 这个和前面说的一样，当使用双向外键联系的时候，一定要设置主导的实体类(mappedBy)否则的话就会出现冗余，因此一定要指定主导关系。 下面我们的范例是指定学生的主导位置，因此要在老师的实体类中设置mappedBy属性 Student类 由于指定Student为主导位置，因此设置外键的名称和第三张表名字只能在Student的类中设置 123456789101112131415161718192021222324252627282930313233343536373839@Entity@Table(name="student")public class Student &#123; private int id; //主键 private String name; private int age; private Set&lt;Teacher&gt; teachers; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @ManyToMany //指定第三张表的名称，如果默认的是student_teacher,joinColumns指定的是当前的实体类的外键名称，inverseJoinColumns指定的是另外一个实体类的外键名称 //如果不指定外键的名称，那么默认的是student_id,和teacher_id @JoinTable(name="stu_tea",joinColumns=@JoinColumn(name="st_id"),inverseJoinColumns=@JoinColumn(name="t_id")) public Set&lt;Teacher&gt; getTeachers() &#123; return teachers; &#125; public void setTeachers(Set&lt;Teacher&gt; teachers) &#123; this.teachers = teachers; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; Teacher类（指定学生的主导位置，因此这里不能设置外键的名称和外键的字段名） 123456789101112131415161718192021222324252627282930313233343536@Entity@Table(name="teacher")public class Teacher &#123; private int id; //主键 private String name; private int age; private Set&lt;Student&gt; students; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; @ManyToMany(mappedBy="teachers") //将维护权交给teacher表，这里的teachers是Student类中的字段名，一定要一模一样的 public Set&lt;Student&gt; getStudents() &#123; return students; &#125; public void setStudents(Set&lt;Student&gt; students) &#123; this.students = students; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 完整核心配置文件1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 必须要配置的5大参数，4大参数，一个方言 其中的四大参数是连接JDBC必须的参数 这里的方言也是必须的 --&gt; &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/hirbernate&lt;/property&gt; &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt; &lt;property name="hibernate.connection.password"&gt;root&lt;/property&gt; &lt;!-- mysql的方言 --&gt; &lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 可选的配置文件 --&gt; &lt;!-- 输出所有的sql语句到控制台 --&gt; &lt;property name="hibernate.show_sql"&gt;true&lt;/property&gt; &lt;!-- 在控制台上打印出漂亮的sql语句 --&gt; &lt;property name="hibernate.format_sql"&gt;true&lt;/property&gt; &lt;!-- 配置如果这个表还没有创建，那么就会自动创建，如果已经创建了，那么会自动更新 --&gt; &lt;property name="hibernate.hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!-- 配置不生成Hibernate_sequence --&gt; &lt;property name="hibernate.id.new_generator_mappings"&gt;false&lt;/property&gt; &lt;!-- 直接指定这个Teacher实体类的全类名即可，即是完成了映射 --&gt; &lt;mapping class="cn.tedu.bean.Student"&gt;&lt;/mapping&gt; &lt;mapping class="cn.tedu.bean.Teacher"&gt;&lt;/mapping&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 总结 在双向外键关联的关系中，一定要使用mappedBy指定外键的维护权，否则将会出现数据冗余 在一对以和一对多，多对一的关系中，我们可以使用@JoinColumn这个注解来设置外键的字段名，但是在多对多的关系中，因为需要第三张表来维护，因此要使用@JoinTable这个注解来设置外键和第三张表的一些属性]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate之一级缓存]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E4%B9%8B%E4%B8%80%E7%BA%A7%E7%BC%93%E5%AD%98%2F</url>
      <content type="text"><![CDATA[Hibernate之一级缓存什么是一级缓存 Hibernate创建每个Session对象时，都会给Session分配一块独立的缓存区，用于存放Session查询出来的对象，这个分配给Session的缓存区称之为一级缓存，也叫Session级缓存 为什么使用一级缓存 Session读取数据时，会优先向缓存区取数据，如果存在数据直接返回，不存在才会区数据库查询，从而降低了数据库的访问次数。提升了代码的运行效率 如何使用一级缓存 一级缓存默认是开启的，在使用Hibernate的API进行查询时会自动使用 验证 从控制台可以看到只发出一条sql的查询语句 1234567891011121314151617181920212223@Test public void Test() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=2 的数据，这个是session的第一次查询，那么会发出sql语句 Student student1=session.get(Student.class, 2); //再次使用同一个Session查询id=2的对象，由于前面已经查询过一次，因此这里不需要发出sql语句 Student student2=session.get(Student.class,2); transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; 一级缓存的规则 一级缓存是Session独享的，每个Session不能访问其他的Session的缓存区 12345678910111213141516171819202122232425@Test public void test1()&#123; Session session1 = null; Session session2 = null; Transaction transaction = null; try &#123; // 创建session session1=HibernateUntil.getSession(); //获取session1 session2=HibernateUntil.getSession(); // 开始事务 transaction = session1.beginTransaction(); transaction = session2.beginTransaction(); //使用session1查询id=2的对象，这个对象会在session1的缓存区缓存 Student s1=session1.get(Student.class, 2); //使用Session2查询id=2的对象，可以看到这还是会发出sql语句，因为在session2的缓存区没有这个对象 Student s2=session2.get(Student.class, 2); transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session1!=null) &#123; session1.close(); &#125; &#125; &#125; Session的save，update，delete操作会出发缓存更新 此时的缓存区将会将之前的查询到的对象全部清除 一级缓存管理 session.evit(obj) 将obj对象从一级缓存中清除 12345678910111213141516171819202122232425public void Test2() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=2 的数据，这个是session的第一次查询，那么会发出sql语句 Student student1=session.get(Student.class, 2); //清楚一级缓存中的student1对象 session.evict(student1); //再次使用同一个Session查询id=2的对象，由于前面已经清除了这个对象，因此这里还是会发出sql语句 Student student2=session.get(Student.class,2); transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; session.clear() 清除一级缓存中的所有对象 session.close() 关闭session，释放缓存空间 总结 一级缓存是默认开启的 一级缓存的使用可以减少服务器和数据库之间的交互，减轻服务器的压力 提高查询的效率，不必查询发出重复的sql语句]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate中的三种状态]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E7%8A%B6%E6%80%81%2F</url>
      <content type="text"><![CDATA[Hibernate中的三种状态 在Hibernate中可以将实体对象看成3种状态，分别是临时态，持久态，游离态 临时态(瞬时态)特征 临时态的对象可以被垃圾回收 临时态的对象未经过持久化，没有和session关联(没有经过session存储和查找) 转换 新new出来的对象就是临时态 在Hibernate中,可通过 session的save()或saveOrUpdate()方法将临时对象与数据库相关联,并将数据对应的插入数据库中,此时该临时对象转变成持久化对象. 12Student st=new Student(); //此时的对象是临时态st.setName("陈加兵"); 持久态 处于该状态的对象在数据库中具有对应的记录,并拥有一个持久化标识.通过session的get()、load()等方法获得的对象都是持久对象。 持久态的对象与session关联 在数据库中有与之关联的数据 12//使用get方法获取id=2的对象，此时的Student是持久态Student student=session.get(Student.class, 2); 特点 session.save()方法将一个临时态的对象转换成持久态 123456//新建的Student对象，这个是临时态对象，并没有数据库关联Student student = new Student();student.setAge(22);student.setName("陈加兵");// 保存数据到数据库，此时的student就是一个持久态的对象，与session有了关联，并且数据库中也有了这条数据session.save(student); Session的update()方法 将一个游离对象转变为持久对象 不能调用save()方法，因为游离态对象在数据库中是对应着一条数据的(数据库中有id的值与其对应)，如果此时调用save()方法，那么就会向其中插入一条数据(此时的主键是自增长的)。因此要想一个游离态的对象变成持久态的对象，必须使用update()方法 12345678910111213141516171819202122232425@Test public void Test() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //此时的student为临时态 Student student=new Student(); //设置了id的值，并且这个id=2在数据库中有这么一条数据，因此是游离态 student.setId(2); //调用了update()方法，此时变成持久态的对象 session.update(student); transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; 只要是这个持久态的对象的数据和数据库中的数据不相同了，不需要主动的调用update()方法，在执行的时候会自动的更新到数据库中。如果比较之后发现对象中的属性是相同的，那么即使调用了update()方法，也不会发出sql的更新语句。 1234567891011121314151617181920212223242526 @Test public void TestPersit() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //使用get方法获取id=2的对象，此时的Student是持久态 Student student=session.get(Student.class, 2); //修改了持久态的对象，这里只要session提交了就会自动更新到数据库中，不需要使用update()方法 student.setName("陈加兵"); //更新Student对象到数据库中，但是student是持久态，因此这里的语句是多余// session.update(student); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; Session的lock()方法: 调用lock()方法将对象同Session相关联而不强制更新。 Session的merge()方法: 拷贝指定对象的状态到具有相同对象标识符的持久对象。 Session的saveOrUpdate()方法: saveOrUpdate() 方法对于临时对象，执行save()方法，对于游离对象，执行update()方法。 Session的load()和get()方法: load()方法和get()方法都可以根据对象的标识符加载对象，这两个方法加载的对象都位于Session的缓存中，属于持久对象。 Session的 delete()方法: delete()方法用于从数据库中删除与持久化对象对应的记录。如果传入的是一个持久化对象，Session就执行一条 delete语句。如果传入的参数是游离对象，先使分离对象与Session关联，使它变为持久化对象，然后才计划执行一个delete语句。 Session 的evict()方法: evict()方法从Session的缓存中删除一个持久对象。 游离态(脱管态) 当与某持久对象关联的session被关闭后,该持久对象转变为游离对象.当游离对象被重新关联到session上 时,又再次转变成持久对象（在Detached其间的改动将被持久化到数据库中）。 游离对象拥有数据库的识别值,但已不在持久化管理范围之内。 对象中有id的值(这个id的值对应数据库中的数据)，但是和session没有关联 123Student student2=new Student();student.setId(2); //设置了id的值，这个id的值在数据库中对应一条记录student.setName("陈加兵"); 参考文章 https://blog.csdn.net/leefengboy/article/details/52723849]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate之延迟加载]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E4%B9%8B%E5%BB%B6%E8%BF%9F%E5%8A%A0%E8%BD%BD%2F</url>
      <content type="text"><![CDATA[hibernate之延迟加载什么是延迟加载 在使用某些Hibernate方法查询数据的时候，Hibernate返回的只是一个空对象(除了id外属性都为null)，并没有真正的查询数据库。而是在使用这个对象的时候才会出发查询数据，并将查询到的数据注入到这个空对象中，这种查询时机推迟到对象访问时的机制称之为延迟加载。 简单的说，使用延迟加载获取的对象，只有在获取其中的除了id之外的属性才会发出sql语句。 好处 可以提升内存资源的使用率 可以降低对数据库的访问次数 如何使用延迟加载 session.load() query.iterate() 1234567891011121314151617181920212223242526@Test public void Testload() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //使用延迟加载load()方法获取对象，这里并没有发出sql查询语句，其中除了一个id属性之外没有其他的属性 Student student=session.load(Student.class,2); //查询其中的id属性，这里也没有发出查询语句 System.out.println(student.getId()); //查询对象中的name属性，这里将会发出查询的sql语句 System.out.println(student.getName()); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; 使用延迟加载需要注意的问题 采用延迟加载机制的操作，需要避免session的提前关闭。避免在使用对象之前关闭session 因为在使用延迟加载的时候并没有发出sql查询语句，只有当使用其中的除了id属性之外的属性才会发出查询语句，因此这里的session不能提前关闭]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate注解之基本注解的注解使用]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E6%B3%A8%E8%A7%A3%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%B3%A8%E8%A7%A3%E7%9A%84%E6%B3%A8%E8%A7%A3%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[Hibernate注解之基本注解的注解使用使用注解须知 我们在使用注解自动创建表的时候，系统会默认为我们创建一张表Hibernate_sequence，我们可以在Hibernate.cfg.xml文件中添加如下语句解决问题12&lt;!-- 配置不生成Hibernate_sequence --&gt;&lt;property name="hibernate.id.new_generator_mappings"&gt;false&lt;/property&gt; 类级别注解 @Entity : 映射实体类，其中有一个name属性指定当前实体类映射的表的名称 name: 可选属性 ，指定对应表的名称，如果没有指定name属性，那么创建表的名称和类名一样 @Table : 在实体类的上方使用，和Entity配合使用，指定实体类对应的数据库中的表的信息 name ：可选，指定表的名称，默认的是和类名一样，只有在不一致的情况下才会指定表名 catalog ： 可选，表示Catalog名称，默认为 Catalog(“”) schema ： 可选 , 表示 Schema 名称 , 默认为Schema(“”) 属性级别的注解 属性级别的注解在getXXX()方法上使用 @Id 映射生成主键 @Version 定义乐观锁 @Column 映射表的列 @Transient 定义暂态属性 主键相关的注解 @id： 指定该属性为主键 @GeneratedValue(strategy=,generator=&quot;&quot;) : 主键生成策略 Strategy的值 GenerationType.AUTO - 根据底层数据库自动选择（默认），若数据库支持自动增长类型，则为自动增长。 GenerationType.INDENTITY - 根据数据库的Identity字段生成，支持DB2、MySQL、 MS、SQL Server、SyBase与HyperanoicSQL数据库的Identity 类型主键。 GenerationType.SEQUENCE - 使用Sequence来决定主键的取值，适合Oracle、DB2等 支持Sequence的数据库，一般结合@SequenceGenerator使用。 GenerationType.TABLE - 使用指定表来决定主键取值，结合@TableGenerator使用。 与非主键相关的注解 @Version - 可以在实体bean中使用@Version注解,通过这种方式可添加对乐观锁定的支持 @Basic - 用于声明属性的存取策略： @Basic(fetch=FetchType.EAGER) 即时获取（默认的存取策略） @Basic(fetch=FetchType.LAZY) 延迟获取 @Temporal 这个使用来设置数据库表中显示的日期的精度，因为java中的Date属性可以对应着数据库中的三种类型(DATE,TIME, TIMESTAMP)即是单纯的表示日期，时间，两者兼备的，默认的是两者兼备的，输出的是:2012-01-22 17:55:55 因此可以使用@Temporal来设置显示的时间的精度，这三种的表示形式如下： TemporalType.TIME 输出到数据库中的仅仅是小时格式的，比如:12:22:12 TemporalType.DATE 输出到数据库中的是日期的格式：2012-12-01 TemporalType.TIMESTAMP 两者兼备，这个是默认的 @Column - 可将属性映射到列，使用该注解来覆盖默认值，@Column描述了数据库表中 该字段的详细定义，这对于根据 JPA 注解生成数据库表结构的工具非常有作用。 name - 可选，表示数据库表中该字段的名称，默认情形属性名称一致 nullable -可选，表示该字段是否允许为 null，默认为true unique - 可选，表示该字段是否是唯一标识，默认为 false length - 可选，表示该字段的大小，仅对 String 类型的字段有效，默认值255. insertable -可选，表示在ORM框架执行插入操作时，该字段是否应出现INSETRT 语句中，默认为 true updateable -可选，表示在ORM 框架执行更新操作时，该字段是否应该出现在 UPDATE语句中，默认为 true. 对于一经创建就不可以更改的字段，该 属性非常有用，如对于 birthday字段。 columnDefinition - 可选，表示该字段在数据库中的实际类型。通常ORM框架可以根 据属性类型自动判断数据库中字段的类型，但是对于Date类型仍无法确定数据 库中字段类型究竟是 DATE,TIME还是 TIMESTAMP. 此外 ,String 的默认映射类型为VARCHAR, 如果要将 String 类型映射到特定数据库的 BLOB或 TEXT字段类型，该属性非常有用。 @Transient - 可选，表示该属性并非一个到数据库表的字段的映射，ORM框架将忽略该属性，如果一个属性并非数据库表的字段映射，就务必将其标示为@Transient。 如果使用这个注解，那么表中不会出现这个字段 实例 我们现在创建一个实体类Teacher，映射到数据库teacher表中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.Date;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;import javax.persistence.Table;import javax.persistence.Temporal;import javax.persistence.TemporalType;import javax.persistence.Transient;@Entity@Table(name="teacher")public class Teacher &#123; private int id; //主键 private String name; private int age; private double sal; private Date joinDate; private String wife; //妻子的名字 @Transient //设置该属性不在表中 public String getWife() &#123; return wife; &#125; public void setWife(String wife) &#123; this.wife = wife; &#125; @Id @GeneratedValue(strategy=GenerationType.AUTO) //设置主键自增长 public int getId() &#123; return id; &#125; @Temporal(TemporalType.DATE) //设置时间精确到天数，2012-01-12 @Column(name="JoinTime") //改变表中字段的名字 public Date getJoinDate() &#123; return joinDate; &#125; public void setId(int id) &#123; this.id = id; &#125; @Column(nullable=false) //设置名字不为空 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public double getSal() &#123; return sal; &#125; public void setSal(double sal) &#123; this.sal = sal; &#125; public void setJoinDate(Date joinDate) &#123; this.joinDate = joinDate; &#125;&#125; 在核心配置文件(hibernate.cfg.xml)中配置这个映射12&lt;!-- 直接指定这个Teacher实体类的全类名即可，即是完成了映射 --&gt;&lt;mapping class="cn.tedu.bean.Teacher"&gt;&lt;/mapping&gt; @JoinColumn 我们知道外键的生成的字段的名称是默认的，但是我们也可以使用这个注解改变这个名称 这个注解是用来设置自动生成的外键的属性，比如外键的名称，非空…… name指定外键的名称 nullable指定外键是否为空，默认的是true unique生成唯一的约束，就是这个字段的值唯一，默认的false @JoinTabl 当涉及到多对多的映射关系的时候，用来定义第三表的表名，和字段的名称。 name设置第三张表的名称 joinColumns设置的是当前实体类对应的表在第三张表的外键的字段名称 inverseJoinColumns设置的是另外一个实体类对应的表在第三张表的外键的字段名称 参考文档 http://docs.jboss.org/hibernate/annotations/3.4/reference/zh_cn/html_single/#d0e1148 http://www.cnblogs.com/qjjazry/p/6306744.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate使用日志(log4j)]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E4%BD%BF%E7%94%A8%E6%97%A5%E5%BF%97-log4j%2F</url>
      <content type="text"><![CDATA[Hibernate使用日志(log4j)添加依赖 在pom.xml中添加如下的依赖123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 在resource目录下创建log4j.properties文件123456789101112131415161718192021222324# Direct log messages to a log filelog4j.appender.file=org.apache.log4j.RollingFileAppender# define the log to filelog4j.appender.file.File=jsnu-log4j.loglog4j.appender.file.MaxFileSize=1MBlog4j.appender.file.MaxBackupIndex=1log4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=%d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%n# Direct log messages to stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%n# Root logger optionlog4j.rootLogger=INFO, file, stdout# Log everything. Good for troubleshootinglog4j.logger.org.hibernate=INFO# Log all JDBC parameterslog4j.logger.org.hibernate.type=ALL]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate常用API]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E5%B8%B8%E7%94%A8API%2F</url>
      <content type="text"><![CDATA[Hibernate常用API Configuration ：负责加载核心配置文件 加载的默认名字为hibernate.cfg.xml，如果不是这个名字，那么需要指定 SessionFactory configuration.buildSessionFactory() 创建SessionFactory SessionFactory ： 用来创建Session(会话) Session openSession() 获取Session Session : 数据库连接会话，用来实现增删改查 save(Object) 增加数据 get(Class&lt;T&gt; cls,arg) 根据id查询 update(Object object) 更新，一般先要根据条件获取到其中的记录，然后在其对象中修改 delete(Object object) 删除 Transaction ：负责事务控制 session.beginTransaction() 开始事务 rollback() 回滚 commit() 提交事务 Query ：执行特殊的查询 增删改查的是实例(Session)创建一个工具类 用于获取Session，相当于JDBC获取Connection12345678910111213141516171819public class HibernateUntil &#123; private static Configuration configuration; private static SessionFactory sessionFactory; /* * 静态语句块中的内容只是在类加载的时候只创建一次，因此这里的大大减少了资源的消耗 */ static &#123; // 加载核心配置文件hibernate.cfg.xml configuration = new Configuration(); configuration.configure(); // 创建SessionFactotry对象 sessionFactory = configuration.buildSessionFactory(); &#125; //创建session对象，在测试类中可以使用这个静态方法获取session public static Session getSession() &#123; return sessionFactory.openSession(); &#125;&#125; 增删改查 使用的是Session中的相关方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package cn.tedu.test;import org.hibernate.Session;import org.hibernate.Transaction;import org.junit.Test;import cn.tedu.bean.Student;import cn.tedu.utils.HibernateUntil;public class Demo1 &#123; /** * 添加数据到数据库中 * save(Object object) * 直接传入的是一个实体类的对象，我们在实体类中设置值，那么设置的值就会根据映射关系文件将其添加到指定的表的字段的值 */ @Test public void TestAdd() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); Student student = new Student(); student.setAge(22); student.setName("陈加兵"); // 保存数据到数据库 session.save(student); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; /** * 删除数据 * 1. 根据id查询出想要删除的对象 * 2. 使用delete(Object obj) 删除 */ @Test public void testDelete()&#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); Student student=session.get(Student.class, 1); //根据id查询想要删除的对象 session.delete(student); //删除查询到的对象 // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; /** * 根据id查询数据，返回的是一个实体类对象 * get(Class&lt;T&gt; cls,id) */ @Test public void testGet()&#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=1的数据，并且返回对象 Student student=session.get(Student.class, 1); System.out.println(student); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; /** * 测试更新数据 * 1. 先根据id获取指定的对象 get(Class&lt;T&gt; class,id) * 2. 使用set方法修改对象中的属性值 * 3. update(Object object) 直接将对象更新即可 */ @Test public void TestUpdate() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); //查询id=1的数据，并且返回对象 Student student=session.get(Student.class, 1); student.setName("Jack"); student.setAge(33); session.update(student); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate的基本配置]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[Hibernate的基本配置核心配置文件(hibernate.cfg.xml) 名字为hibernate.cfg.xml 放在根目录下(resource) 必须的配置(配置数据库信息) hibernate.connection.driver_class加载驱动，其中的mysql的为：com.mysql.jdbc.Driver hibernate.connection.url数据库的连接，其中mysql是jdbc:mysql://localhost:3306/hirbernate hibernate.connection.username数据库的用户名 hibernate.connection.password数据库的密码 hibernate.dialect数据库的方言，其中mysql：org.hibernate.dialect.MySQLDialect 可选的配置 hibernate.show_sql输出sql执行的语句到控制台，false，true hibernate.format_sql格式化sql语句，true，false hibernate.hbm2ddl.auto配置自动生成表，其中有四个值，分别是create（表示hibernate自动创建表，但是每次执行完成之后都会删除上一个表重新创建一个），update（如果还没有表，那么就生成一个，如果已经存在这个表，那么就会更新这个表），validate（不会自动创建表，字段不一致时会出现异常），create-drop（每次加载的时候都会创建表，但是SessionFactory关闭后就会自动删除这个表）。我们使用最多的是update &lt;mapping resource=&quot;com/bean/Student.hbm.xml&quot; /&gt;设置映射文件的路径 实例12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 必须要配置的5大参数，4大参数，一个方言 其中的四大参数是连接JDBC必须的参数 这里的方言也是必须的 --&gt; &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/hirbernate&lt;/property&gt; &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt; &lt;property name="hibernate.connection.password"&gt;root&lt;/property&gt; &lt;!-- mysql的方言 --&gt; &lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 可选的配置文件 --&gt; &lt;!-- 输出所有的sql语句到控制台 --&gt; &lt;property name="hibernate.show_sql"&gt;true&lt;/property&gt; &lt;!-- 在控制台上打印出漂亮的sql语句 --&gt; &lt;property name="hibernate.format_sql"&gt;true&lt;/property&gt; &lt;!-- 配置如果这个表还没有创建，那么就会自动创建，如果已经创建了，那么会自动更新 --&gt; &lt;property name="hibernate.hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!-- 映射配置文件，这里是引用Student类的配置文件，注意这里的配置文件可以有多个 --&gt; &lt;mapping resource="cn/tedu/bean/Student.hbm.xml" /&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 映射关系文件作用 指定实体类的各个字段与表的关系 缺点 太麻烦了，一个项目中有很多个实体类，那么我们也需要配置多个映射关系文件 后面会使用注解的方式替代这个映射关系文件 创建 每一个实体类对应一个映射配置文件 映射关系文件的名字最好是实体类名.hbm.xml(不强制规定) 最好和实体类放在同一个包中 属性 class name : 对应的实体类的全类名(包名+类名) table : 在数据库中对应的表的名称 id 指定主键的对应关系，这个mybatis很相似 property : 实体类中的主键的字段 column ： 表中的主键字段 property 指定表中其他字段的对应关系 实例 实体类Student 1234567891011121314151617181920212223public class Student &#123; private String name; private Integer id; //主键 private Integer age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 映射关系文件 (Student.hbm.xml) 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;!-- 根节点 --&gt;&lt;hibernate-mapping&gt; &lt;!-- name：指定实体类的路径 table：指定该实体类对应的表的名称 --&gt; &lt;class name="cn.tedu.bean.Student" table="student"&gt; &lt;!-- &lt;id&gt;配置主键，name指定JavaBean中的属性，column指定的是表中的属性 --&gt; &lt;id name="id" column="id"&gt; &lt;!-- 配置主键的生成策略 --&gt; &lt;generator class="native"&gt;&lt;/generator&gt; &lt;/id&gt; &lt;!-- property是定义非主键的类型 name：指定实体类中的属性名称 column：指定实体类中的属性对应在表中的元素的名称 如果这里的name和column相同，那么可以省略这里的colum，不过建议写全，更加清晰 --&gt; &lt;property name="name" column="name"&gt;&lt;/property&gt; &lt;property name="age" column="age"&gt;&lt;/property&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 注意 如果实体类中的属性和表中的属性字段相同，那么其中的column可以省略，但是建议写全 SQL方言 告诉Hibernate你使用的是哪一个数据库，Hibernate便可以根据设定的方言来对应数据库 常用的方言(Mysql,Oracle) mysql : org.hibernate.dialect.MySQLDialect Oracle : org.hibernate.dialect.OracleDialect 主键生成方式 我们在学习mysql的时候，一般都会设置主键为自增长，这个自增长就是主键生成方式 如何使用 主键生成策略是在映射关系文件中定义的，使用的是&lt;generator&gt;定义的 分类常见的分类 sequence： 采用序列方式生成主键，适用于Oracle数据库 123&lt;generator class="sequence"&gt; &lt;param name="sequence"&gt;序列名&lt;/param&gt;&lt;/generator&gt; identity 是采用数据库自增长机制生成主键，适用于Oracle之外的其他的数据库 配置语法 ： &lt;generator class=&quot;identity&quot;&gt;&lt;/generator&gt; native 是根据当前配置的数据库方言，自动选择sequence或者identity 在mysql的环境下是自增长的方式 配置语法如下：&lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt; uuid用一个128-bit的UUID算法生成字符串类型的标识符， 这在一个网络中是唯一的（使用了IP地址）。UUID被编码为一个32位16进制数字的字符串。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate第一个程序]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%2F</url>
      <content type="text"><![CDATA[Hibernate第一个程序创建一个Maven项目 在pom.xml中配置Hibernate的jar包1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;dependencies&gt; &lt;!-- hibernate核心jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;5.1.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysqljar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建一个实体类(JavaBean)12345678910111213141516171819202122232425package cn.tedu.bean;public class Student &#123; private String name; private Integer id; //主键 private Integer age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 创建这个实体类Student的映射文件 这个实体类的映射文件的名字最好要和是：实体类名.hbm.xml 映射文件最好和实体类放在同一个包中1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;!-- 根节点 --&gt;&lt;hibernate-mapping&gt; &lt;!-- name：指定实体类的路径 table：指定该实体类对应的表的名称 --&gt; &lt;class name="cn.tedu.bean.Student" table="student"&gt; &lt;!-- &lt;id&gt;配置主键，name指定JavaBean中的属性，column指定的是表中的属性 --&gt; &lt;id name="id" column="id"&gt; &lt;!-- 配置主键的生成策略 自增长--&gt; &lt;generator class="native"&gt;&lt;/generator&gt; &lt;/id&gt; &lt;!-- property是定义非主键的类型 name：指定实体类中的属性名称 column：指定实体类中的属性对应在表中的元素的名称 如果这里的name和column相同，那么可以省略这里的colum，不过建议写全，更加清晰 --&gt; &lt;property name="name" column="name"&gt;&lt;/property&gt; &lt;property name="age" column="age"&gt;&lt;/property&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 核心配置文件(hibernate.cfg.xml) 核心配置文件的名字是hibernate.cfg.xml 放在根目录中，resource下12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 必须要配置的5大参数，4大参数，一个方言 其中的四大参数是连接JDBC必须的参数 这里的方言也是必须的 --&gt; &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/hirbernate&lt;/property&gt; &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt; &lt;property name="hibernate.connection.password"&gt;root&lt;/property&gt; &lt;!-- mysql的方言 --&gt; &lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 可选的配置文件 --&gt; &lt;!-- 输出所有的sql语句到控制台 --&gt; &lt;property name="hibernate.show_sql"&gt;true&lt;/property&gt; &lt;!-- 在控制台上打印出漂亮的sql语句 --&gt; &lt;property name="hibernate.format_sql"&gt;true&lt;/property&gt; &lt;!-- 配置如果这个表还没有创建，那么就会自动创建，如果已经创建了，那么会自动更新 --&gt; &lt;property name="hibernate.hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!-- 映射配置文件，这里是引用Student类的配置文件，注意这里的配置文件可以有多个 --&gt; &lt;mapping resource="cn/tedu/bean/Student.hbm.xml" /&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 工具类(HibernateUtil) 用于读取配置文件 获取Session12345678910111213141516171819202122import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;public class HibernateUntil &#123; private static Configuration configuration; private static SessionFactory sessionFactory; /* * 静态语句块中的内容只是在类加载的时候只创建一次，因此这里的大大减少了资源的消耗 */ static &#123; // 加载核心配置文件hibernate.cfg.xml configuration = new Configuration(); configuration.configure(); // 创建SessionFactotry对象 sessionFactory = configuration.buildSessionFactory(); &#125; //创建session对象，在测试类中可以使用这个静态方法获取session public static Session getSession() &#123; return sessionFactory.openSession(); &#125;&#125; 测试类 添加一条记录到数据库中123456789101112131415161718192021222324252627282930313233import org.hibernate.Session;import org.hibernate.Transaction;import org.junit.Test;import cn.tedu.bean.Student;import cn.tedu.utils.HibernateUntil;public class Demo1 &#123; @Test public void TestAdd() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUntil.getSession(); // 开始事务 transaction = session.beginTransaction(); Student student = new Student(); student.setAge(22); student.setName("陈加兵"); // 保存数据到数据库 session.save(student); // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session!=null) &#123; session.close(); &#125; &#125; &#125; 总结 核心配置文件名字一定要是: hibernate.cfg.xml 实体类的配置文件要和实体类最好放在同一个包中 运行测试类，我student表将会自动创建，在控制台还会输出sql语句]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate对象导航语言]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E5%AF%B9%E8%B1%A1%E5%AF%BC%E8%AF%AD%E8%A8%80HQL%2F</url>
      <content type="text"><![CDATA[HQL - 对象导航语言简介 HQL(Hibernate Query Language) 是面向对象的查询语言, 它和 SQL 查询语言有些相似. 在 Hibernate 提供的各种检索方式中, HQL 是使用最广的一种检索方式. 它有如下功能: 在查询语句中设定各种查询条件； 支持投影查询, 即仅检索出对象的部分属性； 支持分页查询； 支持连接查询； 支持分组查询, 允许使用 HAVING 和 GROUP BY 关键字； 提供内置聚集函数, 如 sum(), min() 和 max()； 支持子查询； 支持动态绑定参数； 能够调用 用户定义的 SQL 函数或标准的 SQL 函数。 步骤 获取Session对象 编写hql语句 使用session.createQuery(String hql)创建Query对象 使用session.setXX(index,Object)设置占位符的值 执行query.list()获取实体对象即可 准备 创建Husband实体类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package cn.tedu.hibernate.entity;import java.io.Serializable;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.FetchType;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToOne;import javax.persistence.Table;@Entity@Table(name="husband")public class Husband implements Serializable&#123; private static final long serialVersionUID = 7403209578400736239L; private Integer id; private String name; private int age; private Wife wife; @Id @GeneratedValue //主键自增长 public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @OneToOne(fetch=FetchType.LAZY) @JoinColumn(name="wife_id") //设置外键名称为wife_id public Wife getWife() &#123; return wife; &#125; public void setWife(Wife wife) &#123; this.wife = wife; &#125; @Override public String toString() &#123; return "Husband [id=" + id + ", name=" + name + ", age=" + age + ", wife=" + wife + "]"; &#125;&#125; 创建Wife的实体类 1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.Serializable;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.Table;@Entity@Table(name="wife")public class Wife implements Serializable &#123; private static final long serialVersionUID = -7203920255946679244L; private Integer id; private String name; private int age; @Id @GeneratedValue public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; @Column(length=10) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Wife [id=" + id + ", name=" + name + ", age=" + age + "]"; &#125;&#125; 创建工具类，用来生成Session 123456789101112131415161718192021import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;public class HibernateUtil &#123; private static Configuration configuration; private static SessionFactory sessionFactory; /* * 静态语句块中的内容只是在类加载的时候只创建一次，因此这里的大大减少了资源的消耗 */ static &#123; // 加载核心配置文件hibernate.cfg.xml configuration = new Configuration(); configuration.configure(); // 创建SessionFactotry对象 sessionFactory = configuration.buildSessionFactory(); &#125; //创建session对象，在测试类中可以使用这个静态方法获取session public static Session getSession() &#123; return sessionFactory.openSession(); &#125;&#125; 实体查询 查询结果返回的是一个List&lt;&gt;的集合。其中的泛型为实体类 相当于sql语句中的select * from husband; 使用的hql语句是from Husband where id=?,这里还可以和sql语句一样使用别名来获取其中的值，比如： from Husband h where h.id=? 格式 from Husband where id=? ，其中的Husband是实体类的名字，而不是表的名称，后面的属性实体类中的属性名称，而不是表中字段的名称，区分大小写 拓展 where子句中只要是sql语句被能够满足的都是可以写的，比如=, , &lt;, &gt;, &lt;=, &gt;=, between, not between, in ,not in, is, like，同时也是可以写算术表达式 12345FROM User user WHERE user.age&lt;20FROM User user WHERE user.name IS nullFROM User user WHERE user.name LIKE 'Er%'FROM User user WHERE (user.age % 2 = 1)FROM User user WHERE (user.age&lt;20) AND (user.name LIKE '%Er') 实例 查询husband这张表，其中对应的实体类是Husband 12345678910111213141516171819202122232425262728293031323334@Test public void test1() &#123; Session session = null; Transaction transaction = null; try &#123; // 创建session session = HibernateUtil.getSession(); // 开始事务 transaction = session.beginTransaction(); //编写hql语句 String hql="from Husband where id=?"; //String hql="from Husband h where h.id=?"; //创建Query Query query=session.createQuery(hql); //设置占位符的值，这里的用法和PreparedStatement一样的用法 query.setInteger(0,1); List&lt;Husband&gt; husbands=query.list(); //执行查询语句，返回的是list集合 for (Husband husband : husbands) &#123; System.out.println(husband); &#125; // 提交事务 transaction.commit(); &#125; catch (Exception exception) &#123; transaction.rollback(); // 事务回滚 &#125; finally &#123; if (session != null) &#123; session.close(); &#125; &#125; &#125; 部分字段的查询 实体对象的查询返回的是一个实体对象的List&lt;&gt;集合，我们这里需要查询的是表中的执行字段，而不是全部的字段 格式 select 实体类属性名 from 实体类名字 where 条件语句 实例 查询出id=1的所有的husband中的name和age sql语句：select name,age from husband where id=1 hql语句： select name,age from Husband h where h.id=?，此时的占位符id的值为1 此时查询返回的结果List是一个Object[]，其中的元素是name，age，并且是按照hql的语句的查询顺序存储的 12345678910111213141516//编写hql语句,只查询name和age属性字段String hql="select name,age from Husband where id=?";//创建QueryQuery query=session.createQuery(hql);//设置占位符的值，这里的用法和PreparedStatement一样的用法query.setInteger(0,1);//这里返回的是一个List集合，但是其中的每一个元素都是一个Object数组List&lt;Object[]&gt; lists=query.list(); //遍历List集合for (Object objects : lists) &#123; //遍历数组，[0]的元素是name，[1]的元素是age for(int i=0;i&lt;objects.length;i++)&#123; System.out.println(objects[i]); &#125;&#125; 这里查询的是两个字段，返回的结果List中存放的是Object[]，但是如果我们查询的只有一个字段，那么返回的结果List中存放的是Object，这个值是你查询的字段的值 多表联合查询前提 必须存在关联关系，比如一对一，一对多，多对多 常见的联合查询方式 对象方式的关联查询 这个是HQL所特有的，因为这个需要用到对象之间的关系 join方式关联 select子句关联 对象方式关联查询 假设我们需要查询wife的id值为1的husband表中指定的字段，我们除了使用多表联合查询，我们也可以使用关联查询，因为在Husband的实体类中有Wife这个对象 hql语句： select name,age from Husband h where h.wife.id=? 实例12345678910111213141516//编写hql语句,where字句中的条件是wife的id String hql="select h.name,w.name from Husband h,Wife w where h.wife.id=? "; //创建Query Query query=session.createQuery(hql); //设置占位符的值，这里的用法和PreparedStatement一样的用法 query.setInteger(0,1); List&lt;Object&gt; lists=query.list(); //遍历查询结果 for (Object object : lists) &#123; Object[] objects=(Object[])object; for (int i = 0; i &lt; objects.length; i++) &#123; System.out.println(objects[i]); &#125; &#125; join方式查询左外连查询 这个是等值连接的一种，即使两张表中的某一条数据不存在关联关系，那么也会全部查询出左边的那张表的全部数据 sql语句：select * from husband h left join wife w on h.wife_id=w.id,查询丈夫的所有数据并且和其对应妻子的信息，其中husband和wife这两张表是通过wife_id这个外键关联的 hql语句： select h.name,h.age,w.name,w.age from Husband h left join h.wife w,这条语句和上面的sql语句是一样的功能 格式 select 实体类属性 from 实体类名 [as] 别名 left join 别名.关联对象名 [as] 别名 其中的as可以省略 如果不需要查询关联对象的属性，那么后面的别名可以省略 left join后面跟的是实体类的关联对象，比如Husband中的Wife对象h.wife，这里就相当sql中的on h.wife_id=w.id 实例 查询所有丈夫的信息和其对应的妻子的所有信息 hql: from Husband h left join h.wife,虽然这里的使用的是实体查询的方式，但是返回的却是Object[]，其中的第一个元素是Husband对象，第二个是Wife对象 1234567891011//编写hql语句String hql="from Husband h left join h.wife";//创建QueryQuery query=session.createQuery(hql);//执行查询，这里返回的是一个Object数组，其中数组的第一个元素是husband的数据，第二个是wife的数据List&lt;Object[]&gt; list=query.list();for (Object[] objects : list) &#123; Husband husband=(Husband) objects[0]; //获取Husband对象 Wife wife=(Wife)objects[1]; //获取Wife对象&#125; 查询所有的丈夫信息和起对应的妻子的所有信息，这个和上面的例子一样，只不过是另外一种hql语句方式 1234567891011//编写hql语句String hql="select h,w from Husband h left join h.wife w";//创建QueryQuery query=session.createQuery(hql);List&lt;Object[]&gt; list=query.list();for (Object[] objects : list) &#123; Husband husband=(Husband) objects[0]; //获取Husband对象 Wife wife=(Wife)objects[1]; //获取Wife对象&#125; 查询所有丈夫的name，age和其对应的妻子的的name，age信息 1234567891011121314//编写hql语句String hql="select h.name,h.age,w.name,w.age from Husband h left join h.wife w";//创建QueryQuery query=session.createQuery(hql);List&lt;Object&gt; list=query.list();for (Object object : list) &#123; Object[] objects=(Object[])object; for (int i = 0; i &lt; objects.length; i++) &#123; System.out.print(objects[i]+"\t"); &#125; System.out.println();&#125; 查询丈夫的所有信息 右外连接查询 右外链接查询和左外连接查询的方式是一样的，只是此时如果出现两条记录没有关联关系的话，那么保留的是右边的表中的数据，即是查询右边表的所有数据和其对应的左边表的数据 格式 select 实体类属性 from 实体类名 [as] 别名 right join 别名.关联对象名 [as] 别名 其中的as可以省略 如果不需要查询关联对象的属性，那么后面的别名可以省略 right join后面跟的是实体类的关联对象，比如Husband中的Wife对象h.wife，这里就相当sql中的on h.wife_id=w.id 实例 查询所有妻子的信息和其对应的丈夫的信息： select h,w from Husband h right join h.wife w 迫切左外连接迫切右外连接select子句关联查询格式 select 对象.属性名,.... from 类名 其中的对象是实体类中的对象属性，比如Husband类中的Wife对象 实例 select h.wife.name,h.wife.age,h.name from Husband h 123456789101112131415//编写hql语句,where字句中的条件是wife的idString hql="select h.wife.name,h.wife.age,h.name from Husband h";//创建QueryQuery query=session.createQuery(hql);//设置占位符的值，这里的用法和PreparedStatement一样的用法List&lt;Object&gt; lists=query.list();//遍历查询结果for (Object object : lists) &#123; Object[] objects=(Object[])object; for (int i = 0; i &lt; objects.length; i++) &#123; System.out.println(objects[i]); &#125;&#125; 去除重复的数据 和sql语句一样，使用distinct即可 比如： select distinct name,age from Husband where id=? 聚合函数的查询 hql语句和sql一样，都是可以使用聚集函数查询 select count(*) from Husband where id=? 根据id查询出对应的人数 常见的聚合函数 count(*)： 计算数量 select count(*) from Husband where id=? sum() ：求和 select sum(age) from Husband h where h.wife.id=? AVG()： 求平均值 select avg(age) from Husband where age&gt;10 MAX(): 求最大值 select max(age) from Husband where age&gt;10 and age&lt;90 MIN()： 求最小值 select min(age) from Husband where age&gt;10 and age&lt;100 order by子句 from Husband where id=? order by name desc,age asc 按照姓名将序排列，年龄升序排列 group by 子句 在hql中也是可以使用group by子句进行分组的，比如select count(*),sum(age),max(age) from Husband h where h.age&gt;? group by h.name 同时也是可以使用having子句进行聚合函数的条件过滤，比如select count(*),sum(age),max(age) from Husband h where h.age&gt;? group by h.name having count(*)&gt;? 参考文章 http://www.cnblogs.com/bobomail/archive/2005/09/20/240352.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate简介]]></title>
      <url>%2F2018%2F04%2F22%2FHibernate%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[hibernate简介什么是hibernate hibernate是数据访问层的框架，对JDBC进行了封装，是针对数据库访问提出的面向对象的解决方案 Hibernate的作用 使用Hibrenate可以直接访问对象，从hierbnate自动将此访问转换成SQL执行，从而达到间接访问数据库的目的，简化了数据访问层的代码开发 hibernate与JDBC对比使用JDBC具有以下缺点 需要编写大量SQL语句 需要给大量的占位符?赋值 需要将ResultSet结果集转换成实体对象 SQL中包含特有函数，无法移植 使用Hibernante的优点 自动生成SQL语句 自动给？参数赋值 自动将ResultSet结果集转换成实体对象 采用一致的方法对数据库操作，移植性好 总结 简单的来说，hibernate对JDBC进行了封装，比如JDBCTemplate可以简便的操作数据库，底层还是使用了JDBC Hibernate与Mybatis的对比共性 对JDBC进行了封装 采用ORM思想解决了Entity和数据库的映射问题 MyBaits Mybatis采用SQL与Entity映射，对JDBC封装成都较轻 Mybatis需要程序猿自己写sql语句，更具灵活性 Hibernate Hibernate采用数据库和Entity映射。对JDBC封装程度较重Hibernate自动生成SQL，对于基本的操作，开发效率高 总结 Hibernate对JDBC的封装较重，程序猿不需要写SQL语句，比如写好映射关系就可以自动创建表，使用JDBCTemplate直接操作数据库 Hibernate框架设计原理设计原理 Hibernate采用了ORM思想对JDBC进行了封装 Hibernate框架是ORM思想的一种体现，解决了对象和数据库映射问题 Hibernate提供了一系列的API，允许我们直接访问实体对象，然后其根据ORM映射关系，转换成SQL并且去执行，从而达到访问数据库的目的 ORM思想 ORM： Object Relation Mapping，即是对象关系映射，指的是java独享和关系数据库之间的映射 ORM思想： 就是将对象与数据库进行相互转换的思想，不同的框架技术实现ORM的手段不同，但更多的是采用配置+反射的方式ORM hibernate文档 http://docs.jboss.org/hibernate/orm/3.5/reference/zh-CN/html/session-configuration.html#configuration-sessionfactory]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自己写springmvc框架]]></title>
      <url>%2F2018%2F04%2F22%2F%E8%87%AA%E5%B7%B1%E5%86%99springmvc%E6%A1%86%E6%9E%B6%2F</url>
      <content type="text"><![CDATA[简易的springmvc框架三层架构 表示层(视图层，显示层) jsp servlet 业务逻辑层 service 数据访问层(持久层) dao 什么是mvc Model View Controller 是一种架构思想，其核心思想将项目划分成三种不同模块，分别是模型，视图，控制器 模型： 负责封装业务逻辑和数据访问 控制器： 负责调度 视图： 负责显示 View : JSP 负责显示 Controller :控制器 起到调度分发请求 Model ： 模型层 代表除了Servlet，Controller之外的java代码，包括service，dao 好处 项目的可维护性，可扩展性更高，抽取service 实现思想 首先需要一个RequestMapping注解 创建前端控制器DispatcherServlet用来转发请求 创建视图解析器来对应不同的页面 创建注解RequestMapping 使用@Target可以设置这个注解在方法体上还是在类上使用，这里我们只是在方法体上使用，这个和Springmvc有点出入1234567891011import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(ElementType.METHOD) //设置这个注解是给方法使用的@Retention(RetentionPolicy.RUNTIME) //设置注解的存在时间为运行时public @interface RequestMapping &#123; //设置传入的参数 public String value(); //设置一个参数 ，必须传入参数 如果添加 default "" ,那么默认的参数就是空字符串 //public String method() default "get"; //设置method参数，默认的是get方法&#125; 创建Handler类 用来保存反射调用的方法和对象123456789101112131415161718192021222324252627282930313233import java.lang.reflect.Method;public class Handler &#123; private Method method; // 方法 private Object object; // Object对象，用于反射调用方法method public Handler(Method method, Object object) &#123; super(); this.method = method; this.object = object; &#125; public Method getMethod() &#123; return method; &#125; public void setMethod(Method method) &#123; this.method = method; &#125; public Object getObject() &#123; return object; &#125; public void setObject(Object object) &#123; this.object = object; &#125; @Override public String toString() &#123; return "Handler [method=" + method + ", object=" + object + "]"; &#125;&#125; config.xml(resource目录下) 用来存放bean，不同的controller类都需要在这个配置文件重视配置12345&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans&gt; &lt;bean class="cn.controller.UserController"&gt;&lt;/bean&gt; &lt;bean class="cn.controller.DeptController"&gt;&lt;/bean&gt;&lt;/beans&gt; XMLUtils 解析config.xml的文件，使用的是Dom4j 在pom.xml中导入依赖 123456&lt;!-- 读取xml文件的jar包 --&gt;&lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt;&lt;/dependency&gt; 解析xml文件的工具类 123456789101112131415161718192021222324252627282930313233343536373839404142import java.io.InputStream;import java.util.ArrayList;import java.util.List;import org.dom4j.Document;import org.dom4j.Element;import org.dom4j.io.SAXReader;import cn.reflect.ReflectDemo;/** * 读取XML文件的工具类 * @author chenjiabing * */public class XMLUtils &#123; /** * 读取xml文件中的内容,使用的jar包是dom4j * @return xml配置文件中的所有bean的对象 */ public static List&lt;Object&gt; getBeans() throws Exception&#123; SAXReader reader=new SAXReader(); InputStream inputStream=ReflectDemo.class.getClassLoader().getResourceAsStream("config.xml"); //获取输入流 Document document=reader.read(inputStream); //得到根节点 Element beansEle=document.getRootElement(); //得到根节点下面的所有子节点 List&lt;Element&gt; elements=beansEle.elements(); List&lt;Object&gt; beans=new ArrayList&lt;Object&gt;(); //保存bean中的class属性创建的对象 //遍历子节点 for (Element element : elements) &#123; //得到class属性的值 String className=element.attributeValue("class"); //直接使用遍历的className创建对象并且保存在集合中 Class cls=Class.forName(className); Object bean=cls.newInstance(); beans.add(bean); //将创建的对象添加到集合中 &#125; return beans; &#125;&#125; HandlerMapping 读取config.xml中的bean，并且利用反射获取注解上的value值(请求路径)、方法、创建类。存储在Map中1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package cn.reflect;import java.io.InputStream;import java.lang.reflect.Method;import java.util.HashMap;import java.util.List;import java.util.Map;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.Element;import org.dom4j.io.SAXReader;import cn.annoation.RequestMapping;public class HandlerMapping &#123; private Map&lt;String, Handler&gt; map = new HashMap&lt;String, Handler&gt;(); // 创建一个Map存储path和Handler /** * 初始化方法，将指定类的带有注解的方法放入Map中 * @param beans 对象集合 */ public void init(List&lt;Object&gt; beans) &#123; for (Object bean : beans) &#123; Class cls=bean.getClass(); //获取所有方法 Method[] methods=cls.getDeclaredMethods(); for (Method method : methods) &#123; RequestMapping requestMapping=method.getAnnotation(RequestMapping.class); //如果方法上面存在RequestMapping注解 if (requestMapping!=null) &#123; String path=requestMapping.value(); //获取注解上的地址 Handler handler=new Handler(method, bean); //创建handler对象 map.put(path, handler); //存放键值对 &#125; &#125; &#125; &#125; /** * 根据给定的path返回一个Handler对象 * * @param path * 指定的路径，map中的key * @return Handler 对象 */ public Handler getHandler(String path) &#123; return map.get(path); &#125;&#125; 视图解析器 根据controller方法中的返回值转发或者重定向到指定的视图 默认是转发的 重定向需要使用: redirect:add.do 12345678910111213141516171819202122232425262728import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class ViewResolver &#123; /** * 视图解析器 * @param returnValue controller方法的返回值 */ public void process(Object returnValue, HttpServletRequest request, HttpServletResponse response) &#123; String path=(String)returnValue; try &#123; //判断是转发还是重定向 if (path.startsWith("redirect:")) &#123; //重定向 response.sendRedirect(request.getContextPath()+"/"+path.split(":")[1]); &#125;else &#123; //转发 request.getRequestDispatcher("/WEB-INF/"+path+".jsp").forward(request, response); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; DispatcherServlet 前端控制器，其实是一个Servlet，不过用来拦截.do的请求，因此需要在web.xml中配置`.do` 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import java.io.IOException;import java.lang.reflect.Method;import java.util.List;import java.util.Scanner;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import cn.reflect.Handler;import cn.reflect.HandlerMapping;import cn.reflect.ViewResolver;import cn.utils.XMLUtils;/** * Servlet implementation class DispatcherServlet */public class DispatcherServlet extends HttpServlet &#123; @Override protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; List&lt;Object&gt; beans; try &#123; beans = XMLUtils.getBeans();// 获取xml配置文件中所有bean的对象 HandlerMapping handlerMapping = new HandlerMapping(); String uri = request.getRequestURI(); // 请求地址 String appName = request.getContextPath(); // 工程名 String path = uri.replace(appName, ""); // 获取注解的path handlerMapping.init(beans); // 初始化 Handler handler = handlerMapping.getHandler(path); // 获取指定的Handler Method method = handler.getMethod(); Object object = handler.getObject(); Class[] paramTypes = method.getParameterTypes(); // 获取方法中的参数类型 Object returnValue=null; //申明目标方法的返回值 // 如果调用的方法有参数 if (paramTypes.length &gt; 0) &#123; Object[] args = new Object[paramTypes.length]; //创建参数列表 for (int i = 0; i &lt; args.length; i++) &#123; Class cls = paramTypes[i]; // 判断类型是request或者response if (cls == HttpServletRequest.class) &#123; args[i] = request; &#125; else if (cls == HttpServletResponse.class) &#123; args[i] = response; &#125; &#125; returnValue=method.invoke(object, args); &#125; else &#123; returnValue=method.invoke(handler.getObject()); // 调用方法执行 &#125; //有返回值，要么转发，要么重定向 if (returnValue!=null) &#123; //通过视图解析器对象，处理转发或者重定向 ViewResolver viewResolver=new ViewResolver(); viewResolver.process(returnValue,request,response); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之适配器模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[结构型模式之适配器模式定义 适配器模式用于将一个接口转化成客户想要的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 Target（目标抽象类）：目标抽象类定义客户所需接口，可以是一个抽象类或接口，也可以是具体类。 Adapter（适配器类）：适配器可以调用另一个接口，作为一个转换器，对Adaptee和Target进行适配，适配器类是适配器模式的核心，在对象适配器中，它通过继承Target并关联一个Adaptee对象使二者产生联系。 Adaptee（适配者类）：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码。 根据对象适配器模式结构图，在对象适配器中，客户端需要调用request()方法，而适配者类Adaptee没有该方法，但是它所提供的specificRequest()方法却是客户端所需要的。为了使客户端能够使用适配者类，需要提供一个包装类Adapter，即适配器类。这个包装类包装了一个适配者的实例，从而将客户端与适配者衔接起来，在适配器的request()方法中调用适配者的specificRequest()方法。因为适配器类与适配者类是关联关系（也可称之为委派关系），所以这种适配器模式称为对象适配器模式 类适配器 类适配器是继承适配者类实现的，其中对象适配器是使用组合的方式实现的，就是适配者类作为适配器类的成员变量而实现的 一般目标抽象类是一个接口，适配者类一般是一个具体的实现类，有时候甚至不知道其中的源代码，因此需要适配器类将适配者类转换成适合用户的目标类 实例 我们知道笔记本充电的电压是5v，但是我们的高压电是220v，那么我们此时就需要一个适配器将这个220v电压转换成为5v的电压给笔记本充电 这里的220v电压就是适配者类，即是需要转换的类 5v电压是目标抽象类，由适配器将220v转换而来 这里的适配器类的主要功能就是将220v电压转换成5v电压 目标接口(5v电压) 1234567/* * 接口为5v电压的接口 ， 这个目标抽象类 */public interface Power5 &#123; void getPower5();&#125; 220v电压的类（这里是一个具体的类，适配者类） 12345public class Power220 &#123; public void getPower220()&#123; System.out.println("正在输出220v电压....."); &#125;&#125; 适配器类（将220v电压转换成5v） 1234567891011121314151617181920212223242526/* * 适配器类，主要的目的就是将220v电压转换为5v的电压供笔记本充电 * 其中Power5是目标抽象接口，是最终需要的接口，Power220是一个适配者类，是已经存在的，只需要适配器转换即可 */public class AdapterPower5 extends Power220 implements Power5 &#123; /** * 重载Power5中的方法，获取需要的5v电压 * 过程： 先获取220v电压，然后进行转换即可 * */ @Override public void getPower5() &#123; super.getPower220(); //首先获取220v电压 this.transform(); //将220v电压转换成5v的电压 System.out.println("获取5v电压......."); &#125; /* * 将220v电压转换成5v电压的方法 */ public void transform() &#123; System.out.println("现在将220v电压转换成5v电压......."); &#125;&#125; 笔记本充电的类 12345678910111213/* * 笔记本类 */public class NoteBook &#123; /** * 笔记本充电的方法 * @param power5 电压为5v的对象 */ public void PowerOn(Power5 power5)&#123; power5.getPower5(); //获取5v电压 System.out.println("笔记本获取了5v的电压，正在开始充电......"); &#125;&#125; 测试类 123456public class Client &#123; public static void main(String[] args) &#123; NoteBook noteBook=new NoteBook(); //创建笔记本的类 noteBook.PowerOn(new AdapterPower5()); //调用笔记本充电的类 &#125;&#125; 对象适配器 对象适配器是将适配者类作为适配器类的成员变量并不是继承，这个是一种组合方式 这种方式使用的更加普遍 实例 这里的实例还是前面的例子 这里唯一不同的就是适配器类，不是继承适配者类，而是使用组合的方式 1234567891011121314151617181920212223242526/* * 适配器类，这个是对象适配器，适配者类是作为成员变量存在，是组合关系 */public class Adapter implements Power5 &#123; private Power220 power; //220v电压类的对象，作为成员变量 /* * 构造方法，主要是为类初始化Power220v的对象 */ public Adapter(Power220 power)&#123; this.power=power; &#125; @Override public void getPower5() &#123; power.getPower220(); //获取220v电压 transform(); //转换电压 System.out.println("正在输出5v电压......."); &#125; public void transform()&#123; System.out.println("将220v电压转换成5v的电压......"); &#125;&#125; 总结 类适配器是使用类继承的方式，适配器类继承适配者类(不提倡使用) 对象适配器使用的是一种组合的方式，将适配者类作为其中的成员变量，那么也是可以实现（提倡使用） 麻烦支持下博主的广告事业，点击下即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之桥接模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[结构型模式之桥接模式 桥接模式是一种很实用的结构型设计模式，如果软件系统中某个类存在两个独立变化的维度，通过该模式可以将这两个维度分离出来，使两者可以独立扩展，让系统更加符合“单一职责原则”。与多层继承方案不同，它将两个独立变化的维度设计为两个独立的继承等级结构，并且在抽象层建立一个抽象关联，该关联关系类似一条连接两个独立继承结构的桥，故名桥接模式。 桥接模式用一种巧妙的方式处理多层继承存在的问题，用抽象关联取代了传统的多层继承，将类之间的静态继承关系转换为动态的对象组合关系，使得系统更加灵活，并易于扩展，同时有效控制了系统中类的个数。桥接定义如下： 桥接模式(Bridge Pattern)：将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体(Handle and Body)模式或接口(Interface)模式。 在桥接模式结构图中包含如下几个角色： Abstraction（抽象类）：用于定义抽象类的接口，它一般是抽象类而不是接口，其中定义了一个Implementor（实现类接口）类型的对象并可以维护该对象，它与Implementor之间具有关联关系，它既可以包含抽象业务方法，也可以包含具体业务方法。 RefinedAbstraction（扩充抽象类）：扩充由Abstraction定义的接口，通常情况下它不再是抽象类而是具体类，它实现了在Abstraction中声明的抽象业务方法，在RefinedAbstraction中可以调用在Implementor中定义的业务方法。 Implementor（实现类接口）：定义实现类的接口，这个接口不一定要与Abstraction的接口完全一致，事实上这两个接口可以完全不同，一般而言，Implementor接口仅提供基本操作，而Abstraction定义的接口可能会做更多更复杂的操作。Implementor接口对这些基本操作进行了声明，而具体实现交给其子类。通过关联关系，在Abstraction中不仅拥有自己的方法，还可以调用到Implementor中定义的方法，使用关联关系来替代继承关系。 ConcreteImplementor（具体实现类）：具体实现Implementor接口，在不同的ConcreteImplementor中提供基本操作的不同实现，在程序运行时，ConcreteImplementor对象将替换其父类对象，提供给抽象类具体的业务操作方法。 实例 从上面的这个实例我们可以看出，如果使用多层继承的话，那么我们可以定义是三个抽象类（台式机，笔记本，平板电脑），在这个三个抽象类的下面每个都有三个不同品牌的具体实现类，那么总共要有3x3=9个具体的实现类。不仅仅是类的数量多，在扩展性能上也是成倍的增加，如果想要添加一个品牌，那么需要添加三个类，这个是极其浪费的。 针对上面的缺点，我们可以使用桥接模式，将电脑分类，品牌分类分成两个维度，如下图： 其中Computer是一个抽象类，不是接口，其中Brand（品牌）是其中的成员变量，我们就完成了一个电脑具有不同品牌，那么如果我们想添加一个品牌，就只是添加一个具体的实现类即可，就不需要添加三个了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之原型模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之原型模式定义 原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要 在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 原型模式可以分为浅克隆和深度克隆 角色 java语言中实现克隆的两种方式 直接创建一个对象，然后设置成员变量的值 123Obj obj=new Obj(); //创建一个新的对象obj.setName(this.name); //设置其中变量的值obj.setAge(this.age); 实现cloneable接口 浅克隆 如果克隆的对象的成员变量是值类型的，比如int，double那么使用浅克隆就可以实现克隆完整的原型对象，但是如果其中的成员变量有引用类型的，那么这个引用类型的克隆过去的其实是地址，克隆对象的这个引用类型变量改变了，那么原来变量的值也是会改变的。 简单的说，浅克隆只能复制值类型的，对于引用类型的数据只能复制地址 实例 一个公司出版周报，那么这个周报的格式一般是相同的，只是将其中的内容稍作修改即可。但是一开始没有这个原型，员工每周都需要重新手写这个周报，现在有了这个周报的原型，只需要在这个clone这个原型，然后在其基础上修改即可。 其中的Cloneable就是抽象原型类 附件类（这个是一个引用类型的对象，验证浅克隆只是复制其中的地址，如果两个对象中的任何一个改变了这个变量的值，那么另外一个也会随之改变） 12345678910111213141516171819/* * 附件类，这个是周报的附件 */public class Attachment &#123; private String name; // 名称 public Attachment(String name) &#123; super(); this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 周报的类（其中实现了Cloneable接口） 其中的clone()方法返回的就是一个克隆的对象，因此我们调用这个方法克隆一个新的对象 1234567891011121314151617181920212223242526272829303132333435/* * 这个是周报类，这个类是实现接口Prototype这个接口的 */public class WeeklyLog implements Cloneable &#123; private String name; // 姓名 private String date; // 日期 private String content; // 内容 private Attachment attachment; //附件，是一个引用对象，这个只能实现浅克隆 public WeeklyLog() &#123; super(); &#125; /** * 构造方法 */ public WeeklyLog(String name, String date, String content) &#123; super(); this.name = name; this.date = date; this.content = content; &#125; /** * 提供一个clone方法，返回的是一个clone对象 */ public WeeklyLog clone() &#123; Object object = null; // 创建一个Object对象 try &#123; object = super.clone(); // 直接调用clone方法，复制对象 return (WeeklyLog) object; // 返回即可 &#125; catch (CloneNotSupportedException e) &#123; System.out.println("这个对象不能复制....."); return null; &#125; &#125;&#125; 测试类 测试浅克隆的值类型是是否完成复制了 测试引用类型的值能否完成克隆，还是只是复制了一个引用地址 从结果来看，对象是完成复制了，因为判断两个对象的地址是不一样的，但是其中的引用类型的成员变量没有完成复制，只是复制了一个地址 12345678910111213141516public class Client &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; WeeklyLog p1 = new WeeklyLog("陈加兵", "第一周", "获得劳动模范的称号..."); // 创建一个对象 Attachment attachment = new Attachment("消息"); p1.setAttachment(attachment); // 添加附件 WeeklyLog p2 = p1.clone(); System.out.println(p1 == p2); // 判断是否正确 p2.setName("Jack"); // 修改P2对象的内容 p2.setDate("第二周"); p2.setContent("工作认真....."); System.out.println(p2.getName()); // 返回true，可以知道这两个附件的地址是一样的 System.out.println(p1.getAttachment() == p2.getAttachment()); &#125;&#125; 总结 浅克隆对于值类型的数据可以复制成功，但是对于引用卡类型的数据只能复制一个地址，如果一个对象中的引用类型的变量的值改变了，那么另外一个也会随之改变 深度克隆 浅克隆只能完成复制值类型，深度克隆可以完成复制引用类型和值类型 条件 引用类型的变量类实现序列化(实现Serializabl接口） 需要克隆的类实现序列化(实现Serializable接口) 为什么实现序列化 因为深度克隆的实现的原理是使用输入和输出流，如果想要将一个对象使用输入和输出流克隆，必须序列化。 实现 附件类(引用类型的成员变量，实现序列化) 1234567891011121314151617/* * 附件类，这个是周报的附件 */public class Attachment implements Serializable&#123; private static final long serialVersionUID = -799959163401886355L; private String name; // 名称 public Attachment(String name) &#123; super(); this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 周报类（需要克隆的类，因为其中有引用类型的成员变量，因此需要实现序列化) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* * 这个是周报类，这个类是实现接口Prototype这个接口的 */public class WeeklyLog implements Serializable &#123; private static final long serialVersionUID = -8782492113927035907L; private String name; // 姓名 private String date; // 日期 private String content; // 内容 private Attachment attachment; // 附件，是一个引用对象，这个只能实现浅克隆 public WeeklyLog() &#123; super(); &#125; /** * 构造方法 */ public WeeklyLog(String name, String date, String content) &#123; super(); this.name = name; this.date = date; this.content = content; &#125; /** * 提供一个clone方法，返回的是一个clone对象 */ public WeeklyLog clone() &#123; // 将对象写入到对象流中 ByteArrayOutputStream arrayOutputStream = new ByteArrayOutputStream(); try &#123; ObjectOutputStream objectOutputStream = new ObjectOutputStream( arrayOutputStream); // 创建对象输出流 objectOutputStream.writeObject(this); // 将这个类的对象写入到输出流中 &#125; catch (IOException e) &#123; e.printStackTrace(); return null; &#125; // 将对象从流中读出 ByteArrayInputStream arrayInputStream = new ByteArrayInputStream( arrayOutputStream.toByteArray()); WeeklyLog weeklyLog; try &#123; ObjectInputStream objectInputStream = new ObjectInputStream( arrayInputStream);// 新建对象输入流 weeklyLog = (WeeklyLog) objectInputStream.readObject(); // 读取对象从流中 return weeklyLog; &#125; catch (IOException | ClassNotFoundException e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; 测试类 从中可以看出其中的附件地址是不同的，如果一个对象的附件变量改变了，那么另外一个将保持不变，因此实现了深度克隆，是两个完全不同的对象 12345678910111213141516public class Client &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; WeeklyLog p1 = new WeeklyLog("陈加兵", "第一周", "获得劳动模范的称号..."); // 创建一个对象 Attachment attachment = new Attachment("消息"); p1.setAttachment(attachment); // 添加附件 WeeklyLog p2 = p1.clone(); System.out.println(p1 == p2); // 判断是否正确 p2.setName("Jack"); // 修改P2对象的内容 p2.setDate("第二周"); p2.setContent("工作认真....."); System.out.println(p2.getName()); //返回false，可以看出这个是不同的地址，因此完成了深克隆 System.out.println(p1.getAttachment() == p2.getAttachment()); &#125;&#125; 总结 因为深度克隆使用的是将对象写入输入和输出流中的，因此需要实现序列化，否则将不能完成 总结 浅克隆只能克隆对象中的值类型，不能克隆有引用类型成员变量的对象 使用深度克隆： 引用类型的成员变量的类必须实现序列化 需要克隆的类必须实现序列化]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之建造模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之建造者模式定义 建造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。 简单说，建造者的功能就是先构造复杂对象的每一个部件，指挥者的功能就是将这些部件以一定的步骤组装起来，形成一个具有一定功能的产品或者对象。当然这个步骤是透明的对于客户端。 建造者模式一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。建造者模式结构如图8-2所示： 实例 下面是一个组装汽车的例子，其中汽车由发动机和轮胎组成，那么我们只需要组装轮胎，发动机即可组装完成一个汽车。 汽车包括轮胎，引擎，我们通常在组装汽车的时候一般都是一步一步的组装，比如先装引擎，后装轮胎。使用建造者模式就是将建造汽车的这个过程抽离成几个不同的过程，比如建造引擎和建造轮胎就是两个过程。 轮胎的JavaBean 12345678910111213141516171819/* * 轮胎 */class Tyre &#123; private String name; public Tyre(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 引擎的JavaBean 1234567891011121314151617181920/* * 引擎 */class Engine &#123; private String name; public Engine(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 汽车的JavaBean(汽车包含轮胎和引擎，因此使用聚合的关系) 123456789101112131415161718192021222324/* * 汽车的类 */public class Car &#123; private Tyre tyre; // 轮胎 private Engine engine; // 引擎 public Tyre getTyre() &#123; return tyre; &#125; public void setTyre(Tyre tyre) &#123; this.tyre = tyre; &#125; public Engine getEngine() &#123; return engine; &#125; public void setEngine(Engine engine) &#123; this.engine = engine; &#125;&#125; 抽象建造者(实际上是一个接口，其中定义了建造轮胎和引擎的方法) 1234567891011public interface Builder &#123; /** * 构造引擎的方法 */ Engine buliderEngine(); /** * 构造轮胎的方法 */ Tyre builderTyre();&#125; 具体的建造者(实现了抽象建造者，实现建造轮胎和引擎的详细过程) 12345678910111213141516/* * 具体的建造者，主要是构造汽车的部件 */public class BuilderCar implements Builder &#123; @Override public Engine buliderEngine() &#123; System.out.println("构造汽车发动机"); return new Engine("傻逼牌发动机"); &#125; @Override public Tyre builderTyre() &#123; System.out.println("构造汽车轮胎"); return new Tyre("傻逼牌轮胎"); &#125;&#125; 抽象指挥者(定义了一个构造汽车的方法)，指挥者的作用就是按照一定步骤将构造者建造的部件组装起来 123456/* * 指挥者的接口，用来按照顺序组装汽车 */public interface Director &#123; Car CreateCar();&#125; 具体的指挥者(实现了指挥者接口) 1234567891011121314151617181920212223242526/* * 指挥者的实现类 */public class DirectorCar implements Director &#123; private Builder builder; // 建造者的对象 /** * 构造方法，主要用来初始化建造者对象 * * @param builder Builder的对象 */ public DirectorCar(Builder builder) &#123; this.builder = builder; &#125; @Override public Car CreateCar() &#123; Car car = new Car(); // 创建汽车对象 Engine engine = builder.buliderEngine(); // 构建发动机 Tyre tyre = builder.builderTyre(); // 构造轮胎 car.setEngine(engine); // 设置属性 car.setTyre(tyre); // 设置属性 return car; // 返回构造好的汽车 &#125;&#125; 测试类 12345678public class Client &#123; public static void main(String[] args) &#123; Director director = new DirectorCar(new BuilderCar()); // 创建指挥者的对象 Car car = director.CreateCar(); // 获取组装完成的 System.out.println(car.getEngine().getName()); // 输出引擎的名字 System.out.println(car.getTyre().getName()); // 输出轮胎的名字 &#125;&#125; 适用场景 基本部件不变，但是其中的组合经常变化的情况 比如你去肯德基点餐，汉堡，可乐，鸡翅这些食物是不变的，但是套餐的组合是经常变化的，建造者模式的指挥者就是将这些部件按照一定步骤将其组合起来的。 java中StringBuilder 需要生成的对象具有复杂的内部结构 复杂的内部结构，我们可以使用建造者模式将其分离，先将其中的各个小的部件组装成功，然后由指挥者按照一定的步骤将其组装成一个复杂的对象 需要生成的对象内部属性本身相互依赖。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之代理模式]]></title>
      <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[结构型模式之代理模式(静态代理) 由于某些原因，客户端不想或不能直接访问一个对象，此时可以通过一个称之为“代理”的第三者来实现间接访问，该方案对应的设计模式被称为代理模式。 代理其实是实现简介访问的媒介，当然在代理类中还可以在执行代理操作之前，之后，之中，环绕等执行相关动作。Spring 中面向切面编程就是这个原理 代理模式是一种应用很广泛的结构型设计模式，而且变化形式非常多，常见的代理形式包括远程代理、保护代理、虚拟代理、缓冲代理、智能引用代理等，后面将学习这些不同的代理形式 当使用代理类的时候， 真实类中的信息对用户来说是透明的(不可见的) 主要就是用于对象的间接访问提供了一个方案，可以对对象的访问进行控制 定义 Subject（抽象主题角色）：它声明了真实主题和代理主题的共同接口，这样一来在任何使用真实主题的地方都可以使用代理主题，客户端通常需要针对抽象主题角色进行编程。 Proxy（代理主题角色）：它包含了对真实主题的引用，从而可以在任何时候操作真实主题对象；在代理主题角色中提供一个与真实主题角色相同的接口，以便在任何时候都可以替代真实主题；代理主题角色还可以控制对真实主题的使用，负责在需要的时候创建和删除真实主题对象，并对真实主题对象的使用加以约束。通常，在代理主题角色中，客户端在调用所引用的真实主题操作之前或之后还需要执行其他操作，而不仅仅是单纯调用真实主题对象中的操作。 RealSubject（真实主题角色）：它定义了代理角色所代表的真实对象，在真实主题角色中实现了真实的业务操作，客户端可以通过代理主题角色间接调用真实主题角色中定义的操作。 实例第一个例子 需求： 我们知道mac笔记本是在美国生产的，那么如果中国供销商想要卖mac笔记本，那么必须从美国供销商那里先进货，然后中国的顾客才可以在中国供销商买mac。这里的中国供销商就相当于代理，美国供销商就相当于真实主题角色 Mac笔记本抽象接口(相当于其中的抽象主题) 123456/* * 苹果笔记本的接口，其中有一个方法实现了买笔记本的动作 */public interface MacBook &#123; public void buy(); //购买笔记本的行为&#125; 美国供销商(相当于这里RealSubject) 1234567891011/* * 美国的笔记本，实现了MacBook接口，表示在美国买笔记本 */public class USAMac implements MacBook &#123; @Override public void buy() &#123; System.out.println("在美国买笔记本"); &#125;&#125; 中国供销商(相当于这里的代理角色) 我们可以看到我们在使用代理模式的时候可以在之前和之后进行操作12345678910111213141516171819202122232425262728293031/* * 中国的笔记本，实现了MacBook 表示在中国买笔记本 * 但是中国想要买到苹果笔记本，那么还是需要先从美国进货，因此中国只是一个中间的代理作用而已 * 当然代理的最大作用就是在代理之前、之后、之中执行相关的操作，这就是面向切面编程的原理 */public class ChinaMac implements MacBook &#123; private MacBook mcBook=new USAMac(); //创建USAMac的对象 /** * 在购买之前执行的操作 */ public void preBuy()&#123; System.out.println("购买之前执行的操作"); &#125; /** * 在购买之后执行的操作 */ public void afterBuy()&#123; System.out.println("购买之后执行的操作"); &#125; @Override public void buy() &#123; this.preBuy(); //之前执行的操作 mcBook.buy(); //在美国买笔记本 System.out.println("在中国买笔记本"); this.afterBuy(); //之后执行的操作 &#125;&#125; 测试类 我们在使用的时候直接使用代理类即可，我们根本不知道在真实类的使用，完全是代理类为我们提供了 1234567public class Client &#123; public static void main(String[] args) &#123; MacBook macBook=new ChinaMac(); //创建ChinaMac对象，在中国买笔记本 macBook.buy(); //直接在中国买笔记本 &#125;&#125; 第二个例子 我们登录一个网站的服务器端的验证步骤： 读取用户名和密码 验证用户名和密码 记录到日志中 这里的验证密码和记录到日志中可以在代理类中实现，在用户执行操作之前需要读取用户名和密码，并且验证，在操作之后需要将用户的一些操作记录到日志中。其实这里的真实用户需要做的只是执行自己的操作，而验证和记录都是交给代理类实现的。 实现 用户接口(User) 1234567/* * 用户的抽象类 */public interface User &#123; public void DoAction(); //执行动作&#125; 真实的用户类（实现了用户接口） 主要的做的就是执行自己的操作 12345678910111213141516public class RealUser implements User &#123; public String name; public String password; public RealUser(String name, String password) &#123; this.name = name; this.password = password; &#125; public RealUser() &#123;&#125; /* * 执行一些操作 */ @Override public void DoAction() &#123; System.out.println("开始执行操作......"); &#125;&#125; 代理类(实现了User接口) 在执行操作之前验证密码和用户名是否正确 在执行操作之后记录到日志中 实际上这里就是面向切面编程 12345678910111213141516171819202122232425262728293031323334353637383940public class ProxUser implements User &#123; private RealUser user; // 真实用户的对象 /** * 创建对象 * @param name 姓名 * @param password 密码 */ public ProxUser(String name, String password) &#123; user = new RealUser(name, password); &#125; @Override public void DoAction() &#123; //验证用户名和密码 if (Validate()) &#123; user.DoAction(); //调用真实用户的DoAction方法执行相关操作 logger(); //调用日志记录信息 &#125; else &#123; System.out.println("请重新登录......."); &#125; &#125; /* * 验证用户的用户名和密码 */ public Boolean Validate() &#123; if ("陈加兵".equals(user.name) &amp;&amp; "123456".equals(user.password)) &#123; return true; &#125; return false; &#125; /** * 添加日志记录信息 */ public void logger() &#123; System.out.println(user.name + "登录成功......"); &#125;&#125; 测试类 实际上执行了验证用户名和密码，记录日志的操作，但是对于客户端来说只能看到自己执行的操作 123456public class Client &#123; public static void main(String[] args) &#123; ProxUser proxUser=new ProxUser("陈加兵", "123456"); //创建代理对象 proxUser.DoAction(); //执行操作，实际执行了验证信息，doaction(),日志记录这个三个动作 &#125;&#125; 缺点 如果增加一个接口就需要增加一个代理类，如果是要增加很多，那么就要增加很多代理类，代码将会重复 解决方法 下面我们将会讲解到动态代理，仅仅需要一个代理类即可 结构型模式之动态代理模式 前面我们说的代理模式其实是属于静态代理模式，就是说在程序执行之前已经写好了代理类，但是缺点也是说过，必须为每个接口都实现一个代理类，如果有多个接口需要代理，那么代码肯定是要重复的，因此就需要动态代理了。 动态代理可以实现多个接口共用一个代理类，只需要改变初始化的参数即可，可以省去很多的重复的代码。 JDK的动态代理需要一个类一个接口，分别为Proxy和InvocationHandler 主要原理就是利用了反射的原理 InvocationHandler 这个是代理类必须实现的接口，其中有一个方法public Object invoke(Object proxy,Method method,Object[] args) Object proxy：指被代理的对象。 Method method：要调用的方法 Object[] args：方法调用时所需要的参数 Proxy Proxy类是专门完成代理的操作类，可以通过此类为一个或多个接口动态地生成实现类，此类提供了如下的操作方法：public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) ClassLoader loader：类加载器 Class&lt;?&gt;[] interfaces：得到全部的接口 InvocationHandler h：得到InvocationHandler接口的子类实例 实例 肯德基的接口 123456/* * 肯德基的接口，其中一个eat方法 */public interface IKFC &#123; public void eat();&#125; 肯德基的实现类(RealSubject) 1234567891011/* * IKFC的实现类 */public class KFC implements IKFC &#123; @Override public void eat() &#123; System.out.println("我在肯德基吃了饭......"); &#125;&#125; 苹果笔记本的接口 123456/* * 苹果笔记本的接口 */public interface MacBook &#123; public void buy();&#125; 美国供销商的类(RealSubject) 12345678910/* * 美国笔记本的类，实现了MacBook接口 */public class USAMacBook implements MacBook &#123; @Override public void buy() &#123; System.out.println("在美国买了一个苹果电脑......"); &#125;&#125; 动态代理的类（实现了InvocationHandler接口） 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * 这个是代理类，实现了InvocationHandler接口 * */public class ProxyHandler implements InvocationHandler &#123; private Object Realobject; //被代理的对象 //构造方法，用来初始化被代理的对象 public ProxyHandler(Object obj)&#123; this.Realobject=obj; //初始化真实类的对象 &#125; /** * @param proxy 表示被代理的对象的，就是真实类的对象 * @param method 表示要调用真实类的方法 * @param args 表示方法调用的时候所需要的参数 * @return 方法调用之后的返回值 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; prefunction(); //执行之前调用的方法 Object res=method.invoke(Realobject, args); //Method类中的执行方法的函数，在反射中常用 afterFunction(); //执行之后调用的方法 return res; &#125; /** * 执行方法之前调用的方法 */ public void prefunction()&#123; System.out.println("执行方法之前......"); &#125; /** * 执行方法之后调用的方法 */ public void afterFunction()&#123; System.out.println("执行方法之后......"); &#125;&#125; 测试类 1234567891011121314151617181920212223import java.lang.reflect.Proxy;import com.sun.org.apache.bcel.internal.generic.NEW;import com.sun.org.apache.bcel.internal.util.Class2HTML;public class Client &#123; public static void main(String[] args) &#123; Class[] cls1=&#123;IKFC.class&#125;; //第一个代理的所有接口数组，直接用接口的反射即可 Class[] cls2=USAMacBook.class.getInterfaces(); //直接具体的实现类的反射调用getInterfaces即可返回所有的接口数组 // 返回KFC的代理对象 IKFC kfc = (IKFC) Proxy.newProxyInstance(Client.class.getClassLoader(), cls1, new ProxyHandler(new KFC())); kfc.eat(); //执行方法 MacBook macBook = (MacBook) Proxy.newProxyInstance(Client.class.getClassLoader(), cls2, new ProxyHandler( new USAMacBook())); macBook.buy(); //执行方法 &#125;&#125; 总结 动态代理的好处 即使有多个接口，也仅仅只有一个动态代理类]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之工厂模式]]></title>
      <url>%2F2018%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之工厂模式什么是工厂模式 工厂模式是java中最常见的创建型模式，客户端在不知道创建逻辑的情况下，只需要在工厂中直接创建即可 简单工厂模式 简单工厂在创建对象的时候不需要知道具体的创建逻辑，客户端只需要知道该产品的一个标志即可，比如产品的名字 必备的两个元素： 产品的抽象类 生产产品的工厂类 实现 假设现在我们需要根据客户端的要求创建不同的图形，比如矩形，圆形…..，此时我们可以将图形抽象成接口，具体的产品只需要实现这个图形接口即可 shape接口（图形的接口，其中提供了一个创建图形的方法） 123456/* * 这个是抽象的产品类，后续的所有的产品都必须实现这个抽象类 */public interface Shape &#123; public void draw(); //提供一个实现方法，作为画画的动作&#125; 矩形产品类（实现shape接口） 123456789101112131415/* * 矩形的产品类，其中实现了Shape这个类 */public class Rectangle implements Shape &#123; /** * 实现了Shape中的方法 */ @Override public void draw() &#123; System.out.println("我们画了一个矩形"); &#125;&#125; 圆形产品类（实现Shape接口） 1234567891011/* * 圆形的产品类，实现了Shape这个类 */public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println("我们画了一个圆"); &#125;&#125; 工厂方法（创建产品的类） 根据传入的标志创建对应的产品123456789101112131415161718/* * 简单工厂的实例 * 其中提供一个getShape(String name) 可以根据提供的名字来返回一个对象，其实工厂生产的产品 */public class SimpleFactoryDemo &#123; public Shape getShape(String name) &#123; switch (name) &#123; case "矩形": return new Rectangle(); // 返回矩形的对象 case "圆形": return new Circle(); // 返回圆形对象 default: System.out.println("我们不能创建一个额外的对象"); return null; // 没有指定对象就返回null &#125; &#125;&#125; 测试 12345678public class ClientMain &#123; public static void main(String[] args) &#123; String name = "圆形"; // 填入名字 SimpleFactoryDemo simpleFactoryDemo = new SimpleFactoryDemo(); // 创建简单工厂实例 Shape shape = simpleFactoryDemo.getShape(name); // 根据名字获取对象 shape.draw(); // 调用方法 &#125;&#125; 优缺点 优点： 每次增加一个产品类只需要增加一个实现类即可（实现产品接口） 缺点： 如果添加一个产品类，那么我们就需要在工厂类中添加对应的代码（违反开闭原则） 开闭原则： 简单的说就是在对功能进行扩展的时候对原先的代码不做任何修改 工厂方法模式 简单工厂模式是一个抽象产品类派生出多个具体的产品类，但是一个工厂就生产了全部的产品 工厂方法模式是有一个抽象工厂派生出多个具体的工厂，每个工厂生产一件具体的产品 条件 抽象产品类 抽象工厂类 每个具体的产品类都有一个具体的工厂类生产 实现 我们对上面的实例进行改写，只需要定义一个抽象工厂类即可，其中派生出两个具体的工厂类用来生产圆形和矩形 这里的抽象产品接口和具体的产品类和上面相同，不需要写了 抽象工厂（使用的接口，其中有一个生产方法） 1234567/* * 抽象的工厂类 * 其中定义一个方法 getShape() 返回的是Shape类型的产品类 */public interface FactoryInterface &#123; public Shape getShape();&#125; 生产圆形的工厂类（实现抽象工厂） 1234567891011/* * 生产圆形的产品类 其中实现了抽象的工厂类 */public class FactoryCircle implements FactoryInterface &#123; @Override public Shape getShape() &#123; return new Circle(); &#125;&#125; 生产矩形的工厂类（实现抽象工厂接口） 123456789/** * 生产矩形的工厂类，其中实现了抽象工厂类 */public class FactoryRectangle implements FactoryInterface &#123; @Override public Shape getShape() &#123; return new Rectangle(); &#125;&#125; 测试类 123456789101112public class ClientMain &#123; public static void main(String[] args) &#123; //使用多态创建工厂类 FactoryInterface factoryInterface=new FactoryCircle(); //创建圆形的工厂类 factoryInterface.getShape().draw(); //生成Circle对象并且调用方法 FactoryInterface factoryInterface2=new FactoryRectangle(); //创建矩形的工厂类 factoryInterface2.getShape().draw(); //生成Rectangle的对象并且调用方法 &#125;&#125; 优缺点 优点： 易于扩展，如果需要添加一个产品类，只需要添加一个具体的产品类和对应的工厂类即可，不需要对原工厂的方法进行任何的修改 在工厂方法模式中，用户只需要知道所需要产品的具体工厂类即可，不需要知道具体的创建过程，甚至不需要知道具体产品类的类名。 缺点： 每次新增一个产品时，都需要增加一个具体的产品类和具体的工厂类，明显的成倍增加代码。 抽象工厂模式 多个抽象产品类，派生出多个具体产品类；一个抽象工厂类，派生出多个具体工厂类；每个具体工厂类可创建读个具体产品类实例。 即是提供一个创建一系列相关或相互依赖对象的接口，而无需指定他们的具体的类。“一对多的关系” 这里的抽象产品类就像是一类产品的族，其中具体实现类就是不同的表现形式而已。 这里的每一个具体的工厂类可以生产不同种类的产品，并不是一个具体的工厂类只能生产一个具体的产品罢了 下面我们举一个麦当劳和肯德基的例子，他们两家中都买薯条和鸡翅，那么薯条和鸡翅就是两类产品，麦当劳和肯德基就是具体的工厂类用来生产薯条和鸡翅，那么我们需要一个抽象的工厂类来生产这两类产品，肯德基和麦当劳只需要实现即可。 总结定义 简单的说： 抽象工厂模式一个一个工厂生产一个产品类族 其中的工厂并不是生产一种产品，而是生产多种产品（一类的产品） 条件 多个抽象产品类派生出多个具体的产品类，比如鸡翅(麦当劳，肯德基)，薯片（麦当劳，肯德基） 一个抽象工厂，派生出多个具体的工厂类，比如肯德基和麦当劳就相当于两个工厂，这两个工厂都生产各自品牌的鸡翅，薯片，汉堡等 实现 抽象产品类 这里我们有两种产品，一个是鸡翅，一个薯片，因此需要创建两个抽象产品接口 鸡翅的抽象接口 1234567/* * 鸡翅的接口，这是一类产品的接口，在其中可以实现具体的产品类，比如麦当劳的麦乐鸡，肯德基的奥尔良烤翅*/public interface IChicken &#123;public void eat();&#125; 薯片的抽象接口 123456/* * 薯条的接口，这也是一个抽象的产品类，其中可以有多个具体的产品类，比如麦当劳的薯条，肯德基的薯条 */public interface IChips &#123; public void eat();&#125; 抽象工厂类 抽象工厂类只有一个，但是具体的工厂类一个是麦当劳，一个肯德基，工厂中生产各自品牌的产品 抽象工厂 12345678910/* * 抽象工厂类，用来生产鸡翅和薯条的工厂类，下面可以衍生出多个具体的工厂类来生产指定商家的鸡翅和薯条 */public interface IStore &#123; public IChicken createChicken(); // 生产鸡翅 public IChips createChips(); // 生产薯条&#125; 具体的产品类 肯德基的薯条 123456789101112/** * 肯德基的薯条，是IChips具体实现类，也是一个具体的产品类 */public class KfcChips implements IChips &#123; @Override public void eat() &#123; System.out.println("你吃了肯德基的薯条......"); &#125; &#125; 肯德基的鸡翅 1234567891011/* * 肯德基的奥尔良烤翅类，是IChicken的具体实现类，是一个具体的产品 */public class KfcChicken implements IChicken &#123; @Override public void eat() &#123; System.out.println("你吃了肯德基的奥尔良烤翅......"); &#125;&#125; 麦当劳的薯条 1234567891011/** * 麦当劳的薯条，是IChips具体实现类，也是一个具体的产品类 */public class McChips implements IChips &#123; @Override public void eat() &#123; System.out.println("你吃了麦当劳的薯条......"); &#125;&#125; 麦当劳的鸡翅 1234567891011/* * 麦当劳的鸡翅，这是IChicken的具体的实现产品类 */public class McChicken implements IChicken &#123; @Override public void eat() &#123; System.out.println("你吃了的麦当劳的鸡翅......"); &#125; &#125; 具体的工厂类 麦当劳的工厂类 12345678910111213141516/* * 麦当劳的工厂，实现了抽象工厂，这个工厂可以生产麦当劳的鸡翅和薯条 */public class McFactory implements IStore &#123; @Override public IChicken createChicken() &#123; return new McChicken(); // 生产麦当劳的鸡翅 &#125; @Override public IChips createChips() &#123; return new McChips(); // 生产麦当劳的薯条 &#125;&#125; 肯德基的工厂类 12345678910111213141516/* * 肯德基的工厂，实现了抽象工厂，这个工厂可以生产肯德基的鸡翅和薯条 */public class KFCFactory implements IStore &#123; @Override public IChicken createChicken() &#123; return new KfcChicken(); // 生产肯德基的鸡翅 &#125; @Override public IChips createChips() &#123; return new KfcChips(); // 生产肯德基的薯条 &#125;&#125; 测试类 1234567891011121314public class ClientMain &#123; public static void main(String[] args) &#123; IStore iStore1=new KFCFactory(); //创建肯德基的具体工厂类 iStore1.createChicken().eat(); //吃了肯德基的鸡翅 iStore1.createChips().eat(); //吃了肯德基的薯条 IStore iStore2=new McFactory(); //创建麦当劳的具体工厂类 iStore2.createChicken().eat(); //吃了麦当劳的鸡翅 iStore2.createChips().eat(); //吃了麦当劳的薯条 &#125;&#125; 优缺点 优点 当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点 产品族比较难扩展，比如你要添加一个鞋子这个产品族，那么需要自己定义一个鞋子的抽象产品类，还要添加这个不同品牌的具体的产品实现类，另外还需要在抽象工厂里添加一个生产鞋子的方法]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之单例模式]]></title>
      <url>%2F2018%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[创建型模式之单例模式(Singleton)什么是单例模式 该类只有一个实例 构造方法是私有的 有一个获取该类对象的静态方法getInstance() 应用场景 一个国家只有一个主席 如果此时的限定必须是抽象出来的类只能是一个对象，这个时候就需要使用单例模式 懒汉式什么是懒汉式 懒汉式是当用到这个对象的时候才会创建，即是在getInstance()方法创建这个单例对象 优缺点 只有用到的时候才会创建这个对象，因此节省资源 线程不安全 我们知道一旦我们使用了懒汉式就是在getInstance()方法中创建这个单例对象，那么不可避免的就是线程安全问题 实现12345678910111213141516171819202122/** * 懒汉式的单例模式： 不是线程安全的 * 优点： 在使用的时候才会初始化，可以节省资源 */public class SignalLazy &#123; // 将默认的构造器设置为private类型的 private SignalLazy() &#123; &#125; // 静态的单例对象 private static SignalLazy instance; //静态的获取单例的对象，其中有一个判断，如果没有初始化，那么就创建 public static SignalLazy getInstance() &#123; // 如果instance没有被初始化，那么就创建即可，这个是保证了单例，但是并不是线程安全的 if (instance == null) &#123; System.out.println("this is SignalLazy"); instance = new SignalLazy(); // 创建一 个对象 &#125; return instance; // 返回这个对象 &#125;&#125; 从上面的代码中我们可以知道一旦使用多线程创建对象，那么就会出现线程不安全，最后创建出来的就不是单例了 测试代码如下 12345678910111213141516171819public class MainTest &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; //创建实例，并且输出其中的地址，如果地址相同， 那么就是同一个实例 System.out.println("this is"+ SignalLazy.getInstance()); &#125; &#125;).start(); //主线程也是创建输出其中的地址，运行可以看出这两个地址是不一样的 System.out.println("this is"+SignalLazy.getInstance()); &#125;&#125; 解决线程不安全 线程同步锁(synchronized) 我们知道每一个类都有一个把锁，我们可以使用线程同步锁来实现线程同步方法 但是使用线程同步锁浪费资源，因为每次创建实例都需要请求同步锁，浪费资源 12345678public synchronized static SignalLazy getInstance() &#123; // 如果instance没有被初始化，那么就创建即可，这个是保证了单例，但是并不是线程安全的 if (instance == null) &#123; System.out.println("this is SignalLazy"); instance = new SignalLazy(); // 创建一个对象 &#125; return instance; // 返回这个对象 &#125; 双重校验 双重校验： 两次判断单例对象是否为 null，这样的话，当当线程经过这个判断的时候就会先判断，而不是等待，一旦判断不成立，那么就会继续执行，不需要等待 相对于前面的同步方法更加节省资源 123456789101112131415161718192021222324public class SignalTonDoubleCheck &#123; private volatile static SignalTonDoubleCheck instance = null; private SignalTonDoubleCheck() &#123; &#125;; // 将默认的构造方法设置私有 public static SignalTonDoubleCheck getInstance() &#123; if (instance == null) &#123; synchronized (SignalTonDoubleCheck.class) &#123; if (instance == null) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 这个new 并不是原子操作，因此当多线程进行到这里需要及时刷新这个值，因此要设置为voliate instance = new SignalTonDoubleCheck(); &#125; &#125; &#125; return instance; &#125;&#125; 匿名内部类 （推荐使用） 我们知道静态变量、静态代码块、静态方法都是在类加载的时候只加载一次 12345678910111213141516public class SignalTonInnerHolder &#123; //私有构造函数 private SignalTonInnerHolder() &#123; &#125; /* * 匿名内部类，其中利用了静态成员变量在类加载的时候初始化，并且只加载一次，因此保证了单例 */ private static class InnerHolder &#123; private static SignalTonInnerHolder instance = new SignalTonInnerHolder(); &#125; public static SignalTonInnerHolder getInstance() &#123; return InnerHolder.instance; //加载类 &#125;&#125; 一旦加载SignalTonInnerHolder类的时候就会加载其中的静态类，随之加载的就是其中的创建对象语句，因此在类加载的时候就完成了创建，这个和我们后面说的饿汉式有点相同 饿汉式什么是饿汉式 在类加载的时候就创建单例对象，而不是在getInstance()方法创建 所谓的饿汉式就是利用静态成员变量或者静态语句块在类加载的时候初始化，并且只初始化一次，因此这个是线程安全的，但是在没有用到的时候就初始化，那么是浪费资源 优缺点 还没用到就创建，浪费资源 类加载的时候就创建，线程安全 实现12345678910111213141516/* * 饿汉式：线程安全 * */public class SignalHungry &#123; private SignalHungry() &#123; &#125; // 静态变量只有在类加载的时候初始化一次，因此这个是线程安全的 private static SignalHungry instance = new SignalHungry(); public static SignalHungry getInstance() &#123; return instance; &#125;&#125; 测试12345678910111213141516171819public class MainTest &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; //创建实例，并且输出其中的地址，如果地址相同， 那么就是同一个实例 System.out.println("this is"+ SignalHungry.getInstance()); &#125; &#125;).start(); //主线程也是创建输出其中的地址，运行可以看出这两个地址是不一样的 System.out.println("this is"+SignalHungry.getInstance()); &#125;&#125; 总结 饿汉式在类加载的时候就会创建单例对象，因此浪费资源 懒汉式在用到的时候才创建，节省资源，但是线程不安全，但是我们可以使用匿名内部类的方式使其线程安全 一般在使用的时候会使用懒汉式的匿名内部类的实现和饿汉式的创建方式]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之常见关系]]></title>
      <url>%2F2018%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B8%B8%E8%A7%81%E5%85%B3%E7%B3%BB%2F</url>
      <content type="text"><![CDATA[继承和泛化 泛华关系是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。 使用三角箭头的实线表示继承，其中箭头指向的是父类 接口与实现 在java中一个类只能继承一个父类，但是可以实现多个接口 使用的是带三角的虚线表示，其中箭头指向的是接口 依赖 是一种使用关系，即一个类的实现需要另外一个类的协助，所以尽量不使用双向的依赖关系。 最典型的就是import 比如：一个类要定义String类型的变量，那么这个类就是依赖String这个类 关联 是一种拥有的关系，它使一个类知道另外一个类的属性和方法，比如数据库中的关系，通过学生可以查找到自己课程的成绩，只需要在学生中定义一个课程的对象即可。 代码体现： 成员变量 带普通箭头的实心线，指向被拥有者 聚合 是整体和部分的关系，且部分可以离开整体而单独的存在。车和轮胎是整体和部分的关系，但是轮胎离开车还是可以单独存在的 代码体现： 成员变量 带空心菱形的实心线，菱形指向整体 组合 是整体和部分的关系，但是部分不能离开整体而单独存在 代码体现：成员变量 带实心菱形的实线，菱形指向整体]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts2之类型转换器]]></title>
      <url>%2F2018%2F04%2F12%2FStruts2%E4%B9%8B%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%99%A8%2F</url>
      <content type="text"><![CDATA[Struts2之类型转换器 在我们接收表单的请求参数的时候其实默认的都是String类型，但是有时候我们需要其他的数据类型，比如int,double,float,Date。 其实前面表单的传值都是字符串形式的，但是为什么我们在JavaBean中定义了不同的类型的数据，Struts还是会正确接收表单传递过来的值呢，因为使用了Struts中的内建的类型转换器 传统的类型转换器 在Servlet中我们可以自己获取请求参数自己转换类型，通常使用request.getParamerter(String name) 获取请求的参数 如下: 123String username= requst.getParameter("username");//获取年龄然后转换成了整数int age=Integer.parseInt(requst.getParameter("age")); 内建的类型转换器 其实内建的类型转换器已经可以完成大部分的功能了，比如表单传值，其实传递的是字符串，但是我们在JavaBean中定义的却是不同类型的数据，内部原理就是用了内置的类型转换器 内建类型转换器可以完成基本类型之前的转换 自定义类型转换器 前面说的内建的类型转换器只是在普通的类型之间的转换，都是一些基本的类型可以实现自动转换，并不用自己定义类型转换器。但是我们现在需要将输出的字符串转换为复合对象，比如一个User（username，password）类，那么现在就不能使用内建的类型转换器自动转换了，现在需要自己定义类型转换器了。 实现类型转换器也是基于OGNL实现的，在OGNL中有一个TypeConverter接口，但是这个接口太复杂了，因此OGNL还提供了一个类DefaultTypeConverter，通过继承这个类就可以实现类型转换器了。 假设我们在登录界面需要在一个text中输入用户名和密码用逗号隔开，现在我们可以使用自定义的转换器。现在登录的JSP如下: 12345&lt;form action="http://localhost:8080/web3/login" method="post"&gt; &lt;label&gt;请输入用户名和密码(逗号隔开)：&lt;/label&gt; &lt;input type="text" name="user"&gt; &lt;input type="submit" value="提交"&gt; &lt;/form&gt; 定义的User类如下 12345678910111213141516public class User &#123; private String username; //用户名 private String password; //密码 public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; Action类 12345678910111213141516import com.opensymphony.xwork2.Action;import com.user.User;public class LoginAction implements Action &#123; private User user; // User对象 public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public String execute() throws Exception &#123; return SUCCESS; &#125;&#125; UserConverter（转换器类） 123456789101112131415161718192021222324252627282930313233import java.util.Map;import com.user.User;import ognl.DefaultTypeConverter;public class UserConverter extends DefaultTypeConverter &#123; /* * context：类型转换的上下文环境 * value: value是需要转换的参数，随着转换的方向不同，value的参数值也是不一样的，因此需要强制转化 * toType： 表示转换后的目标类型 */ public Object convertValue(Map context, Object value, Class toType) &#123; System.err.println("调用了"); // 有字符串转http://download.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html#sum换为User类 // toType表示转向的类型 if (toType == User.class) &#123; String[] params = (String[]) value; // 将字符串转换为数组 User user = new User(); // 创建User对象 // 利用逗号将数组中的第一个字符串分割为两个字符串，设置成username，password user.setUsername(params[0].split(",")[0]); user.setPassword(params[0].split(",")[1]); return user; // 最后一定要返回User对象 &#125; // 如果是从复合类转换为字符串 else if (toType == String.class) &#123; User user = (User) value; // 将value转换为User对象 // 最后返回一个字符串表现的形式 return user.getUsername() + "," + user.getPassword(); &#125; else &#123; return null; // 没有相互转换的条件返回null &#125; &#125;&#125; 从上面的代码可以看出有两类的转换:一是从字符串转换为User类，二是从User类转换为字符串，这个都是使用toType来控制的。 ConverterValue方法参数和返回值的含义 context： 是类型转换环境的上下文 value ：是需要转换的类型参数。随着转换方向的不同，value参数的值也是不一样的，当把字符串类型转换为User类型时，value就是原始字符串。当需要把User类型向字符串类型转换时，value是User的实例。当然无论向哪一个方向转换，value都是需要强制转换的。 toType: 是转换后的目标类型。 为什么自己当向User类转换的时候，value要转换为一个字符数组呢？ 因为这里对应的是一个文本，如果我们对应的是一个多选框，那么此时就是一个数组了，因此这里强制转换为数组是一个通用的写法 局部转换器 转换器分为局部转换器和全局转换器，局部转换器是针对指定的Action类，但是全局转换器是针对的是该项目中所有需要转换的Action类。 前面已经实现了Action类，现在我们只需要定义一个ActionName-conversion.properties文件和Action放在一个目录下即可，其中的ActionName是Action的类名，比如上面的Action类是LoginAction，那么这里的文件就是LoginAction-conversion,.properties。其中的内容如下： user是Action中定义User对象，com.converter.UserConverter是对应的转换的类，一定要定义到包名。 1user=com.converter.UserConverter 全局转换器 全局转换器是作用于全部需要转换的Action的，只需要定义一个xwork-conversion. Properties。这个的名字就不需要改变了，放在src目录下即可，这样才可以作用到全局中。内容如下: 12com.user.User=com.converter.UserConvertercom.date.Date=com.converter.Date 其中的内容是一键值对存在的，com.user.User对应的是定义的JavaBean类，这里不再是action类中的定义的User对象了，是需要转换对象的类，com.converter.UserConverter这个是定义转换器的类。 从上面我们可以看出来定义两个转换器，最后一个是将字符串转换为日期类型的转换器。其实其中可以定多个类型转换器，并且只要是一键值对的形式写出即可。 基于Struts2的类型转换器 上面的类型转换器都是基于OGNL的DefaultTypeConverter类实现的，基于该类实现转换时都要实现ConverterValue()方法，无论是从字符串转换为复合类型还是从复合类型转换为字符串都是在这个方法中实现。 为了简化类型转换器的实现，Struts2提供了一个StrutsTypeConverter抽象类，这个抽象类是DefaultTypeConverter的子类。其中重要的方法如下: public Object convertFromString(Map context, String[] values, Class toClass)将字符串转换为复合类型个方法。 context是上下文环境，value是字符串数组，toClass是要转换的类型 public String convertToString(Map context, Object values) 将复合类型转换为字符串 values是复合类对象，context是上下文环境 public Object convertValue(Map context, Object values, Class toClass)实现DefaultTypeConverter方法，其中的变量还是上面的意思 下面实现上面的登录转换，如下: 12345678910111213141516171819202122232425import java.util.Map;import org.apache.struts2.util.StrutsTypeConverter;import com.user.User;public class UserConverterStruts extends StrutsTypeConverter &#123; protected Object performFallbackConversion(Map context, Object o, Class toClass) &#123; return super.performFallbackConversion(context, o, toClass); &#125; // 将字符串转换为复合类型的方法 public Object convertFromString(Map context, String[] values, Class toClass) &#123; User user = new User(); //创建User对象 String[] userValues = values[0].split(","); // 将字符串数组中的第一个字符串分隔开 user.setUsername(userValues[0]); user.setPassword(userValues[1]); return user; &#125; // 将复合类型转换为字符串 public String convertToString(Map context, Object values) &#123; User user = (User) values; //强制转换成User类型的 String username = user.getUsername(); //获取username和password String password = user.getPassword(); return "&lt;" + username + "," + password + "&gt;"; &#125;&#125; 有了上面的转换器，那么局部转换器和全局转换器的配置还是和上面的一样，这里就不在赘述了。 数组属性的类型转换器 数组类型的转换器是用于提交的参数为数组的类型的，也就是同时Action中有一个属性为数组。 现在我们要同时输入两个用户的信息，jsp如下: 123456&lt;form action="http://localhost:8080/web3/login" method="post"&gt;&lt;label&gt;请输入用户名和密码(逗号隔开)：&lt;/label&gt;&lt;input type="text" name="users"&gt;&lt;input type="text" name="users"&gt;&lt;input type="submit" value="提交"&gt;&lt;/form&gt; 从上面的代码我们可以看出这里text中有两个name属性相同的表单，这个同时提交上去就是一个数组。 Action类：(定义一个User数组): 12345678910111213141516171819import com.opensymphony.xwork2.Action;import com.user.User;public class LoginSAction implements Action &#123; private User[] users; //定义数组类型User public User[] getUsers() &#123; return users; &#125; public void setUsers(User[] users) &#123; this.users = users; &#125; public String execute() throws Exception &#123; System.out.println(getUsers()[0].getUsername()); return SUCCESS; &#125;&#125; 数组转换器: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.Map;import org.apache.struts2.util.StrutsTypeConverter;import com.user.User;public class UsersConverterStruts extends StrutsTypeConverter &#123; // 将字符串转换复合类型 public Object convertFromString(Map context, String[] values, Class toClass) &#123; if (values.length &gt; 1) &#123; User[] results= new User[values.length]; // 创建对象，这里是创建和字符串数组一样的长度 // 遍历所有的字符串数组，然后将其填入每一个User对象中 for (int i = 0; i &lt; values.length; i++) &#123; User user=new User(); //创建user对象 String[] uservalues = values[i].split(","); user.setUsername(uservalues[0]); // 将其设置为User的属性 user.setPassword(uservalues[1]); results[i]=user; //将实例化的user对象，填入数组 &#125; return results; &#125; else &#123; // 这里表示数组中只有一个字符串 User user = new User(); // 创建对象 String[] uservalues = values[0].split(","); user.setUsername(uservalues[0]); user.setPassword(uservalues[1]); return user; &#125; &#125; // 将复合类型转换为字符串 public String convertToString(Map context, Object values) &#123; // 只是一个单个的User类型的 if (values instanceof User) &#123; User user = (User) values; String username = user.getUsername(); String password = user.getPassword(); return "&lt;" + username + "," + password + "&gt;"; &#125; // User数组 else if (values instanceof User[]) &#123; User[] users = (User[]) values; //转换为User数组 String results = "["; for (User user : users) &#123; String username = user.getUsername(); String password = user.getPassword(); results += "&lt;" + username + "," + password + "&gt;"; &#125; return results + "]"; //返回全部的字符串 &#125; else &#123; return ""; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts之标签库]]></title>
      <url>%2F2018%2F04%2F12%2FStruts%E4%B9%8B%E6%A0%87%E7%AD%BE%E5%BA%93%2F</url>
      <content type="text"><![CDATA[Struts标签库 如果想要在jsp页面使用struts2的标签，需要引入标签库 &lt;%@ taglib uri=&quot;/struts-tags&quot; prefix=&quot;s&quot;%&gt; 数据标签 作用: 用于数据的存储和处理 action action标签是用来在JSP页面中调用Action某个Action类的，该标签有如下的几个属性； Id该属性用来指定Action的引用id name该属性是用来指定Action类的映射地址 namespace该属性用来指定Action类所在namespace executeResult该属性用来指定是否将Action类的处理结果也跳转的那个视图内容包含到本页面中，默认值为false，不包含 ignoreContextParams该属性用来指定是够将请求的参数传入到Action中，默认为false，即是传入 1234567891011&lt;h1&gt;调用第一个action&lt;/h1&gt;&lt;!-- 调用登录的Action类，name指定&lt;action&gt;标签的name属性值，executeResult为true指示包含Action响应的内容 namespace指定Action类所在包指定的namespace--&gt;&lt;s:action name="login" executeResult="true" namespace="/"&gt;&lt;/s:action&gt;&lt;hr&gt;&lt;h1&gt;调用第二个action&lt;/h1&gt;&lt;!-- 调用第二个Action，表示注册页面，ignoreContextParams为true表示不传入参数，那么其中的password和username就不能接收参数了，因此输出为NULL --&gt;&lt;s:action name="regist" executeResult="true" namespace="/" ignoreContextParams="true"&gt;&lt;/s:action&gt; bean bean标签用来创建一个JavaBean实例，和action标签差不多，就是在jsp页面中调用JavaBean对象，创建一个对象,不过这个对象是存在Stack Context中的，不是值栈中的。 id用来表示创建的JavaBean类的实例，这个是用来在Stack Context中查看状态的,使用标签 name用来指定JavaBean，指定JavaBean类所在的路径 var这个是id一样的功能，其实可以代替id 12345678&lt;s:bean name="com.user.User" id="myBean" &gt; &lt;!-- 使用param标签为其赋值 --&gt; &lt;s:param name="username" value="'陈加兵'"&gt;&lt;/s:param&gt; &lt;s:param name="age" value="22"&gt;&lt;/s:param&gt; 姓名: &lt;s:property value="username"/&gt;&lt;br&gt; 年龄:&lt;s:property value="age"/&gt;&lt;/s:bean&gt; date date标签用于格式化一个日期，除了格式化输出当前的日期，也可以计算指定的日期和当前日期时刻之间的时差 format可选属性，用于指定格式化的格式，如yyyy/MM/dd-HH:mm:ss name必填的值，该属性指定格式化日期的值，比如Date对象 nice可选属性，如果为true那么将会输出指定日期和当前日期的时差，默认为false timezone可选属性，指定格式化所用的时区 var可选属性，如果指定了该属性，该时间对象将放入值栈中，可以使用id代替，但是推荐使用var 如果同时指定了nice=true，和format那么format将会失效 1234&lt;!-- 创建一个日期对象now，表示当前的时间 --&gt; &lt;s:set var="now" value="new java.util.Date()"&gt;&lt;/s:set&gt; &lt;!-- 格式化当前的日期--&gt; &lt;s:date name="#now" format="dd/MM/yyyy HH:mm:ss"/&gt;&lt;br&gt; debug 该标签是辅助标签，用来生成一个超链接，便于查看值栈，和Stack Context中的信息。 i18n 主要用于在视图上加载国际资源，使用该标签时需要指定一个name属性，该name属性为需要加载的国际化资源文件的basename include 将指定的jsp文件或者Servlet文件包含在当前的jsp页面，这个相当于标签。 value指定被包含的jsp或者Servlet文件路径 1&lt;s:include value="success.jsp"&gt;&lt;/s:include&gt; param param标签主要是为其他的标签提供参数的 注意value的值是使用的OGNL表达式，一定要注意，如果指定字符串要加单引号或者双引号 name指定要赋值的变量名 value指定变量的值 12345&lt;s:bean name="com.user.User" id="myBean" &gt; &lt;!-- 使用param标签为其赋值 --&gt; &lt;s:param name="username" value="'陈加兵'"&gt;&lt;/s:param&gt; &lt;s:param name="age" value="22"&gt;&lt;/s:param&gt;&lt;/s:bean&gt; push push标签用于将某个值放到ValueStack(值栈)中，从而更简单的访问该值，其实不将其防放置在值栈中也是可以访问，使用#即可。只有一个属性value就是需要放在栈顶的值 1234567891011121314&lt;s:bean name="com.user.User" id="myBean"&gt; &lt;s:param name="username" value="'陈加兵'"&gt;&lt;/s:param&gt; &lt;s:param name="age" value="22"&gt;&lt;/s:param&gt;&lt;/s:bean&gt;&lt;%-- 只有在push标签内是，被放到值栈中的对象才存在，一旦出了push标签那么就不存在了 --%&gt; &lt;s:push value="#myBean"&gt; &lt;s:property value="username"/&gt; &lt;s:property value="age"/&gt; &lt;!-- 这个可以看出值栈中有值 --&gt; &lt;s:debug&gt;&lt;/s:debug&gt; &lt;/s:push&gt; &lt;!-- 这个没有myBean对象 --&gt; &lt;s:debug&gt;&lt;/s:debug&gt; set set标签是用来将某一个值放入指定的范围，当然也是相当于创建一个新的变量 id该属性用来指定该元素的引用ID（废弃） var该属性用来指定创建的新变量的名称 value用来指定变量的值，这个是使用的OGNL表达式 scope该属性用来指定新变量的放置范围，可选值有page,request,session,application和action，如果没有指定该属性，则默认放在Stack Context中 12&lt;s:set var="x" value="'陈加兵'"&gt;&lt;/s:set&gt;&lt;s:property value="#x"/&gt; 获取指定范围的值,其实相当于在指定的范围内绑定属性值，可以实现数据共享： 12&lt;s:set var="x" value="'陈加兵'" scope="session"&gt;&lt;/s:set&gt;&lt;s:property value="#session.x"/&gt; 其实set的真正的作用是变量放置在指定的范围内，如果一个属性的访问的太繁琐了，比如访问user.name,但是这个值需要频繁的使用，这时就创建一变量存放这个值，并且设定范围: 12&lt;s:set var="x" value="user.name"&gt;&lt;/s:set&gt;&lt;s:property value="#x"/&gt; url url标签用于在页面生成一个url地址，该标签的属性如下: id指定该元素的引用id，如果指定了该属性，那么在Stack Context中就会有这个id，那么就可以使用#来获取它的值 value该属性用来指定生成URL地址，如果不指定该属性，那么action属性指定的Action作为URL地址 action该属性用来指定生成URL地址值的action，如果不指定该属性，那么使用value属性值作为URL地址值 method该属性用来指定使用action的方法 encode该属性用来指定是否需要encode请求参数，默认值为true includeParams该属性用来指定是否包含请求参数，可选值为：none,get,和all默认的为none includeContext该属性指定是否需要当前上下文包含在url地址中 anchor该属性指定URL的锚点 Scheme该属性用来指定URL使用的协议(HTTP或者HTTPS) namespace该属性用来指定命名空间，使用action的时候指定 1234567891011121314&lt;s:url value="success.jsp" includeParams="get" id="myUrl"&gt; &lt;s:param name="username" value="'陈加兵'"&gt;&lt;/s:param&gt;&lt;/s:url&gt;&lt;hr&gt;&lt;s:url action="login"&gt;&lt;/s:url&gt;&lt;hr&gt;&lt;s:url action="login" namespace="/user" includeParams="get"&gt; &lt;s:param name="username" value="'陈加兵'"&gt;&lt;/s:param&gt;&lt;/s:url&gt;&lt;hr&gt;&lt;!-- 获取值 --&gt;&lt;s:property value="#myUrl"/&gt; property property标签是用来在页面中输出指定值，该标签有如下属性: id指定该元素的标识（废弃） value指定需要输出的特定的值，注意这里使用的OGNL表达式，如果没有指定value属性，那么将会输出值栈中的栈顶的值 escape指定是否转义输出内容中HTML，其默认值为true default指定一个默认的输出值，如果value中的值为空，那么就会默认输出这个值 123456&lt;!-- 转义标签h1，输出内容 --&gt;&lt;s:property value="'&lt;h1&gt;陈加兵&lt;/h1&gt;'" escape="false"/&gt;&lt;!-- 输出Stack Context中的内容，并且指定了默认值 --&gt;&lt;s:property value="#username" default="输出一个默认值"/&gt;&lt;!-- 输出栈顶的值 --&gt;&lt;s:property/&gt; 总结 数据标签最重要的就是set,property,debug,i18n这些标签，其他的了解写即可 控制标签 控制标签主要用于条件和循环等流程控制 if/elseif/else 其中elseif允许出现多次 12345678910&lt;s:set var="age" value="22"&gt;&lt;/s:set&gt;&lt;s:if test="#age&gt;10"&gt; &lt;s:property value="#age+'大于10'" /&gt;&lt;/s:if&gt;&lt;s:elseif test="#age&gt;20"&gt; &lt;s:property value="#age+'大于20'" /&gt;&lt;/s:elseif&gt;&lt;s:else&gt; &lt;s:property value="#age+'在10与20之间'" /&gt;&lt;/s:else&gt; 并且和或的关系(&amp;&amp;,||) 123456789&lt;%-- 新建一个集合list --%&gt;&lt;s:set var="list" value="&#123;'陈加兵','郑元梅',22,33&#125;"&gt;&lt;/s:set&gt;&lt;%-- 指定begin,end获取前3个元素--%&gt;&lt;s:iterator value="#list" var="item" status="iter"&gt; &lt;s:if test="#iter.isOdd()&amp;&amp;#iter.getIndex()&gt;0"&gt; &lt;s:property value="#item+'---'+#iter.getIndex()"/&gt; &lt;br&gt; &lt;/s:if&gt;&lt;/s:iterator&gt; iterator iterator标签主要用于对集合进行迭代，这里的集合包含list，Set和数组，也可以对Map集合进行迭代输出。 value可选属性，该属性指定迭代的集合，如果没有指定value属性，那么就会迭代ValuStack栈顶的集合。 var可选属性，该属性指定的是迭代的集合中的每一个元素，放在Stack Context中· status可选属性，该属性指定迭代对象的IteratorStatus实例存放在Stack Context中，通过这个属性可以判断当前迭代元素的属性。例如是否为最后一个，以及当前元素的索引 begin可选属性，指定从迭代对象第几个元素开始迭代 end可选属性，指定迭代到对象的第几个元素结束 step可选属性，指定步长 如果迭代元素指定了status，那么就可以调用如下的属性查看迭代元素的当前的属性，可以调用如下的几个方法查看： int getCount() 返回当前迭代了几个元素 int getIndex() 返回当前迭代元素的索引 boolean isEven() 当前迭代元素的索引是否为偶数 boolean isFirst() 当前迭代元素是否为第一个元素 boolean isLast() 当前迭代元素是否为最后一个元素 boolean isOdd() 判断当前的迭代元素的索引是否为奇数 此标签每次进行迭代的时候就会把元素放在值栈的顶部，那么我们都知道如果不指定value属性，那么默认的就是从栈顶取元素： 1234567&lt;%-- 新建一个集合list --%&gt; &lt;s:set var="list" value="&#123;'陈加兵','郑元梅',22,33&#125;"&gt;&lt;/s:set&gt; &lt;%--指定了value属性，但是其他属性都没有，那么直接可以从栈顶取数据 --%&gt; &lt;s:iterator value="#"&gt; &lt;s:property/&gt; &lt;/s:iterator&gt; 指定var属性来获取迭代对象的值: 1234567&lt;%-- 新建一个集合list --%&gt; &lt;s:set var="list" value="&#123;'陈加兵','郑元梅',22,33&#125;"&gt;&lt;/s:set&gt;&lt;%-- 指定var表示当前迭代对象的每一个元素--%&gt; &lt;s:iterator value="#list" var="item"&gt; &lt;%-- 因为var元素是放在Stack Context中，因此可以使用#取值 --%&gt; &lt;s:property value="#item" /&gt; &lt;/s:iterator&gt; 指定begin，end来获取指定范围的值。 12345678&lt;%-- 新建一个集合list --%&gt; &lt;s:set var="list" value="&#123;'陈加兵','郑元梅',22,33&#125;"&gt;&lt;/s:set&gt; &lt;%-- 指定begin,end获取前3个元素--%&gt; &lt;s:iterator value="#list" var="item" begin="0" end="2"&gt; &lt;%-- 因为var元素是放在Stack Context中，因此可以使用#取值 --%&gt; &lt;s:property value="#item" /&gt; &lt;/s:iterator&gt; 指定status获取每一个迭代元素的当前状态: 12345678910&lt;%-- 新建一个集合list --%&gt; &lt;s:set var="list" value="&#123;'陈加兵','郑元梅',22,33&#125;"&gt;&lt;/s:set&gt; &lt;%-- 指定begin,end获取前3个元素--%&gt; &lt;s:iterator value="#list" var="item" status="iter"&gt; &lt;s:if test="#iter.isOdd()&amp;&amp;#iter.getIndex()&gt;0"&gt; &lt;s:property value="#item+'---'+#iter.getIndex()"/&gt; &lt;br&gt; &lt;/s:if&gt; &lt;/s:iterator&gt; 迭代Map 12345&lt;s:set var="map" value="#&#123;'age':22,'username':'陈加兵' &#125;"&gt;&lt;/s:set&gt;&lt;s:iterator value="#map" var="item"&gt; 获取集合中的key:&lt;s:property value="#item.key"/&gt; 获取集合中的值：&lt;s:property value="#item.value"/&gt;&lt;/s:iterator&gt; append append标签用于将多个集合拼接起来形成一个新的集合。 var拼接之后形成的新的集合，放在Stack Context中 id这个和var是一样的，两个可以互换使用的，不过推荐使用var 12345678910111213&lt;%-- 新建一个集合list --%&gt;&lt;s:set var="list1" value="&#123;'陈加兵','郑元梅',22,33&#125;"&gt;&lt;/s:set&gt;&lt;s:set var="list2" value="&#123;44,55,6,99&#125;"&gt;&lt;/s:set&gt;&lt;s:append var="list3"&gt; &lt;%-- 使用param标签指定要拼接的集合 --%&gt; &lt;s:param value="#list1"&gt;&lt;/s:param&gt; &lt;s:param value="#list2"&gt;&lt;/s:param&gt;&lt;/s:append&gt;&lt;s:iterator value="#list3" var="item"&gt; &lt;s:property value="#item"/&gt;&lt;/s:iterator&gt; generator 使用这个标签可以将字符串按照指定的分隔符分割成多个子串，临时生成的子串可以使用标签迭代输出。可以这样理解：这个标签使用指定的的分隔符将字符串分割，然后这些字符串组成一个集合。 val必选属性，该属性指定被解析的字符串 var可选属性，如果指定了该属性，那么生成的Iterator对象将会以这个名称放在Stack Context中，就可以访问这个集合了。 count可选属性，该属性指定生成集合中元素的个数 separator必选属性，这个属性指定分隔符 converter可选属性，该属性指定一个转换器，该转换器负责将集合中的每一个字符串转换成对象，通过该转换器可以将一个字符串解析成对象集合。该属性值必须是org.apache.struts2.util.IteratorGenerator.Convertere 123456&lt;%--分隔符为',',并且选取其中的前两个元素 --%&gt; &lt;s:generator separator="," val="'陈加兵,郑元梅,chenjiabing'" var="x" count="2"&gt;&lt;/s:generator&gt; &lt;s:iterator value="#x" var="item"&gt; &lt;s:property value="#item" /&gt; &lt;/s:iterator&gt; merge merge这个标签和append的功能是一样的，都是将两个集合拼接在一起，但是append是将一个集合拼接在另外一个集合的末尾，但是merge是将后面一个集合的对应索引的元素添加到前面一个集合的索引所在的位置，也就是后面集合的第一个元素变成了新集合的第二个元素了。 123456789101112&lt;s:set var="list1" value="&#123;'陈加兵','郑元梅'&#125;"&gt;&lt;/s:set&gt; &lt;s:set var="list2" value="&#123;1,2&#125;"&gt;&lt;/s:set&gt; &lt;s:merge var="list3"&gt; &lt;s:param value="#list1"&gt;&lt;/s:param&gt; &lt;s:param value="#list2"&gt;&lt;/s:param&gt; &lt;/s:merge&gt; &lt;s:iterator var="item" value="#list3"&gt; &lt;s:property value="#item"/&gt; &lt;/s:iterator&gt; subset subset标签用于取得集合的子集，形成新的集合。 count可选属性，指定选取集合的子集的个数，如果不指定该属性，那么默认的就是截取全部的元素 source可选属性，该属性指定源集合，如果没有指定，那么默认是从栈顶取集合 start可选属性，该属性指定子集从源集合的第几个元素开始截取，默认从第一个开始(即start=0) decider可选属性，该属性有开发真决定是否选中该元素 var可选属性，如果指定了该属性，那么生成Iterator对象设置成为Page范围内的属性，可以使用#attr.name获取其值，也可以替换成id，但是推荐使用var 12345678910&lt;!-- 创建一个集合 --&gt; &lt;s:set var="list1" value="&#123;'陈加兵','郑元梅',1,2,3&#125;"&gt;&lt;/s:set&gt; &lt;!-- 指定变量为x，存储在page中，源集合为list1，截取其中的两个元素，从第二个元素开始截取 --&gt; &lt;s:subset var="x" source="#list1" count="2" start="1"&gt;&lt;/s:subset&gt; &lt;!-- 由于x存储在Page中，因此使用#attr.x来获取 --&gt; &lt;s:iterator value="#attr.x" var="item"&gt; &lt;s:property value="#item" /&gt; &lt;/s:iterator&gt; sort 主要用于对集合进行排序 comparator必填属性，该属性指定进行排序的实例，必须实现java.util.Comparator接口 source可选属性，这是一个源集合，如果没有指定，那么就拿栈顶的集合进行排序 var可选属性，如果指定了属性，那么生成的Iterator对象设置成Page范围的属性，该属性也可替换成id 12345678910&lt;s:set var="list" value="&#123;'陈加兵','123459999+','4442555'&#125;"&gt;&lt;/s:set&gt; &lt;!-- 创建一个实例 --&gt; &lt;s:bean name="com.compare.Compare" id="compare"&gt;&lt;/s:bean&gt; &lt;!-- 排序 --&gt; &lt;s:sort comparator="#compare" source="#list" var="x"&gt;&lt;/s:sort&gt; &lt;!-- 迭代输出 --&gt; &lt;s:iterator var="item" value="#attr.x"&gt; &lt;s:property value="#item" /&gt; &lt;/s:iterator&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts之OGNL使用]]></title>
      <url>%2F2018%2F04%2F02%2FStruts%E4%B9%8BOGNL%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[OGNL的使用OGNL简介 OGNI是一种对象图导航语言(object graphics navigation language) ,这也是一种表达式语言，这个和EL表达式一样，但是EL表达式只能在JSTL标签库中使用，这个OGNL只能在struts标签库中使用。 值栈（valueStack) 值栈就是存储Action的信息，包括其中定义的成员变量和其他的一些自己的属性，比如error,fieldError,如果想要让action中属性在值栈中显示或者获取，一定要为这些属性设置get,set方法 值栈是存储的action的栈，同时可以存储多个action，先执行的先进栈 值栈中的元素是根元素，访问值栈中的元素不需要使用#(#是访问非根元素的值，比如#session.username) 在jsp页面可以使用struts标签库&lt;s:debug/&gt;,查看值栈中的内容 实验 我们新建一个Action类，用表单传递数据请求action，最后action跳转到success.jsp页面，我们在success.jsp使用&lt;s:debug&gt;查看此时值栈中的数据 其中的属性必须要有get，set方法 LoginAction 123456789101112131415161718192021222324//实现ModelDriven接口&lt;&gt;指定的泛型为JavaBean类public class LoginAction extends ActionSupport &#123; private User user; private String tips; public String getTips()&#123; return tips; &#125; public void setTips(String tips)&#123; this.tips=tips; &#125; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; @Override public String execute() &#123; System.out.println("执行execute方法"); System.out.println(this.getUser().getName()+"------"+this.getUser().getPassword()); return SUCCESS; &#125; success.jsp页面 其中要引用struts2的标签库 12345678910111213&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ taglib prefix="s" uri="/struts-tags" %&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;s:debug&gt;&lt;/s:debug&gt;&lt;/body&gt;&lt;/html&gt; 此时我们可以看到在值栈中有个user属性，并且有LoginAction 常量 我们现在先接触一下&lt;s:property value=&quot;&quot;&gt;标签，struts2中的标签在后面再详细讲解，这个标签的意思是输出属性的值 这个标签中的value属性填写的是OGNL表达式，如果我们要输出一个常量，那么我们必须使用单引号 引用struts2中的标签库&lt;%@ taglib prefix=&quot;s&quot; uri=&quot;/struts-tags&quot; %&gt; 字符常量 如果我们仍然使用上面的实例，但是我们要在success.jsp页面中使用OGNL使用显示表单传递过来的值，其中我们还输出自己的一个常量字符串 success.jsp 123456789101112131415161718&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ taglib prefix="s" uri="/struts-tags" %&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;&lt;s:property value="user.name" default="如果为null，输出这个字段"/&gt;&lt;/h1&gt; &lt;h1&gt;&lt;s:property value="user.password" default="如果为null，输出这个字段" /&gt;&lt;/h1&gt; &lt;h1&gt;输出一个字符串常量: &lt;s:property value="'jack'"/&gt;&lt;/h1&gt; &lt;s:debug&gt;&lt;/s:debug&gt;&lt;/body&gt;&lt;/html&gt; 数值常量 int 1,2,3 double 1.24d或者1.24 float 1.23f long 122l 最后一个是字母l BigDecimal 123b BigInteger 123h 在其中直接输出即可:&lt;s:property value=&quot;1&quot;/&gt; 布尔常量 直接输出即可 &lt;s:property value=&quot;true&quot;/&gt; 总结 当需要输出一个字符串常量的时候，一定要使用单引号，否则就会默认的将其作为OGNL表达式，输出的就为空 集合list OGNL中的list相当于数组，其中存放的可以是任意类型的数据 读取的时候直接使用数组的形式读取即可，使用索引读取即可 我们的创建形式是使用&lt;s:set&gt;标签，因此这个变量不是值栈中的，需要使用# 1234&lt;!-- 创建list --&gt;&lt;s:set var="list" value="&#123;1,2,3,'jack',true&#125;"&gt;&lt;/s:set&gt;&lt;s:property value="#list[0]"/&gt;&lt;br&gt;&lt;s:property value="#list[4]"/&gt; Map 使用#{}的形式创建，其中存放的是键值对(key-value)的形式 读取的方式有两种 map[‘key’] map.key 123&lt;s:set var="map" value="#&#123;'name':'jack','age':22&#125;"&gt;&lt;/s:set&gt;&lt;s:property value="#map['name']"/&gt;&lt;s:property value="#map.age"/&gt; 访问action中的属性值 action都是存放在值栈中，我们可以使用OGNL读取值栈中的数据 使用上面的LoginAction类，我们通过表单提交到这个LoginAction中，跳转到success.jsp页面中，那么我们就可以在success.jsp页面中访问LoginAction属性的值(前提是属性必须有get，set方法) LoginAction中的属性是一个User对象，那么我们既可以获取这个User对象，之后在获取User对象中的数据了，这个相当于链式操作，前提还是有get，set方法 123&lt;!-- 这里的user一定要和LoginAction中的成员变量User的对象字段相同 --&gt;User对象中的name属性：&lt;s:property value="user.name"/&gt;User对象中的age属性：&lt;s:property value="user.age"/&gt; 操作符# 值栈中的的属性称为是根属性，#访问的是非根属性，就不是值栈中的值，比如#session.username 相当于调用ActionContext.getContext.getSession.getAttribute(&quot;username&quot;) 创建Map 过滤和投影 $符号 在国际化文件中使用OGNL表达式，例如年龄必须在${min}到${max}之间 在Struts配置文件中使用OGNL表达式，例如两个Action之间进行跳转，并且附带参数 % 符号 当标签的属性为字符串类型时，计算OGNL表达式的值。 123&lt;s:url value="#map.name"/&gt;&lt;br&gt;&lt;s:url value="%&#123;#map.name&#125;"/&gt; 大括号 {} 用来创建一个Map，其中存放的是键值对 创建一个list集合 12&lt;s:set var="map" value="#&#123;'name':'jack','age':22&#125;"&gt;&lt;/s:set&gt;&lt;s:property value="#map['name']"/&gt; in ,not in 判断某一个值是否存在一个集合中，返回的是布尔值 不过经过自己测试，只有数字类型的可以判断出来，字符串不能判断出来，如果哪位能够测出来，和我说说原因 123456&lt;!-- 创建一个集合list --&gt; &lt;s:set var="list" value="&#123;1,2,3,'jack','Tom'&#125;"&gt;&lt;/s:set&gt; &lt;s:property value="1 in #list"/&gt;&lt;br&gt; &lt;s:property value="1 not in #list"/&gt;&lt;br&gt; &lt;!-- 没有结果 --&gt; &lt;s:property value=" 'jack' in #list"/&gt;&lt;br&gt; + 这个和java是一样的，如果两个整数相加就执行整数相加，如果字符串相加就拼接 12&lt;s:property value=&quot;2+3&quot;/&gt;&lt;s:property value=&quot;&apos;ce&apos;+22&quot;/&gt; 集合的伪属性 集合的伪属性是用来代替java集合API的方法的属性，比如迭代器的使用 List list.iterator list.size Set set.iterator set.isEmpty Map map.keys （map.keySet） map.values (map.values) Iterator Iterator.next Iterator.hasNext Enumeration enum.next enum.hasNext 123456789101112131415161718192021&lt;%--创建列表 --%&gt;&lt;s:set var="list" value="&#123;1,'陈加兵'&#125;"&gt;&lt;/s:set&gt;&lt;%-- 创建Map --%&gt;&lt;s:set var="map" value="#&#123;'one':'陈加兵','tow':'郑元梅'&#125;"&gt;&lt;/s:set&gt;&lt;%-- 创建数组 --%&gt;&lt;s:set var="number" value="new String[]&#123;'aaa','bbb','ccc']"&gt;&lt;/s:set&gt;&lt;%-- 获取list的迭代器对象 --%&gt;&lt;s:set var="iter" value="#list.iterator"&gt;&lt;/s:set&gt;list的大小:&lt;s:property value="#list.size"/&gt;&lt;s:if test="#iter.hasNext"&gt; list中的第一个元素的值:&lt;s:property value="#iter.next"/&gt;&lt;/s:if&gt;&lt;hr&gt;&lt;%-- #map.keys返回的是set类型，然后使用迭代器输出即可 --%&gt;&lt;s:property value="#map.keys.iterator.next" default="NULL"/&gt;&lt;s:property value="#map.values"/&gt; 投影 在OGNL中，投影是对一个集合中对每一个元素调用相同的方法，或者抽取相同的属性，并将一个结果保存为一个新的集合。 下面的例子是将集合list中的元素转换成字符串 1234&lt;%--创建列表 --%&gt;&lt;s:set var="list" value="&#123;1,'陈加兵'&#125;"&gt;&lt;/s:set&gt;&lt;%-- 这个&#123;#&#125;首先会取list中的每一个元素然后赋值给tihs，接着调用toString方法转换为字符串 --%&gt;&lt;s:property value="#list.&#123;#this.toString()&#125;"/&gt; 选择 在OGNL中使用表达式从集合中选择某一些元素，并将这些元素保存到新的集合中 12345&lt;%--创建列表 --%&gt;&lt;s:set var="list" value="&#123;1,2,3&#125;"&gt;&lt;/s:set&gt;&lt;%-- 选取大于2的元素组成一个新的集合 --%&gt;&lt;s:property value="#list.&#123;?#this&gt;2&#125;"/&gt; [N]语法 我们知道一次请求值栈中可以存放两个或者多个action(只需要设置result跳转类型为chain即可完成在action之间的跳转)，那么我们一般取值栈中的值默认是获取栈顶的action，但是如果有多个action呢，此时我们需要获取其他action中的数据，这下就要用到[N]语法了 [N].propertyName可以用来指定从值栈中的从上向下数位置N的action的属性值，N从事0开始的。 实现 假设我们有两个Action，一个是SimpleAction，一个是LoginAction(上面的，有一个属性为user)，我们在在配置的时候，发出请求给SimpleAction，之后跳转到LoginAction(result的type类型为chain即可），之后跳转到success.jsp，那么此时的值栈中的action就有两个了，栈顶的是SimpleAction，第二个是LoginAction。 我们想要获取LoginAction属性user的值，在值栈中的位置是第二个，那么此时使用[1].propertName 12User对象中的name:&lt;s:property value="[1].user.name"/&gt;User对象中的age：&lt;s:property value="[1].user.age"/&gt; top 语法 我们知道[N]语法中，如果想要访问栈顶的action属性使用[0].propertyName，我们也可以使用top，直接top.propertyName即可 Struts2的命名对象 这些对象都不是值栈中的数据，因此需要使用#来获取 parameters用来访问请求参数，比如#parameters.name, # parameters [‘name’]相当与request.getParameters(“name”) request用来访问request的属性，比如#request.name或者# request [‘name’] 相当于request,getAttrubute(“name”) session用来访问session属性，例如 #session.name或者#session[‘name’]相当于 session.getAttribute(“name”) application用来访问application属性，比如:#application.name相当于application.getAttribute(“name”) attr用来访问PageContext，如果PageContext不可用，则一次搜索request,session,application对象 123456789101112&lt;% //设置属性 request.setAttribute("login","true"); session.setAttribute("regist", "false"); application.setAttribute("auto", "true");%&gt;获取的请求参数中的name的值:&lt;s:property value="#parameters.name"/&gt;&lt;br&gt;获取request中的login属性:&lt;s:property value="#request.login"/&gt;&lt;br&gt;获取session中的regist属性:&lt;s:property value="#session.regist"/&gt;&lt;br&gt;获取application中的auto属性:&lt;s:property value="#application.auto"/&gt;&lt;s:debug&gt;&lt;/s:debug&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts之配置拦截器]]></title>
      <url>%2F2018%2F04%2F02%2FStruts%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
      <content type="text"><![CDATA[struts2之配置拦截器什么是拦截器 java里的拦截器是动态拦截Action调用的对象。它提供了一种机制可以使开发者可以定义在一个action执行的前后执行的代码，也可以在一个action执行前阻止其执行，同时也提供了一种可以提取action中可重用部分的方式。在AOP（Aspect-Oriented Programming）中拦截器用于在某个方法或字段被访问之前，进行拦截然后在之前或之后加入某些操作。 拦截器是可插拔式的，一旦出现了问题，可以不用改变软件的很多代码就可以实现修复，给维护工作带来方便，其实过滤器也是这样的。 Struts2其实就实现了很多的拦截器，可以在struts-default.xml中看到定义很多的拦截器，其中向类型转换，文件上传都是通过拦截器实现的。 Struts2拦截器实现原理与Servlet过滤器实现原理类似，它以链式执行，对真正要执行的方法（execute（））进行拦截。首先执行Action配置的拦截器，在Action和Result执行之后，拦截器会再次执行（与先前调用的顺序相反），在此链式执行的过程中，每一个拦截器都可以直接返回，从而终止余下的拦截器、Action及Result的执行。 拦截器的作用 拦截器适合封一些通用处理，便于重复利用，比如日志的记录，访问权限的检查，事务处理等，拦截器通过配置方式调用，因此使用方法比较灵活，便于维护和扩展 拦截器的配置元素 &lt;interceptors&gt;用来定义拦截器，所有的拦截器和拦截器栈都是在此元素中定义的，可以包含子元素, &lt;Interceptor&gt;用来定义拦截器，需要指定两个属性，name属性指定了拦截器的名字，class指定了拦截器的实现的类。这个是在下定义的 &lt;interceptor-stack&gt;用来定义拦截器栈，其中的name属性指定了拦截器栈的名称。另外在此元素下可以指定引入其他的拦截器或者拦截器栈 &lt;interceptor-ref&gt;用来引用其他的拦截器或者拦截器栈，name属性指定了拦截器或者拦截栈的名称 &lt;param&gt;用来为拦截器指定参数，可以作为或者的子元素。并且可以定义多个。其中的name属性指定了参数的名称 &lt;default-interceptor-ref&gt;将某一个拦截器定义为默认拦截器 内建的拦截器 struts2中提供了许多内建的拦截器，在struts-core.jar中，我们只需要在struts.xml中引用这个内建的拦截器即可 比如我们在实现文件上传的时候，使用的就是内建的拦截器 内建的拦截器使用的很少，通常我们都是使用自定义的拦截器，比如验证访问权限的拦截器 自定义拦截器 实现自定义的拦截器有两种方法，一种是实现接口，一种是继承 需求 我们需要将表单传递过来的数据转换成大写的，再传递给action 实现接口(com.opensymphony.xwork2.interceptor.Interceptor)接口中的方法 void init()初始化拦截器执行的方法 String intercept(ActionInvocation invocation) throws Exception实现拦截器逻辑的主要方法。 ActionInvocation包含了Action的引用，因此使用这个对象可以对Action进行相应的操作，比如可以获取和设置Action类的成员变量 ActionInvocation包含了Action的引用，可以调用其中的invoke()方法继续调用下一个拦截器，如果后面没有拦截器了，那么就会执行Action中对应的映射方法，如果有，那么就会继续执行下一个拦截器，直到执行完全部的拦截器才会执行对应的映射方法 invoke()方法将拦截器的作用分成了两个部分，在调用invoke()之前的实在Action方法执行之前的逻辑，在之后的代码是在Action执行result，跳转到指定视图之后执行的逻辑 这个方法返回的是一个字符串，对应的也是结果视图，如果在其中没有调用invoke()方法，那么返回的字符串就作为Action跳转的视图，因此在一定要定义这个对应的视图。如果调用了invoke()方法，那么返回的字符串就会失效，就会以Action中方法返回的字符串为主 void destroy() 销毁拦截器开启的资源 实现 拦截器类 这里并没有在init和destroy方法中写什么逻辑，可以根据实际情况来定义其中的逻辑 12345678910111213141516171819202122232425262728293031323334import com.jsnu.struts2.controller.SimpleAction;import com.opensymphony.xwork2.ActionInvocation;import com.opensymphony.xwork2.interceptor.Interceptor;public class TestInterceptor implements Interceptor&#123; @Override public void destroy() &#123; // TODO Auto-generated method stub &#125; @Override public void init() &#123; // TODO Auto-generated method stub &#125; @Override public String intercept(ActionInvocation invocation) throws Exception &#123; Object object=invocation.getAction(); //获取当前调用拦截器的Action类的对象 //如果不为null，就可以获取其中的属性，否则空指针 if (object!=null) &#123; SimpleAction simpleAction=(SimpleAction)object; //将User属性全部转换成大写字母 simpleAction.getUser().setName(simpleAction.getUser().getName().toUpperCase()); simpleAction.getUser().setPassword(simpleAction.getUser().getPassword().toUpperCase()); String result=invocation.invoke(); //调用下一个拦截器 System.out.println("成功跳转视图后执行的逻辑"); return result; &#125; return null; &#125;&#125; 继承AbstractInterceptor（推荐） 继承AbstractInterceptor抽象类，里面只有一个抽象方法String intercept(ActionInvocation invocation)，只需要实现这个方法即可，如果你需要初始化和销毁，那么也可以覆盖其中的init()和destroy()方法 继承抽象类的方式比实现接口对一个类的更加简洁，对这个类的污染更加小 其中的方法逻辑还是和上面的一样 还是完成上面的需求，把传递的请求参数转换成大写字母 1234567891011121314151617181920212223import com.jsnu.struts2.controller.SimpleAction;import com.opensymphony.xwork2.ActionInvocation;import com.opensymphony.xwork2.interceptor.AbstractInterceptor;//继承类AbstractInterceptorpublic class AbstractInterceptorTest extends AbstractInterceptor &#123; @Override public String intercept(ActionInvocation invocation) throws Exception &#123; Object object = invocation.getAction(); // 获取当前调用拦截器的Action类的对象 // 如果不为null，就可以获取其中的属性，否则空指针 if (object != null) &#123; SimpleAction simpleAction = (SimpleAction) object; // 将User属性全部转换成大写字母 simpleAction.getUser().setName( simpleAction.getUser().getName().toUpperCase()); simpleAction.getUser().setPassword( simpleAction.getUser().getPassword().toUpperCase()); String result = invocation.invoke(); // 调用下一个拦截器 System.out.println("成功跳转视图后执行的逻辑"); return result; &#125; return null; &#125;&#125; 配置拦截器 因为struts2的很多功能都要依赖内建的拦截器，比如表单传值。这一系列的拦截器都定义在一个拦截器栈中，如果在一个中引用了拦截器，那么这拦截器就会被覆盖，因此一定要在自定义的拦截器之前定义默认的拦截器栈&lt;interceptor-ref name=&quot;defaultStack&quot;&gt;&lt;/interceptor-ref&gt; 配置拦截器只需要在下定义拦截器即可，如果哪个action想要引用拦截器，使用&lt;interceptor-ref &gt;引用已经定义好的拦截器即可 一个action中可以引用多个拦截器，在上面配置的拦截器先执行，因此默认的拦截器栈一定要在最上面 在struts.xml中配置上面我们自定义的拦截器 1234567891011121314151617181920212223&lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义拦截器 --&gt; &lt;interceptors&gt; &lt;!-- 实现接口的拦截器 --&gt; &lt;interceptor name="testInterceptor" class="com.jsnu.struts2.Interceptor.TestInterceptor"&gt;&lt;/interceptor&gt; &lt;!-- 继承类的 --&gt; &lt;interceptor name="abstractInterceptorTest" class="com.jsnu.struts2.Interceptor.AbstractInterceptorTest"&gt;&lt;/interceptor&gt; &lt;/interceptors&gt; &lt;action name="simple" class="com.jsnu.struts2.controller.SimpleAction"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;!-- 在使用了自定的拦截器之后，那么系统默认的拦截器栈将会失去作用，因此这里需要重新指定拦截器栈--&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;!-- 引用自定义的拦截器，在上面要定义 --&gt; &lt;interceptor-ref name="abstractInterceptorTest"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="testInterceptor"&gt;&lt;/interceptor-ref&gt; &lt;/action&gt; &lt;/package&gt; 配置拦截器栈 如果一个action中的需要用到的拦截器很多，或者同时引用几个相同的拦截器的action很多，那么我们此时在action一个一个的引用拦截器效率太低，此时我们就需要将这些拦截器定义在一个拦截器栈中，直接在action中引用了拦截器栈即可。 直接使用标签中使用定义即可 拦截器栈中的拦截器一定要在上面定义过的，否则将会引用出错 拦截器栈中的拦截器引用是有顺序的，在上面的拦截器最先执行 我们把上面自定义的两个拦截器放在拦截器栈中,并在action中引用拦截器栈，注意此时的默认的default-stack还是要放在最上面 123456789101112131415161718192021222324252627&lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义拦截器 --&gt; &lt;interceptors&gt; &lt;!-- 实现接口的拦截器 --&gt; &lt;interceptor name="testInterceptor" class="com.jsnu.struts2.Interceptor.TestInterceptor"&gt;&lt;/interceptor&gt; &lt;!-- 继承类的 --&gt; &lt;interceptor name="abstractInterceptorTest" class="com.jsnu.struts2.Interceptor.AbstractInterceptorTest"&gt;&lt;/interceptor&gt; &lt;!-- 自定拦截器栈，其中引用了上面的两个拦截器 --&gt; &lt;interceptor-stack name="myStack"&gt; &lt;!-- 引用自定义的拦截器，在上面要定义 --&gt; &lt;interceptor-ref name="abstractInterceptorTest"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="testInterceptor"&gt;&lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;action name="simple" class="com.jsnu.struts2.controller.SimpleAction"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;!-- 在使用了自定的拦截器之后，那么系统默认的拦截器栈将会失去作用，因此这里需要重新指定拦截器栈--&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="myStack"&gt;&lt;/interceptor-ref&gt; &lt;/action&gt;&lt;/package&gt; 拓展 拦截器中还可以包含其他的拦截器栈，那么此时我们就可以将struts2中内建的拦截器放在自己的拦截器栈顶，那么就不用在每个action中引用了，直接引用这个拦截器栈即可 123456789101112131415161718192021222324252627&lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义拦截器 --&gt; &lt;interceptors&gt; &lt;!-- 实现接口的拦截器 --&gt; &lt;interceptor name="testInterceptor" class="com.jsnu.struts2.Interceptor.TestInterceptor"&gt;&lt;/interceptor&gt; &lt;!-- 继承类的 --&gt; &lt;interceptor name="abstractInterceptorTest" class="com.jsnu.struts2.Interceptor.AbstractInterceptorTest"&gt;&lt;/interceptor&gt; &lt;!-- 自定拦截器栈，其中引用了上面的两个拦截器 --&gt; &lt;interceptor-stack name="myStack"&gt; &lt;!-- 在使用了自定的拦截器之后，那么系统默认的拦截器栈将会失去作用，因此这里需要重新指定拦截器栈--&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;!-- 引用自定义的拦截器，在上面要定义 --&gt; &lt;interceptor-ref name="abstractInterceptorTest"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="testInterceptor"&gt;&lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;action name="simple" class="com.jsnu.struts2.controller.SimpleAction"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;interceptor-ref name="myStack"&gt;&lt;/interceptor-ref&gt; &lt;/action&gt;&lt;/package&gt; 自定义默认的拦截器栈 在一个包中定义一个默认的拦截器栈后(使用定义)，那么当下没有显式的配置拦截器的时候，那么此时就会默认使用自定义的默认的拦截器或者默认的拦截器栈。 一个包中只能定义一个默认的拦截器，如果想要定义多个拦截器可以使用拦截器栈，定义一个默认的拦截器栈即可解决。 在定义了默认的拦截器之后一定要在每一个action都定义系统默认的拦截器栈defaultStack,前面已经说过如果action定义了拦截器(这里虽然不是显式的定义，但是实际上是定义了),那么就会失去defaultStack的作用，其实我们需要很多defaultStack的功能，因此还是要定义的。 比如登录检查的拦截器，这个是每一个action都需要用到的，那么我们可以设置一个默认的拦截器栈，栈顶引用的是struts2内建的默认的拦截器栈 使用 即可定义 1234567891011121314151617181920212223242526272829&lt;struts&gt; &lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义拦截器 --&gt; &lt;interceptors&gt; &lt;!-- 实现接口的拦截器 --&gt; &lt;interceptor name="testInterceptor" class="com.jsnu.struts2.Interceptor.TestInterceptor"&gt;&lt;/interceptor&gt; &lt;!-- 继承类的 --&gt; &lt;interceptor name="abstractInterceptorTest" class="com.jsnu.struts2.Interceptor.AbstractInterceptorTest"&gt;&lt;/interceptor&gt; &lt;!-- 自定拦截器栈，其中引用了上面的两个拦截器 --&gt; &lt;interceptor-stack name="myStack"&gt; &lt;!-- 在使用了自定的拦截器之后，那么系统默认的拦截器栈将会失去作用，因此这里需要重新指定拦截器栈--&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;!-- 引用自定义的拦截器，在上面要定义 --&gt; &lt;interceptor-ref name="abstractInterceptorTest"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="testInterceptor"&gt;&lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;!-- 定义默认的拦截器栈，其中引用了上面定义的拦截器栈 --&gt; &lt;default-interceptor-ref name="myStack"&gt;&lt;/default-interceptor-ref&gt; &lt;action name="simple" class="com.jsnu.struts2.controller.SimpleAction"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 配置拦截方法的拦截器 一般我们的Action类中有很多的方法，但是我们在使用动态调用的时候会调用其中不同的方法，如果不想Action类中的某个方法不被拦截，此时就需要使用拦截方法的拦截器 其中可以设置拦截的方法，也可以设置不拦截的方法 自定义拦截器类 继承MethodFilterInterceptor 其中的方法doIntercept是在执行其中指定方法之前执行，和前面的逻辑一样，也有invoke方法 123456789101112import com.opensymphony.xwork2.ActionInvocation;import com.opensymphony.xwork2.interceptor.MethodFilterInterceptor;public class SimpleActionInteceptor extends MethodFilterInterceptor&#123; @Override protected String doIntercept(ActionInvocation invocation) throws Exception &#123; System.out.println("拦截方法的拦截器起了作用"); String result=invocation.invoke(); System.out.println("执行之后"); return result; &#125;&#125; struts中配置 &lt;param name=&quot;excludeMethods&quot;&gt;login&lt;/param&gt; 用来定义不拦截的方法 &lt;param name=&quot;includeMethods&quot;&gt;regist&lt;/param&gt; 用来定义拦截的方法，如果有多个使用逗号隔开 这里使用的是动态调用的method的，但是我们也可以使用 action!方法名 假设我们的项目名称为web1，并且把method=“”去掉，那么我们开启action!方法名进行调用，具体方法前面有介绍，开启之后，我们在地址栏输入 http://localhost:8080/web1/simple.regist,将会成功被拦截器拦截器，但是我们输入http://localhost:8080/web1/simple.login，拦截器不起作用 1234567891011121314151617181920&lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义拦截器 --&gt; &lt;interceptors&gt; &lt;!-- 配置拦截方法的拦截器 --&gt; &lt;interceptor name="simpleMethod" class="com.jsnu.struts2.Interceptor.SimpleActionInteceptor"&gt;&lt;/interceptor&gt; &lt;/interceptors&gt; &lt;action name="simple" class="com.jsnu.struts2.controller.SimpleAction" method="regist"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;!-- 在使用了自定的拦截器之后，那么系统默认的拦截器栈将会失去作用，因此这里需要重新指定拦截器栈--&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="simpleMethod"&gt; &lt;!-- 定义不拦截login方法 --&gt; &lt;param name="excludeMethods"&gt;login&lt;/param&gt; &lt;!-- 定义需要拦截器的方法 --&gt; &lt;param name="includeMethods"&gt;regist&lt;/param&gt; &lt;/interceptor-ref&gt; &lt;/action&gt; &lt;/package&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDBC干货三]]></title>
      <url>%2F2018%2F04%2F02%2FJDBC%E5%B9%B2%E8%B4%A7%E4%B8%89%2F</url>
      <content type="text"><![CDATA[JDBC干货三生成get,set方法的快捷键 alt+shift+s r alt+a a松手 alt不松手 按o 最后回车 eclipse中生成toString方法的快捷键 alt+shift+o 回车 数据库操作和对象的关系 因为数据库中查询的数据比较零散，需要通过对象的形式把数据封装起来 这种封装数据的对象通常称为javaBean 以后项目开发，基本上有什么表在代码中就会创建相应的对象，表中有什么字段，对象中就有什么属性 JavaBean 俗称简单的java对象 -具备如下的三个特点 - 私有属性 - 无参构造 - 为属性提供get，set方法 Statement和PreparedStatement应用场景 通常DDL使用Statement 通常DML 和DQL使用PreparedStatement 只有需要传入参数的就要使用PreparedStatent 实例 我们将数据库中的表和JavaBean相对应实现了crud操作 使用了PreparedStatement对象操作数据库 JavaBean对象12345678910111213141516171819202122232425262728293031323334353637public class Item &#123; private int id; private String title; private int price; private int num; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public int getPrice() &#123; return price; &#125; public void setPrice(int price) &#123; this.price = price; &#125; public int getNum() &#123; return num; &#125; public void setNum(int num) &#123; this.num = num; &#125; @Override public String toString() &#123; return "Item [id=" + id + ", title=" + title + ", price=" + price + ", num=" + num + "]"; &#125;&#125; crud操作 传入的参数全部都是JavaBean对象 其中的sql语句不能有中的占位符部分不能有空格，否则可能会出现错误 这里使用的是前一篇讲的数据库工具类终结版（使用了DBCP连接池),详情请看前一篇的文章 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// 插入数据，传入JavaBean对象作为参数 public void insert(Item item) &#123; Connection connection = null; PreparedStatement statement = null; // 创建预处理对象 ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "insert into t_item(id,title,price,num) values(?,?,?,?)"; statement = connection.prepareStatement(sql); statement.setInt(1, item.getId()); statement.setString(2, item.getTitle()); // 为预处理对象中的占位符赋值 statement.setInt(3, item.getPrice()); statement.setInt(4, item.getNum()); int row = statement.executeUpdate(); System.out.println(row); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125; &#125; // 查询数据，封装在JavaBean中 public List&lt;Item&gt; findAll() &#123; ArrayList&lt;Item&gt; items = new ArrayList&lt;Item&gt;(); Connection connection = null; PreparedStatement statement = null; // 创建预处理对象 ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "select * from t_item where price&gt;100"; statement = connection.prepareStatement(sql); resultSet = statement.executeQuery(); while (resultSet.next()) &#123; String title = resultSet.getString("title"); int price = resultSet.getInt("price"); int num = resultSet.getInt("num"); Item item = new Item(); item.setNum(num); item.setPrice(price); item.setTitle(title); items.add(item); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125; return items; &#125; //更新操作，传入JavaBean对象，只需要将要更新的条件封装进去即可 public void update(Item item) &#123; Connection connection = null; PreparedStatement statement = null; // 创建预处理对象 ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "update t_item set title=?,num=?,price=? where id=?"; statement = connection.prepareStatement(sql); //设置其中的占位符的值 statement.setString(1, item.getTitle()); statement.setInt(2, item.getNum()); statement.setInt(3, item.getPrice()); statement.setInt(4, item.getId()); int row = statement.executeUpdate(); System.out.println(row); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125; &#125; // 删除的数据，其中参数传入的还是JavaBean对象 public void delete(Item item) &#123; Connection connection = null; PreparedStatement statement = null; // 创建预处理对象 ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "delete from t_item where id=?"; statement = connection.prepareStatement(sql); statement.setInt(1, item.getId()); int row = statement.executeUpdate(); System.out.println(row); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125; &#125; 批量操作 因为类似的sql语句执行，每一个次都需要和数据库服务器进行数据交互，多次交互会浪费资源，并且耗时，可以使用批量 Statement执行批量操作 需要写多个重复的sql语句，只是其中的想用批量的内容不同，比较繁琐-最后将这些sql语句中添加到批量操作中 statement.addBatch(sql); 添加到批量操作之后，就开始执行批量方法了 statement.executeBatch(); 123456789101112131415161718192021222324@Testpublic void testStatement() &#123; Connection connection = null; Statement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 statement = connection.createStatement(); // 创建Statement语句对象 String sql1 = "insert into t_item(id,title) values(100,'asaa')"; String sql2 = "insert into t_item(id,title) values(101,'asaa')"; String sql3 = "insert into t_item(id,title) values(102,'asaa')"; // 添加批量操作 statement.addBatch(sql1); statement.addBatch(sql2); statement.addBatch(sql3); // 执行批量操作 statement.executeBatch(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; PreparedStatement 只需要写一个条sql语句，其中要批量的内容使用占位符即可 设置占位符的内容，将其添加到批量中，再重新设置，这样的好处就是减少了重复的sql语句了 statement.addBatch() 最后直接执行批量操作即可 statement.executeBatch(); 12345678910111213141516171819202122232425262728293031@Testpublic void testPreparedStatement() &#123; Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "insert into t_item(id,title) values(?,?)"; statement = connection.prepareStatement(sql); statement.setInt(1, 200); statement.setString(2, "联想电脑"); statement.addBatch(); // 添加上面的数据到Batch中 statement.setInt(1, 201); statement.setString(2, "华硕笔记本"); statement.addBatch(); // 添加上面的数据到Batch中 statement.setInt(1, 202); statement.setString(2, "海尔洗衣机"); statement.addBatch(); // 添加上面的数据到Batch中 statement.executeBatch(); // 执行批量操作 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 批量插入数据 注意：addBatch()其中的数量是有限的，如果存放的批量操作太多，那么会造成内存溢出，因此我们应该当其中批量操作的数量达到一定值的时候先执行一次，然后清除执行完的操作即可(clearBatch()) 批量操作的时候如果批量操作的数量太多的话，肯定会造成内存溢出，这个时候最好的办法就是当数量达到一定数量时候就执行，然后将其中的已经执行完成的清除即可 下面是向表中插入有100条数据，我们每20条插入一次，这样就可以避免内存的溢出 1234567891011121314151617181920212223242526@Testpublic void test1()&#123; Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "insert into t_v(name) values(?)"; statement=connection.prepareStatement(sql); for(int i=0;i&lt;100;i++)&#123; statement.setString(1, "name"+(i+1)); statement.addBatch(); //为了避免内存溢出，当批量操作数量达到一定值时先执行一次，在向其中添加 //每二十次添加一次 if (i%20==0) &#123; statement.executeBatch(); //执行批量操作 statement.clearBatch(); //清除已经执行过的 &#125; statement.executeBatch(); //为了避免有剩余的，把剩下的执行掉 &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 分页查询 要求： 在控制台输入页数(n)，和每页显示的数量(m) 分析： 我们知道sql语句中的limit ?,?，第一个参数表示的是跳过的条数，第二个参数是每页显示的条数，那么此时我们限定显示第n页，每页显示m条，那么此时的跳过的条数就是(n-1)*m,因此此时的查询语句就是: select * from table_name limit (n-1)*m,m; 代码如下： 12345678910111213141516171819202122232425262728293031323334@Testpublic void testLimit()&#123; Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; Scanner scanner=new Scanner(System.in); //控制台输入 try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql = "select * from t_v limit ?,?"; statement=connection.prepareStatement(sql); // n页，每页m条 limit (n-1)*m m System.out.println("第几页："); int n=Integer.parseInt(scanner.nextLine()); //页数,控制台读取的是字符串，因此这里需要转换 System.out.println("每页的条数"); int m=Integer.parseInt(scanner.nextLine()); //每页显示的条数 //设置占位符 statement.setInt(1, (n-1)*m); statement.setInt(2, m); //查询，获取结构集 resultSet=statement.executeQuery(); //遍历结果集 while(resultSet.next())&#123; int id=resultSet.getInt("id"); //获取id String name=resultSet.getString("name"); //获取name System.out.println(id+"-----"+name+"\t"); //制表符输出值 &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 事务ACID 原子性 一致性 隔离性 持久性 jdbc操作事务 connection.setAutoCommit(false) 关闭自动提交 如果不关闭自动提交，那么会每执行一行都会提交一次 connection.commit() 提交 connection.rollback() 回滚 转账的实现过程 创建表：create table user(id int,name,varchar(10),money int); 插入数据：insert into user values(1,&#39;超人&#39;,200),(2,&#39;蝙蝠侠&#39;,10000); 关闭自动提交 connection.setAutoCommit(false) 修改超人的钱(money+3000) 修改蝙蝠侠的钱(money-3000) 查询蝙蝠侠的钱是否大于0，如果小于0，则抛出运行时异常，大于0 提交(commit) 在catch异常的地方把SQLException改成Exception，并且在catch里面回滚 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Testpublic void testTransaction() &#123; Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 connection.setAutoCommit(false); // 关闭自动提交 String sql = "update user set money=money+? where id=?"; // 修改蝙蝠侠和超人钱的sql语句 String sql_select = "select money from user where id=?"; // 查询钱 // 创建更新的预编译对象 statement = connection.prepareStatement(sql); // 超人+3000 statement.setInt(1, 3000); statement.setInt(2, 1); int row1 = statement.executeUpdate(); // 执行更新语句 // 蝙蝠侠-3000 statement.setInt(1, -3000); statement.setInt(2, 2); int row2 = statement.executeUpdate(); // 执行更新语句 // 预编译查询sql语句 statement = connection.prepareStatement(sql_select); statement.setInt(1, 2); resultSet = statement.executeQuery(); // 执行查询语句 while (resultSet.next()) &#123; int money = resultSet.getInt("money"); // 获取蝙蝠侠的此时的钱 // 如果&lt;0 抛出运行异常 if (money &lt; 0) &#123; throw new RuntimeException(); // 手动抛出异常 &#125; else &#123; // 如果 &gt;0 可以成功提交 connection.commit(); // 提交 &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); try &#123; connection.rollback(); // 回滚，如果运行出错，那么就回滚到起始点，数据库中就不会生效 &#125; catch (SQLException e1) &#123; e1.printStackTrace(); &#125; &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 获取自增主键的值 为什么获取： 因为某些插入的数据，插入完之后，需要用到数据的主键作为下一条数据外键 准备sql create table t_d(id int primary key auto_increment,name varchar(10)); 1234567891011121314151617181920212223@Testpublic void testAuto() &#123; Connection connection = null; Statement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 String sql="insert into t_d values(null,'神仙')"; statement=connection.createStatement(); //执行sql，并且标记此时执行需要获取生成的key值 statement.executeUpdate(sql,Statement.RETURN_GENERATED_KEYS); //得到生成的key值 resultSet=statement.getGeneratedKeys(); while(resultSet.next())&#123; int id=resultSet.getInt(1); //获取第一个值，不能写getInt("id") 因为这里不是查询得到的数据，字段名并不是id System.out.println("自增主键的值为:"+id); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 获取元数据 数据库元数据： 数据库厂商信息（mysql,oracle) 数据库连接信息，都称为数据库的元数据 表元数据 12345678910111213141516171819202122232425262728293031323334@Testpublic void testMetaData() &#123; Connection connection = null; Statement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); // 获取连接 statement=connection.createStatement(); //得到数据库元数据 DatabaseMetaData data=connection.getMetaData(); System.out.println(data.getDriverName()); //数据库驱动名字 System.out.println(data.getDriverVersion()); //驱动版本 System.out.println(data.getUserName()); //用户名 System.out.println(data.getURL()); //连接地址 System.out.println(data.getDatabaseProductName()); //数据库厂商的名称 String sql="select * from t_d"; resultSet=statement.executeQuery(sql); //从结果集中获取表的元数据 ResultSetMetaData sqldata=resultSet.getMetaData(); int columcount=sqldata.getColumnCount(); //获取表字段的数量 //获取表中每个字段的名称 for(int i=0;i&lt;columcount;i++)&#123; String name=sqldata.getColumnName(i+1); System.out.println("字段名："+name+"\t"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); // 关闭资源 &#125;&#125; 乱码问题 在JDBC连接数据的url后面添加如下参数： jdbc:mysql://localhost:3306/test?UseUnicode=true&amp;characterEncoding=UTF-8]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts之获取请求参数]]></title>
      <url>%2F2018%2F03%2F31%2FStruts%E4%B9%8B%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%2F</url>
      <content type="text"><![CDATA[获取请求参数 在Servlet中可以调用HttpServletRequest的getParameter()的方法接收传递过来的请求参数，但是在struts2中对这种方式进行了三种封装 我们一般发出请求都是通过表单传递的，但是在服务端如果获取表单传递过来的值，其中有三种不同的方式 属性驱动 属性驱动就是将一个Action类作为一个POJO类，在类中定义表单的请求参数的name属性，但是还要为这些成员变量设置get，set方法。因为在获取请求参数的时候自动调用的是set方法，获取参数的时候调用的是get方法。 当表单提交的时候，实际上是提交了表单元素的值，之后会给ACtion类中的属性设置值(set)，因此这里的属性需要添加set方法 当表单请求成功的时候，实际上是先经过Action类，然后跳转到指定的视图，这个过程都是转发(ddispatcher)，因此会保留request域中的键值对，此时在success.jsp页面中使用EL表达式取值即可(get方法),取值使用的是属性的get方法，因此需要添加get方法 实现 SimpleAction类，其中定义了属性 为每一个属性都需要添加get，set方法 表单提交之后会自动调用属性的set方法为其赋值 跳转到指定视图之后，使用EL表达式取值时会调用属性的get方法 1234567891011121314151617181920212223242526public class SimpleAction implements Action &#123; private String name; //姓名 private String password; //密码 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override public String execute() &#123; System.out.println(name+"----"+password); return SUCCESS; &#125;&#125; struts.xml 配置Action 1234&lt;action name="simple" class="com.jsnu.struts2.controller.SimpleAction"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt;&lt;/action&gt; index.jsp 提价表单 input中的属性name对应的是SimpleAction的属性名 123456789101112&lt;body&gt;&lt;%String path = request.getContextPath();String basePath = request.getScheme()+"://"+request.getServerName()+":"+request.getServerPort()+path+"/";%&gt;&lt;form action="&lt;%=basePath %&gt;simple" method="post"&gt; name:&lt;input type="text" name="name"&gt; password:&lt;input type="text" name="password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt;&lt;/body&gt; success.jsp 表单提交成功之后跳转的视图 12345&lt;body&gt; &lt;h1&gt;success&lt;/h1&gt; &lt;h1&gt;$&#123;name &#125;&lt;/h1&gt; &lt;h1&gt;$&#123;password &#125;&lt;/h1&gt;&lt;/body&gt; 域驱动 域驱动是将表单中name属性抽象出一个JavaBean类成为一个modle，并不是Action类成为modle了，只需要在Action类引用JavaBean的对象即可(作为成员变量，get，set，方法都有) 既然Action类中的成员变量已经是JavaBean的对象了，那么表单的中name属性的设置就要使用OGNL形式的取该对象中的属性了，而不是像属性驱动一样直接设置的属性 实现 JavaBean实体类 必须为每一个属性设置get，set方法 必须有无参构造 12345678910111213141516171819202122232425/** * POJO类，model 其中必须为每一个属性设置get，set方法 */public class User &#123; private String name; // 姓名 private String password; // 密码 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; Action类 JavaBean对象作为其成员变量，必须为这个成员变量设置get,set方法 必须有一个无参构造 1234567891011121314151617public class SimpleAction implements Action &#123; private User user; // POJO类对象，必须有set，get方法，和无参构造方法 public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; @Override public String execute() &#123; System.out.println(user.getName() + "---&gt;" + user.getPassword()); return SUCCESS; &#125;&#125; struts.xml配置同上 index.jsp 表单提交 input中的name属性使用OGNL表达式来设置其值 123456789&lt;%String path = request.getContextPath();String basePath = request.getScheme()+"://"+request.getServerName()+":"+request.getServerPort()+path+"/";%&gt;&lt;form action="&lt;%=basePath %&gt;simple" method="post"&gt; name:&lt;input type="text" name="user.name"&gt; password:&lt;input type="text" name="user.password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; success.jsp页面 此时使用EL表达式取值，也是使用OGNL形式的取值方式 12345&lt;body&gt; &lt;h1&gt;success&lt;/h1&gt; &lt;h1&gt;$&#123;requestScope.user.name &#125;&lt;/h1&gt; &lt;h1&gt;$&#123;requestScope.user.password &#125;&lt;/h1&gt;&lt;/body&gt; 模型驱动 模型驱动和域驱动比较相似，都是用一个JavaBean类作为model，但是模型驱动必须实现ModelDriven&lt;&gt;这个接口,这个可以指定一个泛型，其中泛型类为JavaBean的类，必须实现的方法是getmodel()方法 Type getModel(){} 返回一个Type对象，这个对象是在实现接口的时候定义泛型类(JavaBean类) 使用模型驱动，那么表单中的name属性值就不需要使用OGNL表达式了，而是直接使用属性字段即可，这个和属性驱动一样的 JavaBean类，这个和上面的一样 Action类，实现了ModelDriver 接口 12345678910111213141516171819202122232425262728//实现ModelDriven接口&lt;&gt;指定的泛型为JavaBean类public class SimpleAction implements Action,ModelDriven&lt;User&gt; &#123; private User user; // POJO类对象，必须有set，get方法，和无参构造方法 public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; @Override public String execute() &#123; System.out.println(user.getName() + "---&gt;" + user.getPassword()); return SUCCESS; &#125; @Override public User getModel() &#123; System.out.println("调用了getModel方法"); // 如果对象为空，就创建一个对象，然后返回 if (user == null) &#123; this.user = new User(); &#125; return user; &#125;&#125; struts.xml 同上 index.jsp 表单提交 这里name属性值直接使用JavaBean属性即可，必须字段一样 12345&lt;form action="&lt;%=basePath %&gt;simple" method="post"&gt; name:&lt;input type="text" name="name"&gt; password:&lt;input type="text" name="password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; success.jsp 取值仍然使用的是OGNL形式的取值方式 123&lt;h1&gt;success&lt;/h1&gt;&lt;h1&gt;$&#123;requestScope.user.name &#125;&lt;/h1&gt;&lt;h1&gt;$&#123;requestScope.user.password &#125;&lt;/h1&gt; 总结 根据我的经验，在框架整合的基础上，我们必须使得单独的实体类对应一张表，那么此时就需要使得Action类和JavaBean分离，因此我推荐使用第二种方式，第三种方式还需要实现接口，对类的污染比较严重]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts之Action类访问Servlet_API]]></title>
      <url>%2F2018%2F03%2F31%2FStruts%E4%B9%8BAction%E7%B1%BB%E8%AE%BF%E9%97%AEServlet-API%2F</url>
      <content type="text"><![CDATA[Action类访问Servlet API Struts2并未直接和Servlet API耦合，这是Struts2的一个改良之处。但是对于web应用控制器而言，不访问Servlet API是不可能，因此下面我们介绍三种方式访问Servlet API ActionContext 使用这个可以获取Servlet中HttpServletRequest,HttpSession,ServletContext 其中的方法 static ActionContext getContext()返回一个实例化ActionContext对象，用于调用下面的方法 Object get(key) 返回ActionContext中存放的键值对的值 其实这里获取的是Servlet中HttpServletRequest对象的属性 Object put(key,value) 向ActionContext中存放键值对,同样该方法用于存放HttpServletRequest的属性 Map getSession()返回一个Map对象，不过这个模拟了HttpSession的用法，只不过现在向其中存放键值对使用put,获取属性用get Map getApplication()返回一个Map对象，不过这个模拟了Servlet中的ServletContext对象的方法。只不过存放和获取属性的方法用的分别是put和get Map getParameters()获取所有的请求参数，类似调用HttpServletRequest对象的getParameterMap()方法 Map setSession(Map session)直接传入一个Map实例，将其中的kay-value转换成session的属性名和属性值 Map setApplication(Map application)直接传入一个Map实例，将Map实例中的key-value转换成属性名，属性值 使用 如果想要使用这个类，当然需要实例化的对象，其中提供了一个获取对象的静态方法，就是上面方法中的第一个 我们在Action方法中使用这个设置request域，session域中的属性 12345678910111213141516171819public class SimpleAction implements Action &#123; @Override public String execute()&#123; ActionContext actionContext=ActionContext.getContext(); //获取实例化对象 //向request域中存放键值对 actionContext.put("name", "jack"); //获取request域中的name值 System.out.println(actionContext.get("name")); //向session中存放键值对 actionContext.getSession().put("password", "123456"); //向application中存放键值对 actionContext.getApplication().put("a", "b"); return SUCCESS; &#125;&#125; success.jsp 使用EL表达式获取 1234&lt;h1&gt;success&lt;/h1&gt;&lt;h1&gt;request域中的name:$&#123;requestScope.name&#125;&lt;/h1&gt;&lt;h1&gt;session域中的password: $&#123;sessionScope.password &#125;&lt;/h1&gt;&lt;h1&gt;application域中的a: $&#123;a &#125;&lt;/h1&gt; 总结 虽说现在可以向各种域中添加属性获取属性，但是我们不可以移除属性，所以说这种方法不如直接使用Servlet API功能更加强大 实现接口访问Servlet API 实现接口访问对一个Action类的污染实在太严重了，这个是不推荐使用的，可以了解一下 可以实现的接口 ServletContextAware实现该接口的Action可以直接访问用户请求的ServletContext实例 ServletRequestAware实现该接口的Action可以直接访问用户请求的HttpServletRequest实例 ServletResponseAware实现该接口的Action可以直接访问请求的HttpServletResponse实例 ServletActionContext（推荐） 使用这个类可以直接获取HttpServletRequest，HttpServletResponse等对象，其功能比第一种更加强大，因此推荐使用这种方式获取Servlet API 方法 PageContext getPageContext()取得web应用的PageContext对象 HttpServletRequest getRequest()获取HttpServletRequest对象 HttpServletResponse getResponse()获取HttpServletResponse对象 ServletContext getServletContext()获取ServletContext对象 使用 我们在Action类中使用 123456789101112131415161718public class SimpleAction implements Action &#123; @Override public String execute()&#123; //获取Request域的对象 HttpServletRequest request=ServletActionContext.getRequest(); request.setAttribute("name", "jack"); //获取Session域的对象 HttpSession session=request.getSession(); session.setAttribute("password", "123456"); //获取Response的对象 HttpServletResponse response=ServletActionContext.getResponse(); return SUCCESS; &#125;&#125; 总结 直接获取Servlet API中的对象，可以使用的功能更加强大，因此推荐使用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts2之动态调用]]></title>
      <url>%2F2018%2F03%2F31%2FStruts2%E4%B9%8B%E5%8A%A8%E6%80%81%E8%B0%83%E7%94%A8%2F</url>
      <content type="text"><![CDATA[动态调用什么是动态调用 动态调用就是一个Action类对应着多个请求，比如一个Action类中包含许多的方法，实现动态调用就是让这些方法都配上不同的URL请求映射，这个就是动态调用 好处 我们知道如果一个Action类只是对应着一个URL请求，那么我们要写很多Action类，但是如果我们使用了动态调用，那么就可以减少很多的重复工作 method实现动态调用-在struts核心配置文件详解(action)中已经详细讲解了method的用法，使用这个方式可以指定Action类中的不同的方法映射请求，那么就完成了动态调用 action名!方法名 这种方式不推荐使用，要想使用的话还要开启开关，如下 &lt;constant name=&quot;struts.enable.DynamicMethodInvocation&quot; value=&quot;true&quot; /&gt;将这个常量设置true才能使用 实现 创建SimpleAction的类 这个Action类中有一个login方法，我们的动态调用这个login方法，使用action名!方法名 1234567891011public class SimpleAction implements Action &#123; @Override public String execute()&#123; return SUCCESS; &#125; //实现登录的action public String login()&#123; System.out.println("这个是login方法......"); return INPUT; &#125;&#125; struts.xml中的配置(在src目录下) 开启开关 配置SimpleAction这Action类 123456789101112131415&lt;struts&gt; &lt;!-- 开启开关，否则不能使用!的方式 --&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="true"&gt;&lt;/constant&gt; &lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义这个包下的默认处理类 --&gt; &lt;default-class-ref class="com.jsnu.struts2.controller.SimpleAction"&gt;&lt;/default-class-ref&gt; &lt;!-- 这个是SimpleAction的类 --&gt; &lt;action name="simple"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 输入地址 假设项目的名称为web1，那么在地址栏中输入的url为：http://localhost:8080/web1/simple!login,注意这个感叹号一定是英文的 输入成功之后我们看到可以正确跳转，那么就成功了 通配符的方式 使用这种方式首先需要关闭上面开启的开关，当然如果你没有开启，那么就不用配置，因为其中默认就是关闭的 &lt;constant name=&quot;struts.enable.DynamicMethodInvocation&quot; value=&quot;false&quot; /&gt; 这种方式是官网推荐使用 在Servelt设置url的时候也使用过通配符，一般都是使用*来替代的。现在使用通配符也是一样的道理，也是可以使用动态调用的。 这种方式是和method方式配合使用的，在我看来就是method方式，只不过通过通配符传参而已 实现 我们还是使用上面的SimpleAction类，仍然是调用其中的login方法，不过struts.xml此时的配置文件改变了 struts.xml 关闭开关(默认是关闭的) 定义SimpleAction类的action 12345678910111213&lt;struts&gt; &lt;!-- 设置为false，关闭开关，默认是关闭的，因此可以不设置 --&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="false" /&gt; &lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义action，其中name属性使用一个*的通配符，method=&#123;1&#125;，这个1就是用来接收第一个通配符*的内容 假设此时输入的Simple_regist ,那么此时&#123;1&#125;=regist --&gt; &lt;action name="simple_*" class="com.jsnu.struts2.controller.SimpleAction" method="&#123;1&#125;"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 此时如果我们的项目名称为让web1，那么输入的url为http://localhost:8080/Struts2/simple_login.action,那么就会调用SimpleAction中的login方法执行 总结 推荐使用method和通配符的方式实现动态调用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[struts核心配置文件详解(result配置)]]></title>
      <url>%2F2018%2F03%2F31%2Fstruts%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3-result%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[struts核心配置文件详解(result配置)配置处理结果(result) 我们在包中定义的&lt;result name=&quot;&quot; type=&quot;&quot;&gt;value&lt;/result&gt;,这个是用来根据action方法返回的字符串，跳转到指定的视图或者其他的action。 name指定的是action方法返回的结果。 type 指定的是跳转的类型，默认的是dispatcher，相当于Servlet中的RequestDispatcher,地址栏中的url不会改变 如果一个action方法中可能返回的值是多个，比如如果测试成功返回success，测试失败返回input，出现异常返回error，那么此时就需要用到多个&lt;result&gt;标签来定义这些返回值跳转的视图 1234&lt;action name="login" class="com.controller.LoginAction"&gt; &lt;result name="success"&gt;/JSP/success.jsp&lt;/result&gt; &lt;result name="login"&gt;/JSP/login.jsp&lt;/result&gt;&lt;/action&gt; 类型 dispatcher 表示采用的跳转方式为转发，这个和Servlet中的RequestDispathcher是一个原理，地址栏的url是不会改变的 dispatcher 结果类型是在Action与JSP页面之中的一种默认的跳转发方式，相当于之间的Servlet中的转发(RequestDispatcher) redirect 用于跳转到其他的页面，但是这个地址栏的url是改变的 这个结果类型主要用于重定向到指定的视图资源，这个和dispatcher比较相似，但是这个地址改变了。相当于Servlet中的sendirect()这个方法。 chain Action链式处理结果类型 很多时候，当一个Action处理完之后并不想转发到视图资源，而是想要跳转到指定的Action继续未完成的处理，这时就需要使用chain，使得两个Action成为链式处理。 范例如下： 其中中的value要写成指定的标签中的name值，如果不是一个包中的，还要引入另外一个包中的action，看上面的内容 1234567891011&lt;package name="Login" extends="struts-default" namespace="/"&gt; &lt;action name="regist" class="com.action.regist"&gt; &lt;result name="success" type="chain"&gt;login&lt;/result&gt; &lt;/action&gt; &lt;action name="login" class="com.action.LoginAction"&gt; &lt;result name="success"&gt;/JSP/success.jsp&lt;/result&gt; &lt;result name="login"&gt;/JSP/login.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; freemaker 用于与FreeMaker整合的结果类型 httpheader 用于控制特殊的HTTP行为的结果类型 redirectAction 用于直接跳转到其他Action的结果类型 上面说个redirect是用于重定向到指定的视图资源的，那么这个是用于重定向到指定的Action类的，这个和chain类型非常相似，不过一个是重定向，一个是转发，当然其中的request中的内容会丢失。 stream 用于浏览器返回一个InputStream的结果类型（一般用于下载） velocity 用于与Velocity整合的结果类型 xslt 用于与XML/XSTL整合的结果类型 plainText 用于显示某个页面的原始代码的结果类型 局部结果 配置局部结果就是在作为的子标签配置，就是上面的配置方式，但是这种局部配置只针对自己的父标签的action起作用。如下： 1234567&lt;!-- name指定了包的名称，extends指定继承的类，namespace指定url路径，这里使用/表示在根路径下就可以直接访问 --&gt;&lt;package name="Login" extends="struts-default" namespace="/"&gt;&lt;action name="login" class="com.controller.LoginAction"&gt; &lt;result name="success"&gt;/JSP/success.jsp&lt;/result&gt; &lt;result name="login"&gt;/JSP/login.jsp&lt;/result&gt;&lt;/action&gt;&lt;/package&gt; 配置全局结果 当我们需要一个视图可能这个package中action都需要，如果一个action中定义一个这样的result难免有些多余，现在我们使用只需要在元素内定义一次即可，一旦有返回值满足即可调用这个视图。比如我们定义一个错误处理的界面，因为这个处理视图是一样的，只需要配置全局result即可。 123456789&lt;package name=”Login” extends=”struts-default” namespace=”/user”&gt;&lt;global-results &gt; &lt;!—只要执行action的类返回error就会跳转到error.jsp--!&gt; &lt;result name=”error”&gt;error.jsp&lt;/result&gt;&lt;/global-results&gt;&lt;action name=”login”class=”com.action.LoginAction”&gt; &lt;result name=”success”&gt;success.jsp&lt;/result&gt;&lt;/action&gt;&lt;/package&gt; 根据上面的配置，如果此时login这个action返回的字符串为error，那么此时的全局配置结果就起作用了，就会跳转到error.jsp页面 但是我们一个action处理错误的页面和特殊，虽然返回的是error，但是我就想跳转到其他的页面，那么可以在这个action的标签下重新定义一个结果，此时的局部结果就会覆盖全局结果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[struts核心配置文件详解(action配置)]]></title>
      <url>%2F2018%2F03%2F31%2Fstruts%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3-action%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[struts核心配置文件详解(action配置)配置action 前面我们已经说过Action类的三个实现方式，现在我们该说说Action类在struts.xml中的配置问题了 指定特定的方法执行(method) 我们知道ActionSupport类实际上相当与一个POJO类，这个和springmvc不同，struts2中的控制层Action类没有和实体类分离，其中可以有很多的方法，我们知道struts2默认调用的execute方法，但是如果我们想要指定其他的方法来处理请求呢，这时我们就需要使用method这个属性了 method: 是&lt;action name=&quot;&quot; class=&quot;&quot; method=&quot;&quot;&gt;标签中的属性,指定的是Action类中的方法名，如果不使用这属性，那么默认的值是execute 12345&lt;!-- 使用method指定 SimpleAction中的login方法执行这个login.action这个URL --&gt;&lt;action name="login" class="com.jsnu.struts2.controller.SimpleAction" method="login"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt;&lt;/action&gt; 配置默认的处理类 上面我们讲解了method的使用方式，但是现在有一个问题，如果一个Action类中有多个处理方法，那么每次定义action都需要在其中指定相同的class属性，如果我们把这个class抽离出来，不用每一个action都写class属性。 只需要在标签内部加上&lt;default-class-ref class=&quot;&quot;&gt;即可，那么这个包下的所有的action没有设置class的是属性的都是使用的这个默认的处理类。 但是如果&lt;action&gt;标签中指定了class属性，那么会覆盖这个默认的处理类 12345678910111213141516171819202122&lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 定义这个包下的默认处理类 --&gt; &lt;default-class-ref class="com.jsnu.struts2.controller.SimpleAction"&gt;&lt;/default-class-ref&gt; &lt;!-- 这个action使用的是另外一个处理类，此时的默认处理类对这个action没有作用，被覆盖掉--&gt; &lt;action name="testaction" class="com.jsnu.struts2.controller.TestAction" &gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;/action&gt; &lt;!-- 这个action没有指定class属性，那么就会使用默认处理类的exit方法 --&gt; &lt;action name="simpleAction" method="exit"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;/action&gt; &lt;!-- 使用method指定 SimpleAction中的login方法执行这个login.action这个URL，同样的没有指定class，使用默认处理类中的login方法 --&gt; &lt;action name="login" method="login"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; 配置默认的处理action-如果用户输入的的URL地址在这个&lt;package&gt;下，即是namespace符合，但是在其中没有相应的action的做出响应，可能是地址输错了，此时的我们需要使其跳转到error.jsp页面，给用户一个提示。那么我们这个时候就需要使用默认的action。 默认的action的作用就是在用户输入地址没有响应，但是符合&lt;package&gt;下的一个namespace，那么可能是用户输错了，那么我们为了提高友好性，此时需要跳转到error.jsp页面，此时就需要一个默认的action类映射了 -直接在&lt;package&gt; 定义即可，其中的name属性指定的package下的已经存在的action的名称 1234567891011121314151617&lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 指定默认的action，如果在namespace路径下的找不到指定的action来映射请求，那么就会使用package下的默认的action来做出响应 name： 指定这个package下的action的名字，相当于已经定义好的action --&gt; &lt;default-action-ref name="login"&gt;&lt;/default-action-ref&gt; &lt;!-- 定义这个包下的默认处理类 --&gt; &lt;default-class-ref class="com.jsnu.struts2.controller.SimpleAction"&gt;&lt;/default-class-ref&gt; &lt;!-- 使用method指定 SimpleAction中的login方法执行这个login.action这个URL，同样的没有指定class，使用默认处理类中的login方法 --&gt; &lt;action name="login" method="login"&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/jsp/input.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts2Action类实现]]></title>
      <url>%2F2018%2F03%2F30%2FStruts2Action%E7%B1%BB%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[Action类的实现方式Action类的实现方式 如果想要浏览器可以映射到其中的方法，那么必须返回一个String，使用这个值指示需要跳转的视图或者Action Struts中的Action类实际上可以是一个POJO类，其中也是可以定义许多的方法，但是如果在struts.xml的配置文件中特指调用哪个方法的话，那么就会默认会调用名为execute的方法。后续将会讲如何调用类中其他的方法 普通的pojo类 不需要实现或者继承任何类，只是一个普通的类 这个普通的类中有一个名为execute的方法，返回的一个字符串 123456public class SimpleAction &#123; public String execute()&#123; System.out.println("这是一个普通的pojo类"); return "success"; &#125;&#125; struts.xml 配置跳转的视图 1234&lt;!-- 配置跳转到添加学生页面的action --&gt; &lt;action name="simpleAction" class="com.jsnu.struts2.controller.SimpleAction" &gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;/action&gt; 继承ActionSupport 在其中封装了execute方法，我们只需要覆盖即可 在这个类中还默认的封装了一些静态变量，比如： public static final String EOORO=”error” public static final String INPUT=”input” public static final String LOGIN=”login” public static final String NONE=’none’ public static final String SUCCESS=”success” 实现 1234567public class ActionSupportAction extends ActionSupport &#123; @Override public String execute() throws Exception &#123; System.out.println("继承了ActionSupport"); return SUCCESS; &#125;&#125; struts中配置 同上 实现Action类 实现这个类，同样是还要实现其中的execute方法 其中也是和ActionSupport一样，封装了许多的字符串静态变量，我们自己调用即可。同上 实现 123456789101112/** * action类： 这里实现的Action接口 * @author chenjiabing */public class TestAction implements Action &#123; @Override public String execute() throws Exception &#123; System.out.println("cchjemko"); return SUCCESS; &#125;&#125; struts.xml配置 同上 只需要改变中的name 和 class即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts2核心配置文件(package)]]></title>
      <url>%2F2018%2F03%2F30%2FStruts2%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[struts核心配置文件详解包(package) 在核心配置文件中需要配置&lt;package&gt; 元素可以把逻辑上相关的一组Action、Result、Intercepter等元素封装起来，形成一个独立的模块，package可以继承其他的package，也可以作为父包被其他的package继承 属性 name 这是一个必填的属性，指定包的名字，便于其他的包引用，因为其他的包可以继承这个包 extends ： 该属性是一个选择属性，表示继承其他的包，但是我们一般都会继承struts-default 如果我们学到了处理json数据的时候，我们将会继承处理json的包 namespace ：该属性是一个可选属性，指定该包的命名空间，默认的是“/”,以为一个配置文件中可能有相同名字的action，如果配置不同的namespace，那么就可以配置相同的action的名字 namespace配置的是包的命名空间，同一个命名空间里面不能有同名的Action，当然不同的命名空间里面是可以有同名的Action的。类似于Java的包的功能，namespace可以有效的防止action重名的冲突，因为配置了namespace后，在访问action的时候就需要添加namespace来作为action的前缀。如果不配置namespace，表示是默认的namespace，那么访问的时候不需要添加namespace前缀。 比如有一个项目为Web1，在struts.xml的&lt;package namespace = &quot;/student&quot;&gt;,这个包的下面有一个&lt;action name =&quot;add&quot;&gt;,那么我们要访问这个action使用的url为：http://localhost:8080/Web1/student/add.action abstract：这是一个可选属性，表示这个包是否是抽象的，抽象包不能包含action定义 范例12&lt;!—指定了继承自strtus-default这个类，namespace指定了命名空间，那么当其中的action访问的时候要必须使用如下:http://localhost:8080/web1/user/*--!&gt;&lt;package name="Login" extends="struts-default" namespace="/user"&gt;&lt;/package&gt; 引入另一个包中的action 需求： 前面我们都是跳转到指定的视图，但是我们也是可以跳转到指定的action，但是这个要跳转的action和当前的action不是一个包中的。 此时我们就需要在当前包中引入另外一个包中的action，那么我们可以如下设置 &lt;param name=&quot;namespace&quot;&gt;中的值为另外一个包的namespace &lt;param name=&quot;actionName&quot;&gt;中的值为需要跳转到的action名字 1234567891011121314151617&lt;package name="Login" extends="struts-default" namespace="/"&gt; &lt;action name="login" class="com.action.LoginAction"&gt; &lt;result name="success" type="chain"&gt; &lt;!-- namespace指定另外一个包中的namespace，actionName指定action的名字 --&gt; &lt;param name="namespace"&gt;/user&lt;/param&gt; &lt;param name="actionName"&gt;regist&lt;/param&gt; &lt;/result&gt; &lt;/action&gt;&lt;/package&gt;&lt;package name="Regist" extends="struts-default" namespace="/user"&gt; &lt;action name="regist" class="com.action.RegistAction"&gt; &lt;result name="success"&gt;JSP/success.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; 包含另外一个包（include) 一个项目中的配置文件中可能需要定义很多个package和action，那么都写在一个xml文件中，不免有些混乱，因此需要使用include包含其他的配置文件，相当于jsp文件中的&lt;jsp:include&gt;,要注意的是配置文件都要放在项目的src目录下 &lt;include file=”user.xml”&gt;&lt;/include&gt; 配置处理结果(result) 我们在包中定义的&lt;result name=&quot;&quot; type=&quot;&quot;&gt;value&lt;/result&gt;,这个是用来根据action方法返回的字符串，跳转到指定的视图或者其他的action。 name指定的是action方法返回的结果。 type 指定的是跳转的类型，默认的是dispatcher，相当于Servlet中的RequestDispatcher,地址栏中的url不会改变 如果一个action方法中可能返回的值是多个，比如如果测试成功返回success，测试失败返回input，出现异常返回error，那么此时就需要用到多个&lt;result&gt;标签来定义这些返回值跳转的视图 1234&lt;action name="login" class="com.controller.LoginAction"&gt; &lt;result name="success"&gt;/JSP/success.jsp&lt;/result&gt; &lt;result name="login"&gt;/JSP/login.jsp&lt;/result&gt;&lt;/action&gt; 类型 dispatcher 表示采用的跳转方式为转发，这个和Servlet中的RequestDispathcher是一个原理，地址栏的url是不会改变的 dispatcher 结果类型是在Action与JSP页面之中的一种默认的跳转发方式，相当于之间的Servlet中的转发(RequestDispatcher) redirect 用于跳转到其他的页面，但是这个地址栏的url是改变的 这个结果类型主要用于重定向到指定的视图资源，这个和dispatcher比较相似，但是这个地址改变了。相当于Servlet中的sendirect()这个方法。 chain Action链式处理结果类型 很多时候，当一个Action处理完之后并不想转发到视图资源，而是想要跳转到指定的Action继续未完成的处理，这时就需要使用chain，使得两个Action成为链式处理。 范例如下： 其中中的value要写成指定的标签中的name值，如果不是一个包中的，还要引入另外一个包中的action，看上面的内容 1234567891011&lt;package name="Login" extends="struts-default" namespace="/"&gt; &lt;action name="regist" class="com.action.regist"&gt; &lt;result name="success" type="chain"&gt;login&lt;/result&gt; &lt;/action&gt; &lt;action name="login" class="com.action.LoginAction"&gt; &lt;result name="success"&gt;/JSP/success.jsp&lt;/result&gt; &lt;result name="login"&gt;/JSP/login.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; freemaker 用于与FreeMaker整合的结果类型 httpheader 用于控制特殊的HTTP行为的结果类型 redirectAction 用于直接跳转到其他Action的结果类型 上面说个redirect是用于重定向到指定的视图资源的，那么这个是用于重定向到指定的Action类的，这个和chain类型非常相似，不过一个是重定向，一个是转发，当然其中的request中的内容会丢失。 stream 用于浏览器返回一个InputStream的结果类型（一般用于下载） velocity 用于与Velocity整合的结果类型 xslt 用于与XML/XSTL整合的结果类型 plainText 用于显示某个页面的原始代码的结果类型 局部结果 配置局部结果就是在作为的子标签配置，就是上面的配置方式，但是这种局部配置只针对自己的父标签的action起作用。如下： 1234567&lt;!-- name指定了包的名称，extends指定继承的类，namespace指定url路径，这里使用/表示在根路径下就可以直接访问 --&gt;&lt;package name="Login" extends="struts-default" namespace="/"&gt;&lt;action name="login" class="com.controller.LoginAction"&gt; &lt;result name="success"&gt;/JSP/success.jsp&lt;/result&gt; &lt;result name="login"&gt;/JSP/login.jsp&lt;/result&gt;&lt;/action&gt;&lt;/package&gt; 配置全局结果 当我们需要一个视图可能这个package中action都需要，如果一个action中定义一个这样的result难免有些多余，现在我们使用只需要在元素内定义一次即可，一旦有返回值满足即可调用这个视图。比如我们定义一个错误处理的界面，因为这个处理视图是一样的，只需要配置全局result即可。 123456789&lt;package name=”Login” extends=”struts-default” namespace=”/user”&gt;&lt;global-results &gt; &lt;!—只要执行action的类返回error就会跳转到error.jsp--!&gt; &lt;result name=”error”&gt;error.jsp&lt;/result&gt;&lt;/global-results&gt;&lt;action name=”login”class=”com.action.LoginAction”&gt; &lt;result name=”success”&gt;success.jsp&lt;/result&gt;&lt;/action&gt;&lt;/package&gt; 根据上面的配置，如果此时login这个action返回的字符串为error，那么此时的全局配置结果就起作用了，就会跳转到error.jsp页面 但是我们一个action处理错误的页面和特殊，虽然返回的是error，但是我就想跳转到其他的页面，那么可以在这个action的标签下重新定义一个结果，此时的局部结果就会覆盖全局结果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Struts2入门]]></title>
      <url>%2F2018%2F03%2F30%2FStruts2%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[入门操作##导入jar 包 到官网下载相应的jar包 导入前阶段必须的jar包 创建项目 在eclipse中创建一个web项目 在webContent下WEB-INF/lib下导入需要的jar包即可 配置核心过滤器 StrutsPrepareAndExecuteFilter （web.xml) 核心过滤器相当于springmvc中的前端控制器的功能，都是用来分发请求的 这里的核心过滤器默认分发的请求是以.action结尾的请求，因此我们可以使用这个默认的，但是我们也可以自己配置自己的，下面我配置的是所有的请求都分发 在web.xml中配置 1234567891011&lt;!-- 配置struts2的核心过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;!-- struts2中默认的访问路径是以.action结尾的路径才会分发， 因此我们这里需要设置即使不是.action结尾的也能分发请求给对应的action --&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 创建action类 定义action类有两种方法，一种是实现Action接口，一种是继承ActionSupport,这个在第二章会详细讲解 12345678910111213import com.opensymphony.xwork2.Action;/** * action类： 这里实现的Action接口 * @author chenjiabing */public class TestAction implements Action &#123; @Override public String execute() throws Exception &#123; System.out.println("cchjemko"); return SUCCESS; &#125;&#125; 创建核心配置文件 文件名为： struts.xml 存放的路径： 在src目录下，或者自己创建的源文件夹的根目录下 struts.xml 内容 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE struts PUBLIC "-//Apache Software Foundation//DTD Struts Configuration 2.1//EN" "http://struts.apache.org/dtds/struts-2.1.dtd"&gt;&lt;struts&gt; &lt;!--定义package ，name是这个package的名字，唯一标识 extends: 该属性是一个选择属性，表示继承其他的包，但是我们一般都会继承struts-default namespace：该属性是一个可选属性，指定该包的命名空间，默认的是“/”,以为一个配置文件中可能有相同名字的action，如果配置不同的namespace，那么就可以配置相同的action的名字，这个和调用执行请求的url息息相关 --&gt; &lt;package name="test" extends="struts-default" namespace="/"&gt; &lt;!-- 配置测试的action类，其中name是调用的别名，class是Action类的全路径 类名+包名--&gt; &lt;action name="testaction" class="com.jsnu.struts2.controller.TestAction" &gt; &lt;!--name是Action类中返回的值，/jsp/success.jsp是对应的跳转视图，这里如果返回success，那么跳转到/jsp/success.jsp这个视图--&gt; &lt;result name="success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 创建视图 前面的核心配置文件中定义了跳转的视图为 /jsp/success.jsp 在webContent下创建一个jsp文件夹，在其中创建一个success.jsp文件 执行 开启tomcat，在浏览器张输入：http://localhost:8080/Struts2/testaction.action 执行成功之后，我们将会看到调用上面的链接，页面就会跳转到success.jsp页面 但是我们看到地址依然没有改变，因为struts默认的跳转是以转发的方式，不是重定向，后面我们会讲到怎样设置跳转方式]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDBC干货二]]></title>
      <url>%2F2018%2F03%2F30%2FJDBC%E5%B9%B2%E8%B4%A7%E4%BA%8C%2F</url>
      <content type="text"><![CDATA[Day02Properties属性配置对象什么是properties 程序猿可以把工程中出现的某些数据以配置文件的形式保存起来，就是处理 *.properties文件的对象，在properties文件中是以键值对形式保存的数据 把数据库中的信息存放到该文件中 其中存放的是driver ,url , username,password 为什么要保存到该配置文件中 因为以后的工作中有更换数据库的需求，此时如果写在java类中修改比较麻烦，所以需要把这些数据保存到配置文件中 存放数据 在src的目录下创建一个jdbc.properties配置文件 将数据库的信息保存到其中(键值对的形式) 1234driver=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/jdbcusername=rootpassword=root 存放数据注意事项 数据是以键值的形式存放的（key-value） value的值不能带有引号，并且后面不能有空格 读取Properties配置文件中的信息 既然我们将数据库中的配置信息存放到配置文件中，我们当然需要将其读取到java代码中使用 前提：这个配置文件在src目录下 12345678910111213@Testpublic void testPro()&#123; Properties properties=new Properties(); //创建Properties对象 //使用类加载器生成输入流（读取） 前提是该配置文件必须在src目录下 InputStream ips=TestProperties.class.getClassLoader().getResourceAsStream("jdbc.properties"); try &#123; properties.load(ips); String s1=properties.getProperty("url"); //直接读取，以键值 System.out.println(s1); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 定义此时的工具类 我们引用了配置文件，那么我们的工具类就需要改变了，在工具类需要读取配置文件中数据库信息 我们知道数据库的配置信息是不变的，因此我们不需要每次连接都加载一次，所以我们可以将读取数据库配置信息的代码放在静态语句块中，那么只有当类加载的时候才会加载一次 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import java.io.IOException;import java.io.InputStream;import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import java.util.Properties;/** * 数据库封装类 * @author chenjiabing */public class DBUtils &#123; private static String driver; //驱动 private static String url; //url private static String username; //用户名 private static String password; //密码 //静态语句块,只在使用类加载的时候加载一次，因为其中的数据不用每次都加载，所以只需要加载一次 static&#123; Properties properties=new Properties(); //创建对象 //使用类加载器读取文件输入流 InputStream ips=DBUtils.class.getClassLoader().getResourceAsStream("jdbc.properties"); try &#123; properties.load(ips); //读取属性值 driver=properties.getProperty("driver"); url=properties.getProperty("url"); username=properties.getProperty("username"); password=properties.getProperty("password"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取连接对象 * @param user 数据库用户名 * @param password 密码 * @param database : 数据库名称 */ public static Connection getConnection() throws Exception &#123; Class.forName("com.mysql.jdbc.Driver"); // 注册驱动 // 链接数据库 Connection connection = DriverManager.getConnection( url, username, password); return connection; &#125; /** * 关闭数据库资源 * @param connection 连接对象 * @param statement Statement对象 * @param resultSet 结果集 */ public static void close(Connection connection, Statement statement, ResultSet resultSet) &#123; try &#123; if (resultSet != null) &#123; resultSet.close(); &#125; if (statement != null) &#123; statement.close(); &#125; if (connection != null) &#123; connection.close(); &#125; &#125; catch (Exception exception) &#123; exception.printStackTrace(); &#125; &#125;&#125; 数据库连接池什么是数据库连接池(DBCP DatabaseConnection Pool) 一套管理数据库连接的api 为什么用 如果没有数据库连接池的话，每次和数据库进行交互都需要建立连接和关闭连接，如果有1万次交互就有一万次建立和关闭连接，频繁开关连接非常消耗资源。使用数据库连接池，可以设置一个初始连接数量，如果有连接需求会和连接池要，连接池中有空闲连接则用空闲的，如果没有此时会检测是否是最大数量，如果是则等待，如果不是则创建新的连接，每个连接使用完之后会归还到连接池中。等待连接池的，如果有归还的连接会直接得到此连接进行操作 原理 使用数据库连接池，可以设置一个初始连接数量，如果有连接需求会和连接池要，连接池中有空闲连接则用空闲的，如果没有此时会检测是否是最大数量，如果是则等待，如果不是则创建新的连接，每个连接使用完之后会归还到连接池中。等待连接池的，如果有归还的连接会直接得到此 如何使用数据库连接池 下载jar包 去maven私服中，找到dbcp-1.4版本的 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt; 初次使用（连接数据库） 1234567891011121314151617//创建数据源对象 BasicDataSource dataSource=new BasicDataSource(); //设置连接信息 driver url username password dataSource.setDriverClassName("com.mysql.jdbc.Driver"); dataSource.setUrl("jdbc:mysql://localhost:3306/jdbc"); dataSource.setUsername("root"); dataSource.setPassword("root"); //设置连接池策略信息 dataSource.setInitialSize(3); //设置初始连接数量 dataSource.setMaxActive(5); //设置最大连接数量 //获取连接 Connection connection=dataSource.getConnection(); System.out.println(connection); JDBC工具类终极版 使用数据库连接池 使用了properties配置文件的形式存储数据库配置信息 jdbc.properties(key-value 键值对形式存储) value最后不能有空格 value的值不能用引号 因为使用的是类加载器加载的，因此这个文件的位置应该在src目录下 123456driver=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/jdbcusername=rootpassword=rootinitSize=3maxSize=5 实现 数据库的配置信息不是经常改变的，因此不用每次使用都重新加载，只需要加载一次(静态语句块) 数据源和数据库连接池的配置信息(初始连接数量，最大连接数量) 只需要加载一次（静态语句块) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import java.io.IOException;import java.io.InputStream;import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import java.util.Properties;import org.apache.commons.dbcp.BasicDataSource;/** * 数据库封装类 ： 终极版 * @author chenjiabing */public class DBUtils &#123; private static String driver; //驱动 private static String url; //url private static String username; //用户名 private static String password; //密码 private static String maxSize; //最大连接数量 private static String initSize; //初始化连接数量 private static BasicDataSource dataSource; //数据源 //静态语句块,只在使用类加载的时候加载一次，因为其中的数据是不会经常改变的，所以只需要加载一次 static&#123; Properties properties=new Properties(); //创建对象 //使用类加载器读取文件输入流 InputStream ips=DBUtils.class.getClassLoader().getResourceAsStream("jdbc.properties"); try &#123; properties.load(ips); //读取属性值 driver=properties.getProperty("driver"); url=properties.getProperty("url"); username=properties.getProperty("username"); password=properties.getProperty("password"); initSize=properties.getProperty("initSize"); maxSize=properties.getProperty("maxSize"); dataSource=new BasicDataSource(); //获取数据源 //设置数据源的属性-----数据库的配置信息 dataSource.setDriverClassName(driver); dataSource.setUrl(url); dataSource.setUsername(username); dataSource.setPassword(password); dataSource.setInitialSize(Integer.parseInt(initSize)); dataSource.setMaxActive(Integer.parseInt(maxSize)); &#125; catch (IOException e) &#123; System.out.println("配置文件jdbc.properties读取失败！！！"); e.printStackTrace(); &#125; &#125; /** * 获取数据库连接 * @return * @throws Exception */ public static Connection getConnection() throws Exception &#123; Connection connection=dataSource.getConnection(); return connection; &#125; /** * 关闭数据库资源 * @param connection 连接对象 * @param statement Statement对象 * @param resultSet 结果集 */ public static void close(Connection connection, Statement statement, ResultSet resultSet) &#123; try &#123; if (resultSet != null) &#123; resultSet.close(); &#125; if (statement != null) &#123; statement.close(); &#125; if (connection != null) &#123; connection.close(); &#125; &#125; catch (Exception exception) &#123; exception.printStackTrace(); &#125; &#125;&#125; 测试连接123456789101112131415161718192021222324252627282930313233343536import java.sql.Connection;import java.sql.ResultSet;import java.sql.Statement;import org.junit.Test;import com.jsnu.db.DBUtils;public class TestDBUtils &#123; @Test public void test() &#123; Connection connection = null; Statement statement = null; ResultSet resultSet = null; try &#123; connection = DBUtils.getConnection(); //获取连接 statement = connection.createStatement(); //创建Statement语句对象 String select_sql = "select * from t"; resultSet = statement.executeQuery(select_sql); //执行查询方法 while (resultSet.next()) &#123; int id = resultSet.getInt("id"); //获取属性 String name = resultSet.getString("name"); int age = resultSet.getInt("age"); System.out.println(id + "---" + age + " ----" + name); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; DBUtils.close(connection, statement, resultSet); //关闭资源 &#125; &#125;&#125; 测试等待 我们知道连接池有最大的连接限制，只要连接的数量需求超过最大值，那么我们就需要等待，直到连接池中有空闲的连接。 上面我们设置的最大连接数量为5，此时我们利用多线程来测试等待的过程 connection.close 就是归还连接，因为连接关闭了 线程类： 123456789101112131415public class TestDButils2 extends Thread &#123; @Override public void run() &#123; try &#123; Connection connection=DBUtils.getConnection(); System.out.println(connection); //获取连接 System.out.println(this.getName()+ "： 正在运行"); Thread.sleep(5000); //睡眠5s connection.close(); //关闭连接，相当于释放连接，归还到连接池中 System.out.println(this.getName()+":连接已经归还"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; main方法中测试 在main方法中创建了六个线程，那么最大的连接数量是5，此时肯定有一个线程在等待获取连接，直到前面的线程归还连接才会执行 1234567public static void main(String[] args) &#123; for(int i=0;i&lt;=6;i++)&#123; TestDButils2 testDButils2=new TestDButils2(); testDButils2.start(); //线程启动 &#125; &#125; PrepareStatement好处 代码结构更加清晰，比拼接字符串出错概率要低 执行效率要比Statement高（效果不是太明显）因为使Statement每次执行sql都需要把sql编译成执行计划，而PrepareStatement只需要创建时转化一次，之后只需要修改里面的值即可，所以效率会高 有预编译可避免sql注入，预编译的时候把sql语句的逻辑已经定死，不能再向其中添加新的逻辑 sql注入 创建用户表 drop table user if exists; //有则先删除 create table user(id int primary key auto_increment,username varchar(10),password varchar(20)); insert into user(username,password) values(‘libai’,’admin’),(‘zhaosi’,’123456’); 用户登录 根据用户名和密码查询人数，如果 &gt;0 表示有这个人，如果 &lt;0 登录失败 select count(*) from user where username=”libai” and password=”admin”; 我们只需要使用select count(*) from user where username=&#39;xds&#39; and password=&#39;&#39; or &#39;1&#39;=&#39;1&#39; 那么会直接登录成功，无论用户名和密码是多少。这种是使用Statement才会生效，因为其中的sql是拼接的。我们只需要输入密码为 &#39; or &#39;1&#39;=1即可sql注入]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDBC干货一]]></title>
      <url>%2F2018%2F03%2F30%2FJDBC%E5%B9%B2%E8%B4%A7%E4%B8%80%2F</url>
      <content type="text"><![CDATA[JDBC什么是JDBC Java Database Connectivity JDBC是java中一套和数据库进行交互的API(应用程序编程接口) 为什么使用JDBC 因为java程序猿需要连接各种数据库（oracle，mysql，db2等）为了避免java程序猿每一种数据库都需要学习一遍，sun公司提出一个JDBC接口，各个数据库厂商去针对此接口写实现类（数据库驱动），这样的话java程序猿连接数据库只需要掌握JDBC接口的调用就可以操作各种数据库 eclipse配置maven 本机安装maven 修改远程仓库地址 maven的配置文件settings中修改 123456789101112131415161718192021222324252627282930 &lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;servers&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Tedu Maven&lt;/name&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;!--&lt;url&gt;http://maven.tedu.cn/nexus/content/groups/public&lt;/url&gt;--&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 在eclispe中配置 window —- &gt; perferences —- &gt; Maven — &gt; User Settings —- &gt; 在Global Settings中选择你的maven配置文件settings即可 OK 新建项目 New — &gt; Maven Project — &gt; Create Simple Project 第一次创建可能需要很长的时间 在pom.xml中写上依赖 123456789101112131415161718192021222324252627 &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.tedu&lt;/groupId&gt; &lt;artifactId&gt;JDBCMaven&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.44&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 如何使用JDBC 创建maven工程 下载mysql相关jar包 登录阿里私服： maven.aliyun.cn 执行方法(Statement) execute(sql) 执行DDL create alter executeUpdate(sql) 执行DML insert update delete executeQuery(sql) 执行select语句 12345678910111213141516171819202122232425 Class.forName("com.mysql.jdbc.Driver"); //注册驱动//链接数据库Connection connection=DriverManager.getConnection("jdbc:mysql://localhost:3306/jdbc", "root", "root");//创建Statement，执行sql语句的对象Statement statement =connection.createStatement();String sql_create="create table if not exists t(id int primary key auto_increment,age int ,name varchar(10))";String sql_insert="insert into t(age,name) values(22,'jack'),(33,'tom')";String sql_sselect="select * from t";//执行create 语句Boolean flag=statement.execute(sql_create);System.out.println(flag);//执行insert语句int row=statement.executeUpdate(sql_insert);System.out.println(row);//执行selectResultSet resultSet=statement.executeQuery(sql_sselect);while(resultSet.next())&#123; int id=resultSet.getInt("id"); int age=resultSet.getInt("age"); String name = resultSet.getString("name"); System.out.println(id+"----"+age+"----"+name);&#125; ResultSet(查询得到结果集) 代表查询语句得到的结果集(executeQuery) 见到resultSet 就用while next() 移动游标 有下一条返回true，没有返回false 1234567891011121314 Class.forName("com.mysql.jdbc.Driver"); //加载驱动 // 链接数据库Connection connection=DriverManager.getConnection("jdbc:mysql://localhost:3306/jdbc", "root", "root");Statement statement =connection.createStatement(); //获取执行sql语句对象 String sql_sselect="select * from t"; //创建sql语句 ResultSet resultSet=statement.executeQuery(sql_sselect); //获取结果集while(resultSet.next())&#123; int id=resultSet.getInt("id"); int age=resultSet.getInt("age"); String name = resultSet.getString("name"); System.out.println(id+"----"+age+"----"+name);&#125; 关闭资源(close) 关闭Connection 如果sql执行完，继续持有连接没有意义，会造成服务器压力过大，所以需要关闭 关闭Statement 会占用内存的资源，所以用完就关闭 关闭ResultSet 因为ResultSet对象中包含查询结果的数据，会占用内存空间 关闭顺序 ResultSet , Statement , Connection 异常处理123456789101112131415161718192021222324252627282930313233343536@Test public void testException() &#123; Connection connection = null; //申明Connection为null Statement statement = null; // 申明 Statement为null try &#123; Class.forName("com.mysql.jdbc.Driver"); // 注册驱动 // 链接数据库 connection = DriverManager.getConnection( "jdbc:mysql://localhost:3306/jdbc", "root", "root"); // 创建Statement，执行sql语句的对象 statement = connection.createStatement(); String sql_insert = "insert into t(age,name) values(22,'marry'),(33,'Alice')"; int row=statement.executeUpdate(sql_insert); System.out.println(row); &#125; catch (Exception e) &#123; System.out.println("出异常"); e.printStackTrace(); &#125; finally &#123; if (statement != null) &#123; try &#123; statement.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (connection != null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; JDBC封装 目的：把频繁出现的代码封装起来，起到代码复用的作用，从而提高开发效率 创建DBUtils类(数据库工具类) 封装建立数据连接 封装关闭资源 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;/** * 数据库封装类 * @author chenjiabing */public class DBUtils &#123; /** * 获取连接对象 * @param user 数据库用户名 * @param password 密码 * @param database : 数据库名称 */ public static Connection getConnection(String user, String password, String database) throws Exception &#123; Class.forName("com.mysql.jdbc.Driver"); // 注册驱动 // 链接数据库 Connection connection = DriverManager.getConnection( "jdbc:mysql://localhost:3306/" + database, user, password); return connection; &#125; /** * 关闭数据库资源 * @param connection 连接对象 * @param statement Statement对象 * @param resultSet 结果集 */ public static void close(Connection connection, Statement statement, ResultSet resultSet) &#123; try &#123; if (resultSet != null) &#123; resultSet.close(); &#125; if (statement != null) &#123; statement.close(); &#125; if (connection != null) &#123; connection.close(); &#125; &#125; catch (Exception exception) &#123; exception.printStackTrace(); &#125; &#125;&#125; 测试 1234567891011121314151617 @Testpublic void testUntils()&#123; Connection connection=null; Statement statement=null; ResultSet resultSet=null; try &#123; connection=DBUtils.getConnection("root", "root", "jdbc"); //获取连接 statement=connection.createStatement(); //插入数据 int row = statement.executeUpdate("insert into t(age,name) values(22,'陈加兵'),(33,'Jackson')"); System.out.println(row); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; DBUtils.close(connection, statement, resultSet); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL操作六]]></title>
      <url>%2F2018%2F03%2F28%2FSQL%E6%93%8D%E4%BD%9C%E5%85%AD%2F</url>
      <content type="text"><![CDATA[Day06视图视图概述 什么是视图： 在数据库中存在多种对象，表和视图都是数据库中的对象，创建视图时视图名称不能和表名相同，实际上，视图就代表一个sql查询语句，也可以理解成视图是一张虚拟的表，但是虚拟表中的数据会随着原表数据的改变而改变 为什么使用视图： 因为有些数据的查询需要书写大量的sql语句，每次书写比较麻烦，使用视图可起到重用sql语句的作用 可以通过视图隐藏敏感信息，比如隐藏员工工资的字段，那么我们可以创建一个视图，其中不包含工资这个字段 创建视图的格式： create view 视图名 as 子查询 create view view_emp_10 as(select * from emp where deptno=10); 创建一个视图view_emp_10 （简单视图） create view view_dep_20 as(select * from EMP where deptno=20 and sal&lt;3000 ); 创建emp表部门是20，工资小于3000的视图 create view view_emp_sum_max(select max(sal),sum(sal),min(sal) from EMP); 复杂视图，只能查看，不能删除修改插入 如何查看视图： 查询的方式和表的查询方式一样(select) 视图分类 简单视图 ： 创建视图的子查询中 不包含去重，函数，聚合，关联查询的视图成为简单视图 简单视图可以实现增删改查 复杂视图 ： 和简单视图相反 复杂视图是能查询 视图数据污染 什么是数据污染： 在视图中插入一条数据，在视图中不显示，但是在原表中显示的数据，称为数据污染 在视图中只要进行insert操作时才会造成数据污染，因为update和delete只能操作视图中存在的数据 如果一旦执行插入语句，但是插入的数据不符合创建视图时的子查询条件，那么就会插入视图中失败，但是会插入到原表中，这个是我们不需要的，这个就叫做视图数据污染。 往视图中插入数据，删除数据，修改数据 简单视图： 删除数据： 如果将视图中的数据删除了，那么原表中的数据也会删除掉 插入数据： 如果插入的数据符合创建视图的子查询的条件，那么就会将数据插入进视图和原表中，如果不符合创建视图时的子查询的条件，那么数据只会插入到原表中，不会插入进视图。 比如上面创建的view_emp_10视图，子查询条件为deptno=10,如果插入视图的数据的的deptno字段为10，那么就会显示在视图和表中，如果不为10，那么只会显示在表中。 更新数据： 如果更新后的数据不符合创建视图时子查询的条件的话，那么这些数据就会移除视图，但是原表中还会显示，只是不在视图中显示。 如果满足子查询的条件，那么就会成功更新在视图中，原表和视图的数据都会更新并且都会显示 比如上面创建的view_emp_10的视图，如果我们将视图中的一条数据的deptno改为11，那么这条数据将不会显示在视图中，只会显示在原表中。 总结： 更新和删除都是对视图中已经存在的数据进行操作，如果存在就会直接删除和更新，并且原表中的数据也会同时被删除和更新，但是如果执行更新操作，更新后的条件不符合创建视图时子查询的条件，那么这些数据将不会显示在视图中，但是在表中还是存在的 插入数据有可能会造成数据污染 避免视图数据污染(with check option) 我们在创建的视图的时候加上with check option 即可 create view v_emp_30 as(select * from EMP where deptno=30) with check option; 现在我们在往v_emp_30的视图中插入数据，其中字段deptno不等于30，那么就会报错，因为不符合创建视图时的子查询条件 但是如果我们没有使用with check option，那么我们就会插入成功，虽然不会在视图中显示，但是插入到原表中了，造成了视图数据污染 修改视图 我们创建一个视图 create view view_emp_10 as(select * from emp where deptno=10); 现在我们需要为子查询加上一个条件 工资大于3000的，即是 创建一张视图，里面数据是部门号为10，工资大于3000的全部员工信息，那么我们就需要在原有的view_emp_10的基础上修改 create or replace view view_emp_10 as(select * from EMP where deptno=10 and sal&gt;3000);直接在create后面加上or replace即可，有就替换 删除视图 格式 ：drop view 视图名称 drop view_emp_10; 删除视图view_emp_10，如果存在就删除，不存在就报错 加上关键字 if exists 如果存在就删除，不存在也不报错 drop view if exists view_emp_10; 如果创建视图的时候对视图中的字段使用了别名，那么以后对视图的操作只能使用别名来操作 create view view_1 as(select ename name from emp where deptno=10); 这里面的子查询将字段ename起了别名，那么我们在以后操作的时候只能使用别名对这个字段操作 案例 创建视图显示每个部门对应的员工的名字 `create view view_emp_dept as(select d.dname,e.ename from EMP e join Dept d on d.deptno=e.deptno); 修改上面的视图在上面题的前提下只显示工资在3000以内的 create or replace view view_emp_dept as(select d.dname,e.ename from EMP e join Dept d on d.deptno=e.deptno where e.sal&lt;3000); 删除上面的视图 drop view if exists v_emp_dept; 索引原理索引概述 什么是索引： 索引是用来提高查询速度的技术，类似于一个目录，查询数据时会从索引中对数据进行定位，然后直接找到数据所在的位置 为什么使用索引 ： 因为不使用索引的话，查询数据会按照磁盘块一块一块的去查，如果数据量很大，效率很低 索引分为聚集索引和非聚集索引 在mysql中数据库会为主键自动创建聚集索引，聚集索引中数据是有序保存 索引内部实现原理 ： B+tree 数据库中创建索引的过程是数据库内部自己控制，然后使用索引的过程也是数据库自己操作的，不需要程序猿干涉 创建索引 格式： create index 索引名 on 表名(字段名([长度])); 创建索引之前先查询title=’100’的数据，看看查询时间 select * from item2 where title=’100’; 创建title索引 create index index_title on item2(title); 再次查询，查看时间 select * from item2 where title=’100’; 查看索引 格式: show index from 表名 其中包含主键的索引，这个是自动创建的 删除索引 格式：drop index 索引名 on 表名 drop index index_title on item2; 索引是越多越好吗？有索引就一定好吗？ 因为索引会占用磁盘空间，所以创建索引需谨慎，只创建查询需求的索引 索引要建立在大量的数据的表中，如果数据量不够大，可能会降低查询效率 复合索引 创建索引的时候指定多个字段，此时如果查询数据正好过滤条件为这多个字段的话，可以降低磁盘块的访问，从而提高查询效率 创建复合索引: create index index_title_price on item2(title,price); 执行查询语句 select * from item2 where title=&#39;100&#39; and price &lt;100000; 可以看出查询效率很高 创建表的时候直接创建索引 create table t_index(id int,age int ,index index index_age(age)); 直接在字段后面写入 index 名字(字段) 总结 索引会占磁盘空间，不是越多越好 数据量小的表不要创建索引 对于经常出现在where ，order by，distinct 后面的字段创建索引 ，效果更好 不要在频繁修改的表中创建索引 约束 什么是约束： 约束就是对表字段的数据进行限制的规则 唯一约束 unique 添加唯一约束的字段，这个字段的值不能重复,否则报错 crate table t(id int ,age int unique); 主键约束 (primary key) 创建表时添加主键约束 create table t(id int primary key auto_increment,age int); 创建表之后添加主键 (primary key(字段名) ) alter table t add primary key(id); 删除主键约束 格式： alter table 表名 drop primary key alter table t drop primary key; 自增约束(auto_increment) 当字段赋的值为null时，字段会自动增长 如果删除了某条数据，自增数值不会减少 自增的基础是根据字段的最大值来自增的 create table t(id int primary key auto_increment,age int); 如果使用delete清空表(delete from t) ,那么自增的值不会从头开始 如果使用truncate table t 的方式清空表，那么自增的值会从头开始，则从1开始 外键约束（foreign key） 外键约束是保证一个表或者两个表之间数据一致性和完整性的约束 工作中除非特殊情况，一般不使用外键约束，通过代码逻辑进行限制，避免测试时不必要的麻烦 外键的值通常是另外一张表的主键 外键可以重复，可以为null，但不能是另外一张表中不存在的数据- 使用外键约束的条件： 必须保证两张表使用相同的引擎(engine) 引擎必须是innodb,myisam不支持外键约束 外键和关联字段必须是相同的数据类型，比如一张表的主键id的外键，那么这个外键一定要是int类型 外键所对应的关联字段如果不是主键，会自动为该字段创建索引 创建外键约束 格式 ： create table t(id int primary key auto_increment,deptid int,constraint 约束名 foregin key(deptid) references 关联的表名(关联表的字段名)) 创建两张表 t_emp 和 t_dept 先创建部门表 create table t_dept(id int primary key auto_increment,name varchar(10)); 创建t_emp create table t_emp(id int primary key auto_increment,name varchar(10),deptid int,constraint fk_dept foreign key(deptid) references t_dept(id)); 测试： 如果插入数据到t_emp中的时候，其中的deptid的值在t_dept中的id不存在的话，那么插入失败，因为两个是外键关联的 如果想要删除t_dept的数据，但是在t_emp中的还有关联的数据(即是deptid)，那么删除失败，只有将t_emp中关联的数据字段deptid设置为null，此时在删除才会成功 外键总结 保证一个表或两个表之间的数据一致性和完整性，工作不怎用，外键的值是关联表的主键，值可以是null可以重复，不能是不存在的数据，使用外键必须两张表使用innodb引擎，数据类型要一致，会自动添加索引 非空约束(not null) 该字段的值不能为null，否则报错 默认约束(default) 给字段设置默认值 create table t(id int primary key auto_increment,age int not null default 0); 设置字段age设置默认值为0 ，如果插入数据的时候没有插入age的值，那么默认赋值为0 check 约束 在mysql中不生效，但是语法不报错 create table t_check(id int,age int,check(age&gt;10)); 什么是事务 事务是数据库执行sql语句的工作单元或者最小单元，写在事务里面的sql要么同时成功，要么同时失败 事务的ACID性质(重要，面试常考) Automicity ： 原子性 ： 执行的sql语句要么同时成功，要么同时失败 Consistency： 一致性 ： 无论事务是否执行成功，必须保证一个一致性的标准，比如转账，必须保证转账前后的总金额不变 Isolation： 隔离性 ： 事务和事务之间互不影响 Durablity ： 持久性 ： 事务执行完之后数据持久保存到数据库中 MySQL事务 show variables lile “%autocommit%” set autocommit=0/1 开启 begin commit rollback savepoint s1 rollback to s1 事务案例 转账]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL操作五]]></title>
      <url>%2F2018%2F03%2F28%2FSQL%E6%93%8D%E4%BD%9C%E4%BA%94%2F</url>
      <content type="text"><![CDATA[Day05关联关系自关联 当前表的数据和当前表里面的数据有关联关系 一对一一对多多对多 学生和老师的关系就是多对多的关系一个学生可以被多个老师教，一个老师可以教多个学生 创建表 创建教师表 teacher(id,name)创建学生表 stu(id,name)创建第三张关系表t_s(sid,t_id) 查询 查询学生小明的所有老师 通过小明查询出小明的id 得到小明的id 在关系表中查询出对应的老师的id 通过关系表中的老师的id再和教师表关联查询查出所有的老师 select name from teacher where id in ( select t_s.tid from stu join t_s on stu.id=t_s.sid where stu.name=&#39;小明&#39;); 子查询方式，但是子查询中使用了内连接，也可以使用等值连接 select t_s.tid from stu join t_s on stu.id=t_s.sid join teacher t on t.id=tid where stu.name=&#39;小明&#39;; 使用内连接的方式查询，多个join连接，where条件语句应该放在最后一个join的on的后面 查询所有老师对应的所有学生0 select t.name t_name,stu.name s_name from stu join t_s on stu.id=t_s.sid join teacher t on t.id=tid; 查询唐僧的所有学生 select t.name t_name,stu.name s_name from stu join t_s on stu.id=t_s.sid join teacher t on t.id=tid where t.name=&#39;唐僧&#39;; 如何让两张表建立关系 自关联 自关联是在一张表中，这张表中要有一个字段记录上级的主键 一对一： 需要在从表中有个字段表示主表的主键值 （外键） 一对多 部门和员工为例，需要在多的一端通过字段记录另外一张的表的主键 （外键） 多对多 需要准备一张关系表，表中保存两张表的主键值（第三张表） （外键） 连接方式和关联关系的区别 连接方式： 包括内连接，等值连接，左/右外连接 是指查询两张表时使用的查询方式 关联关系： 一对一，一对多，多对多 是指两张表之间存在的逻辑关系 数据库设计值权限管理什么是权限管理 不同用户登录网站后可能会有不同的权限，实现此功能的过程称为权限管理 权限管理表的实现 总共需要5张表 用户表 角色表 权限表 用户和角色关系表 角色和权限的关系表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL操作四]]></title>
      <url>%2F2018%2F03%2F26%2FSQL%E6%93%8D%E4%BD%9C%E5%9B%9B%2F</url>
      <content type="text"><![CDATA[Day 04创建数据库和表商城建表语句123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110DROP TABLE IF EXISTS `t_item`;CREATE TABLE `t_item` ( `id` varchar(200) NOT NULL COMMENT '商品id', `category_id` bigint(20) DEFAULT NULL COMMENT '分类id', `item_type` varchar(100) DEFAULT NULL COMMENT '商品系列', `title` varchar(100) DEFAULT NULL COMMENT '商品标题', `sell_point` varchar(150) DEFAULT NULL COMMENT '商品卖点', `price` bigint(20) DEFAULT NULL COMMENT '商品单价', `num` int(10) DEFAULT NULL COMMENT '库存数量', `barcode` varchar(30) DEFAULT NULL COMMENT '条形码', `image` varchar(500) DEFAULT NULL COMMENT '图片路径', `status` int(1) DEFAULT '1' COMMENT '商品状态 1：上架 2：下架 3：删除', `priority` int(10) DEFAULT NULL COMMENT '显示优先级', `created_time` datetime DEFAULT NULL COMMENT '创建时间', `modified_time` datetime DEFAULT NULL COMMENT '最后修改时间', `created_user` varchar(50) DEFAULT NULL COMMENT '创建人', `modified_user` varchar(50) DEFAULT NULL COMMENT '最后修改人', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `t_item` VALUES ('10000000',238,'牛皮纸记事本','广博(GuangBo)10本装40张A5牛皮纸记事本子日记本办公软抄本GBR0731','经典回顾！超值特惠！',23,99999,NULL,'/images/portal/00GuangBo1040A5GBR0731/collect.png',1,53,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000001',238,'牛皮纸记事本','广博(GuangBo)10本装40张A5牛皮纸记事本子日记本办公软抄本GBR0731','经典回顾！超值特惠！',23,99999,NULL,'/images/portal/00GuangBo1040A5GBR0731/collect.png',1,62,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000002',238,'皮面日程本','广博(GuangBo)皮面日程本子 计划记事本效率手册米色FB60322','经典回顾！超值特惠！',46,99999,NULL,'/images/portal/001GuangBo)FB60322/collect.png',1,49,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000021',238,'皮面日程本','广博(GuangBo)皮面日程本子 计划记事本效率手册蓝色FB60321','经典回顾！超值特惠！',22,99999,NULL,'/images/portal/001GuangBo)FB60322/collect.png',1,73,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000003',238,'记事本日记本笔记本','广博(GuangBo)16K115页线圈记事本子日记本文具笔记本图案随机','经典回顾！超值特惠！',13,99999,NULL,'/images/portal/01GuangBo16K115FB60506/collect.png',1,58,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000004',241,'计算器','得力（deli）1548A商务办公桌面计算器 太阳能双电源','经典回顾！超值特惠！',58,99999,NULL,'/images/portal/002calculator1548A/collect.png',1,42,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000005',241,'圆珠笔','施耐德（Schneider） K15 经典款圆珠笔 (5支混色装)','经典回顾！超值特惠！',29,99999,NULL,'/images/portal/03SchneiderK15/collect.png',1,36,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000006',236,'票据网格拉链袋','三木(SUNWOOD) C4523 票据网格拉链袋/文件袋 12个装 颜色随机','经典回顾！超值特惠！',28,99999,NULL,'/images/portal/04_SUNWOODC452312/collect.png',1,53,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000007',163,'燃 7000经典版','戴尔Dell 燃700金色','下单赠12000毫安移动电源',32999,99999,NULL,'/images/portal/11DELLran7000gold/collect.png',1,59,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000008',163,'燃 7000经典版','戴尔Dell 燃700R1605银色','仅上海，广州，沈阳仓有货！预购从速！',4549,99999,NULL,'/images/portal/11DELLran7000R1605Ssilvery/collect.png',1,32,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000009',163,'燃 7000学习版','戴尔Dell 燃700金色','下单赠12000毫安移动电源',39929,99999,NULL,'/images/portal/11DELLran7000gold/collect.png',1,84,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000010',163,'燃 7000学习版','戴尔Dell 燃700R1605银色','仅上海，广州，沈阳仓有货！预购从速！',5559,99999,NULL,'/images/portal/11DELLran7000R1605Ssilvery/collect.png',1,21,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000011',163,'燃 7000高配版','戴尔Dell 燃700金色','下单赠12000毫安移动电源',3994,99999,NULL,'/images/portal/11DELLran7000gold/collect.png',1,56,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000012',163,'燃 7000高配版','戴尔Dell 燃700R1605银色','仅上海，广州，沈阳仓有货！预购从速！',6559,99999,NULL,'/images/portal/11DELLran7000R1605Ssilvery/collect.png',1,16,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000013',238,'A5优品商务笔记本','齐心（COMIX）C5902 A5优品商务笔记本子记事本日记本122张','下单即送10400毫安移动电源！再赠手机魔法盒！',41,99999,NULL,'/images/portal/02COMIXC5902A5122blue/collect.png',1,10,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000014',163,'XPS13-9360','戴尔(DELL)XPS13-9360-R1609 13.3','仅上海，广州，沈阳仓有货！预购从速！',4600,99999,NULL,'/images/portal/12(DELL)XPS13gold/collect.png',1,1,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000015',163,'XPS13-9360','戴尔(DELL)XPS13-9360-R1609 13.3','仅上海，广州，沈阳仓有货！预购从速！',4601,99999,NULL,'/images/portal/12DELLXPS13-silvery/collect.png',1,73,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000016',163,'XPS13-9360','戴尔(DELL)XPS13-9360-R1609 13.3','仅上海，广州，沈阳仓有货！预购从速！',4602,99999,NULL,'/images/portal/12(DELL)XPS13gold/collect.png',1,64,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000017',163,'XPS13-9360','戴尔(DELL)XPS13-9360-R1609 13.3','仅上海，广州，沈阳仓有货！预购从速！',4604,99999,NULL,'/images/portal/12DELLXPS13-silvery/collect.png',1,100,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000018',163,'XPS13-9360','戴尔(DELL)XPS13-9360-R1609 13.3','仅上海，广州，沈阳仓有货！预购从速！',4605,99999,NULL,'/images/portal/12(DELL)XPS13gold/collect.png',1,7,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000019',163,'XPS13-9360','戴尔(DELL)XPS13-9360-R1609 13.3','仅上海，广州，沈阳仓有货！预购从速！',4899,99999,NULL,'/images/portal/12DELLXPS13-silvery/collect.png',1,34,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000020',163,'IdeaPad310低配版','联想（Lenovo）IdeaPad310低配版','清仓！仅北京，武汉仓有货！',5119,99999,NULL,'/images/portal/13LenovoIdeaPad310_black/collect.png',1,50,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000021',163,'IdeaPad310低配版','联想（Lenovo）IdeaPad310低配版','清仓！仅北京，武汉仓有货！',5129,99999,NULL,'/images/portal/13LenovoIdeaPad310_silvery/collect.png',1,48,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000022',163,'IdeaPad310经典版','联想（Lenovo）IdeaPad310经典版','清仓！仅北京，武汉仓有货！',5119,99999,NULL,'/images/portal/13LenovoIdeaPad310_black/collect.png',1,90,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000023',163,'IdeaPad310经典版','联想（Lenovo）IdeaPad310经典版','清仓！仅北京，武汉仓有货！',5129,99999,NULL,'/images/portal/13LenovoIdeaPad310_silvery/collect.png',1,6,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000024',163,'IdeaPad310高配版','联想（Lenovo）IdeaPad310高配版','清仓！仅北京，武汉仓有货！',5119,99999,NULL,'/images/portal/13LenovoIdeaPad310_black/collect.png',1,60,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000025',163,'IdeaPad310高配版','联想（Lenovo）IdeaPad310高配版','清仓！仅北京，武汉仓有货！',5129,99999,NULL,'/images/portal/13LenovoIdeaPad310_silvery/collect.png',1,80,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000026',163,'YOGA710','联想（Lenovo）YOGA710 14英寸触控笔记本（i7-7500U 8G 256GSSD 2G独显 全高清IPS 360°翻转 正版office）金','【0元献礼】好评过万，销量传奇！经典蓝光电视，独有自然光技术专利，过大年带最好的回家！【0元白条试用，1001个拜年计划】',59999,99999,NULL,'/images/portal/14LenovoYOGA710 _gold/collect.png',1,19,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000027',163,'YOGA710','联想（Lenovo）YOGA710 14英寸触控笔记本（i7-7500U 8G 256GSSD 2G独显 全高清IPS 360°翻转 正版office）银','【0元献礼】好评过万，销量传奇！经典蓝光电视，独有自然光技术专利，过大年带最好的回家！【0元白条试用，1001个拜年计划】',59999,99999,NULL,'/images/portal/14LenovoYOGA710 _silvery/collect.png',1,55,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000028',163,'310低配版','联想（Lenovo）小新310低配版','清仓！仅北京，武汉仓有货！',4939,99999,NULL,'/images/portal/15Lenovo_xiaoxin_310_black/collect.png',1,19,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000029',163,'310低配版','联想（Lenovo）小新310低配版','清仓！仅北京，武汉仓有货！',4839,99999,NULL,'/images/portal/15Lenovo_xiaoxin_310_silvery/collect.png',1,27,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000030',163,'310经典版','联想（Lenovo）小新310经典版','清仓！仅北京，武汉仓有货！',4739,99999,NULL,'/images/portal/15Lenovo_xiaoxin_310_black/collect.png',1,78,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000031',163,'310经典版','联想（Lenovo）小新310经典版','清仓！仅北京，武汉仓有货！',4639,99999,NULL,'/images/portal/15Lenovo_xiaoxin_310_silvery/collect.png',1,9,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000032',163,'310高配版','联想（Lenovo）小新310高配版','清仓！仅北京，武汉仓有货！',4539,99999,NULL,'/images/portal/15Lenovo_xiaoxin_310_black/collect.png',1,9,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000033',163,'310高配版','联想（Lenovo）小新310高配版','清仓！仅北京，武汉仓有货！',4439,99999,NULL,'/images/portal/15Lenovo_xiaoxin_310_silvery/collect.png',1,18,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000034',163,'YOGA900','联想（Lenovo）YOGA900绿色','青春的活力 清新漂亮高端大气上档次',5200,99999,NULL,'/images/portal/16LenovoYOGA900green/collect.png',1,63,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000035',163,'YOGA900','联想（Lenovo）YOGA900粉色','青春的活力 清新漂亮高端大气上档次',5200,99999,NULL,'/images/portal/16LenovoYOGA900pink/collect.png',1,62,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000036',163,'YOGA900','联想（Lenovo）YOGA900红色','青春的活力 清新漂亮高端大气上档次',5200,99999,NULL,'/images/portal/16LenovoYOGA900red/collect.png',1,21,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000037',163,'小新13旗舰版','联想(Lenovo)小新Air13 Pro 13.3英寸14.8mm超轻薄笔记本电脑','青春的活力 青年专属',6439,99999,NULL,'/images/portal/17Lenovo)xiaoxinAir13Pro_gold/collect.png',1,16,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000038',163,'小新13旗舰版','联想(Lenovo)小新Air13 Pro 13.3英寸14.8mm超轻薄笔记本电脑','青春的活力 青年专属',6439,99999,NULL,'/images/portal/17Lenovo)xiaoxinAir13Pro_silvery/collect.png',1,17,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000039',163,'XPS15','戴尔(DELL) XPS15 银色','限时特价！好评过万条优秀产品！',3333,99999,NULL,'/images/portal/18(DELL)XPS15_silvery/collect.png',1,37,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000391',163,'XPS15','戴尔(DELL) XPS15 金色','限时特价！好评过万条优秀产品！',3333,99999,NULL,'/images/portal/18(DELL)XPS15_silvery/collect.png',1,81,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000040',163,'DELL 15MF Pro','戴尔(DELL)魔方15MF Pro-R2505TSS灵越','15.6英寸二合一翻转笔记本电脑 (i5-7200U 8GB 1TB IPS Win10)触控银',4443,99999,NULL,'/images/portal/19DELL15MF Pro/collect.png',1,35,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000401',163,'DELL 15MF Pro','戴尔(DELL)魔方15MF Pro-R2505TSS灵越','15.6英寸二合一翻转笔记本电脑 (i5-7200U 8GB 1TB IPS Win10)触控白',4443,99999,NULL,'/images/portal/19DELL15MF Pro/collect.png',1,86,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000402',163,'DELL 15MF Pro','戴尔(DELL)魔方15MF Pro-R2505TSS灵越','15.6英寸二合一翻转笔记本电脑 (i7-7200U 8GB 512GB IPS Win10)触控银',6443,99999,NULL,'/images/portal/19DELL15MF Pro/collect.png',1,84,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000403',163,'DELL 15MF Pro','戴尔(DELL)魔方15MF Pro-R2505TSS灵越','15.6英寸二合一翻转笔记本电脑 (i7-7200U 8GB 512GB IPS Win10)触控白',6443,99999,NULL,'/images/portal/19DELL15MF Pro/collect.png',1,63,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000041',163,'DELL XPS15-9550','戴尔(DELL) XPS15升级版 ','15.6英寸二合一翻转笔记本电脑 (i5-7200U 8GB 1TGB IPS Win10)触控',8443,99999,NULL,'/images/portal/20DellXPS15-9550/collect.png',1,61,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000411',163,'DELL XPS15-9550','戴尔(DELL) XPS15升级版 ','15.6英寸二合一翻转笔记本电脑 (i5-7200U 8GB 256GB IPS Win10)触控',8443,99999,NULL,'/images/portal/20DellXPS15-9550/collect.png',1,60,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000412',163,'DELL XPS15-9550','戴尔(DELL) XPS15升级版 ','15.6英寸二合一翻转笔记本电脑 (i7-7200U 8GB 1TB IPS Win10)触控',8443,99999,NULL,'/images/portal/20DellXPS15-9550/collect.png',1,13,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000413',163,'DELL XPS15-9550','戴尔(DELL) XPS15升级版 ','15.6英寸二合一翻转笔记本电脑 (i7-7200U 8GB 256GB IPS Win10)触控',8443,99999,NULL,'/images/portal/20DellXPS15-9550/collect.png',1,83,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000042',163,'ThinkPad New s1','联想ThinkPad New S2（01CD） i5 6代 红色','经典回顾！超值特惠！',4399,99999,NULL,'/images/portal/21ThinkPad_New_S1/collect.png',1,99,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000421',163,'ThinkPad New s1','联想ThinkPad New S2（01CD） i7 6700 红','经典回顾！超值特惠！',6399,99999,NULL,'/images/portal/21ThinkPad_New_S1/collect.png',1,74,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000422',163,'ThinkPad New s1','联想ThinkPad New S2（01CD） i5 6代 黄','经典回顾！超值特惠！',4399,99999,NULL,'/images/portal/21ThinkPad_New_S1/collect.png',1,23,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000424',163,'ThinkPad New s1','联想ThinkPad New S2（01CD） i5 6代 蓝','经典回顾！超值特惠！',4399,99999,NULL,'/images/portal/21ThinkPad_New_S1/collect.png',1,87,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('100000425',163,'ThinkPad New s1','联想ThinkPad New S2（01CD） i7 6700 蓝','经典回顾！超值特惠！',6399,99999,NULL,'/images/portal/21ThinkPad_New_S1/collect.png',1,59,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000043',917,'书包 bag','乐尚书包 电脑包 bag黑色','给你满载而归的喜悦！',89,99999,NULL,'/images/portal/22_LEXON_LNE6025B06T/collect.png',1,12,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin'),('10000044',917,'书包 bag','乐尚书包 电脑包 bag粉色','给你满载而归的喜悦！',89,99999,NULL,'/images/portal/22_LEXON_LNE6025B06T/collect.png',1,62,'2017-10-25 15:08:55','2017-10-25 15:08:55','admin','admin');DROP TABLE IF EXISTS `t_item_category`;CREATE TABLE `t_item_category` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键', `parent_id` bigint(20) DEFAULT NULL COMMENT '父分类id', `name` varchar(150) DEFAULT NULL COMMENT '名称', `status` int(1) DEFAULT '1' COMMENT '状态 1：正常 2：删除', `sort_order` int(4) DEFAULT NULL COMMENT '排序号', `is_parent` tinyint(1) DEFAULT NULL COMMENT '是否是父分类 1：是 0：否', `created_time` datetime DEFAULT NULL COMMENT '创建时间', `modified_time` datetime DEFAULT NULL COMMENT '最后修改时间', `created_user` varchar(50) DEFAULT NULL COMMENT '创建人', `modified_user` varchar(50) DEFAULT NULL COMMENT '最后修改人', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1183 DEFAULT CHARSET=utf8;INSERT INTO `t_item_category` VALUES (163,162,'笔记本',1,1,0,'2017-10-25 15:00:55','2017-10-25 15:00:55','admin','admin'),(236,229,'文件管理',1,7,0,'2017-10-25 15:00:55','2017-10-25 15:00:55','admin','admin'),(238,229,'本册/便签',1,9,0,'2017-10-25 15:00:55','2017-10-25 15:00:55','admin','admin'),(241,229,'笔类',1,12,0,'2017-10-25 15:00:55','2017-10-25 15:00:55','admin','admin'),(917,913,'双肩包',1,4,0,'2017-10-25 15:00:55','2017-10-25 15:00:55','admin','admin'); 员工建表语句12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152create table EMP(EMPNO int(4) primary key,ENAME varchar(10) not null,JOB varchar(9),MGR int(4),HIREdate date,SAL double(7,2),COMM double(7,2),DEPTNO int(4));create table Dept(DEPTNO int(4) primary key,DNAME varchar(14) not null unique,LOC varchar(13)); insert into Dept VALUES (10,'ACCOUNTING','NEW YORK');insert into Dept VALUES (20,'RESEARCH','DALLAS');insert into Dept VALUES (30,'SALES','CHICAGO');insert into Dept VALUES (40,'OPERATIONS','BOSTON');SELECT * FROM DEPT;insert into EMP VALUES(7369,'SMITH','CLERK',7902,str_to_date('17-12-1980','%d-%m-%Y'),800,null,20);insert into EMP VALUES(7499,'ALLEN','SALESMAN',7698,str_to_date('20-2-1981','%d-%m-%Y'),1600,300,30);insert into EMP VALUES(7521,'WARD','SALESMAN',7698,str_to_date('22-2-1981','%d-%m-%Y'),1250,500,30);insert into EMP VALUES(7566,'JONES','MANAGER',7839,str_to_date('2-4-1981','%d-%m-%Y'),2975,NULL,20);insert into EMP VALUES(7654,'MARTIN','SALESMAN',7698,str_to_date('28-9-1981','%d-%m-%Y'),1250,1400,30);insert into EMP VALUES(7698,'BLAKE','MANAGER',7839,str_to_date('1-5-1981','%d-%m-%Y'),2850,NULL,30);insert into EMP VALUES(7782,'CLARK','MANAGER',7839,str_to_date('9-6-1981','%d-%m-%Y'),2450,NULL,10);insert into EMP VALUES(7839,'KING','PRESIDENT',NULL,str_to_date('17-11-1981','%d-%m-%Y'),5000,NULL,10);insert into EMP VALUES(7844,'TURNER','SALESMAN',7698,str_to_date('8-9-1981','%d-%m-%Y'),1500,0,30);insert into EMP VALUES(7900,'JAMES','CLERK',7698,str_to_date('3-12-1981','%d-%m-%Y'),950,NULL,30);insert into EMP VALUES(7902,'FORD','ANALYST',7566,str_to_date('3-12-1981','%d-%m-%Y'),3000,NULL,20);insert into EMP VALUES(7934,'MILLER','CLERK',7782,str_to_date('23-1-1982','%d-%m-%Y'),1300,NULL,10);commit; group by 分组查询 通常和聚合函数结合使用通常查询每个部门(性别/分类) 就以部门(性别/分类)为分组条件group by语句的位置可以对多个字段进行分组格式:select 字段 from 表名 where 条件 group by 分组字段 having 聚合函数条件 order by 字段 limit n,m 分页 查询emp表中每个部门的编号(deptno)，人数，工资总和 最后根据人数进行升序排序，如果人数一致，根据工资总和降序排列 select deptno,count(*) c,sum(sal) s from emp group by deptno order by c asc,s desc; 查询工资平均在1000-3000之间的员工信息，每个部门的编号，平均工资，最低工资，最高工资，根据平均工资进行升序排列 select deptno,avg(sal) a,min(sal),max(sal) from emp where sal between 1000 and 3000 group by deptno order by a; 查询含有上级领导的员工，每个职业的人数，工资的总和，平均工资，最低工资，最后根据人数进行降序排列，如果人数一致，根据平均工资进行升序排列 select count(*) c,sum(sal),avg(sal) a,min(sal) from emp where mgr is not null group by job order by c desc,a asc; 每个部门中，每个主管的手下人数（两个分组，使用逗号即可） select deptno,mgr ,count(*)from emp where mgr is not null group by deptno,mgr; 每种工作的平均工资 select job,avg(sal) from emp group by job; 每年的入职人数 其中hiredate的格式是2015-01-02(%Y-%m-%d),因此这里需要用到日期截取的函数extract()，具体使用参看SQL操作三 select extract(year from hiredate) year,count(*) from emp group by y; having子句 聚合函数不可以对where结合使用 select deptno,avg(sal) a from emp where a&gt;2000 group by deptno; 这句话是错误的，因为avg(sal)是聚合函数，不能和where结合使用 having中也是可以使用普通字段的过滤，不一定是聚合函数，但是聚合函数的过滤只能使用having，但是建议写在where条件语句中 对聚合函数的结构进行条件过滤要使用having having语句要写在group by 后面 select from where group by having order by limit 查询每个部门中平均工资，只显示平均工资大于2000的 select deptno,avg(sal) a from emp group by deptno having a&gt;2000; 查询所有分类商品所对应的库存总量中，高于1000的总量 这个就是查询每一种商品的库存(group by ) ，库存高于1000(having) select category_id, sum(num) sum from t_item group by category_id having sum&gt;1000; 查询所有分类商品所对应的平均单价中，低于1000的均价 select category_id, avg(price) avg from t_item group by category_id having avg&lt;100; 查询编号238和编号917分类商品的平均单价 这里没有查询编号就是category_id的值，没有涉及到聚合函数，因此可以使用where条件进行过滤 &gt; select category_id, avg(price) avg from t_item where category_id in(238,917) group by category_id ; 虽然没有涉及到聚合函数，但是我们也是可以使用having子句进行过滤（不建议） select category_id, avg(price) avg from t_item group by category_id having category_id in(238,917); 查询emp中，每个部门的平均工资高于2000的部门的编号，部门的人数，平均人数，平均工资，最后根据平均工资进行升序排列 select avg(sal) avg,deptno,count(*) from emp group by deptno having avg&gt;2000 order by avg; 查询emp表中名字中不是以k开头的信息，每个部门的最低工资高于1000的部门的编号，工资总和，平均工资以及最低工资，最后根据平均工资进行升序排列 select deptno,sum(sal) sum,avg(sal) avg,min(sal) min from emp where ename not like &#39;k%&#39; group by deptno having min&gt;1000 order by avg; 查询emp表中部门编号是10,30号部门的员工，每个职业的最高工资低于5000的职业的名称，人数，平均工资，最高工资，最后根据人数进行升序排列，如果人数一致，根据最高工资进行降序排列 select max(sal) max,job,avg(sal) avg,count(*) c from emp where deptno in(10,30) group by job having avg&lt;5000 order by c asc,max desc; 查询emp表中，每个部门的编号，人数，工资总和，最高工资以及最低工资，过滤掉最高工资是5000的部门，根据部门的人数进行升序排列，如果人数一致，则根据最高工资进行降序排列。 select deptno,count(*) c,sum(sal) sum,max(sal) max,min(sal) min from emp group by deptno having max !=5000 order by c asc,max desc; 查询emp表中工资在1000~3000之间的员工信息，每个部门的编号，工资总和，平均工资，过滤掉平均工资低于2000的部门，按照平均工资进行升序排列 select deptno,sum(sal) sum,avg(sal) avg from emp where sal between 1000 and 3000 group by deptno having avg &gt;=2000 order by avg; 查询emp表中名字不是以‘S’开头，每个职位的名字，人数，工资总和，最高工资，过滤掉工资是3000的职位，根据人数进行升序排列，如果人数一致，根据工资总和进行降序排列。 select job,count(*) c,sum(sal) sum,max(sal) max from emp where ename not like &#39;s%&#39;and sal !=3000 group by job order by c asc,sum desc; 查询emp表的信息，每个职位的名称，人数，平均工资，最低工资，过滤掉平均工资是3000的职位信息，根据人数进行降序排列，如果人数一致，根据平均工资进行升序排列 select job,count(*) c,avg(sal) avg,min(sal) min from emp group by job having avg !=3000 order by c desc,avg asc; 子查询Mysql子查询 子查询 ： 嵌套到sql语句里面的查询sql语句称为”子查询” 子查询中返回的字段一定要和查询的判断条件字段类型一致，否则没有意义，比如 ： 这里的最高员工工资，那么子查询返回的一定是一个字段并且这个字段是最高的工资。当然子查询中也是可以返回多个值，那么此时需要使用in关键字判断 如果子查询中返回的是一个值，比如最大工资，那么我们可以使用 = &gt; &lt; !=如果子查询中返回的是一组值，那么我们就不能使用 = 或者 != 我们可以使用in关键字 查询工资最高的员工的所有信息 子查询中返回的是最高工资 select * from emp where sal=(select max(sal) from emp); 工资多于平均工资的员工信息 子查询中返回的是平均工资 select * from emp where sal &gt; (select avg(sal) from emp); 最后入职的员工信息 子查询中返回的是最后入职的日期 select * from emp where hiredate=(select max(hiredate) from emp); 查询出有商品的分类信息 子查询中返回的是t_item中不重复的category_id的值，这个就是在t_item_category中的id，因此我们只需要将t_item_category中的id值在t_item中的信息查询出来即可、 由于子查询中可能返回的不是一个值，而是一组值，因此使用in select * from t_item_category where id in(select category_id from t_item where category_id is not null); 查询工资高于20号部门最高工资的员工的所有信息 select * from emp where sal&gt;(select max(sal) from emp where deptno=20); 查询emp表中姓名是‘KING’所属的部门的编号，名称 emp表中存放的是员工信息，dept表中存放的是部门信息，emp表中的deptno对应的dept表中的deptno(相当于外键) 子查询是返回的emp表中ename为king的部门编号 select deptno,dname from dept where deptno = (select distinct deptno from emp where ename=&#39;king&#39;); 查询部门名称是SALES的部门下所有员工的编号，姓名，职位，以及所属部门的编号 emp和dept表是以deptno关联的 select empno,ename,job,deptno from emp where deptno=(select deptno from dept where dname=&quot;sales&quot;); 查询部门地址是DALLAS的部门下所有员工的所有信息 仍然是emp和dept的查询 select * from emp where deptno in (select deptno from dept where loc=&#39;dallas&#39;); 查询跟JONES同样工作的员工的所有信息（包含JONES） select * from emp where job=(select job from emp where ename=&#39;jones&#39;); 查询跟JONES同样工作的员工的所有信息（不包含JONES） where句中可以包含子查询，也可以包含其他的条件，使用and或者or select * from emp where job=(select job from emp where ename=&#39;jones&#39;) and ename!=&#39;jones&#39;; 查询部门平均工资最高的部门详情 复杂写法： (select * from t) new 这个可以当做一个新表进行查询，也是一种嵌套查询123456select * from dept where deptno in (select deptno from (select max(a),deptno from (select avg(sal) a,deptno from emp group by deptno)new)n);``` - 简单写法 - 查询每个部门的deptno，然后对平均工资进行降序排序，之后取其中的第一条数据，那么就是平均工资最大的。```sql select * from dept where deptno=(select deptno from emp group by deptno order by avg(sal) desc limit 0,1); 查询所有分类产品商品库存总量最大的分类详情 简单写法1select * from t_item_category where id =(select category_id from t_item group by category_id order by sum(num) desc limit 0,1); 总结 子查询可以写在where后面作为查询条件 可以写在from后面作为一张新表，作为新表时必须起别名 select * from (select * from t_item where title like &#39;%广博%&#39; limit 0,10) newtable; 上面的select子句中返回的字段就是新表newtable的字段 可以把子查询写在创建表的时候、 select table t_item_new as (select title,price from t_item from t_item where price&gt;1000) 子查询可以嵌套n层 关联查询 同时查询多张表信息中的字段同时查询多张表的字段的时候，一定要指定关联关系，否则就会出现笛卡尔积的错误，比如外键关联，emp和dept表中的deptno是对应字段的关系（相当于外键） 查看每个员工的名字以及所在部门的名字 select ename,dname from emp,dept where emp.deptno=dept.deptno; 查询在new york 工作的员工 select ename from emp,dept where dept.loc=&#39;new york&#39; and emp.deptno=dept.deptno; 查看工资高于3000的员工，名字，工资，部门名，所在地 这里的关联关系依然是两张表中都有deptno字段 select ename,sal,dname,loc from emp,dept where emp.deptno=dept.deptno and sal&gt;3000; 笛卡尔积 笛卡尔积通常是一种错误的查询结果笛卡尔积是在不谢关联关系的情况下，查询出来的两张表的乘积 查看每个员工的名字以及所在部门的名字 select ename,dname from emp,dept where emp.deptno=dept.deptno; 上面的sql语句如果没写where中的子句，那么就会出现笛卡尔积的错误，因为没有设置关联关系 等值连接/内连接等值连接 select * from A,B where A.x=B.x and age&gt;18; 内连接 select * from A [inner] join B on A.x=B.x where age&gt;18; 查询在new york 工作的员工 select * from emp e join dept d on e.deptno=d.deptno where d.loc=&#39;new york&#39;; 查看工资高于3000的员工，名字，工资，部门名，所在地 select ename ,sal,dname,loc from emp e join dept d on e.deptno=d.deptno where sal&gt;3000; 总结 等值连接和内连接只能查询有关联关系的数据，如果其中的数据没有关联关系，那么没有关联关系的数据查询不出来 左外连接 两张表中其中有数据没有关联关系，那么使用等值连接和内连接就查询不出来，因此需要使用左外连接查询结构以左边的表为主，内容全部显示，左边的只是显示有关系的 select * from emp e left join dept d on e.deptno=d.deptno; 右外连接 两张表中其中有数据没有关联关系，那么使用等值连接和内连接就查询不出来，因此需要使用左外连接查询结构以右边的表为主，内容全部显示，左边的只是显示有关系的 select * from emp e right join dept d on e.deptno=d.deptno; 案例 查询出所有可以匹配的商品分类及商品数据 select c.name , t.* from t_item t,t_item_category c where t.category_id=c.id; 等值连接 select t.* ,c.name from t_item t join t_item_category c on t.category_id = c.id; 内连接 查询出所有的分类,以及与之匹配的商品 这里侧重于查询分类，如果某一个分类中没有商品，那么使用等值连接和内连接就会导致查询不到所有的分类，因此这里可以使用左外连接或者右外连接，以分类所在的表(t_item_category)为主 select c.name,t.* from t_item_category c left join t_item t on t.category_id=c.id; 左外连接 select c.name,t.* from t_item t right join t_item_category c on t.category_id=c.id; 右外连接 查询出所有的商品,以及与之匹配的分类 这里侧重于所有的商品，如果其中某一件商品与分类没有关联关系，即是没有指定分类，那么我们使用等值连接或者内连接就会查询不到这件商品，我们可以使用左外连接或者右外连接 商品类(t_item) 分类（t_item_category） select t.title,c.name from t_item t left join t_item_category c on c.id=t.category_id; 左外连接 select t.title,c.name from t_item_category c right join t_item t on c.id=t.category_id; 右外连接 每个部门的人数,根据人数排序 select deptno count(*) c from emp group by deptno order by c; 每个部门中，每个主管的手下人数 select deptno,mgr,count(*) from emp group by deptno,mgr; 每种工作的平均工资 select job,avg(sal) avg from emp group by job; 每年的入职人数 select extract(year from hiredate) year, count(*) from emp group by year; 少于等于3个人的部门 select deptno, count(*) c from emp group by deptno having c&lt;=3; 拿最低工资的员工信息 select * from emp having sal=min(sal); (不推荐) select * from emp having sal=(select min(sal) from emp); 只有一个下属的主管信息 select e.* from emp e join (select count(*) c ,mgr from emp group by mgr having c=1)newtable on newtable.mgr=e.empno; 平均工资最高的部门编号 select deptno from emp group by deptno order by avg(sal) desc limit 0,1 下属人数最多的人，查询其个人信息 先分组查询出所有的主管的信息，然后根据人数降序排列，最后取出第一条就是数据就是下属人数最多的主管 select * from emp group by mgr order by count(*) desc limit 0,1; 拿最低工资的人的信息 select * from emp where sal=(select min(sal) from emp); 最后入职的员工信息 select * from emp where hiredate=(select max(hiredate) from emp); 工资多于平均工资的员工信息 select * from emp where sal&gt;(select avg(sal) from emp); 查询员工信息，部门名称 select e.*,d.dname from emp e join dept d on e.deptno=d.deptno; 员工信息，部门名称，所在城市 select e.*,d.dname,d.loc from emp e join dept d on e.deptno=d.deptno; DALLAS 市所有的员工信息 select e.* from emp e join dept d on e.deptno=d.deptno where d.loc=&#39;DALLAS&#39;; 按城市分组，计算每个城市的员工数量 select loc ,count(*) from (select e.*,d.dname,d.loc from emp e join dept d on e.deptno=d.deptno) newtable group by newtable.loc; select d.loc,count(*) from emp e join dept d on e.deptno=d.deptno group by loc; 查询员工信息和他的主管姓名 员工信息和主管姓名在同一张表中，我们可以抽离出主管编号mgr和ename组成一张新表，那么我们就可以使用关联查询了 select e.*,n.ename &#39;主管名字&#39; from emp e join (select mgr,ename from emp) n on e.empno=n.mgr; 或者我们可以不抽离字段，而是直接整个当做一张新表 select e.*,n.ename mgrname from emp e join emp n on e.empno=n.mgr; 员工信息，员工主管名字，部门名 直接join（可以连接多张表）,直接在后面join即可 select e.*,n.ename mgrname,dname from emp e join emp n on e.empno=n.mgr join dept d on e.deptno=d.deptno; 把上面的查询结果当成一张新表，和dept内连接即可 select new.*,d.dname from (select e.*,n.ename mgrname from emp e join emp n on e.empno=n.mgr) new join dept d on new.deptno=d.deptno; 总结 如果涉及到两张表，甚至多张表，想要查询某张表的所有信息，此时就需要使用左/右外连接，因为如果某条数据没有关联关系，那么使用等值连接或者内连接将会缺失没有关联关系的数据。 如果涉及到多张表的时候，使用内连接可以连接多张表，直接在后面添加join即可，比如 select e.*,n.ename mgrname,dname from emp e join emp n on e.empno=n.mgr join dept d on e.deptno=d.deptno; 分组(group by)是对前面查询到的结果进行分组，因此在where条件语句后，也是在内连接之后，因为必须查询到完整的一张表才能进行分组 推荐使用内连接，不使用等值连接 使用内连接的时候，where条件语句一定要放在 on的后面，即使是多个内连接(多个join)，也必须放在最后一个join的on的后面，不影响结果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL操作三]]></title>
      <url>%2F2018%2F03%2F24%2FSQL%E6%93%8D%E4%BD%9C%E4%B8%89%2F</url>
      <content type="text"><![CDATA[Day03查询null 查询列值为null (is null) select * from emp where mgr is null; 查询上级领导为空的员工 查询列值不为null (is not null) select * from emp where mgr is not null and comm&gt;0; 别名 如果表中的字段名称太长或者不是很容易直接看懂，那么我们可以使用别名，使用的方式有三种： select ename &quot;姓名&quot; from emp; select ename as &quot;姓名&quot; from emp; select ename 姓名 from emp; 去除重复的值(distinct) select distinct job from emp; where 条件语句支持的运算符： &gt; &lt; = != &gt;= &lt;= !=(&lt;&gt;) and 和 or and 并且 多个条件属于与的关系or 或者 select * from user where id=1 or id=2; 查询id=1的数据或者id=2的数据 ,如果这两个都存在，那么将会全部返回 like _ 代表单个未知字符 第二个字母为a : _a% 倒数第三个字母为a ：%a__ % 代表多个未知字符 以a开头的 : a% 以a结尾的 ：%a 包含a :%a% select * from user where name like &#39;_加%&#39;; select * from user where name like &#39;_加_&#39;; 此时匹配的名字是三个字符，比如 陈加兵 not like (不包含) select * from user where name not like &#39;_加%&#39;; between … and (在..之间) 在两个数之间select * from t_item where price between 10 and 100; 查询价格在10 到 100之间的数据 in (查询的值为多个) 查询某个字段的值为多个值的时候使用inselect * from t_item where price in(100,200,233); order by 升序（默认 asc） -select price from t_item order by price order by 写在后面，如果有where条件，那么要写在where条件的后面 select price from t_item where price&lt;100 order by price; 降序（desc） select price from t_item order by price desc 如果需要多个字段进行排序，则在by的后面写多个字段 select category_id,price from t_item order by category_id,price desc; 按照分类id升序，价格降序 查询带燃字的商品，按照价格降序排列 select title,price from t_item where title like &quot;%燃%&quot; order by price; 分页 limit 子句 limit n,m ： n表示跳过的条数，m表示每页显示的条数 写在排序（order by 字句）的后面，如果没有排序写在where后面 limit 0,5 查询第一页，每页显示5条 limit 10,5 查询第三页，每页显示5条 limit 12,3 查询第五页 每页3条 select price from t_item order by price limit 10,10; 按照价格升序排列，显示第二页，每页10条 select price from t_item where price &lt;100 limit 0,10; 查询价格小于100的记录，显示第一页，每页10条 concat() 函数 concat()函数可以实现多个字符串的拼接 在终端直接输入 select concat(&#39;a&#39;,&#39;b&#39;); select concat(price,&quot;元&quot;) from t_item limit 0,3; 查询商品，并且将查询到的价格和元这个单位拼接。相当于显示的是价格只是每个价格后面添加了单位 比如： 23元 将标题和单价拼到一起进行展现 select concat(price,&quot;元&quot;,title) from t_item limit 0,5; 数值运算 支持加减乘除，取余(%)等效mod(n,m) 查询商品并在结果中显示商品的总价值 select price,num ,price*num &#39;总价&#39; from t_item; 直接做运算即可，可以使用别名解释字段的含义 日期相关函数 获取当前时间+时间 now() 在终端输入select now(); 获取当前日期 curdate() 获取当前时间 curtime() 测试 select now(),curdate(),curtime(); 从日期和时间中获取日期 date(now()) 从日期和时间中获取时间 time(now()) extract() 提取年月日时分秒的函数 select extract(year from now()); select extract(month from now()); select extract(day from now()); select extract(hour from now()); select extract(minute from now()); select extract(second from now()); DATE_FORMATE() 函数 日期格式化 format %Y 4位年 2018 %y 2位 18 %m 月 05 %c 月 5 %d 日 %H 24小时制 %i 分 %s 秒 测试 select date_format(now(),&#39;%Y年%m月%d日 %h时%i分%s秒&#39;); 输出 2018年03月23日 03时44分51秒 查询商品 并显示商品上传日期 select title,date_format(created_time,&#39;%Y年%m月%d日 %h时%i分%s秒&#39;) from t_item; str_to_date 把字符串转成日期格式 将’2018年10月22日’ 转换成日期 select str_to_date(&quot;2018年10月23日&quot;,&#39;%Y年%m月%d日&#39;); 第一个参数是即将要转换的字符串日期，第二个参数是这个字符串日期的格式，用来解析这个字符串。 输出： 2018-10-23 IFNULL() 函数 age=ifnull(a,b) 如果a是null，age=b，如果不是null，age=a; 把奖金是null 设置成0 update emp set comm=ifnull(comm,0); 如果奖金comm是null，那么comm=0，如果不是空 comm=comm，还是原来的值 聚合函数 对多行数据进行合并统计 sum() 求和 select sum(num) from t_item where price&lt;100; avg() ： 求平均值 select avg(price) from t_item; count() 计算数量 select count(*) from t_item where price&lt;100; max() 最大值 select max(price) from t_item; min() 最小值 select min(price) from t_item; 测试 查询DELL的平均单价 select avg(price) &quot;平均单价&quot; from t_item where title like &quot;%DELL%&quot;; 字符串的函数 char_length(str) instr(str,substr) locate(substr,str) insert(str,start,end,newStr) lower(str) upper(str) left(str,count) right(str,count) trim(str) substring(str,index) substring(str,index,length); repeat(str,count) replace(str,old,new) reverse() 数学相关函数 floor(num) round(num) round(num,m) truncate(num,m)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL操作二]]></title>
      <url>%2F2018%2F03%2F22%2FSQL%E6%93%8D%E4%BD%9C%E4%BA%8C%2F</url>
      <content type="text"><![CDATA[Day02乱码问题 1.数据库字符集 要设置成utf8 表的字符集 设置为utf8 windows系统的命令行里，有些版本是gbk的编码格式，可以通过set names gbk；的方式把mysql接收到数据是的解码格式设置为gbk，这个位置的gbk和数据库还有表的utf8没有关系 在windows系统中修改mysql默认的数据库编码，找到安装文件中的my.ini的配置文件 在里面添加时如下代码：character-set-server=utf8 eclipse 下写sql配置 下载mysql驱动jar包 window -&gt; show view -&gt; other -&gt; Data Management -&gt; Data source(open) / SQL Results(open) 找到控制台的Data source explor中，然后点击DataBaseConnetctions -&gt; new 选择Mysql 点击下拉箭头右面的加号 选择5.1 点击jarList clearAll 点击add jar 在弹出窗口中找到下载的jar文件 然后ok8.修改URL 只需要修改最后面的database即可，这个是选择需要操作的数据库 输入密码，save password 点击test connection 如果显示ping Successd则点击finish 在 Database Connections下的New MySQL 右键 选择 type中选择mysql5.1 Name中选Neq Mysql Database中选择database 在最右侧如果显示connected，那么可以开始写sql语句 自定义代码块 点击windows -&gt; 搜索 templates -&gt; 选择SQL下editor下的templates -&gt; New（新建） 约束主键(primary key) 主键特点 ： 非空 唯一CREATE TABLE user(id int PRIMARY KEY,age int); 自增(auto_increment) 一般和主键一起使用create table t5(id int primary key auto_increment,name varchar(10));如果设置了自增长，那么在插入数据的时候主键可以不设置值。也可以赋值为null，数据库会自动为这个主键赋值(在原来的基础上自增+1) 非空(not null) create table user(id int primary key,age int not null); 注释 直接使用comment来添加字段注释即可create table t6(id int comment &#39;用户的id&#39;,age int comment &#39;用户的年龄&#39;); 事务 数据库中sql语句执行的最小单元 不能分割执行事务内的sql语句，只能是同时执行成功，或者同时执行失败，否则可能出现安全性问题 一个事务中的代码块包含多条sql语句，只有一起执行成功才能成功，只要有一条出现错误都会失败,因为开启事务的话，每操作的一条语句产生的结果都是存储在内存中的，没有及时更新到数据库中，只有提交之后才能更新到数据库中 关闭自动提交 mysql的自动提交属性自动是开启的，就是每执行一次sql语句就会自动提交，如果需要使用事务功能，那么需要将其关闭，因为一旦提交了，数据就会发生改变，但是事务的功能就是当所有的sql语句都执行完才提交，因此要将其关闭。 显示自动提交的状态 show variables like &#39;%autocommit%&#39;; 显示为on表示开启的 关闭自动提交 set autocommit=0; 此时再次查询状态就会显示OFF 再次开启自动提交 set autocommit=1 开启自动提交，此时查看就实现为on 验证 创建表，插入数据 123CREATE TABLE USR(id int primary key auto_increment,name varchar(10),money int);INSERT INTO user values(NULL,'超人',200),(NULL,'蝙蝠侠',205); 关闭自动提交 让超人的钱+100 update user set money=300 where id=1 打开另外一个窗口登录mysql，可以查看此时的超人看看钱是不是300，我们可以看到此时的数据并没有改变，因为我们关闭了自动提交，如果我们此时在原来窗口输入 commit;,那么在看看另外的登录窗口就会发现数据改变了。 回滚(rollback) 当你之前的操作没有提交的话，那么你使用rollback这个命令，那么就会回滚到初始状态 回滚点(savepoint) 前提是没有设置了自动提交，才能回滚到保存点savepint s1(标识); ： 设置保存点回滚到保存点，那么保存点之前的操作都是存在的，一旦提交之后就会执行保存点之前的操作。 rollback to s1; 总结 当将自动提交设置为关闭状态，当改变数据库的内容时，只要手动提交输入 commit;，才能更新到数据库中，否则就只是在内存中改变了。 begin 起始点 savepoint s(标识) 设置回滚点 commit 提交 rollback 回滚 rollback to … 回滚到指定的回滚点 SQL分类数据库定义语言 DDL Data Definition Language 数据库定义语言 常见命令： create drop alter truncate 这些命令不支持事务，就是没有提交也会生效 数据操纵语言 DML Data Manipulation Language :数据操作语言 常见命令： insert update delete select 支持事务，可以回滚，不提交将不会生效 数据查询语言 DQL Data Query Language : 数据查询语言 常见命令： select（也属于DML） TCL Transaction Control Language ： 事务控制语言 常见命令： begin commit rollback savepoint DCL Data Control Language : 数据控制语言 给用户分配权限相关的sql语言 数据类型 整数 int 4字节 bigint 8字节 浮点数 double(m,d): m代表数据的总长度，d表示小数点后面的位数 decimal(m,d): m代表数据的总长度，d表示小数点后面的位数 double精度比float高，decimal精度比double高 字符串类型 char(n) : 固定长度，即是存了abc也是占满了n长度 执行效率高 总长255 varchar(n) : 可变长度 存abc 占3个长度 节省空间 最大长度65535，但是超过255建议使用text text(n) : 可变长度 最大65535 日期类型 date : 只能存储年月日 time ： 只能存储时分秒 datetime ： 年月日时分秒 默认值为null 最大值9999-12-31 timestamp ： 年月日时分秒 默认值是当前时间 最大值2038-01-19 创建表插入数据：123create table p(d1 date, d2 time,d3 datetime,d4 timestamp); insert into p values('2018-03-08',null,null.null); insert into p values('2018-03-08','12:06:03',null,null);]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL操作一]]></title>
      <url>%2F2018%2F03%2F21%2FSQL%E6%93%8D%E4%BD%9C%E4%B8%80%2F</url>
      <content type="text"><![CDATA[Day01-基本的语句数据库简介 因为传统的文本形式存储数据存在很多的弊端： 执行效率低 占用内存 什么是DB Database ： 数据库数据库本质是文件集（多个文件）会按照特定存储规范进行数据增删改查 什么是DBMS DateBaseManagementSystem : 数据库管理系统，本质就是管理数据库文件的软件 Oracle Mysql DB2 Sqlite SqlServer 数据库分类 关系型数据库 是经过数学理论验证过，可以保存现实生活中任何关系的数据库（其中的高级映射，比如一对多，多对一，一对一都是关系） 关系数据库是以表为单位进行存储的 Oracle mysql DB2 sqlite sqlserver都是关系型数据库 非关系型数据库 Redis数据库是非关系型数据库 以key-value形式进行存储 主流关系型数据库介绍 Mysql ： 开源 卖服务赚钱 被sun公司收购 sun被oracle收购 5.5版本因为oracle技术大牛对其进行升级，性能大幅提升，Mysql 从6.0开始收费，导致原来的mysql工程师跳槽创建了MariaDB,MariaDB内部实际上就是mysql，创建者的女儿叫Maria Oracle 闭源 卖产品 支持windows，Linux DB2 闭源 大型数据库 通常是国字头的企业在用 sqlite 轻量级数据库，大小几十k，应用于移动或者嵌入式设备 SQLServer 微软公司 闭源 主要.net开发的网站中 mysql安装 端口号3306编码格式 utf8 数据库相关SQL什么是SQL Strctured Query Language ： 结构化查询语言通过sql语言和DBMS（数据库管理软件）进行交互 连接数据库 终端中输入： mysql -u root -p输入密码即可,没有密码直接回车即可 数据库操作 create database d_name ; 创建数据库d_namedrop database d_name; 删除数据库d_nameshow databases; 显示所有的数据库show create database d_name; 查看单个数据库use d_name; 使用当前的数据库d_namecreate database db_name character set utf8;创建数据库指定字符集 表相关SQL什么是表 表是数据库中存放数据的单元，任何数据都是存放到表中类似java中的Class，表中的字段对应class的属性 数据库表的引擎 innoDB : 支持数据库的高级操作，包括事务 主键 外键等myisam : 只具备基本的数据库储功能 创建表时指定引擎和字符集 格式 ：create table t_name(字段名 字段类型,....) engine=myisam charset=utf8; 创建表 格式: create table 表名(字段名 类型,字段名 类型,......);例子： create table name(id int,name char(10),age int);执行原理： 当在中断输入建表语句 终端会把写好的sql发送给DBMS，然后解析到create table时，识别出要创建一个表。 查询所有表 show tables ; 查询单个表 show create table tale_name;使用上面的语句会出现创建表的语句和字符编码 查看表的字段属性 desc table_name ; 修改表修改表的名称 格式 : rename table 原名 to 新名rename table user to t_user; 修改表的属性（引擎和字符集） 格式 ：alter table 表名 engine-innoDB charset=utf8;alter table t engine=InnoDB charset=GBK; 添加表字段 在最后添加 格式 ： alter table 表名 add 字段名 字段类型;alter table t add age int; 在最前添加 格式： alter table 表名 add 字段名 字段类型 first;alter table t add newage int first; 在某个字段后面添加 格式： alter table 表名 add 字段名 字段类型 after 字段名;alter table t add birthday varchar(10) after id; 修改字段名和类型 alter table 表名 change 原字段名 新字段名 新的字段类型 ;alter table t change birthday bth Date; 修改字段类型和位置 alter table 表名 modify 字段名 类型 位置（first/after 字段名）;alter table t modify name int after age; 将name移到age的后面，并且修改了name字段的类型为int alter table t modify name varchar(10) first; 将字段name移到最前面 删除字段 alter table 表名 drop 字段名;alter table t drop bth; 将t表中的bth字段删除 删除表 格式 ： drop table 表名 ; 数据相关的SQL(CRUD)插入语句 全表插入 格式 insert into 表名 values(value1,value2,…)格式要求: values里面的值的数量和顺序必须要和表的字段一致insert into user values(1,&#39;jack&#39;,22); 指定字段插入 格式： insert into 表名(字段1,字段2,..) values(value1，value2,….)insert into user(id,name,age) values(1,&#39;jack&#39;,22);格式要求： values中的值必须和前面格式的字段一致。 插入多组数据 格式： insert into values(第一组数据),(第二组数据)….insert into user values(1,&quot;孙悟空&quot;,22),(2,&quot;唐僧&quot;,44); 指定字段插入多组数据 insert into user(age) values(22),(33); 查询语句 查询所有字段 格式：select * from 表名select * from user; 查询指定字段 格式：select 字段1,字段2 from 表名select name.age from user; 更新语句 更新表中所有的字段 格式： update 表名 set 字段名 = 新的值;update user set age=22; 改变指定条件的字段 格式： update 表名 set 字段名 = 新的值 where 条件;update user set age=22 where id=1; 修改id=1的那一行数据的age 删除语句 指定条件删除 格式： delete from 表名 where 条件 ;delet from user where id=2; 删除id=2的那一行数据 不指定条件删除，那么将会删除整张表数据 delete from user; TRUNCATE语句 trucate table 表名; 先删除表，然后再创建一样的空表（表的名字相同，字段不变，主要的功能就是清空表中的数据）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Excel表格的写入读取]]></title>
      <url>%2F2017%2F09%2F27%2FExcel%E8%A1%A8%E6%A0%BC%E7%9A%84%E5%86%99%E5%85%A5%E8%AF%BB%E5%8F%96%2F</url>
      <content type="text"><![CDATA[Excel的读取和写入准备 首先需要导入jar包，请点击这里下载 简介 我们知道Excel表格在2007之后就不一样了，后缀名变为xlsx，之前的后缀名为xls,因此读取和写入的操作就对应着不同的方式，但是只是读取和写入的类不同了，思想还是一样的。 我们要知道一个Excel文件(工作簿)包含三部分，分别是工作表(sheet),行(row),列(cell) 工作簿 工作簿对应的类是 XSSFWorkbook(2007之后),在2007之前对应的类是HSSFWorkbook 构造方法 new XSSFWorkbook() 创建一个工作簿用于写入文件 new XSSFWorkbook(java.io.InputStream inputstream) 创建一个工作簿，用于读取文件 常用的方法 XSSFFont createFont() 返回一个XSSFont类的对象，主要用于设置字体用的 XSSFSheet createSheet() 创建一个工作表 XSSFSheet createSheet(String name) 创建一个工作表并且指定姓名 XSSFCellStyle createCellStyle() 创建一个单元格风格类的一个对象，便于设置单元格的属性 write(OutputStream out) 用于将文件写入到文件中 close() setSheetName(int sheetIx,String name) 为指定索引的工作表设置名称 XSSFSheet getSheetAt(int index) 获取指定索引的工作表对象，这个是用来读取文件的时候用的 例子读取文件的例子12345 File file = new File("F:\\demo1.xlsx");//创建输入流FileInputStream inputStream = new FileInputStream(file);//创建工作簿读取XSSFWorkbook workbook = new XSSFWorkbook(inputStream); 写入文件的例子12345678910XSSFWorkbook book=new XSSFWorkbook(); //创建工作簿.....省略写入的内容FileOutputStream out=new FileOutputStream("D:\\demo1.xlsx"); //创建输出流book.write(out); //写入到指定的文件book.close(); // 关闭out.close(); 工作表(sheet) 工作表对应的类为XSSFSheet,2007之前对应的是HSSFSheet一般工作表都是在工作簿基础上创建的，因此构造函数也用不到，所以这里就不多说了 常用方法 int addMergedRegion(CellRangeAddress region) 合并单元格 XSSFRow createRow(int rownum) 创建一个行 rownum表示创建第几行，这是一个行的索引(0开始) 便于写入 XSSFRow getRow(int index) 获取指定索引的那一行，便于读取 int getLastRowNum() 获取文件中最后一行的索引，这个通常在读取的时候用到 int getFirsetRowNum() 获取文件第一行的索引 例子合并单元格1234567// 创建工作簿对象 XSSFWorkbook workbook = new HSSFWorkbook(); XSSFSheet sheet = workbook.createSheet("第一张表"); //创建工作表对象 //合并单元格 CellRangeAddress cell=new CellRangeAddress(int firstRow, int lastRow, int firstCol, int lastCol) //这里表示合并第一行的1-10列 sheet.addMergedRegion(new CellRangeAddress(0, 0, 0, 10)); 创建一行123XSSFWorkbook workbook = new HSSFWorkbook();XSSFSheet sheet = workbook.createSheet("第一张表"); //创建工作表对象XSSFRow row=sheet.createRow(0); //创建第一行 行 行对应的类为XSFFRow,2007之前对应的是HSSFRow 常用的方法 XSSFCell createCell(int columnIndex) 创建一列 columnIndex表示列的索引(0开始) short getFirstCellNum() 返回文件中第一个列的索引，便于以后读取 short getLastCellNum() 返回全部的列数(不是索引)，这个和Sheet中getRowNum()方法不同，便于以后读取文件 XSSFCell getCell(int cellnum) 获取指定索引的那一列，便于以后的读取 XSSCellStyle getCellStyle() 获取单元格风格的对象 void setCellStyle(XSSFCellStyle style) 将设置的风格样式添加到单元格中，否则将不会起作用 列 列对应的类为XSSFCell,2007之前对应的是HSSFCell 常用的单元格类型 常用的单元格的类型有字符串，数字，布尔值，空值，可以使用XSSFCell的int getCellType() 方法获取类型 CELL_TYPE_BLANK 空值 CELL_TYPE_STRING 字符串 CELL_TYPE_NUMERIC 数字(浮点值，整型) CELL_TYPE_BOOLEAN 布尔值(True,FALSE) 常用的方法 int getCellType()获取单元格类型 可以和常用的单元格类型进行比较，然后使用不同的读取方法读取 XSSFCellStyle getCellStyle() 获取单元格风格对象，便于后面设置单元格的风格 setCellValue(Object value) 设置单元格的内容，可以是任意类型的 java.util.Date getDateCellValue() 读取单元格的日期内容 String getStringCellValue() 读取单元格中的字符串内容 double getNumericCellValue() 读取单元格中的数字类型的内容 boolean getBooleanCellValue() 获取单元格中的布尔类型的内容 设置单元格样式 对应的类为XSSFCellStyle 常用的方法 void setAlignment(HorizontalAlignment align) 设置水平对齐方式 void setVerticalAlignment(VerticalAlignment align) 设置垂直的对齐方式 void setTopBorderColor(XSSFColor color) 设置上边框的颜色(还有Left,right..) void setFont(Font font) 设置字体 这里的Font是org.apache.poi.ss.usermodel.Font void setBorderTop(BorderStyle border) 设置上边框的样式，在BorderStyle类中有很多的样式 void setRotation(short rotation) 设置文字的旋转度数 单元格字体的设置 对应的类为XSSFFont 常用的方法: void setBold(boolean bold) 是否设置加粗 void setItalic(boolean italic) 设置是否倾斜 void setUnderline(FontUnderline underline) 设置下划线 void setStrikeout(boolean strikeout) 设置是否带有删除线 void setColor(XSSFColor color) 设置字体的颜色,只需要调用XSSFColor静态颜色变量即可 void setFontHeight(double height) 设置字体高度 void setFontHeightInPoints(short height) 设置字号 void setFontName(java.lang.String name) 设置字体样式(黑体，楷体…) 写入文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.awt.Color;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import org.apache.poi.hssf.util.HSSFColor;import org.apache.poi.ss.usermodel.FontUnderline;import org.apache.poi.ss.usermodel.HorizontalAlignment;import org.apache.poi.ss.usermodel.VerticalAlignment;import org.apache.poi.ss.util.CellRangeAddress;import org.apache.poi.xssf.usermodel.XSSFCell;import org.apache.poi.xssf.usermodel.XSSFCellStyle;import org.apache.poi.xssf.usermodel.XSSFColor;import org.apache.poi.xssf.usermodel.XSSFFont;import org.apache.poi.xssf.usermodel.XSSFRow;import org.apache.poi.xssf.usermodel.XSSFSheet;import org.apache.poi.xssf.usermodel.XSSFWorkbook;public class TestDemo &#123; public static void main(String[] args) throws IOException &#123; XSSFWorkbook workbook = new XSSFWorkbook(); // 创建工作簿 XSSFSheet sheet = workbook.createSheet("第一个工作表"); // 创建一个工作表 XSSFCellStyle style = workbook.createCellStyle(); // 创建单元格风格对象 sheet.addMergedRegion(new CellRangeAddress(0, 0, 0, 10)); // 合并第一行的单元格 style.setAlignment(HorizontalAlignment.CENTER); // 设置水平居中 style.setVerticalAlignment(VerticalAlignment.CENTER); // 设置垂直居中 XSSFFont font = workbook.createFont(); // 创建字体的对象 font.setFontName("黑体"); // 设置字体的样式为黑体 font.setFontHeightInPoints((short) 20); // 设置字体的大小 font.setBold(true); // 设置粗体 font.setItalic(true); // 设置倾斜 font.setColor(HSSFColor.RED.index); // 设置字体的颜色 font.setUnderline(FontUnderline.SINGLE); // 设置下划线 font.setStrikeout(false); // 设置不带下划线 style.setFont(font); // 将设置的字体添加到单元格样式中，显示出来 XSSFRow row1 = sheet.createRow(0); // 创建第一个行 XSSFCell cell1 = row1.createCell(0); // 创建第一行的第一列 cell1.setCellStyle(style); // 将上面定义的风格设置到这个单元格中，这个是必须有的，否则根本不起作用 cell1.setCellValue("员工信息表"); // 设置单元格的内容 // 设置第二行的前三列的值 XSSFRow row2 = sheet.createRow(1); row2.createCell(0).setCellValue("姓名"); row2.createCell(1).setCellValue("性别"); row2.createCell(2).setCellValue("年龄"); // 设置第三行的前三列 XSSFRow row3 = sheet.createRow(2); row3.createCell(0).setCellValue("陈加兵"); row3.createCell(1).setCellValue("男"); row3.createCell(2).setCellValue(22); // 设置数字 // 设置第四行的前三列 XSSFRow row4 = sheet.createRow(3); row4.createCell(0).setCellValue("郑元梅"); row4.createCell(1).setCellValue("女"); row4.createCell(2).setCellValue(22); // 设置数字 // 创建输出流对象 FileOutputStream stream = new FileOutputStream(new File( "F:\\demo2.xlsx")); workbook.write(stream); // 写入文件 workbook.close(); // 关闭 stream.close(); &#125;&#125; 写入文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.IOException;import org.apache.poi.xssf.usermodel.XSSFCell;import org.apache.poi.xssf.usermodel.XSSFRow;import org.apache.poi.xssf.usermodel.XSSFSheet;import org.apache.poi.xssf.usermodel.XSSFWorkbook;public class TestDemo1 &#123; public static void main(String[] args) throws IOException &#123; File file = new File("F:\\demo2.xlsx"); FileInputStream inputStream = new FileInputStream(file); // 创建输入流 XSSFWorkbook workbook = new XSSFWorkbook(inputStream); // 创建读取工作簿的对象 XSSFSheet sheet = workbook.getSheetAt(0); // 获取第一个工作表的对象 // 第一次循环取得所有的行的对象 getLastRowNum()是得到最后一行的索引 for (int i = 0; i &lt;= sheet.getLastRowNum(); i++) &#123; XSSFRow row = sheet.getRow(i); // 获取每一行的对象 for (int j = 0; j &lt; row.getLastCellNum(); j++) &#123; XSSFCell cell = row.getCell(j); // 获取每一行的每一列 int type = cell.getCellType(); // 获取每一个单元格对应的类型 switch (type) &#123; case XSSFCell.CELL_TYPE_BOOLEAN: //如果是布尔类型 boolean b=cell.getBooleanCellValue(); System.out.print(b + " "); break; case XSSFCell.CELL_TYPE_NUMERIC: //如果是数字类型 double d=cell.getNumericCellValue(); //获取值 System.out.print( d+ " "); break; case XSSFCell.CELL_TYPE_STRING: //如果是字符串类型的 String s=cell.getStringCellValue(); System.out.print( s+ " "); case XSSFCell.CELL_TYPE_BLANK: //如果是空值 System.out.print(" "); default: break; &#125; &#125; System.out.println(); &#125; workbook.close(); //关闭 inputStream.close(); &#125;&#125; 参考文章 POI文档 http://lsieun.blog.51cto.com/9210464/1836601]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSP总结四(EL表达式)]]></title>
      <url>%2F2017%2F09%2F26%2FJSP%E6%80%BB%E7%BB%93%E5%9B%9B-EL%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[JSP总结四(EL表达式)简介 JSP页面尽量不要使用scriptlet编写java代码，因此我们可以使用EL表达式可以替代Java语句的使用 隐含对象与属性相关的隐含对象 属性的隐含对象有PageScope,requestScope,sessionScope,applicationScope分别对应的是JSP中的PageContext,request,session,application，因此可以取得JSP对象使用setAttribute()设置的属性，如果没有使用EL隐含对象获取属性的值，那么默认是从PageScope开始寻找 1234567891011&lt;% request.setAttribute("login",'true'); //绑定request对象的属性 session.setAttribute("login",'true'); //绑定session对象的属性 application.setAttribute("login","true"); //设置application对象的属性%&gt;&lt;%--获取request绑定的属性值 相当于request.getAttribute("login");--%&gt;&lt;h1&gt;$&#123;requestScope.login&#125;&lt;h1&gt;&lt;%--获取session绑定的属性值--%&gt;&lt;h1&gt;$&#123;sessionScope.login&#125;&lt;h1&gt; 与请求参数相关的隐含对象(param,paramValues) 与请求参数相关的EL隐含对象有param,paramValues。我们可以使用EL表达式可以获取表单提交的请求参数。 下面我们使用表单提交，测试一下 JSP代码(表单提交) 12345678910&lt;form action="demo1.jsp" method="get"&gt; 姓名:&lt;input type="text" name="username"&gt; 密码:&lt;input type="password" name="password"&gt; &lt;input type="submit" value="提交"&gt; 爱好: 打棒球：&lt;input type="checkbox" name="hobbies"&gt; 打羽毛球：&lt;input type="checkbox" name="hobbies"&gt; &lt;/form&gt; demo1.jsp 文件（接收请求参数） 1234567891011121314&lt;%--获取提交的请求参数username，password 相当于使用如下代码: request.getParameter("username"); request.getParameter("password");--%&gt;&lt;h1&gt;$&#123;param.username&#125;&lt;/h1&gt;&lt;h1&gt;$&#123;param.password&#125;&lt;/h1&gt;&lt;%--获取多选框的值 相当于使用下面的代码: request.getParameterValues("hobbies")[0]--%&gt;&lt;h1&gt;$&#123;paramValues.hobbies[0]&#125;&lt;/h1&gt;&lt;h1&gt;$&#123;paramValues.hobbies[1]&#125;&lt;/h1&gt; 与标头(Header)相关的隐含对象 如果想要取得用户请求的表头数据，那么使用header或者headerValues隐含对象。例如使用${header[&quot;User-Agent&quot;]} 这个相当于使用&lt;%=request.getHeader(&quot;User-Agent&quot;)%&gt;。 HeaderValues对象相当于使用request.getHeaders() cookie隐含对象 cookie的隐含对象可以取得用户设置的Cookie设置的值。如果在Cookie中设置了username属性，那么可以使用${cookie.username} 初始参数隐含对象 隐含对象initParam可以用来取得web.xml中设置的ServletContext初始参数，也就是在&lt;context-param&gt;中设置的初始参数。例如${initParam.initcount}的作用，相当于&lt;%=ServletContext.getInitParameter(&quot;initCount&quot;)%&gt; EL运算符 使用EL运算符直接实现一些算术运算符，逻辑运算符，就如同一般常见的程序语言中的运算 算术运算符 可以直接使用加减乘除 ${1+2},${5/2},${5*3} 逻辑运算符 ${true and false}=false,${true and true}=true,${true or false}=true 关系运算符 可以直接在EL表达式比较大小，返回的也是false和true，可以用来判断，如下：${1&lt;2}=false ,${(10*10)&gt;200}=true 1234&lt;c:if text="$&#123;6&gt;5&#125;"&gt; &lt;c:out value="可以直接使用EL表达式进行比较"&gt;&lt;/c:out&gt;&lt;/c:if&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSP总结三(JSTL核心标签库的使用)]]></title>
      <url>%2F2017%2F09%2F22%2FJSP%E6%80%BB%E7%BB%93%E4%B8%89-JSTL%E6%A0%B8%E5%BF%83%E6%A0%87%E7%AD%BE%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[JSP总结三(JSTL核心标签库的使用)简介 其实在我们编写JSP网页的时候是不希望在JSP页面中出现Java代码的，这里我们就要使用JSTL的核心标签库来实现。 想要使用JSTL，一定要填上这句话：&lt;%@taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot;%&gt; 属性处理与输出标签属性处理标签 在定义变量的时候，我们难免会用到Java代码，但是这里我们介绍&lt;c:set&gt;标签，这个能够实现变量的定义 &lt;c:set&gt;标签中的属性有 var(定义的变量)、value(变量的值)、target(为JavaBean对象赋值的时候使用)、scope(设置变量的存活范围，有request,session,application,page)、property(JavaBean的变量) 使用set标签相当于调用存活范围内的setAttribute()方法来绑定属性 定义一个普通的变量: 123&lt;%--x的值为10，这句话相当于String x="10" --%&gt;&lt;c:set var="x" value="10"&gt;&lt;/c:set&gt; 定义session范围的变量(当然还可以定义其他存活范围的变量，这里就不一一讲了) 123456789&lt;%--seesion范围的变量代表整个会话期间都是可以共享这个变量的，相当于下面这句话： session.setAttribute("x",100); 在另外一个JSP文件中可以使用下面的语句得到其中的值： session.getAttribute("x"); &lt;c:out value="$&#123;sessionScope.x&#125;"&gt;&lt;/c:out&gt;--%&gt;&lt;c:set var="x" value="100" scope="session"&gt;&lt;/c:set&gt; 设置JavaBean对象的值： 12345678&lt;%--获取JavaBean的对象person,如果没有那么就是直接创建一个对象，范围为session,下面可以用到 --%&gt;&lt;jsp:useBean id="person" class="com.Person" scope="session"&gt;&lt;/jsp:useBean&gt;&lt;%-- target是对象的person，这里使用EL表达式，得到session范围内的Person对象 --%&gt;&lt;c:set target="$&#123;sessionScope.person &#125;" property="username" value="陈加兵"&gt;&lt;/c:set&gt;&lt;%-- 输出变量的username的值，这里使用的EL表达式 相当于 session.getAttribute("person").getUsername() --%&gt;&lt;c:out value="$&#123;sessionScope.person.username &#125;"&gt;&lt;/c:out&gt; 如果设置的值太冗长了，那么可以在标签体的中间设置 1&lt;c:set scope="request"&gt;陈加兵&lt;/c:set&gt; 移除变量 使用的是&lt;c:remove&gt;(一定要指定存活范围) 1234&lt;%--移除session范围内的变量x 相当于 session.removeAttribute("x") 这里一定要指定范围--%&gt;&lt;c:remove var="x" scope="session"/&gt; 输出标签 &lt;c:out&gt;相当于out.println()方法，是一个用来向网页中输出内容的 其中的属性有value (输出的内容，其中可以是JEL的${}或者一个字符串) ，escapeXml(这个使用来控制是否将输出的内容中有html标签的是否用替代字符替换，默认为true表示用替代字符替换),default(如果输出的内容为null或者为空的时候那么就直接不显示任何内容，但是我们可以定义default的值来默认显示的值) 使用EL表达式输出 123&lt;%--输出request范围内的属性x 相当于 out.println(request.getAttribute("x"))--%&gt;&lt;c:out value="$&#123;requestScope.x&#125;"&gt;&lt;/c:out&gt; 直接使用字符串输出一个值 12&lt;c:out value="我是陈加兵"&gt;&lt;/c:out&gt; 输出html语句 123&lt;%--设置escapeXml为false--%&gt;&lt;c:out value="&lt;h1&gt;我是陈加兵&lt;/h1&gt;" escapeXml="false"&gt;&lt;/c:out&gt; 指定输出的默认的内容 123&lt;%--如果$&#123;param.username&#125;为空，那么就输出0--%&gt;&lt;c:out value="$&#123;param.username&#125;" default="0"&gt;&lt;/c:out&gt; 流程处理标签 流程处理就是判断，循环语句 if判断语句 &lt;c:if&gt;可以判断语句是否正确，如果正确即可执行，但是这个标签没有else语句，只能处理判断为正确的结果其中的属性有test，这个是设置判断条件的，如果为true即可执行，反之不执行，var是保留判断结果的test中的判断条件既可以是EL表达式也可以是&lt;%=%&gt; 1234567 &lt;c:set var="salary" value="$&#123;3000 &#125;"&gt;&lt;/c:set&gt;&lt;%-- test中写的是判断条件，如果为true那么才执行，这里写的是EL表达式，当然也是可以用&lt;%=%&gt; --%&gt; &lt;c:if test="$&#123;salary&gt;2000 &#125;"&gt; &lt;c:out value="这个员工的工资大于2000"&gt;&lt;/c:out&gt;&lt;/c:if&gt; 高级判断 前面的说过的&lt;c:if&gt;仅仅当判断为真时才执行，但是我们想要当不为真时也执行语句，这时我们要使用&lt;c:choose&gt;,&lt;c:when&gt;,&lt;c:otherwise&gt; 123456789101112131415161718 &lt;%-- 判断题必须在choose中 --%&gt;&lt;c:choose&gt; &lt;%-- 如果提交的username和password都对的话，那么就登录成功 相当于if --%&gt; &lt;c:when test='$&#123;param.username=="陈加兵" &amp;&amp; param.password=="123456"&#125;'&gt; &lt;h1&gt; &lt;c:out value="$&#123;param.username &#125;"&gt;&lt;/c:out&gt; 登录成功 &lt;/h1&gt; &lt;/c:when&gt; &lt;%-- 相当于else --%&gt; &lt;c:otherwise&gt; &lt;h1&gt; &lt;c:out value="$&#123;param.username &#125;"&gt;&lt;/c:out&gt; 登录失败 &lt;/h1&gt; &lt;/c:otherwise&gt;&lt;/c:choose&gt; 网页导入和重定向标签网页导入标签 之前学过JSP中的网页导入，一个是静态导入，一个是动态导入，详情请看上篇文章。 在JSTL中也有一个标签(&lt;c:import&gt;)，用于动态导入网页,并且还可以使用&lt;c:param&gt;设置传入的参数 12345 &lt;%-- url就是要导入的网页，name是设置初始值的变量，value是设置的值。在demo1.jsp中可以使用 request.getParameter(String name)取得参数 --%&gt;&lt;c:import url="demo1.jsp"&gt; &lt;c:param name="username" value="陈加兵"&gt;&lt;/c:param&gt; &lt;c:param name="password" value="123456"&gt;&lt;/c:param&gt;&lt;/c:import&gt; 除了导入web应用程序中的网页，我们还可以导入非目前web应用程序中的网页 12&lt;%--导入百度的首页，并且设置字符集为utf-8，注意这里一定要设置网页的字符集格式和当前的jsp格式一样，否则会出现乱码--%&gt;&lt;c:import url="http://www.baidu.com"&gt;&lt;/c:import charEncoding="utf-8"&gt; 重定向标签 之前的重定向必须使用HttpServletResponse的sendRedirect()方法 现在我们可以使用JSTL标签&lt;c:redirect url&gt; 1&lt;c:redirect url="demo1.jsp"&gt;&lt;/c:rediect&gt; 当然我们也是可以传入参数的，使用&lt;c:param name=&quot;&quot; value=&quot;&quot;&gt; 123&lt;c:redirect url="demo1.jsp"&gt; &lt;c:param name="username" value="陈加兵"/&gt;&lt;/c:rediect&gt; 错误处理标签 在之前的JSP文件中，必须定义errorPage属性才能跳转到指定的页面或者处理错误 现在我们使用JSTL标签&lt;c:catch&gt;,可以捕捉异常，如果有异常就会将异常对象保存下来 1234567891011 &lt;%--捕捉异常，如果有了异常，那么保存在error变量中 --%&gt;&lt;c:catch var="error"&gt; $&#123;10/0 &#125;&lt;/c:catch&gt;&lt;%-- 如果捕捉到了异常，那么error就不是null --%&gt;&lt;c:if test="$&#123;error!=null &#125;"&gt; &lt;h1&gt; &lt;c:out value="$&#123;error.message &#125;"&gt;&lt;/c:out&gt; &lt;/h1&gt;&lt;/c:if&gt; 迭代标签 迭代标签用于数组，集合，列表的输出。 forEach forEach既可以循环也可以迭代 属性 var 变量，用于输出 items 将要迭代的对象 valueStatus 迭代的状态 begin 如果指定了bengin，就在items下标为begin的位置进行迭代 end 如果指定了end，那么就在items下表为end的位置结束迭代 step 指定迭代的步长，默认的是1 实例12345678910111213141516171819202122232425262728 &lt;!-- 循环输出[0,8]之中的所有的整数 --&gt; &lt;c:forEach var="item" begin="0" end="8"&gt; &lt;c:out value="$&#123;item&#125;"&gt;&lt;/c:out&gt; &lt;/c:forEach&gt; &lt;br&gt; &lt;!-- 循环输出[0,8]之中的所有的整数 ,指定步长为2--&gt; &lt;c:forEach var="item" begin="0" end="8" step="2"&gt; &lt;c:out value="$&#123;item&#125;"&gt;&lt;/c:out&gt; &lt;/c:forEach&gt;&lt;% List list=new ArrayList(); for(int i=0;i&lt;3;i++)&#123; list.add(i); &#125; request.setAttribute("items", list);%&gt;&lt;!-- item是创建的变量用来存储迭代中的值，items是迭代的对象，其中的值使用EL表达式给出 --&gt;&lt;c:forEach var="item" items="$&#123;requestScope.items &#125;"&gt; &lt;c:out value="$&#123;item &#125;"&gt;&lt;/c:out&gt;&lt;/c:forEach&gt; forTokens 用于将一个字符串按照定义的符号分隔出来。 属性 var 变量，用于输出 items 将要迭代的string对象 delims 指定分隔字符串的分隔符，可以定义多个分隔符 varStatus 迭代的状态 begin end step 实例12345678&lt;% String str="c,v,d,s,a|v,d"; request.setAttribute("str",str);%&gt;&lt;c:forTokens var="item" items="$&#123;requestScope.str &#125;" delims=",|"&gt; &lt;c:out value="$&#123;item &#125;"&gt;&lt;/c:out&gt;&lt;/c:forTokens&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSP总结二(动作元素)]]></title>
      <url>%2F2017%2F09%2F20%2FJSP%E6%80%BB%E7%BB%93%E4%BA%8C-%E5%8A%A8%E4%BD%9C%E5%85%83%E7%B4%A0%2F</url>
      <content type="text"><![CDATA[JSP总结二(动作元素)&lt;jsp:include&gt; 前面介绍了一种指令元素include，那是一种静态包含JSP文件，这个标签是动态包含一个JSP页面，也就是被包含的JSP页面和原JSP将合并在一起，转译为一个Servlet类。这是有一定的局限性的，如变量的定义不能重复。 动态的包含JSP文件即是被包含的JSP和原JSP分别转译为一个Servlet类，这就保证了其中的变量可以重复定义了，因为并不是在一个类中了 &lt;jsp:include page=&quot;相对的文件路径&quot;&gt;&lt;/jsp:include&gt;这种标签转译为Servlet和指令元素include是一样的 123456&lt;%--动态导入在编译的时候是两个jsp文件各自编译成一个Servlet文件，因此其中的变量是不可以共享的，在当前页面中还是可以定义导入页面定义的变量 --%&gt;&lt;jsp:include page="form.jsp"&gt; //定义的param可以在form.jsp中使用request.getParameter(String name)取得其中的值 &lt;jsp:param value="陈加兵" name="username"/&gt; &lt;jsp:param value="123456" name="password"/&gt;&lt;/jsp:include&gt; &lt;jsp:forward&gt; 这是将请求转发给另外一个JSP或者Servlet文件处理，这个和RequestDispatcher是一样的原理，就是Servlet中转发123456//绑定属性，在login.jsp中可以获取request.setAttribute("username","陈加兵");//当前页面的请求将会交给login.jsp文件处理&lt;jsp:forward page='login.jsp'&gt;&lt;/jsp:forward&gt; &lt;jsp:useBean&gt; 这个动作元素是用来搭配JavaBean组件的标准标签。JavaBean必须满足下面的条件： 必须实现Java.io.Serializable接口 没有公开的(public)类变量 具有无参构造函数（默认的都有） 具有公开的设置方法（setter）与取值方法（getter） 下面就是一个JavaBean组件 12345678910111213141516171819202122232425262728293031323334353637383940package com;import java.io.Serializable;public class Person implements Serializable &#123; //这里的变量的值一定要和表单的中的name属性的值一样，否则不能获取 private String username; private String password; private int age; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Boolean Checkout()&#123; return "陈加兵".equals(username)&amp;&amp;"123456".equals(password); &#125;&#125; 使用JavaBean的目的是减少Scriptlet的使用。其中搭配&lt;jsp:useBean&gt;来使用这个JavaBean,并且使用&lt;jsp:setProperty&gt;与&lt;jsp:getProperty&gt;对javaBean进行设值与取值 注意javaBean一定要搭配表单使用，因为设值的值其实是隐式的调用request.getParameter(String name)来获取表单的值 下面是一个登录的表单(注意这里的input中的name属性的值一定要和JavaBean组件类的成员变量的名字一样) 123456789101112131415161718192021&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--提交给Demo1.jsp处理，下面就实现Demo1.jsp--&gt;&lt;form action="Demo1.jsp"&gt; &lt;label&gt;姓名：&lt;/label&gt; &lt;input type="text" name="username"&gt; &lt;label&gt;密码：&lt;/label&gt; &lt;input type="password" name="password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 下面我们写一个JSP文件设置JavaBean 12345678910111213141516171819202122232425262728293031323334353637383940&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%--使用JavaBean person是Person创建的对象，相当于 Person person=new Person() 其中class是JavaBean的类所在的路径(在com包下的Person文件中) id就是相当于创建的对象 --%&gt; &lt;jsp:useBean id="person" class="com.Person"&gt;&lt;/jsp:useBean&gt; &lt;%--为username和password设置值,相当于下面的语句 person.setUsername(request.getParameter("username")); person.setPassword(request.getParameter("password")); JavaBean中的变量一定要和表单中的值一样，否则就不能对应，出现错误 其中name就是指定上面的id，即是使用的对象，property就是指定变量 --%&gt; &lt;jsp:setProperty property="uesrname" name="person"/&gt; &lt;jsp:setProperty property="password" name="person"/&gt; &lt;%--age是另外的变量，并没有对应着表单的name属性，因此我们可以单独的为其设置值，使用value实行即可设置，这里不必考虑类型，因为在内部会自动转换成JavaBean中的类型 --%&gt; &lt;jsp:setProperty property="age" name="person" value="20"/&gt; &lt;%--获取设置的值，相当于下面的语句： person.getUsername(); person.getPassword(); person.getAge(); --%&gt; &lt;h1&gt;&lt;jsp:getProperty property="username" name="person" /&gt;&lt;/h1&gt; &lt;h1&gt;&lt;jsp:getProperty property="password" name="person" /&gt;&lt;/h1&gt; &lt;h1&gt;&lt;jsp:getProperty property="age" name="person" /&gt;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 其实我们还可以不但可以将表单中的值赋值给变量，还可以使用value和param自己设置 1234567&lt;%-- 将请求的url中的password的值赋值给username，注意这里的使用的get的请求的话，提交的时候url会有请求值的 http://localhost:8080/web2/JSP/Demo1.jsp?username=%E9%99%88%E5%8A%A0%E5%85%B5&amp;password=123456 --%&gt; &lt;jsp:setProperty property="username" name="person" param="password"/&gt; &lt;%--age是另外的变量，并没有对应着表单的name属性，因此我们可以单独的为其设置值，使用value实行即可设置，这里不必考虑类型，因为在内部会自动转换成JavaBean中的类型 --%&gt; &lt;jsp:setProperty property="age" name="person" value="20"/&gt; JavaBean的存活范围 Scope属性决定了javabean对象的存在的范围。可选值有: page(默认值) request session application 1&lt;jsp:useBean id="person" class="com.anllin.bean.Person" scope="page"&gt;&lt;/jsp:useBean&gt; 在page范围 客户每次请求访问jsp页面时，都会创建一个javabean对象。JavaBean对象的有效范围就是当前的jsp文件中，如果不在当前Jsp中，那么就不可以使用该JavaBean对象中设置的值 比如使用forward转发给另外一个JSP文件，那么此时就会再创建一个JavaBean对象，原来页面的JavaBean对象并没有传过来，也就不能使用其中的值，这个和变量的共享是一个道理的，这个JavaBean对象只能在当前的Jsp文件中调用，不能实现共享 在request范围 客户每次请求访问jsp页面时，都会创建新的javabean对象。有效范围为： 客户请求访问的当前jsp网页。 和当前网页共享一个客户请求的网页，即当前jsp网页中&lt;%@include %&gt;指令以及&lt;forward&gt;标记包含的其他jsp文件,也就是转发和包含的Jsp文件也是可以共享这个JavaBean对象的，这个和Servlet中的request是一样的，一旦转发了，就可以通过setAttribute()设置属性，那么在转发的页面中就可以访问这个属性 当所有共享同一个客户请求的jsp页面执行完毕并向客户端发加响应时，javabean对象结束生命周期。 javabean对象作为属性保存在httpServletRequest对象中，属性名javabean的id,属性值为javabean对象，因此可以通过HttpRequest.getAttribute()方法取得javabean对象 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 //Demo1.jsp文件 表单请求提交的JSp文件 &lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt; &lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;%--设置scope属性为request，这个是必须的，这里的JavaBean对象为person--%&gt; &lt;jsp:useBean id="person" class="com.Person" scope="request"&gt;&lt;/jsp:useBean&gt; &lt;jsp:setProperty property="uesrname" name="person"/&gt; &lt;jsp:setProperty property="password" name="person"/&gt; &lt;jsp:setProperty property="age" name="person" value="20"/&gt;&gt; e &lt;%--转发请求到Demo2.jsp文件中，那么就可以在Demo.jsp中共享person对象了--%&gt; &lt;jsp:forward page="Demo2.jsp"&gt;&lt;/jsp:forward&gt;&lt;/body&gt;&lt;/html&gt;//Demo2.jsp &lt;%@page import="com.Person"%&gt; &lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt; &lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;%-- 使用JavaBean,这里的scope是必须的，一定要和Demo1.jsp一样，id也要一样 --%&gt; &lt;jsp:useBean id="person" class="com.Person" scope="request"&gt;&lt;/jsp:useBean&gt; &lt;%--获取username的值 --%&gt; &lt;jsp:getProperty property="username" name="person"/&gt; &lt;% //使用HttpServletRequest获取对象person Person p=(Person)request.getAttribute("person"); out.println(p.getUsername()); //获取username的值 %&gt; &lt;/body&gt; &lt;/html&gt; 在session范围内 我们知道HttpSession是可以在会话期间实现数据共享的，只要是同一个项目中的Jsp文件都是可以共享这个JavaBean对象，但是并不是永久的，因为会话也是有时间限制的， javabean对象作为属性保存在HttpSession对象中，属性名为javabean的id,属性值为javabean对象。除了可以通过javabean的id直接引用javabean对象外，也可以通过HttpSession.getAttribute（）方法取得javabean对象 一定要注意在每一个&lt;jsp:useBean&gt;中都要写上scope=&quot;session&quot; 在application范围内 我们知道ServletContext存在于整个web应用的生命周期，这个不像session，一旦设置的会话时间结束，那么就不存在了，这个是永远存在的，只要web程序在继续 javabean对象作为属性保存在application对象中，属性名为javabean的id，属性值为javabean对象，除了可以通过javabean的id直接引用对象外，也可以通过javabean的application.getAttribute()方法取得javabean对象 重要的属性 其实不仅仅可以对于表单中请求可以转换为对象的值，上面我们说过了存活范围，其实只要在这个请求范围内，并且将对象绑定到响应的属性上面，那么就可以在jsp文件中使用改标签接收其值。 其实一般在表单提交之后，我们会使用Sevlet文件验证是否密码和用户名正确，那么就不是直接提交给jsp文件，此时就像上面说过的，不影响标签的使用，只要将JavaBean对象绑定到响应范围的属性上，便是可以实现对象的共享，代码如下： ServletDemo文件 123456789101112131415161718192021222324252627282930313233343536package com;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.RequestDispatcher;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class ServletDemo extends HttpServlet &#123; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //创建对象，并且设置值 Person person=new Person(); person.setUsername("陈加兵"); person.setPassword("123456"); //将JavaBean对象绑定到request上，相当于存活范围为request //注意这里的键值一定要是和对象的名称一样，否则不行 request.setAttribute("person", person); //转发请求到jsp文件，下面我们就将在jsp文件中使用JavaBean标签接收 RequestDispatcher dispatcher=request.getRequestDispatcher("JSP/demo1.jsp"); dispatcher.forward(request, response); &#125; public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#125; &#125; demo1.jsp:上面文件转发过来的，接收JavaBean对象 123456789101112131415161718&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;%-- 使用标签接收转发过来的JavaBean对象，scope一定要设置为request,id就是传过来的对象，一定要和前面的名称一样，下面的语句相当于： Person person=(Person)request.getAttribute("person"); --%&gt;&lt;jsp:useBean id="person" class="com.Person" scope="request"&gt;&lt;/jsp:useBean&gt;&lt;h1&gt;&lt;jsp:getProperty property="username" name="person"/&gt;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 参考文章http://www.cnblogs.com/zfc2201/archive/2011/08/17/2143615.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSP总结一(标签）]]></title>
      <url>%2F2017%2F09%2F20%2FJSP%E6%80%BB%E7%BB%93%E4%B8%80-%E6%A0%87%E7%AD%BE%EF%BC%89%2F</url>
      <content type="text"><![CDATA[JSP总结一(标签)生命周期 JSP文件在部署到web服务器上的时候还是会编译成Servlet文件，因此JSP的生命周期和Servlet是一样的，都是有_JSPInit()，_JSPService(),_JSPDestroy()方法的 指示元素 在jsp中有三个指示类型，分别为：page,include,tablig。 page page指示类型告知容器如何转译目前的JSP网页。 1&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" import="java.util.*"%&gt; language指定解析语言，contentType表明为html文件，pageEncoding告诉容器转译及编译的时候如何处理这个这个JSP网页中的额中文编码，import是导入包的作用，如果有多个包导入，那么可以使用逗号隔开。 errorPage用于设置当JSP运行错误而产生异常的时候，该转发哪一个页面处理这个异常，可以自己定义一个异常的JSP或者html文件显示这个异常，但是这个必须和isErrorPage配合使用，必须在处理异常的page指令中协商isErrorPage=&quot;true&quot; 还有一些其他的属性，自己可以看看菜鸟教程上的内容 include include是用于静态的包含其他页面中的内容。这个还是很重要的，如果在网页中每一张页面都需要使用一样的导航栏，导入一样的css，js文件，那么可以将这些内容单独做一个jsp文件或者html文件，要使用的时候就直接包含即可。 12 //file指定文件的相对路径 &lt;%@include file="daoru.jsp" %&gt; 其实上面的语句在Servlet语句相当于下面这句话： 12RequestDispatcher dis=request.getRequestDispatcher();dis.include(request,response); 注意这句话写在页面的哪里，那么就将其中的内容导入到哪里，比如要导入css，js文件，那么直接在head标签中直接导入 静态导入的方式在部署到服务器会自动和当前的JSP文件编译为一个Servlet文件，也就是在一个Servlet类中。因此在包含的JSP文件中如果定义了变量或者方法，那么在当前的JSP页面中就不能重复定义，否则将会出现变量重复的错误，代码如下： 1234567891011121314151617181920212223242526272829303132//Demo1.jsp&lt;%@ page language="java" contentType="text/html; charset=UTF-8"pageEncoding="UTF-8"%&gt;&lt;% String name="陈加兵"; int age=22;%&gt;//Demo2.jsp&lt;%@ page language="java" contentType="text/html; charset=UTF-8"pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;//包含Demo1.jsp文件&lt;%@ include file="Demo1.jsp" %&gt;&lt;% //String name="chenji"; //这里不能重复定义，否则将会报错%&gt;//直接输出name的值 &lt;h1&gt;&lt;%=name%&gt;&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 注意这里的Demo1.jsp文件中一定不能重复的出现&lt;html&gt;标签，因为包含的时候是全部内容都是包含到当前页面中，如果出现重复的html标签代码就会混乱。 声明元素 &lt;%! &gt; 这就是声明元素，主要是用来定义类成员和方法声明的。其中不可以出现循环语句等，只能出现定义语句，当然在定义方法的时候函数体中可以出现其他的语句。 声明元素中的内容在编译的都将变成Servlet中的类的成员变量和方法 1234567891011 &lt;%! //变量 String name="陈加兵"; private int age=20; //方法 public void display()&#123; System.out.println(name+":"+age);&#125; %&gt; Scriptlet &lt;% %&gt;这个是写正常的java语句的，其中将会转译成_jspService()方法中的内容 12345&lt;% String name="陈加兵"; request.setAttribute("name",name);%&gt; 表达式元素 &lt;%= %&gt; 其中可以直接写一个表达式 123&lt;h1&gt;&lt;%= new Date() %&gt; &lt;/h1&gt;&lt;h1&gt;&lt;%= 2+3 %&gt; &lt;/h1&gt;&lt;h1&gt;&lt;%= request.getAttribute("name") %&gt; &lt;/h1&gt; 注释元素 &lt;%----%&gt;这是JSP的注释，在浏览器中查看源代码的时候是看不到的 &lt;!-- --&gt; 这是html中的注释，在网页源代码中是可以看到的 隐含对象 request 转译后对应的是HttpServletRequest resposne 译后对应的是HttpServletResponse out 译后对应的是JspWriter对象，其内部关系一个PrintWriter对象 Config 译后对应的是ServletConfig session 译后对应的是HttpSession application 译后对应的是ServletContext pageContext 译后对应的是PageContext对象 exception 译后对应的是Throwable对象 page 译后对应的是this]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet总结五(监听器)]]></title>
      <url>%2F2017%2F09%2F19%2FServlet%E6%80%BB%E7%BB%93%E4%BA%94-%E7%9B%91%E5%90%AC%E5%99%A8%2F</url>
      <content type="text"><![CDATA[Servlet总结五(监听器)分类 监听器按其功能可以分为三种，分别是生命周期监听器(ServletContextListener,ServletRequestListener,HttpSessionListener)，属性监听器(ServletRequestAttributeListener,HttpSessionAttributeListener,ServletContextAttributeListener)，会话属性监听器(HttpSessionBindingListener,HttpSessionActivationListener)。下面我们将会详细的介绍这三种监听器。 生命周期监听器生命周期就是从创建到销毁，因此顾名思义，就是在对象创建的时候会触发，销毁的时候也会触发 ServletContextListener 前面我们说过ServletContext是上下文的，是应用程序共享的，当应用程序启动就会生成的。在应用程序初始化或者结束前，会分别调用contextInitialized()和contextDestroyed()方法，通过传入的ServletContextEvent取得ServletContext对象。 实例 下面读取设置的初始化参数，并且在监听器中将其绑定为属性实现全文共享 web.xml的文件，主要是设置初始化属性值，前面已经讲过 1234567891011121314151617&lt;!-- 设置ServletContext初始参数 --&gt; &lt;context-param&gt; &lt;param-name&gt;username&lt;/param-name&gt; &lt;param-value&gt;陈加兵&lt;/param-value&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;password&lt;/param-name&gt; &lt;param-value&gt;123456&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 设置ServletContext初始参数 --&gt; &lt;!-- 设置监听器，ServletContextListener --&gt; &lt;listener&gt; &lt;listener-class&gt;com.ServletContextListenerDemo&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 设置监听器，ServletContextListener --&gt; 下面是实现监听器的功能 123456789101112131415161718192021222324252627282930313233343536373839package com;import java.util.Enumeration;import javax.servlet.ServletContext;import javax.servlet.ServletContextEvent;import javax.servlet.ServletContextListener;public class ServletContextListenerDemo implements ServletContextListener &#123; // ServletContext销毁的时候触发 public void contextDestroyed(ServletContextEvent arg0) &#123; //当销毁的时候就移除其中绑定的属性 ServletContext context = arg0.getServletContext(); // 获取所有属性的名称 Enumeration enumeration = context.getAttributeNames(); while (enumeration.hasMoreElements()) &#123; String name = (String) enumeration.nextElement(); // 移除绑定的属性 context.removeAttribute(name); &#125; &#125; // ServletContext生成的时候触发，一般当web程序应用的时候就会初始化ServletContext参数 public void contextInitialized(ServletContextEvent arg0) &#123; //获取ServletContext对象 ServletContext context = arg0.getServletContext(); // 读取参数 String name = context.getInitParameter("username"); String password = context.getInitParameter("password"); // 绑定属性，用于全文共享 context.setAttribute("username", name); context.setAttribute("password", password); &#125;&#125; ServletRequestListener 这是在对象ServletRequest对象生成或结束时，会触发的监听器。当生成的时候会触发requestInitialized(),结束时会触发requestDestroyed()方法。ServletRequest对象生成一般在浏览器发出请求，或者转发重定向。注意这个触发是在Servlet的doGet()或者doPost()之前。 实例 ServletRequestListener文件:在ServletRequest对象生成时绑定属性 1234567891011121314151617181920212223242526package com;import javax.servlet.ServletRequestEvent;import javax.servlet.ServletRequestListener;import javax.servlet.http.HttpServletRequest;public class ServletRequestListenerDemo implements ServletRequestListener &#123; //在ServletRequest对象结束时触发 public void requestDestroyed(ServletRequestEvent arg0) &#123; HttpServletRequest request=(HttpServletRequest)arg0.getServletRequest(); &#125; //在ServletRequest对象生成时触发(比如浏览器请求) public void requestInitialized(ServletRequestEvent arg0) &#123; //强制转换成其子类 HttpServletRequest request=(HttpServletRequest) arg0.getServletRequest(); //绑定属性，这里的request和触发其的Servlet中的是一样的，因此可以实现共享 //就好像forward,include一样 request.setAttribute("login", "atuo"); //绑定属性 &#125;&#125; Servlet文件：取得绑定的值 123456public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; PrintWriter pWriter=response.getWriter(); pWriter.println(request.getAttribute("login")); //取得上面监听器绑定的值 &#125; web.xml文件 12345&lt;!-- 设置监听器，ServletRequestListener --&gt; &lt;listener&gt; &lt;listener-class&gt;com.ServletRequestListenerDemo&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 设置监听器，ServletRequestListener --&gt; HttpSessionListener 在HttpSession对象初始化后或者结束时，会分别调用sessionCreated()和sessionDestroyed()方法，你可以通过传入的HttpSessionEvent来取得HttpSession，以针对会话对象做出响应的创建或者结束处理操作 实例 Servlet文件：用来验证登录是否正确，如果正确就创建HttpSession对象，并且绑定属性用来实现自动登录 12345678910111213141516171819202122232425262728293031323334353637package com;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import javax.xml.registry.infomodel.User;public class ServletDemo3 extends HttpServlet &#123; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; String name=request.getParameter("username"); String password=request.getParameter("password"); if ("chenjiabing".equals(name)&amp;&amp;"123456".equals(password)) &#123; //用户名和密码正确创建对象 HttpSession session=request.getSession(); session.setAttribute("login", "auto"); &#125; &#125; public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#125; public void init() throws ServletException &#123; &#125;&#125; HttpSessionListenerDemo文件：用来记录登录的人数 123456789101112131415161718192021222324package com;import javax.servlet.http.HttpSession;import javax.servlet.http.HttpSessionEvent;import javax.servlet.http.HttpSessionListener;import org.omg.CORBA.Request;public class ServletHttpSessionListenerDemo implements HttpSessionListener &#123; private static int count=0; //HttpSession创建时触发 public void sessionCreated(HttpSessionEvent arg0) &#123; count++; //人数++ &#125; //HttpSession销毁时触发 public void sessionDestroyed(HttpSessionEvent arg0) &#123; // TODO Auto-generated method stub count--; //人数-- &#125;&#125; 属性操作监听器 顾名思义，属性操作监听器就是当绑定属性或者移除绑定属性的时候会触发，共有三个监听器，分别为：ServletContextAttributeListener,ServletRequestAttributeListener,HttpSessionAtrributeListener。相同的是它们都有共同需要实现的方法，分别为：attributeAdded(绑定属性的时候触发),attributeRemoved(属性移除的时候触发),attributeReplace(属性被替换的时候触发) 由于这三个监听器实现的方法都是一样的，下面就演示一个即可，其他的都是相同的 HttpSessionAttributeListener 这是监听HttpSession对象属性的，主要有（添加，移除，替换）,当然这个也是要在web.xml设置的 12345678910111213141516171819202122232425262728293031323334package com;import javax.servlet.http.HttpSession;import javax.servlet.http.HttpSessionBindingEvent;public class HttpSessionAttributeListener implements javax.servlet.http.HttpSessionAttributeListener &#123; /*HttpSessionBindingEvent方法 * String getName() 返回最近改变的属性的名称 * Object getValue() 返回已添加、移除或替换的属性的值。如果添加（或绑定）了属性，则这是该属性的值。如果移除（或取消绑定）了属性，则这是被移除属性的值。如果替换了属性，则这是属性原来的值。 * getSession() 获取HttpSession对象 */ //添加新的属性时触发，每绑定一个属性就触发一次 public void attributeAdded(HttpSessionBindingEvent arg0) &#123; //获取HttpSession对象 HttpSession session=arg0.getSession(); String name=arg0.getName(); //获取添加的属性名称 String attribute=(String) arg0.getValue(); //获取添加的属性的值 &#125; //移除属性的时候触发 ，每移除一次就会触发一次 public void attributeRemoved(HttpSessionBindingEvent arg0) &#123; String value=(String) arg0.getValue(); System.out.println("被移除的属性的值为："+value); &#125; //属性值被替换的时候触发，直接重新设置属性值就是替换 public void attributeReplaced(HttpSessionBindingEvent arg0) &#123; System.out.println("被替换的属性的值："+arg0.getValue()); &#125;&#125; 会话属性监听器 先前介绍的几个监听器都是要在web.xml中使用&lt;listener&gt;定义的，这个会话属性监听器是不要在web.xml设置的 这里介绍的监听器分别为：HttpSessionBindingListener,HttpSessionActivationListener HttpSessionBindingListener 当实现HttpSessionBindingListener接口的类的对象被移除或者绑定到HttpSession成为属性的时候就会触发 下面是实现HttpSessionBindingListener接口的类 1234567891011121314151617181920212223242526272829303132package com;import javax.servlet.http.HttpSession;import javax.servlet.http.HttpSessionBindingEvent;public class HttpSessionBindingListenerDemo implements javax.servlet.http.HttpSessionBindingListener &#123; public String name; private int age; public HttpSessionBindingListenerDemo() &#123; super(); this.name="陈加兵"; this.age=22; &#125; //当这个类的对象绑定成为HttpSession的属性的时候将会触发 public void valueBound(HttpSessionBindingEvent arg0) &#123; //获取绑定的属性的对象 HttpSessionBindingListenerDemo listenerDemo=(HttpSessionBindingListenerDemo)arg0.getValue(); //获取对象的值 System.out.println(listenerDemo.name); &#125; //当这个类的对象被移除的时候就会触发 //getValue() getName() public void valueUnbound(HttpSessionBindingEvent arg0) &#123; &#125;&#125; 下面是Servlet文件： 123456789101112131415161718192021222324252627282930313233343536373839package com;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;public class ServletDemo1 extends HttpServlet &#123; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //获取对象 HttpSession session=request.getSession(); //对象 HttpSessionBindingListenerDemo listener=new HttpSessionBindingListenerDemo(); //绑定对象 session.setAttribute("listener", listener); &#125; public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#125; public void init() throws ServletException &#123; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet总结四(过滤器)]]></title>
      <url>%2F2017%2F09%2F17%2FServlet%E6%80%BB%E7%BB%93%E5%9B%9B-%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
      <content type="text"><![CDATA[Servlet总结四(过滤器的使用)简介 在容器调用Servlet的service()的方法钱，Servlet其实并不会知道有请求的到来，而在service()方法执行后，容器真正对浏览器进行HTTP响应之前，浏览器也不知道Servlet真正响应是什么。过滤器(Filter)正如其名称所示，它介于Servlet之前，可拦截浏览器对Servlet的请求，也可以改变Servlet对浏览器的响应。 其实说白了，过滤器就是应用程序的一个额外的组件，为了方便使用并且不改变Servlet源代码，比如用户验证，字符替换，压缩这类的需求，你可能只是暂时的需要这类需求，但是过一段时间又不需要了，如果直接在Servlet中改动源码，那么就太麻烦了。因此此时就需要设置一个独立的组件，在使用的时候直接引用，不需要的时候直接删除即可，这就是过滤器的必要。 过滤器的实现 想要实现过滤器，那么需要实现Filter接口，这个接口中有三个必须实现的方法，分别为init(),doFilter(),destroy()。 init(FilterConfig config) 这是一个初始化方法，其中的参数可以获取定义的初始值，这个在后面会详细说 destroy() 这个是销毁方法 doFilter(HttpServletRequest request,HttpServletResponse response,FilterChain chain) 这是主要的方法，用来执行过滤的作用。当请求来到了web容器中，容器发现了调用Servlet的service()方法之前可以应用某过滤器的时候就会调用该过滤器的doFilter()方法。就是在doFilter()方法中进行了service()方法的前置处理，而后根据是否调用FilterChain中的doFilter()决定是否执行下一个过滤器，如果没有那么就执行第一个过滤器。 如果执行了FilterChain的doFilter()方法，那么就会执行下一个过滤器，如果没有就调用指定的Servlet的service()方法。 重点 Servlet的响应分为前置处理和后置处理。前置处理就是在调用service()方法之前进行的处理，就是Servlet还没有接受到请求的时候，后置处理就是在Servlet执行过service()方法之后，就是Servlet已经处理完请求之后。因此FilterChain的doFilter()方法就将过滤器处理分为了前置处理和后置处理，在调用FilterChain的doFilter()方法之前的都是对Servlet的前置处理，也就是说这时候Servlet并不知道此时有请求过来，而在其之后的都是对Servlet的后置处理。 123456doFilter(HttpServletRequest request,HttpServletResponse response,FilterChain chain)&#123; //service()的前置处理 chain.doFilter(request,response); //service()的后置处理&#125; 在FilterChain执行后会一堆栈顺序返回，就是说如果有多个Filter，那么就先按照顺序执行chain.doFilter(request,response)之前的代码，即是先前置处理，然后入栈，这样一直到执行到最后一个Filter，之后就从栈顶开始执行chain.doFilter()的方法之后的代码，即是后置处理。总的来说就是先执行前置处理，然后入栈，待全部执行完毕之后再从栈顶开始后置处理的代码。 在Filter的doFilter的方法中的request，response和Servlet的doGet()和doPost()方法中的是一样的，即是可以设置属性，可以得到表单提交的值，总之是一样的。 简单的例子 下面实现一个过滤器用来验证提交请求的用户名和密码是否正确 1234567891011121314151617181920212223242526272829303132333435363738package com;import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequestWrapper;import javax.servlet.http.HttpServletResponse;public class FilterDemo1 implements Filter &#123; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; // 根据request获取表单的用户名和密码 String username = request.getParameter("username"); String password = request.getParameter("password"); // 如果用户名和密码正确 if ("陈加兵".equals(username) &amp;&amp; "123456".equals("password")) &#123; System.out.println("用户名或者密码错误，请重新输入"); &#125; //继续执行下一个过滤器，如果有就执行 chain.doFilter(request, response); //当所有过滤器的前置处理都执行完毕才执行这个语句 System.out.println("Servlet已经执行完毕"); &#125; public void init(FilterConfig config) throws ServletException &#123; &#125;&#125; 过滤器的设置 在web.xml中设置过滤器，设置的方式如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;display-name&gt;web2&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 定义FilterDemo1的过滤器 --&gt;&lt;filter&gt; &lt;!--设置过滤器文件的名字--&gt; &lt;filter-name&gt;FilterDemo1&lt;/filter-name&gt; &lt;!--设置过滤器类所在的路径，具体到包名--&gt; &lt;filter-class&gt;com.FilterDemo1&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;FilterDemo3&lt;/filter-name&gt; &lt;!--设置作用的url，即是Demo9这个Servlet应用这个过滤器--&gt; &lt;url-pattern&gt;/Demo9&lt;/url-pattern&gt; &lt;!-- &lt;servlet-name&gt;Demo9&lt;/servlet-name&gt; 这个标签和上面的&lt;url-pattern&gt;是一个效果，直接指明应用的Servlet的名称 --&gt; &lt;!--Demo1也应用这个过滤器--&gt; &lt;servlet-name&gt;Demo1&lt;/servlet-name&gt; &lt;/filter-mapping&gt;&lt;!-- 定义FilterDemo1的过滤器 --&gt; &lt;!-- 定义FilterDemo2的过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;FilterDemo2&lt;/filter-name&gt; &lt;filter-class&gt;com.FilterDemo2&lt;/filter-class&gt; &lt;/filte&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;FilterDemo2&lt;/filter-name&gt;&lt;!-- Demo1这个Servlet文件也应用FilterDemo2这个过滤器，那么当请求Demo的时候要按照定义的先后顺序先执行FilterDemo1这个过滤器 --&gt; &lt;url-pattern&gt;/Demo1&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 定义FilterDemo2的过滤器 --&gt; &lt;/web-app&gt; 注意 可以在同一个&lt;filter-mapping&gt;中定义多个Servlet文件，表示多个Servlet都应用于这个过滤器 一个Servlet文件可以同时应用多个过滤器，但是执行的顺序要按照定义的先后顺序执行 初始参数的设置和获取设置初始值 这个和ServletConfig一样的都存在初始参数，当然定义的方式也是不尽相同，都是在web.xml中定义的，如下： 123456789101112131415&lt;filter&gt; &lt;filter-name&gt;FilterDemo3&lt;/filter-name&gt; &lt;filter-class&gt;com.FilterDemo3&lt;/filter-class&gt; &lt;!--直接在filter下可以设置初始参数，当然我们可以在过滤器中获取参数--&gt; &lt;init-param&gt; &lt;param-name&gt;username&lt;/param-name&gt; &lt;param-value&gt;陈加兵&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;password&lt;/param-name&gt; &lt;param-value&gt;123456&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; 获取初始参数的值 直接利用其中的init(FilteConfig config) 获取初始化参数 12345678910111213141516171819202122232425262728293031323334package com;import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequestWrapper;import javax.servlet.http.HttpServletResponse;public class FilterDemo1 implements Filter &#123; public String username; public String password; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; &#125; //直接在init方法中利用FilterConfig的方法获取参数的值 public void init(FilterConfig config) throws ServletException &#123; //获取初始值 username=config.getInitParameter("username"); password=config.getInitParameter("password"); &#125;&#125; 设置触发的时机 当我们直接请求Servlet文件的url或者表单提交的时候使用的都是浏览器默认发出的请求，这个是可以触发过滤器的。但是如果是那些重定向(sendirect)或者转发包含(forward,include)就不会默认触发，因此我们需要在web.xml设置触发的时机，定义如下: 12345678&lt;filter-mapping&gt; &lt;filter-name&gt;FilterDemo1&lt;/filter-name&gt; &lt;url-pattern&gt;/Demo1&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;!--默认的--&gt; &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt; &lt;!--forward--&gt; &lt;dispatcher&gt;INCLUDE&lt;/dispatcher&gt; &lt;!--include--&gt; &lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; &lt;!--error --&gt;&lt;/filter-mapping&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet总结三(HttpSession会话管理)]]></title>
      <url>%2F2017%2F09%2F16%2FServlet%E6%80%BB%E7%BB%93%E4%B8%89-HttpSession%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[Servlet总结三(HttpSession会话管理)简介 HttpSession是提供一种方式，跨多个页面请求或对 Web 站点的多次访问标识用户并存储有关该用户的信息。简单的来说就是能够实现全局的共享数据，可以跨多个页面请求，当然在Servlet中可以在同一个项目中的不同的Servlet中共享数据 常用方法 void setAttribute(String name, Object value) 绑定对象到此会话上 public void removeAttribute(String name) 移除绑定的对象 Object getAttribute(String name) 根据指定的属性名称获取指定的值(需要强转) Enumeration getAttributeNames() 返回一个所有属性的枚举对象,可以通过Enumeration得到其中的值 public int getMaxInactiveInterval() 返回 servlet 容器在客户端访问之间将使此会话保持打开状态的最大时间间隔，以秒为单位（根据测试，这个默认的值为1800秒，如果在这个默认的时间之内没有响应，那么会话将会中断） public void setMaxInactiveInterval(int interval) 指定在 servlet 容器使此会话失效之前客户端请求之间的时间间隔，以秒为单位。负数时间指示会话永远不会超时。 使用 我们可以通过HttpServletRequest的方法getSession() 获取对象，下面我们来使用其中的函数 1234567891011121314151617 //Demo1中的doGet方法 public void doGet(HttpServletRequest request,HttpServletResponse response)&#123; request.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); //获取对象 HttpSession session=request.getSession(); //设置属性login的值为auto session.setAttribute("login", "auto"); &#125; //Demo2中的doGet方法 public void doGet(HttpServletRequest request,HttpServletResponse response)&#123; //获取对象 HttpSession session=request.getSession(); //获取其中的login的值 String login=session.getAttribute("login");&#125; 简单的例子 下面是一个简单的例子实现自动登录,在填入用户名和密码正确之后，并且勾选其中的自动登录选项，那么登录过一次后在一天之内，如果直接登录首页将会直接跳转到用户界面，实现自动登录的功能 index.jsp文件中实现的是简单的表单登录，并没有加上一些css，js,仅仅是一个例子 123456789101112131415161718192021222324252627282930313233&lt;%@ page language="java" import="java.util.*" pageEncoding="UTF-8"%&gt;&lt;% String path = request.getContextPath(); String basePath = request.getScheme() + "://" + request.getServerName() + ":" + request.getServerPort() + path + "/";%&gt;&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;&lt;html&gt;&lt;head&gt;&lt;base href="&lt;%=basePath%&gt;"&gt;&lt;title&gt;My JSP 'index.jsp' starting page&lt;/title&gt;&lt;meta http-equiv="pragma" content="no-cache"&gt;&lt;meta http-equiv="cache-control" content="no-cache"&gt;&lt;meta http-equiv="expires" content="0"&gt;&lt;meta http-equiv="keywords" content="keyword1,keyword2,keyword3"&gt;&lt;meta http-equiv="description" content="This is my page"&gt;&lt;!-- &lt;link rel="stylesheet" type="text/css" href="styles.css"&gt; --&gt;&lt;/head&gt;&lt;body&gt; &lt;form action="Demo3" method="get"&gt; &lt;label&gt;username:&lt;/label&gt;&lt;input type="text" name="username"&gt;&lt;/br&gt; &lt;label&gt;password:&lt;/label&gt;&lt;input type="password" name="password"&gt;&lt;/br&gt; &lt;label&gt;自动登录：&lt;/label&gt;&lt;input type="checkbox" name="login" value="auto"&gt; &lt;input type="submit" value="提交"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; Demo3.java是用户的首页，实现检测自动登录，没有加一些页面在上面，但是其实是用户的首页 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com;import java.io.BufferedReader;import java.io.File;import java.io.FileNotFoundException;import java.io.FileReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.io.PrintWriter;import java.io.Reader;import javax.servlet.RequestDispatcher;import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.http.Cookie;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;public class Demo3 extends HttpServlet &#123; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; request.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); // 获取HttpSession对象 HttpSession session = request.getSession(); // 设置一天的访问时间间隔，如果超过这个时间，那么中断 session.setMaxInactiveInterval(24 * 60 * 60); // 获取转发对象，页面跳转 RequestDispatcher dispatcher = request .getRequestDispatcher("HTML/user.html"); // 获取表单的数据 String username = request.getParameter("username"); String password = request.getParameter("password"); String login = request.getParameter("login"); // 获取HttpSession中设置的属性名为login的值，如果为null，表示没有设置 String value = (String) session.getAttribute("login"); // 如果不为空，表示已经登录过一次了，并且允许自动登录，直接跳转到用户界面即可 if (value != null) &#123; // 直接跳转到用户界面 dispatcher.forward(request, response); &#125; else &#123; // 如果用户名和密码正确 if ("chenjiabing".equals(username) &amp;&amp; "123456".equals(password)) &#123; // 并且设置了自动登录 if ("auto".equals(login)) &#123; // 设置session的值 session.setAttribute("login", "auto"); &#125; response.sendRedirect("HTML/user.html"); &#125; &#125; &#125; public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125;&#125; 说明: user.html是用户的主页，这里没有给出，可以自己设计]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet总结二(文件路径获取）]]></title>
      <url>%2F2017%2F09%2F15%2FServlet%E6%80%BB%E7%BB%93%E4%BA%8C(%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E8%8E%B7%E5%8F%96)%2F</url>
      <content type="text"><![CDATA[Servlet总结二（文件路径）前言 前面我们说过ServletContext表示的是web容器中的上下文，下面我们也是用到ServletContext中的方法读取文件 读取WebRoot文件下的文件 我们知道当我们将项目部署到Tomcat服务器中时，项目中的文件路径其实就是在Tomcat中的文件路径，所有的项目都是存储在webapps下的，我们可以看到webaapps下有两个文件夹(WEB-INF,META-INF)，这两个其实就是项目中webRoot下的两个文件夹。 public String getRealPath(String path) 为给定虚拟路径返回包含实际路径的String 12345678910111213141516 //获取ServletContext的对象ServletContext context = this.getServletContext();//context.getRealPath("/")获取项目的根目录的绝对路径(webRoot的绝对路径)//得到了webRoot的绝对路径，下面只要再接着写其他文件的路径即可File file = new File(context.getRealPath("/") + "\\WEB-INF\\lib\\file.txt");if (file.exists()) &#123; System.out.println("文件存在");&#125; else &#123; System.out.println("文件不存在，现在我们创建一个"); try &#123; file.createNewFile();// 创建一个新的文件 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; InputStream getResourceAsStream(String path) 根据传入的路径文件，返回一个InputStream对象 123456789101112 // 第一个"/"是表示webRoot的根目录，通过这个函数可以不用指定绝对路径就可以构造一个输入字节流InputStream stream = context .getResourceAsStream("/WEB-INF/lib/file.txt");// 通过InputStreamReader将字节流转换为字符流，然后创建缓冲字符流读取文件BufferedReader reader = new BufferedReader( new InputStreamReader(stream));try &#123; System.out.println(reader.readLine());&#125; catch (IOException e) &#123; System.out.println("文件没有成功读取"); e.printStackTrace();&#125; 注意：这个函数中的path传入的第一个&quot;/&quot;就表示根目录，在eclipse项目中表示webRoot的绝对路径，在Tomcat下的webapps表示项目名称的绝对路径，因此在下面的WEB-INF,META-INF文件夹下的文件只需要在后面继续添加即可 读取src下的class文件 前面我们获取的webRoot下的文件路径，但是如果我们想要获取src下的文件，那么我们要如何获取呢。 我们仔细看看Tomcat下的文件，可以发现在每一个WEB-INF下都有一个classes，这个就是相当于Tomcat下的src，因此我们利用上面得到的路径稍加修改就可以轻易的得到其中的文件路径 下面我们读取src文件夹下的file.txt中的内容，代码如下: 12345678910111213141516171819202122232425262728293031323334353637 // 获取ServletContext对象ServletContext context = this.getServletContext();// 这个是获取项目下的src文件夹下的file.txt文件File file = new File(context.getRealPath("/") + "\\WEB-INF\\classes\\file.txt");BufferedReader reader = null;if (file.exists()) &#123; System.out.println("文件存在，现在可以读取"); try &#123; // 创建缓冲流对象，实现读取文件 reader = new BufferedReader(new FileReader(file)); try &#123; // 输出第一行内容 System.out.println(reader.readLine()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; catch (FileNotFoundException e) &#123; System.out.println("文件不存在"); &#125; finally &#123; if (reader != null) &#123; try &#123; reader.close(); // 如果reader不是空，就关闭 &#125; catch (IOException e) &#123; System.out.println("文件关闭失败"); &#125; &#125; &#125;&#125; else &#123; System.out.println("文件不存在，现在开始创建一个"); try &#123; file.createNewFile();// 创建一个 &#125; catch (IOException e) &#123; System.out.println("没有创建成功"); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Eclipse配置Tomcat]]></title>
      <url>%2F2017%2F09%2F14%2FEclipse%E9%85%8D%E7%BD%AETomcat%2F</url>
      <content type="text"><![CDATA[Eclipse配置tomcatEclipse创建server 首先下载eclipse for javaEE developer 打开控制台，然后到server后右击空白处-&gt;New-&gt;Server-&gt;Apach-&gt;Tomact 7.0 -&gt;Next-&gt;添加tomcat的路径即可 ![第一步](http://ono60m7tl.bkt.clouddn.com/eclipse1.bmp 发布项目 在控制台server的空白处右击-&gt;Add and Remove-&gt;选择项目-&gt;Add-&gt;Finish 文档 javaee中英文对照文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet总结一]]></title>
      <url>%2F2017%2F09%2F14%2FServlet%E6%80%BB%E7%BB%93%E4%B8%80%2F</url>
      <content type="text"><![CDATA[Servlet总结一HttpServlet 想要实现一个servlet必须继承这个类，其实一个servlet就是一个java文件，但是这个类必须是继承HttpServlet。 生命周期 servlet的生命周期是从创建到毁灭的一个过程，具体的过程如下： Servlet 通过调用 init () 方法进行初始化。 Servlet 调用 service() 方法来处理客户端的请求,但是在这一步还是要用到具体的实现的两个方法，分别是doPost(),doGet() Servlet 通过调用 destroy() 方法终止（结束）。 最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。 常用的方法 init() 初试化方法 doGet(HttpServletRequest request,HttpServletResponse response) 处理get请求的方法 doPost(HttpServletRequest request,HttpServletResponse response) 处理post请求的方法 destroy() 最后销毁 Enumeration&lt;E&gt; getInitParameterNames() 该方法从 servlet 的 ServletConfig 对象获取所有的参数名称 public String getInitParameter(String name) 该方法从 servlet 的 ServletConfig 对象获取指定参数的值 name是指定的param-name的值，返回的param-value的值，具体的使用如下： 123456789101112131415161718192021222324252627282930&lt;servlet&gt; &lt;display-name&gt;ServletConfigDemo&lt;/display-name&gt; &lt;servlet-name&gt;ServletConfigDemo&lt;/servlet-name&gt; &lt;servlet-class&gt;com.ServletConfigDemo&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;username&lt;/param-name&gt; //定义的name &lt;param-value&gt;陈加兵&lt;/param-value&gt; //定义的value &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;password&lt;/param-name&gt; &lt;param-value&gt;123456&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletConfigDemo&lt;/servlet-name&gt; &lt;url-pattern&gt;/ServletConfigDemo&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; //下面只是一个servlet类中的init()方法，一般否是在init()方法中获取 public void init() throws ServletException &#123; username=this.getInitParameter("username"); //根据指定的名称获取参数的值 enumeration=this.getInitParameterNames(); //获取枚举对象 while(enumeration.hasMoreElements())&#123; //通过枚举的方法获取其中的所有的值 System.out.println(this.getInitParameter((String) enumeration.nextElement())); &#125; &#125; ServletConfig getServletConfig() 返回一个ServletConfig对象，这个方法在后面讲到ServletConfig类的时候回详细的说到 ServletContext getServletContext() 返回一个ServletContext对象，这个和ServletConfig类一样重要，在后面会详细讲解 HttpServletRequest 这是servlet容器中用来处理请求的类，并且该对象作为一个参数传给doGet,doPost方法中 常用的方法 getParameter(String name) 获取表单中的值，name是input中定义的name值，如果不存在返回null，否则返回的字符串 String[] getParameterValues(String name) 获取表单中有多个name相同的值，例如多选列表，复选框 Enumeration getParameterNames() 返回所有请求中的参数，返回的是一个枚举对象，可以通过对应的方法进行列出所有的参数 12345678910111213141516171819202122232425262728293031 //下面将会详细讲解上面三个方法的使用法，这三个参数是针对表单的，因此需要结合表单讲解，我们将会在index.jsp文件中定义表单 //index.jsp文件的内容如下： &lt;form action="ServletDemo" method="post"&gt; //servletDemo是要处理该请求的servlet的url，使用的是相对路径 username: &lt;input type="text" name="username"&gt; &lt;br&gt;Password: &lt;input type="password" name="pw"&gt; &lt;br&gt; &lt;input type="submit" value="提交"&gt; &lt;br&gt; &lt;label&gt;hobby:&lt;/label&gt; &lt;input type="checkbox" name="hobby" value="1"&gt;swing &lt;input type="checkbox" name="hobby" value="2"&gt;dancing &lt;input type="checkbox" name="hobby" value="3"&gt;song&lt;/form&gt; //下面是ServletDemo中的部分代码 String username = request.getParameter("username"); //获取username的值 String pw = request.getParameter("pw"); //获取password的值 //获取所有复选框的值 String[] hobbies=request.getParameterValues("hobby"); for(String hobby:hobbies)&#123; System.out.println(hobby); &#125; //获得所有的元素的name属性的名称，返回的是一个枚举的对象 Enumeration enumeration = request.getParameterNames(); while (enumeration.hasMoreElements()) &#123; String paramsString = (String) enumeration.nextElement(); //获取其中的每一名称 System.out.println(request.getParameter(request.getParameter)); //根据名称获取其中的值 &#125; Enumeration getHeaderNames() 获取所有请求头中的参数的名称，返回的是一个枚举对象 String getHeader(String name) 根据请求头中的名称获取对应名称的请求内容 1234567//获取所有请求头的名称，返回的是一个枚举对象 Enumeration enumeration=request.getHeaderNames(); while (enumeration.hasMoreElements()) &#123; String name=(String) enumeration.nextElement(); String value=request.getHeader(name); //根据名称返回对应的值 System.out.println(name+":"+value); &#125; String getContextPath() 获取应用程序的环境路径，就是上一级目录 String getMethod() 返回请求的方式 Get Post String getQueryString() 返回请求行中的参数部分 StringBuffer getRequestURL() 返回完整的URL String getRequestURI() 返回请求行中的资源名部分 getRemoteAddr方法返回发出请求的客户机的IP地址。 getRemoteHost方法返回发出请求的客户机的完整主机名。 getRemotePort方法返回客户机所使用的网络端口号。 getLocalAddr方法返回WEB服务器的IP地址。 getLocalName方法返回WEB服务器的主机名。 请求转发与包含 请求转发相当于一个重定向，但是这个又和重定向不同的是：请求转发是在web容器中进行的，因此浏览器的地址栏并不会改变，但是重定向是要求浏览器重新请求另一个url，因此可以在地址栏清楚的看到地址的变化 请求转发使用的是HttpServletRequest中的getRequestDispatcher方法，下面将会详细介绍 getRequestDispatcher RequestDispatcher getRequestDispatcher(String path) 返回的是一个RequestDispatcher对象，path是指定转发的url，可以是绝对url或者是相对url RequestDispatcher 定义接收来自客户端的请求并将它们发送到服务器上的任何资源（比如 servlet、HTML 文件或 JSP 文件）的对象。servlet 容器可创建 RequestDispatcher 对象，该对象被用作包装位于特定路径上的服务器资源或通过特定名称给定的服务器资源的包装器。 void forward(ServletRequest request, ServletResponse response) 执行转发请求,因为继承关系，因此其中的参数也是可以是HttpServletRequest和HttpServletResponse对象 123456789101112 public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; request.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); //获取表单中的值 String name=request.getParameter("username"); String password=request.getParameter("password"); //上面虽然获取了其中的值，但是不可以此时对浏览器进行响应 RequestDispatcher dispatcher=request.getRequestDispatcher("Demo2"); dispatcher.forward(request, response);&#125; 注意： 在转发前后不可以对浏览器进行响应，否则会出现错误，其中forward传入的参数是当前的request和response，也就是说在转发之后的文件之中还是可以获取信息的（请求头，表单） void include(ServletRequest request, ServletResponse response) 包含转发 123456789101112131415161718public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; request.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); //获取表单中的值 String name=request.getParameter("username"); String password=request.getParameter("password"); Cookie cookie=new Cookie("age", "22"); response.addCookie(cookie); PrintWriter pw=response.getWriter(); pw.println("在转发之前先对浏览器进行响应"); //上面可以看出这里对浏览器进行了响应，使用include可以在转发之前或者之后对浏览器进行响应 RequestDispatcher dispatcher=request.getRequestDispatcher("Demo2"); dispatcher.include(request, response); &#125; forward和include的区别 forward在转发之前和之后是不可以对浏览器进行响应的，但是include可以。使用include时，如果同时进行了响应，那么会同时响应在同一网页中，会出现在同一个页面中 相同点 请求转发后地址栏都不会出现改变 请求转发过后会重新回到当前的servlet容器中，因此如果想要在当前的servlet容器中处理一些东西是可以实现的，下面来看一个例子 1234567891011121314 public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; request.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); //获取表单中的值 String name=request.getParameter("username"); String password=request.getParameter("password"); //上面虽然获取了其中的值，但是不可以此时对浏览器进行响应 RequestDispatcher dispatcher=request.getRequestDispatcher("Demo2"); dispatcher.forward(request, response); System.out.println(username); //这个语句当转发请求处理完成之后会返回到这里执行这句话 &#125; 传递数据 就像写到scrapy爬虫的时候，有时候一个数据会传入到下一个函数中使用，因此需要一个机制携带过去。这里可以使用HttpServletRequest中的 setAttribute方法，详细使用如下： public void setAttribute(String name, Object o) 这里其实相当于传入的是一个键值对，name是key，o是value public void removeAttribute(String name) 根据键值的name移除数据 12345678910111213141516171819202122232425262728293031323334 protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 设置编码，这个是通过浏览器访问时能够实现中文显示的功能 response.setContentType("text/html;charset=UTF-8"); //设置和浏览器相应的编码方式，以便在控制台上输出中文，否则将会乱码显示 request.setCharacterEncoding("UTF-8"); String data="大家好，我是陈加兵"; request.setAttribute("data",data); //向请求中传入数据,这个是以键值对存在的，前面的是key，后面的参数是value //将请求转发给HttpServletDemo的servlet文件处理 RequestDispatcher dispatcher=request.getRequestDispatcher("HttpServletResponseDemo"); //如果转发成功，注意这里的转发，地址栏的网址并不会改变 if(dispatcher!=null)&#123; dispatcher.forward(request, response); &#125;&#125; //下面是HttpServletResponseDemo的处理代码 protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; response.setContentType("text/html;charset=UTF-8"); //设置响应内容 request.setCharacterEncoding("UTF-8"); //设置接受的编码 //接收请求转发传递的data数据 String data=(String) request.getAttribute("data"); PrintWriter pWriter=response.getWriter(); pWriter.println(data+"&lt;br/&gt;"); //移除这个键值对 ，下面在访问这个数据就会显示不存在了 request.removeAttribute("data"); pWriter.close();&#125; HttpServletResponse 这个类是用于对浏览器进行响应的 常用的方法 PrintWriter getWriter() 返回一个PrintWriter对象，可以将字符串发送到客户端 addCookie(Cookie cookie) 将指定的cookie添加到响应中，这个是直接添加到set-cookie中，用于存储一些信息 123 Cookie cookie=new Cookie("age", "22");cookie.setMaxAge(7*24*60*60); //设置cookie的失效时间(秒为单位）response.addCookie(cookie); //添加cookie sendError(int src) 将指定的错误信息发送到客户端 比如401，302…. sendError(int sec,String message) 发送错误信息的同时，还发送提醒的信息message sendRedirect(String url) 网页重定向，url是重定向的网址，但是也可以是相对的url ServletOutputStream getOutputStream() 返回适用于在响应中编写二进制数据的 ServletOutputStream。 ServletConfig 在web.xml中对于每一个Servlet的设置web容器会为其生成一个ServletConfig作为代表对象，你可以从该对象中取得设置在web.xml中的Servlet初始参数 常用方法 String getInitParameter(String name) 根据属性的名称获取指定的值 Enumeration getInitParameterNames() 获取该servlet中设置的所有的属性的名称（并不是设置的初始值） ServletContext getServletContext() 获取ServletContext对象 设置和取得初始参数 ServletConfig相当于web.xml中个别Servlet设置代表对象，这意味着可以从ServletConfig中取得Servlet设置信息。ServletConfig定义了getInitParameter()、getInitParameterNames() 方法，可以取得设置的Servlet的初始参数 设置初始参数 直接在web.xml中定义如下： 12345678910111213141516&lt;servlet&gt; &lt;description&gt;This is the description of my J2EE component&lt;/description&gt; &lt;display-name&gt;This is the display name of my J2EE component&lt;/display-name&gt; &lt;servlet-name&gt;Demo3&lt;/servlet-name&gt; &lt;servlet-class&gt;com.Demo3&lt;/servlet-class&gt; &lt;init-param&gt; //定义标签 &lt;param-name&gt;username&lt;/param-name&gt; //定义的name &lt;param-value&gt;陈加兵&lt;/param-value&gt; //定义的value &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;password&lt;/param-name&gt; &lt;param-value&gt;123456&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; 取得初始参数 第一种方法：直接使用带有ServletConfig对象为参数的init直接获取12345678910111213141516 public void init(ServletConfig config) throws ServletException &#123;// username=config.getInitParameter("username"); //单独的获取每一个值// password=config.getInitParameter("password"); //首先获取所有的初始参数的名称 Enumeration enumeration=config.getInitParameterNames(); while(enumeration.hasMoreElements())&#123; String name=(String)enumeration.nextElement(); //获取每一个值 if(name.equals("username"))&#123; username=config.getInitParameter(name); &#125;else if (name.equals("password")) &#123; password=config.getInitParameter(name); &#125; &#125; &#125; 第二种：使用HttpServlet的getServletConfig() 方法直接获取ServletConfig对象，然后再获取参数 1234567 public void init() throws ServletException &#123; ServletConfig config=this.getServletConfig(); //获取ServletConfig对象 username=config.getInitParameter("username"); //获取参数的值 password=config.getInitParameter("password"); &#125; ServletContext ServletContext是整个web应用程序运行之后的代表对象，这是一个全局的对象，一个web项目中的所有Servlet文件都是可以共享这个数据的，因此这个有着很大的作用。 有人说这个不是和ServletConfig一样的用法吗，其实不然，ServletConfig并不是这个web程序的全局变量，它所设置的值只是对当前的servlet共享，并不能对web项目中的所有的servlet文件共享 常用方法 String getInitParameter(String name) 获取指定名称的属性值 Enumeration getInitParameterNames() 获取所有已经设置的属性的名称 void setAttribute(String name, Object object) 将对象绑定到此 servlet 上下文中的给定属性名称。如果已将指定名称用于某个属性，则此方法将使用新属性替换具有该名称的属性。 Object getAttribute(String name) 根据指定的属性名称获取绑定的值(需要进行强转) void removeAttribute(String name) 解除绑定的数据 设置初始参数 这个和ServletConfig是一样的，都是在web.xml中设置的，但是这个是设置在&lt;servlet&gt;&lt;/servlet&gt;的外面的，并不是针对单独的一个servlet来设置的，因此是全局共享的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;display-name&gt;web2&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!--全局变量，对工程中的所有的Servlet都是共享的--&gt; &lt;context-param&gt; &lt;param-name&gt;context_name&lt;/param-name&gt; &lt;param-value&gt;context_value&lt;/param-value&gt; &lt;!--在每一对context-param中只能定义一个变量的值--&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;username&lt;/param-name&gt; &lt;param-value&gt;陈加兵&lt;/param-value&gt; &lt;/context-param&gt; &lt;servlet&gt; &lt;servlet-name&gt;Demo1&lt;/servlet-name&gt; &lt;servlet-class&gt;com.Demo1&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet&gt; &lt;servlet-name&gt;Demo2&lt;/servlet-name&gt; &lt;servlet-class&gt;com.Demo2&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;Demo1&lt;/servlet-name&gt; &lt;url-pattern&gt;/Demo1&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;Demo2&lt;/servlet-name&gt; &lt;url-pattern&gt;/Demo2&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 获取设置的参数 第一种方法：使用无参初始化的方法init() ，结合父类HttpServlet的getServletContext()的方法获取ServletContext对象 1234567891011121314151617//使用无参构造函数public void init() throws ServletException &#123; ServletContext context=this.getServletContext(); //根据属性的名称获取指定的值 String value=context.getInitParameter("username"); System.out.println(value); //获取所有的属性的名称的枚举对象 Enumeration enumeration=context.getInitParameterNames(); while(enumeration.hasMoreElements())&#123; //获取属性的每一个名称 String name=(String) enumeration.nextElement(); //根据名称获取所有的值 System.out.println(name+" = "+context.getInitParameter(name)); &#125; &#125; 第二种方法：使用有参初始化方法init(ServletConfig config)，结合ServletConfig的getServletContext()方法获取对象 123456789//使用有参构造方法public void Init(ServletConfig config)&#123; //调用ServletConfig中的方法获取对象 ServletContext context=config.getServletContext(); //获取属性的值 String value=context.getInitParameter("username"); System.out.println(value); &#125; 绑定属性 有人可能会说如果想用共享数据在web.xml设置有点繁琐，这里可以直接绑定属性，然后就可以在整个web项目中共享这个绑定的属性了 123456789101112131415161718192021public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; request.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); //获取对象（这是父类HttpServlet中的一个方法） ServletContext context=this.getServletContext(); //count表示访问页面的次数，在这里设置了属性可以全局共享该数据，意思就是在一个项目中的所有的servlet都是可以访问到该数据的 Integer count=(Integer) context.getAttribute("count"); //获取设置的属性值 //如果为空，表示该属性还没有被设置，因此这是第一次访问该页面 if(count==null)&#123; count=1; context.setAttribute("count", 1); //初始值为1，表示访问网页1次 &#125;else &#123; //否则表示已经不是第一次访问网页了，因此需要++1 context.setAttribute("count", ++count); &#125; PrintWriter pWriter=response.getWriter(); pWriter.println("该页面已经被访问了"+count+"次了......"); &#125; 参考文档 javaEE中英文对照文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[多线程的使用]]></title>
      <url>%2F2017%2F09%2F03%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[多线程前言 我看了不止一个人说多线程是鸡肋，但是就依照我个人觉得多线程在一些小型的爬虫中还是可以显著的提高速度的，相比多进程来说应该还是挺简单的 使用多线程继承threading.Thread 继承threading.Thread模块是一个很好的一个选择，就像java中也是可以继承类和实现接口一样，这都是很好的选择，下面我们来看看具体如何使用 1234567891011121314151617181920212223242526class Mythread(threading.Thread): def __init__(self,threadID,name,counter): threading.Thread.__init__(self) #首先需要先保留原来threading.Thread中的初始化函数 self.threadID=threadID #重命名线程的ID self.name=name #线程的名字 self.counter=counter #线程的数量 def run(self): lock.acquire() #获取线程锁Lock for i in range(10): print "线程"+self.name+"开始运行" lock.release() #释放线程锁Lockif __name__ == '__main__': lock=threading.Lock() t1=Mythread(0,"thread-1",3) t2=Mythread(1,"thread-2",3) t1.start() t2.start() threads=[] threads.append(t1) threads.append(t2) for t in threads: t.join() #阻塞主线程，直至线程运行完毕才运行main线程的语句 print "线程运行结束" 需要注意的是，这种继承的方式有一个缺点，这个和java中继承来实现多线程是一样的，就是一个对象只能是对应一个线程，并不能一个对象被多个线程共享，下面我们将会介绍另外的一种方式 直接调用threading.Thread 上面我们说过继承的方式，但是我个人觉得对于一些比较小的爬虫还是有些繁琐的，因为总是需要重写run方法，现在我们来看看如何简化实现多线程 12345678910"""这是一个简单的例子，其实也不是一个好的例子，但是为了演示方便就选用了，可以看出这里是直接调用了func函数，然后变成多个线程同时并行，其中target是要调用的方法(没有括号)，args是方法调用需要传入的参数其实这个还是和上面的继承比较相似的"""def func(name,age): for i in range(10): print name+"的年龄为："+str(age) t=threading.Thread(target=func,args=["陈加兵",22])t.start() Thread对象的相关方法 start() 启动线程 join([timeout]) 设置阻塞线程，timeout是可选的参数，表示阻塞的时间，如果没有就是当此线程运行结束才开始运行下一个线程 run() 线程活动的方法 getName() 获取线程名称 setName() 设置线程的名称 isAlive() 判断线程是否还活着 isDaemon() 判断是否是守护线程 setDaemon() 设置为守护线程，守护线程就是当主线程运行完后，这个线程也会随着主线程的结束而结束 共享队列 从源代码可以看出队列是实现了锁原语的，因此可以使用队列实现线程的同步，这里的主要原理就不细说了，简单的说就是get和put等方法都实现了锁原语，就是当一个操作正在执行的时候其他的操作会阻塞等待 下面我自己写了一个使用两个线程实现同时入队和出队的程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import randomimport timefrom Queue import Queueclass myThread(threading.Thread): def __init__(self,threadID,name,counter,q,flag): """ threadID是线程的ID name是线程的名称 q是先进先出队列 flag是用来调用get和put的标志 """ threading.Thread.__init__(self) self.name=name self.threadID=threadID self.counter=counter self.q=q self.flag=flag def run(self): """ 当flag为1时就调用put方法，否则调用get """ if self.flag==1: self.put() else: self.get() def put(self): while True: self.q.put(random.randint(0,10)) def get(self): while True: if not self.q.empty(): print self.q.get() if __name__=="__main__": threadLock=threading.Lock() q=Queue() t1=myThread(1,"Thread-1",1,q,1) t2=myThread(2,"Thread-2",2,q,2) threads=[] threads.append(t1) threads.append(t2) t1.start() t2.start() Queue相关的一些方法 Queue.qsize() 返回队列的大小 Queue.empty() 如果队列为空，返回True,反之False Queue.full() 如果队列满了，返回True,反之False Queue.full 与 maxsize 大小对应 Queue.get([block[, timeout]])获取队列，timeout等待时间 Queue.get_nowait() 相当Queue.get(False) Queue.put(item) 写入队列，timeout等待时间 Queue.put_nowait(item) 相当Queue.put(item, False) Queue.task_done() 在完成一项工作之后， Queue.task_done()函数向任务已经完成的队列发送一个信号 Queue.join() 实际上意味着等到队列为空，再执行别的操作]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[os模块中常用的的方法]]></title>
      <url>%2F2017%2F09%2F02%2Fos%E6%A8%A1%E5%9D%97%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[os模块中常用的方法常用的方法 os.getcwd() 获取当前的路径os.listdir(path) 获取path路径下的全部文件和文件夹，就是显示全部的文件的作用os.mkdir(path) 创建一个文件夹os.rmdir(path) 删除一个文件夹os.remove(path) 删除一个文件os.rename(path1,path2) 将文件或者文件夹重命名，path1是原来件路径，path2是改变后的文件的路径名称os.makedirs(path) 循环创建文件夹，给出一个路径，连续的创建这个路径的全部文件夹，并不是创建文件os.removedirs(path) 循环删除文件夹 会删除整个路径的文件夹os.path.abspath(path) 返回此文件的绝对路径os.path.exists(path) 判断文件或者文件夹是否存在os.path.basename(path) 返回绝对路径中的文件名os.path.normpath(path) 标准化文件路径，Windows下将双斜杠变成单斜杠os.path.commonprefix(list) 返回list中的相同的路径，只是多个路径相同的部分os.path.dirname(path) 返回文件所在上面一层的目录的名称，注意这里是所在紧接着一层的文件夹的名称os.path.split(path) 将路径分割成两个部分，返回的是一个元祖，第一个元素是前面的路径，第二个元素是文件的名称os.path.getatime(path) 返回文件的最后访问时间os.path.getmtime(path) 返回文件的最后修改时间os.path.getctime(path) 在unix的系统上返回的是文件最后修改的时间，在window的系统上返回的是文件的创建时间os.path.getsize(path) 返回文件的大小，以字节为单位os.path.isfile(path) 判断文件是否是文件os.path.isdir(path) 判断文件是否是文件夹os.path.join(path1,path2) 将两个文件的路径拼接在一起 例子 其中的每个方法的例子请点击这里]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python操作MongoDB]]></title>
      <url>%2F2017%2F07%2F09%2Fpython%E6%93%8D%E4%BD%9CMongoDB%2F</url>
      <content type="text"><![CDATA[python操作MongoDB前言 下面推荐本人写的MongoDB的基本操作博文，介绍的还是比较详细的，喜欢的朋友可以去看看 MongoDB干货篇之安装 MongoDB干货篇之查询数据 MongoDB干货篇之更新数据 综合应用 下面是自己写的一个简单的操作，分别对应了增删改查，虽然不太全面，但是只是简单的示范了一下，当然更多的功能还是需要自己去完善的，因为代码中都有注释，这里就不再详细的说了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# coding:utf-8import pymongoclass MongoDB: def __init__(self,db,collections): """ 初始化数据库 :param db:数据库名称 :param collections: 数据库的集合的名称 """ self.client = pymongo.MongoClient('localhost', 27017) #获取的连接 self.db = self.client[db] #创建数据库db self.post = self.db[collections] #创建或者选择要操作的集合 def update(self, data,upsert): """ 更新数据库中的数据，如果upsert为Ture，那么当没有找到指定的数据时就直接插入，反之不执行插入 :param data: 要插入的数据 :param upsert: 判断是插入还是不插入 :return: """ self.post.update(&#123;"ip": data&#125;, &#123;'$set': &#123;'ip': data&#125;&#125; , upsert) def find(self,select): """ 根据传入的参数查找指定的值，注意这里的select是字典 :param select: 指定的查找条件，这里的是字典类型的，比如&#123;"name":"chenjiabing","age":22&#125; :return: 返回的是查询的结果，同样是字典类型的 """ return self.post.find(select) def insert(self,data): """ 向数据库中插入指定的数据 :param data: 要插入的数据，这里的是字典的类型比如：&#123;"name":"chenjiabing","age":22&#125; :return: 插入成功返回True,反之返回false """ try: self.post.insert(data) return True except: return False def remove(self,select): """ 删除指定条件的记录 :param select: 指定的条件，这里是字典类型的，比如&#123;"age":22&#125; 表示删除age=22的所有数据 :return: 如果删除成功返回True，else返回False """ try: self.post.remove(select) return True except: return False 下面是利用上面的Mongo.py文件获取西刺网站的代理并且存入数据库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# coding:utf-8import requestsfrom bs4 import BeautifulSoupimport timefrom Queue import Queueimport threadingfrom Mongo import MongoDB #导入文件class XICI: def __init__(self, page): """ self.header:请求头 self.q:存储ip的队列 slef.urls:页面的url :param page:传入的参数，表示获取多少页的ip """ self.header = &#123;"User-Agent": 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0'&#125; self.q = Queue() self.urls = [] for i in range(1, page + 1): self.urls.append("http://www.xicidaili.com/nn/" + str(i)) self.mongo = MongoDB('python','ip') # 创建MogoDB对象 def get_ips(self, url): """ 根据一页的请求爬取一个页面的ip :param url:传入的参数，表示每一页的链接 :return: None """ try: res = requests.get(url, headers=self.header) if res.status_code == 200: soup = BeautifulSoup(res.text, 'lxml') ips = soup.find_all('tr') for i in range(1, len(ips)): ip = ips[i] tds = ip.find_all("td") ip_temp = "http://" + tds[1].contents[0] + ":" + tds[2].contents[0] print ip_temp self.q.put(ip_temp) # ip进入队列 except: print "-------------------------------------------请求出现异常------------------------------------------------" def insert(self, url): """ 验证出过来的ip，如果成功就直接存入数据库 :param url: 验证ip地址的url :return: 无返回值 """ while not self.q.empty(): ip = self.q.get() proxy = &#123;"http": ip&#125; print proxy try: res = requests.get(url, headers=self.header, proxies=proxy, timeout=5) if res.status_code == 200: self.mongo.update(ip,True) # 如果成功验证直接进入数据库 print "**************************成功存入数据库********************************************" else: print "这个ip地址不能用" except: print "--------------------------请求失败---------------------------------------------" def main(self): for url in self.urls: self.get_ips(url) threads = [] for i in range(5): t=threading.Thread(target=self.insert,args=["http://blog.csdn.net/qq_34162294/article/details/72353389"]) threads.append(t) for t in threads: t.start()if __name__ == '__main__': p = XICI(3) p.main()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Numpy指南]]></title>
      <url>%2F2017%2F07%2F01%2FNumpy%E6%8C%87%E5%8D%97%2F</url>
      <content type="text"><![CDATA[numpy指南 numpy是一个能够处理多维数组的库，虽然python中也内置了处理数组的库，但是这个并不能满足大数据时代的需求，因此产生了可以处理多维数组的numpy 安装 pip install numpy 创建array array函数是一个最基本的创建方式，其中传入的参数是一个序列，既可以创建一维数组，也可以创建二维数组，但是这种方法不太灵活，因为你要把这个序列显式的写出来，先不多说了，自己体会吧 123456import numpy as npa=np.array([1,2,3,4,5]) #创建一个二维数组b=np.array([[1,2,3,4],[2,3,4,5]]) #创建一个二维数组print a.shape #输出数组的维度，(5,)print b.shape #(2,4) arange arange(start,end,step) 创建一个一维数组，起始值为start，终值为end，步长为step，其中np.arrange(10) 表示起始值为0，终值为10，步长为1 12a=np.arange(0,10,1) b=np.arange(10) reshape reshape(a,b)能过改变当前数组的尺寸将其赋值给新的数组，但是当前数组并没有改变，这个用来改变当前数组的维度，可以将以为数组改变为二维数组 123a=np.arange(10) #创建一个有10个元素的一维数组b=np.reshape(2,5) #将改变后的当前数组赋值给b，但是a数组并没有改变 ，2*5=10c=np.reshape(5,-1) #第一个参数为5行，第二个-1表示自动计算生成，10/5=2 linspace linspace(start,end,number) 创建一个等距离的数组，start是起始值，end是终值，number是个数，创建的是一个一维数组，其中的元素全部是浮点数，默认的是包括终值的，但是可以通过endpoint=False指定不包括终值 12a=np.linspace(0,10,10) #包含10的一个等差数组b=np.linspace(0,10,10,endpoint=False) #不包含10的一个等差数组 logspace logspace(start,end,number) 创建的是在10^start和10^end之间包含number个元素的等比数组，创建的是一个等比数组 1a=np.logspace(0,1,10) #创建一个在1-10之间的10个元素的等比数组 存取数据下标存取123456789a=np.arange(10) #[0,1,2,3,4,5,6,7,8,9]a[0] #获取第一个元素的值1a[0:2] #获取下标我0,1的值，注意不包括2a[0:10:1] # 获取下标在0-10之间的(包括0,不包括9)，步长为1的元素，就是每隔一个区娶一个a[1:] #获取从第二个元素开始到最后的所有的元素a[:8] #获取下标为0-8之间的元素(不包括8)a[1::1] #获取下标为0到最后并且步长为1的所有元素a[8:4:-1] #获取起始下标为8，终止下标为4，并且步长为-1，这是从后向前获取元素a[::-1] #将数组逆置 使用整数序列 当使用整数序列对数组元素进行存取时，将使用整数序列中的每个元素作为下标，整数序列可以是列表或者数组。使用整数序列作为下标获得的数组不和原始数组共享数据空间。 12x = np.arange(10,1,-1) x[[3, 3, 1, 8]] # 获取x中的下标为3, 3, 1, 8的4个元素，组成一个新的数组 ufunc ufunc是universal function的缩写，它是一种能对数组的每个元素进行操作的函数。NumPy内置的许多ufunc函数都是在C语言级别实现的，因此它们的计算速度非常快. 12345678910111213np.sin(x) #对数组中的每一个值进行sin操作，并且返回一个数组np.sin(x,y) #对数组x中的值进行sin操纵，所得结果返回给y，但是也返回一个结果数组，这个数组和y共享一块空间的np.add(a,b) #将两个数组中的对应的值都相加，返回的是一个新的数组np.add(a,b,c) # 将两个数组中对应的值相加，结果复制给c，并且返回一个新的数组np.subtract(a,b) # 两个数组相减，a-b,返回的是一个新的数组np.subtract(a,b,c) np.multiply(a,b) #相乘np.multiply(a,b,c) #相乘divide(a,b,[,y]) #相除，如果是两个整数相除，那么返回的是整数true_divide(a,b,[,y]) #相除，总是返回精确的商floor_divide(a,b,[,y]) #总是对返回值取整power(a,b,[,y]) # a^b 平方mod(a,b,[,y]) #取余 %]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lock]]></title>
      <url>%2F2017%2F06%2F22%2FLock%2F</url>
      <content type="text"><![CDATA[Lock 在上一篇文章中我们讲到了如何使用关键字synchronized来实现同步访问。本文我们继续来探讨这个问题，从Java 5之后，在java.util.concurrent.locks包下提供了另外一种方式来实现同步访问，那就是Lock。 也许有朋友会问，既然都可以通过synchronized来实现同步访问了，那么为什么还需要提供Lock？这个问题将在下面进行阐述。本文先从synchronized的缺陷讲起，然后再讲述java.util.concurrent.locks包下常用的有哪些类和接口，最后讨论以下一些关于锁的概念方面的东西 synchronized缺陷 前面我们说过synchronized的线程释放锁的情况有两种: 代码块或者同步方法执行完毕 代码块或者同步方法出现异常有jvm自动释放锁 从上面的synchronized释放锁可以看出，只有synchronized代码块执行完毕或者异常才会释放，如果代码块中的程序因为IO原因阻塞了，那么线程将永远不会释放锁，但是此时另外的线程还要执行其他的程序，极大的影响了程序的执行效率，现在我们需要一种机制能够让线程不会一直无限的等待下去，能够响应中断，这个通过lock就可以办到 另外如果有一个程序，包含多个读线程和一个写线程，我们可以知道synchronized只能一个一个线程的执行，但是我们需要多个读线程同时进行读，那么使用synchronized肯定是不行的，但是我们使用lock同样可以办到 Lock 查看API可知，Lock是一个接口，因此是不可以直接创建对象的，但是我们可以利用其实现的类来创建对象，这个先不着急，我们先看看Lock类到底实现了什么方法,具体的实现我们将会在介绍其实现的类的时候再详细的讲解 方法 lock() 获取锁，如果没有获得就会一直等待 unlock() 释放锁 tryLock() 尝试获得锁，如果成功获得锁就执行，如果没有成功获得锁，那么就不会等待了 lockInterruptibly() 如果当前线程未被中断，则获取锁。 ReentrantLock ReentrantLock是可重入锁，是实现Lock接口的一个类，可重入是一种线程的分配机制，可重入的意思就是总是分配给最近获得锁的线程，这是一种不公平的分配机制，将会出现饥饿现象，当然为了解决这种现象，ReentrantLock的构造方法还提供了一个fair参数，如果fair为true表示使用公平分配机制，将会有等待时间最长的线程获得锁 构造方法 ReentrantLock() 创建一个对象，默认使用的时可重入的机制 ReentrantLock(boolean fair) 如果fair为true那么使用的是公平分配机制 常用方法 lock() 获取锁，如果没有获取到将会一直阻塞 下面使用一段程序演示以下lock方法的使用，代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344//实现接口的线程类public class MyThread implements Runnable &#123; public ReentrantLock rLock = null; //注意这里的锁一定要是全局变量，否则每一个线程都创建一把锁，那么将会毫无意义 public MyThread() &#123; this.rLock = new ReentrantLock(); // 创建默认的可重入锁 &#125; // 将unlock方法放在finally中确保执行中代码出现异常仍然能够释放锁，否则将会造成其它的线程阻塞 public void display() &#123; this.rLock.lock(); // 获取锁 try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Thread.currentThread().getName() + "正在输出" + i); &#125; &#125; finally &#123; this.rLock.unlock(); // 释放锁，注意这步是一定需要的 &#125; &#125; @Override public void run() &#123; this.display(); // 调用display方法 &#125;&#125;//线程的测试类，主要是创建对象启动线程public class Test &#123; public static void main(String[] args) &#123; final MyThread thread = new MyThread(); // 创建对象 // 下面创建两个线程,并且直接启动， new Thread(thread).start(); new Thread(thread).start(); &#125;&#125; 执行上面的代码得到下图的结果: 从上面的结果看出，线程是一个一个输出的，并且只有等待一个线程输出完毕才能执行下一个线程，这里的仅仅是针对lock和unlock之间的代码，之外的代码并不是受到控制 注意： 这里的创建的可重入锁的对象必须对于每一个线程来说是全局的变量，是可以共享的一个对象，如果你在display方法中创建这个对象，那么是毫无意义的，因为每一个线程用的根本不是同一把锁 boolean tryLock() 首先尝试获取锁，如果获取锁了就执行，否则就不会一直等待 下面使用一段代码尝试以下这个方法，代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//实现接口的线程类public class MyThread implements Runnable &#123; public ReentrantLock rLock = null; // 注意这里的锁一定要是全局变量，否则每一个线程都创建一把锁，那么将会毫无意义 public MyThread() &#123; this.rLock = new ReentrantLock(); // 创建默认的可重入锁 &#125; // 将unlock方法放在finally中确保执行中代码出现异常仍然能够释放锁，否则将会造成其它的线程阻塞 public void display() &#123; if (this.rLock.tryLock()) // 如果获取了锁 &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Thread.currentThread().getName() + "正在输出" + i); &#125; &#125; finally &#123; this.rLock.unlock(); // 释放锁，注意这步是一定需要的 &#125; &#125; else &#123; System.out.println(Thread.currentThread().getName() + "获取锁失败，我将不会一直等待........"); &#125; &#125; @Override public void run() &#123; this.display(); // 调用display方法 &#125;&#125;//线程的测试类，主要是创建对象启动线程public class Test &#123; public static void main(String[] args) &#123; final MyThread thread = new MyThread(); // 创建对象 // 下面创建两个线程,并且直接启动， new Thread(thread).start(); new Thread(thread).start(); &#125;&#125; 执行后的结果如下图: 从上面的结果我们知道线程0获取了锁开始执行，但是线程1并没有获取锁，但是使用的是tryLock并不是lock,因此不会一直等待下去，所以直接程序向下运行，直接跳过上锁的代码段，因此就输出了上面的那句话后直接结 ReadWriteLock 从API中可以知道，这个也是一个接口，用于实现读写线程，他有两个方法：Lock readLock(),Lock writeLock() 分别用于获得读锁和写锁，指定特定的锁可以实现特定的功能，比如读锁可以在写线程在执行的情况下可以实现多个读线程进行操作，下面我们来介绍它的具体的实现的类ReentrantReadWriteLock ReentrantReadWriteLock 这个类也是一个可重入分配的类，当然前面已经说过了什么是可重入，现在我们来说说说这个类的详细的用法 构造方法 ReentrantReadWriteLock() 使用默认（非公平）的排序属性创建一个新的 ReentrantReadWriteLock。 ReentrantReadWriteLock(boolean fair) 使用给定的公平策略创建一个新的ReentrantReadWriteLock。 常用的方法 ReentrantReadWriteLock.ReadLock readLock() 用于返回读取操作的锁 前面已经说过读取操作的锁是用来实现多个线程共同执行的，代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//实现接口的线程类public class MyThread implements Runnable &#123; public ReentrantReadWriteLock rwlock = null; public Lock rLock = null; public MyThread() &#123; this.rwlock = new ReentrantReadWriteLock(); // 创建对象，使用的是非公平的 this.rLock = this.rwlock.readLock(); // 获取读取锁对象 &#125; // 将unlock方法放在finally中确保执行中代码出现异常仍然能够释放锁，否则将会造成其它的线程阻塞 public void display() &#123; this.rLock.lock(); // 获取读取锁 try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Thread.currentThread().getName() + "正在输出" + i); &#125; &#125; finally &#123; this.rLock.unlock(); // 释放锁，注意这步是一定需要的 &#125; &#125; @Override public void run() &#123; this.display(); // 调用display方法 &#125;&#125;//线程的测试类，主要是创建对象启动线程public class Test &#123; public static void main(String[] args) &#123; final MyThread thread = new MyThread(); // 创建对象 // 下面创建两个线程,并且直接启动， for(int i=0;i&lt;5;i++) &#123; new Thread(thread).start(); &#125; &#125;&#125; 执行上面的程序结果如下: 从上面的结果可以知道，其实使用读取操作是多个线程同时进行读取的操作，因此一定要小心谨慎的使用，根据自己的需求，一般不能在里面进行修改了，因为出现结果不准确的结果，这个就不多说了，相信大家都明白，总之要小心使用 ReentrantReadWriteLock.WriteLock writeLock() 返回用于写入操作的锁 写入操作的锁和读取操作的锁不一样了，因为一次只能允许一个线程执行写入操作。 并且如果一个线程已经占用了读锁，另外一个线程申请写锁将会一直等待线程释放读锁。 如果一个线程已经占用了写锁，另外一个线程申请读锁，那么这个线程将会一直等待线程释放写锁才能执行。 总之意思就是写线程和读线程不能同时执行，但是多个读线程可以同时执行 下面将使用一个程序详细的体会以下读写锁的综合使用，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101//实现接口的线程类public class MyThread &#123; public ReentrantReadWriteLock rwlock = null; public Lock rLock = null; public Lock wLock = null; public ArrayList&lt;Integer&gt; arrayList = null; public MyThread() &#123; this.rwlock = new ReentrantReadWriteLock(); // 创建对象，使用的是非公平的 this.rLock = this.rwlock.readLock(); // 获取读取锁对象 arrayList = new ArrayList&lt;&gt;(); // 实例化 this.wLock = this.rwlock.writeLock(); // 获取写入锁对象 &#125; // 将unlock方法放在finally中确保执行中代码出现异常仍然能够释放锁，否则将会造成其它的线程阻塞 // //向arraylist中写入数据 public void put() &#123; this.wLock.lock(); // 获取写入锁 try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Thread.currentThread().getName() + "正在执行写入操作，写入" + i); this.arrayList.add(i); &#125; &#125; finally &#123; this.wLock.unlock(); &#125; &#125; // 从arraylist中读取数据，这里只是随机读取使用的是get，并没有做什么修改，因为这仅仅是读取操作，如果进行了修改必须实现同步 public void get() &#123; this.rLock.lock(); // 获取读取操作的锁 Random random = new Random(); if (!arrayList.isEmpty()) &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; int index = random.nextInt(this.arrayList.size() - 1); int data = this.arrayList.get(index); System.out.println(Thread.currentThread().getName() + "正在读取数据 " + data); &#125; &#125; finally &#123; this.rLock.unlock(); &#125; &#125; else &#123; System.out.println("ArrayList为空"); &#125; &#125;&#125;//线程的测试类，主要是创建对象启动线程public class Test &#123; public static void main(String[] args) &#123; final MyThread thread = new MyThread(); // 创建对象 ArrayList&lt;Thread&gt; arrayList = new ArrayList&lt;&gt;(); /* * 创建8个读线程，2个写线程 */ for (int i = 0; i &lt; 2; i++) &#123; arrayList.add(new Thread() &#123; @Override public void run() &#123; thread.put(); &#125; &#125;); &#125; for(int i=0;i&lt;8;i++) &#123; arrayList.add(new Thread()&#123; @Override public void run() &#123; thread.get(); &#125; &#125;); &#125; for (Thread t : arrayList) &#123; t.start(); &#125; &#125;&#125; 结果如下图: 从上面可以看出写入线程都是一个一个执行的，读取线程是一起执行的 注意： 所有的锁对象对于线程来说必须是全局变量，否则毫无意义。读线程只能进行不影响线程安全性的操作，比如不能进行对数据的修改插入，如果想要进行修改的话必须还要使用锁对必要的代码实现同步操作 参考文章 http://www.cnblogs.com/dolphin0520/p/3923167.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[synchronized]]></title>
      <url>%2F2017%2F06%2F20%2Fsynchronized%2F</url>
      <content type="text"><![CDATA[synchronized前言 相信大家都听说过线程安全问题，在学习操作系统的时候有一个知识点是临界资源，简单的说就是一次只能让一个进程操作的资源，但是我们在使用多线程的时候是并发操作的，并不能控制同时只对一个资源的访问和修改，想要控制那么有几种操作，今天我们就来讲讲第一种方法：线程同步块或者线程同步方法(synchronized) 实例 下面举一个例子说明synchronized关键字的使用 线程同步方法123456789101112131415161718192021222324252627public class Sychor &#123; public void insert(Thread thread) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(thread.getName() + "输出: " + i); &#125; &#125; public static void main(String[] args) &#123; final Sychor sychor = new Sychor(); Thread t1 = new Thread() &#123; public void run() &#123; sychor.insert(Thread.currentThread()); &#125;; &#125;; Thread t2 = new Thread() &#123; public void run() &#123; sychor.insert(Thread.currentThread()); &#125;; &#125;; t1.start(); t2.start(); &#125;&#125; 其中输出结果为下图 从上面的结果可以看出这里的两个线程是同时执行insert()方法的，下面我们在原有的代码上添加synchronized关键字看看效果如何，代码如下:123456789101112131415161718192021222324252627public class Sychor &#123; public synchronized void insert(Thread thread) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(thread.getName() + "输出: " + i); &#125; &#125; public static void main(String[] args) &#123; final Sychor sychor = new Sychor(); Thread t1 = new Thread() &#123; public void run() &#123; sychor.insert(Thread.currentThread()); &#125;; &#125;; Thread t2 = new Thread() &#123; public void run() &#123; sychor.insert(Thread.currentThread()); &#125;; &#125;; t1.start(); t2.start(); &#125;&#125; 上面程序的运行结果我就不列出来，自己可以试试，总之就是加上了synchronized关键字使得线程是一个一个的执行的，只有先执行完一个线程才能执行了另外一个线程。 线程同步块 当然上面的我们使用的是线程同步方法，我们可以使用线程同步块，这两个相比线程同步块更加灵活，只需要将需要同步的代码放在同步块中即可，代码如下；12345678910111213141516171819202122232425262728293031public class Sychor &#123; public void insert(Thread thread) &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(thread.getName() + "输出: " + i); &#125; &#125; &#125; public static void main(String[] args) &#123; final Sychor sychor = new Sychor(); Thread t1 = new Thread() &#123; public void run() &#123; sychor.insert(Thread.currentThread()); &#125;; &#125;; Thread t2 = new Thread() &#123; public void run() &#123; sychor.insert(Thread.currentThread()); &#125;; &#125;; t1.start(); t2.start(); &#125;&#125; 从上面的代码中可以看出这种方式更加灵活，只需要将需要同步的代码方法在同步块中，不需要同步的代码放在外面 详细原因 我们知道每一个对象都有一把锁，当我们使用线程同步方法或者线程同步块的时候实际上获得是对象的唯一的一把锁，当一个线程获得了这唯一的锁，那么其他的线程只能拒之门外了，注意这里我们说是一个对象，也就是说是同一个对象，如果是不同的对象，那么就不起作用了，因为不同对象有不同的对象锁，比如我们将上面的程序改成如下：123456789101112131415161718192021222324252627282930313233public class Sychor &#123; public void insert(Thread thread) &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(thread.getName() + "输出: " + i); &#125; &#125; &#125; public static void main(String[] args) &#123; //第一个线程 Thread t1 = new Thread() &#123; public void run() &#123; Sychor sychor = new Sychor(); //在run() 方法中创建一个对象 sychor.insert(Thread.currentThread()); &#125;; &#125;; //第二个线程 Thread t2 = new Thread() &#123; public void run() &#123; Sychor sychor = new Sychor(); //创建另外的一个对象 sychor.insert(Thread.currentThread()); &#125;; &#125;; t1.start(); t2.start(); &#125;&#125; 从上面的结果可知，此时线程同步块根本不起作用，因为他们调用的是不同对象的insert方法，获得锁是不一样的 上面我们已经说过一个对象有一把锁，线程同步方法和线程同步块实际获得的是对象的锁，因此线程同步块的括号中填入的是this，我们都知道this在一个类中的含义 一个类也有唯一的一把锁，我们前面说的是使用对象调用成员方法，现在如果我们要调用类中的静态方法，那么我们可以使用线程同步方法或者同步块获得类中的唯一一把锁，那么对于多个线程同时调用同一个类中的静态方法就可以实现控制了,代码如下:1234567891011121314151617181920212223242526272829public class Sychor &#123; // 静态方法 public static synchronized void insert(Thread thread) &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(thread.getName()+"输出 "+i); &#125; &#125; public static void main(String[] args) &#123; //第一个线程 Thread t1 = new Thread() &#123; public void run() &#123; Sychor.insert(Thread.currentThread()); //直接使用类调用静态方法 &#125;; &#125;; //第二个线程 Thread t2 = new Thread() &#123; public void run() &#123; Sychor.insert(Thread.currentThread()); //直接使用类调用静态方法 &#125;; &#125;; t1.start(); t2.start(); &#125;&#125; 为静态方法或者静态方法中的代码块加上同步锁 上面使用对象锁是为非静态方法实现线程同步的，因为我们在调用非静态方法的时候需要创建对象，因此这里使用的是对象锁。但是我们调用静态方法的时候直接使用的是类名直接调用，并没有用到对象，因此我们需要用到类锁，直接使用类名.class获取即可。 123456789public class myThread&#123; public static void display()&#123; synchronized(myThread.class)&#123; for(int i=0;i&lt;10;i++)&#123; System.out.println(i); &#125; &#125; &#125;&#125; 注意 要想实现线程安全和同步控制，如果执行的是非static同步方法或者其中的同步块，那么一定要使用同一个对象，如果调用的是static同步方法或者其中的同步块那么一定要使用同一个类去调用 如果一个线程访问的是static同步方法，而另外一个线程访问的是非static的同步方法，此时这两个是不会发生冲突的，因为一个是类的锁，一个是对象的锁 如果使用线程同步块，那么同步块中的代码是控制访问的，但是外面的代码是所有线程都可以访问的 当一个正在执行同步代码块的线程出现了异常，那么jvm会自动释放当前线程所占用的锁，因此不会出现由于异常导致死锁的现象 参考文章 http://www.cnblogs.com/dolphin0520/p/3923737.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Thread初探]]></title>
      <url>%2F2017%2F06%2F20%2FThread%E5%88%9D%E6%8E%A2%2F</url>
      <content type="text"><![CDATA[Thread初探前言 以前大家写的都是单线程的程序，全是在main函数中调用方法，可以清楚的看到它的效率是特别低的，就像python中使用单线程取爬一个网站，可以说能让你等的吐血，因为数据量实在太大了，今天我们就来看看java的并发编程多线程的学习 创建线程 创建一个线程可以有多种方法，比如继承Thread类，实现Runnable接口……下面我们来详细的看看创建的方法 继承Thread 为什么继承Thread可以直接调用start()方法启动线程呢，因为start()本身就是Thread的方法，也就是继承了Thread的start()方法，因此这个类的对象可以调用start()启动线程 12345678910111213141516//继承Threadpublic class MyThread extends Thread &#123; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(this.getName()+"正在跑"); &#125; &#125;&#125;public class Test&#123; public static void main(String[] args) &#123; Mythread t1=new MyThread(); //创建对象 t1.start(); //启动线程 &#125;&#125; 注意: 继承Thread类的创建方法一个对象只能创建一个线程，并不能多个线程共用一个对象，只能一个线程对应一个对象，因此我们来看看实现Runnable接口的类来实现多个线程共享同一个对象 实现Runnable接口12345678910111213141516171819202122232425//实现Runnable接口public class Demo implements Runnable &#123; @Override public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread().getName()+"正在跑"); &#125; &#125;&#125;//测试类public class Test&#123; public static void main(String[] args) &#123; Demo d=new Demo(); //创建对象 Thread thread1=new Thread(d); //为对象创建一个线程 Thread thread2=new Thread(d); //创建另外一个线程 //同时启动两个线程 thread1.start(); thread2.start(); &#125;&#125; 从上面可以清楚的看到实现Runnable接口的类一个对象可以供多个线程共享，并不像继承Thread类只为一个线程使用 简便的创建方法 直接在main方法中创建，如果创建的普通类的对象在外面，那么必须是final修饰，可以实现多个线程同时共享一个对象，这个和实现Runnable接口一样，这时候就要控制同步条件了，如果在run方法中定义对象，那么，就是一个线程对应一个对象,这个就和继承Thread类一样的效果。所以可以根据条件自由选择 123456789101112131415161718192021222324252627282930313233343536373839//普通的一个类public class Simple &#123; public void display() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread().getName()+"正在跑"); &#125; &#125;&#125;//线程测试类public class Test &#123; public static void main(String[] args) &#123; //如果在外面必须使用final，当然也可以直写在run方法中,不过写在外面可以实现多个线程共享一个对象 //写在run方法中当前对象只能为一个线程使用，和继承Thread类一样的效果 final Simple simple=new Simple(); //下面创建使用同一个对象创建同两个线程，实现多个线程共享一个对象，和实现Runnable接口一样的效果 Thread t1=new Thread()&#123; public void run() &#123; simple.display(); &#125;; &#125;; Thread t2=new Thread()&#123; public void run() &#123; simple.display(); &#125;; &#125;; //启动这两个线程 t1.start(); t2.start(); &#125;&#125; 常用的方法 static void sleep(long mils) 使正在运行的线程休眠mils毫秒，但是这里需要注意的是如果线程加了锁，那么使线程休眠并不会释放锁 String getName() 得到线程的名称，上面的程序中已经使用了这个方法 void setName(String name) 设置正在运行的线程的名字为name start() 启动线程，线程的创建并不意味着线程的启动，只有调用start()方法线程才是真正的开始运行 long getId() 返回线程的标识符 run() 线程执行的代码都放在run()方法中，在run方法中的调用是有序的，都是按照程序运行的顺序开始执行 使用 下面使用上面的方法创建一个实例 123456789101112131415161718192021222324252627282930313233343536//线程的类，继承Threadpublic class MyThread1 extends Thread &#123; public void run() &#123; // 重载run方法，并且在其中写线程执行的代码块 for (int i = 0; i &lt; 10; i++) &#123; // 获取线程的id和name System.out.println("Thread-Name: " + this.getName() + " Thread-id: " + this.getId()); try &#123; this.sleep(1000); // 线程休眠1秒 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;//线程测试的类public class Test &#123; public static void main(String[] args) &#123; MyThread1 t1 = new MyThread1(); // 创建线程 t1.setName("第一个线程"); // 设置线程的名字 MyThread1 t2 = new MyThread1(); t2.setName("第二个线程"); t1.start(); // 启动线程，开始运行 t2.start(); &#125;&#125; void join() 等待该线程终止才能运行其他的线程 void join(long mils) 等待该线程的时间为mils毫秒，一旦过了这个时间其他线程正常执行 使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//线程类public class MyThread1 extends Thread &#123; public void run() &#123; // 重载run方法，并且在其中写线程执行的代码块 for (int i = 0; i &lt; 10; i++) &#123; // 获取线程的id和name System.out.println("Thread-Name: " + this.getName() + " Thread-id: " + this.getId()); try &#123; this.sleep(1000); // 线程休眠1秒 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; MyThread1 t1 = new MyThread1(); // 创建线程 t1.setName("第一个线程"); // 设置线程的名字 t1.start(); // 启动线程，开始运行 try &#123; t1.join(); //阻塞其他线程，只有当这个线程运行完之后才开始运行其他的线程 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int i = 0; i &lt; 10; i++) &#123; System.out.println("主线程正在运行"); &#125; &#125;&#125;//输出结果/*Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9Thread-Name: 第一个线程 Thread-id: 9主线程正在运行主线程正在运行主线程正在运行主线程正在运行主线程正在运行主线程正在运行主线程正在运行主线程正在运行主线程正在运行主线程正在运行 */ getPriority() 得到当前线程优先级 setPriority(int num) 更改线程的优先级(0-10)默认的是5，优先级越高获得cpu资源的几率就会越高 使用1234567891011121314151617181920212223242526272829303132333435363738394041//线程类public class MyThread1 extends Thread &#123; public void run() &#123; // 重载run方法，并且在其中写线程执行的代码块 for (int i = 0; i &lt; 10; i++) &#123; // 获取线程的id和name System.out.println("Thread-Name: " + this.getName() + " Thread-id: " + this.getId()); try &#123; this.sleep(1000); // 线程休眠1秒 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; MyThread1 t1 = new MyThread1(); // 创建线程 t1.setName("第一个线程"); // 设置线程的名字 MyThread1 t2 = new MyThread1(); t2.setName("第二个线程"); t2.setPriority(8); //设置第二个线程的优先级为8，第一个线程的优先级为5(是默认的) t1.start(); t2.start(); &#125;&#125;/* * 从上面的运行结果可以看出大部分的第二个线程都是在第一个线程之前开始执行的，也就是说优先级越高获得cpu执行的几率就越大 * / setDaemon(boolean) 是否设置为守护线程，如果设置为守护线程，那么主线程销毁守护线程也会随之销毁 isDaemon() 判断是否为守护线程 使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//测试类public class MyThread1 extends Thread &#123; public void run() &#123; // 重载run方法，并且在其中写线程执行的代码块 for (int i = 0; i &lt; 10; i++) &#123; // 获取线程的id和name System.out.println("Thread-Name: " + this.getName() + " Thread-id: " + this.getId()); try &#123; Thread.sleep(1000); //休眠一秒，方便主线程运行结束 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; MyThread1 t1 = new MyThread1(); // 创建线程 t1.setName("第一个线程"); // 设置线程的名字 t1.setDaemon(true); t1.start(); for (int i = 0; i &lt; 1; i++) &#123; System.out.println(i); &#125; &#125;&#125;//结果：/* 0123456789Thread-Name: 第一个线程 Thread-id: 9*//* * 从上面的结果可以看出，一旦主线程结束，那么守护线程就会自动的结束 * / 参考文章 http://www.cnblogs.com/dolphin0520/p/3920357.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java正则表达式]]></title>
      <url>%2F2017%2F06%2F16%2FJava%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[Java正则表达式 java.util.regex是一个用正则表达式所订制的模式来对字符串进行匹配工作的类库包。它包括两个类：Pattern和Matcher。Pattern是一个正则表达式经编译后的表现模式。Matcher对象是一个状态机器，它依据Pattern对象做为匹配模式对字符串展开匹配检查。 首先一个Pattern实例订制了一个所用语法与PERL的类似的正则表达式经编译后的模式，然后一个Matcher实例在这个给定的Pattern实例的模式控制下进行字符串的匹配工作。 正则表达式的构造摘要 详细摘要请看jdk中文文档,下面我只是列出一些经常使用的 构造 匹配 . 任何字符（与行结束符可能匹配也可能不匹配） \d 数字：[0-9] \D 非数字： [^0-9] \s 空白字符：[ \t\n\x0B\f\r] \S 非空白字符：[^\s] \w 单词字符：[a-zA-Z_0-9] \W 非单词字符：[^\w] [abc] a、b 或 c（简单类） [^abc] 任何字符，除了 a、b 或 c（否定） [a-zA-Z] a 到 z 或 A 到 Z，两头的字母包括在内（范围） ^ 行的开头 $ 行的结尾 X? X，一次或一次也没有 X* X，零次或多次 X+ X，一次或多次 X{n} X，恰好 n 次 X{n,} X，至少 n 次 X{n,m} X，至少 n 次，但是不超过 m 次 Pattern 正则表达式的编译表示形式,学过python的都知道这个和python的正则表达式有异曲同工之妙。 但是它的构造方法是私有的，因此不能直接创建对象，但是可以调用它的静态方法返回一个对象，下面会详细介绍 创建对象 Pattern类用于创建一个正则表达式,也可以说创建一个匹配模式,它的构造方法是私有的,不可以直接创建,但可以通过Pattern.complie(String regex)简单工厂方法创建一个正则表达式，代码如下：12345//采用的complie(String regex)Pattern pattern = Pattern.compile("\\d+");//采用的是complie(String regex,int flag)其中flag表示标志，下面的标志表示忽略字母大小写，详细的字段请看文档Pattern pattern=Pattern.compile("(CHEN)(\\D*)(\\d*)",Pattern.CASE_INSENSITIVE); 常用方法 Pattern compile(String regex) 用于创建Pattern对象 Pattern compile(String regex,int flags) 用于创建Pattern对象，并且指定了标志(比如忽略字母大小写) int flags() 返回此模式的匹配标志 String pattern() 返回在其中编译过此模式的正则表达式。 String[] split(CharSequence input) 根据此模式的正则表达式将输入的字符串拆分成String数组,默认的都是全部拆分开 1234 //给出正则表达式用于匹配数字(0-9) Pattern pattern = Pattern.compile("\\d+"); String str = "我是陈加兵456郑元梅34擦市场的逻辑啊";String[] splits = pattern.split(str, 2); //结果:[我是陈加兵,郑元梅34擦市场的逻辑啊] String[] split(CharSequence input,int limit) 将字符串按照正则表达式表示的内容进行分组，如果limit&gt;0那么就分成limit个组，如果limit&lt;0就按照默认全部分开 1234//给出正则表达式用于匹配数字(0-9)Pattern pattern = Pattern.compile("\\d+");String str = "我是陈加兵456郑元梅34擦市场的逻辑啊";String[] splits = pattern.split(str, 2); //结果:[我是陈加兵,郑元梅34擦市场的逻辑啊] Pattern.matches(String regex,CharSequence input)是一个静态方法,用于快速匹配字符串,该方法适合用于只匹配一次,且匹配全部字符串 123Pattern.matches("\\d+","2223");//返回true Pattern.matches("\\d+","2223aa");//返回false,需要匹配到所有字符串才能返回true,这里aa不能匹配到 Pattern.matches("\\d+","22bb23");//返回false,需要匹配到所有字符串才能返回true,这里bb不能匹配到 Matcher matcher(CharSequence input) 创建匹配给定输入与此模式的匹配器,现在只是先了解以下，下面会详细解释Matcher这个类 12Pattern p=Pattern.compile("\\d+"); Matcher m=p.matcher("22bb23"); Matcher Pattern类只能做一些简单的匹配操作,要想得到更强更便捷的正则匹配操作,那就需要将Pattern与Matcher一起合作.Matcher类提供了对正则表达式的分组支持,以及对正则表达式的多次匹配支持.Matcher类和Pattern类一样它的构造方法同样是私有的，因此不能直接构造对象，但是上面我们说过Pattern类中有一个方法可以返回一个Matcher对象(matcher(CharSequence input)) 常用的方法 boolean mathces() 尝试将整个区域与模式匹配(针对的是整个字符串，如果整个字符串未完全匹配，那么返回false,如果完全匹配那么返回true) 12345 Pattern pattern=Pattern.compile("\\d+"); //创建Pattern对象String str="I am hreo 1234"; //需要匹配的字符串Matcher matcher=pattern.matcher(str); //并没有完全匹配，因此返回false，如果str="123445"，那么就会返回trueSystem.out.println(matcher.matches()); boolean lookingAt() 尝试从给定字符串的开头开始匹配，如果有子字符串匹配成功，那么返回true(针对的不是整个字符串，而是从开头开始，如果开头有一段字符串匹配成功，那么返回true) 12345 Pattern pattern=Pattern.compile("\\d+"); //创建Pattern对象String str="1234 I am a hero"; //需要匹配的字符串Matcher matcher=pattern.matcher(str);//开头的1234匹配到了，因此返回true，如果str="I am a hero 1234"将返回falseSystem.out.println(matcher.lookingAt()); int start() 匹配到的字符串的第一个元素的索引,如果没有匹配到调用此方法将会报错 int end() 匹配到的字符串的最后一个元素的索引,如果没有匹配到调用此方法将会报错 String group() 返回的是匹配到的字符串,如果没有匹配到调用此方法将会报错 123456789 Pattern pattern=Pattern.compile("\\d+"); //创建Pattern对象String str="1234 I am a hero 33455"; //需要匹配的字符串Matcher matcher=pattern.matcher(str);if(matcher.lookingAt())&#123; System.out.println("开始匹配到下标为"+matcher.start()); //0 System.out.println("匹配结束的下标为"+matcher.end()); //4 System.out.println("匹配的字符串为"+matcher.group()); //1234&#125; boolean find() 查找整个字符串，如果在任意位置有一段字符串能够匹配成功，那么返回true(任意位置),然后如果再次调用这个查找的话，那么就从上次查找到的末尾开始匹配，也就是说查找的是下一个子序列了 123456789101112131415161718192021222324252627 Pattern pattern=Pattern.compile("\\d+"); //创建Pattern对象String str="1234 I am a hero 6666 chenjiabing8888"; //需要匹配的字符串Matcher matcher=pattern.matcher(str);while(matcher.find()) //如果还有匹配的字符序列&#123; System.out.println("开始匹配到下标为"+matcher.start()); System.out.println("匹配结束的下标为"+matcher.end()); System.out.println("匹配的字符串为"+matcher.group()); &#125; /*结果如下： * 开始匹配到下标为0 匹配结束的下标为4 匹配的字符串为1234 开始匹配到下标为17 匹配结束的下标为21 匹配的字符串为6666 开始匹配到下标为33 匹配结束的下标为37 匹配的字符串为8888 */ /* * 从上面返回的结果可以知道，find()可以匹配多次只要这个字符串还有可以匹配， * 并且每次的匹配字段的开始下标都是上一次匹配的结束字母的下一个下标 */ boolean find(int start) 从指定的索引start位置开始匹配，这个用于重置find()匹配器，因为直接使用find()它的每次开始的索引都是不一样的 String group(int num) 返回指定分组匹配到的字符串,group(0)表示匹配到的整个字符串,group(1) 表示匹配到的第一个字符(即是第一个括号中匹配的模式) int groupCount() 返回匹配到的分组个数 String replaceAll(String str) 将所有于模式相匹配的 字符串全部替换程指定的字符串str,返回的是替换后的文本 String replaceFirst(String str) 只将第一次匹配到的字符串替换成指定的字符串str，返回的时替换后的文本 12345678910Pattern pattern=Pattern.compile("\\d+");String str="chenjiabing2344cal3445";Matcher matcher=pattern.matcher(str);str=matcher.replaceFirst("陈加兵"); System.out.println(str); //输出:chenjiabing陈加兵cal3445 /* * str=matcher.replaceAll("陈加兵"); * System.out.println(str) //输出:chenjiabing陈加兵cal陈加兵 */ 捕获组 捕获组可以通过从左到右计算其开括号来编号，编号是从1 开始的。例如，在表达式 ((A)(B(C)))中，存在四个这样的组：1234((A)(B(C)))(A)(B(C))(C) 总之在正则表达式中在括号中的就是一个分组,下面用一个实例来理解一下12345678910 Pattern pattern=Pattern.compile("(\\D*)(\\d+)\\s(\\D+)");Matcher matcher=pattern.matcher("chenjiabingshizuibangde6666 chenjiabign");if(matcher.find())&#123; System.out.println("总共匹配到了"+matcher.groupCount()+"个分组"); System.out.println("匹配到整个字符串为"+matcher.group(0)); System.out.println("匹配到的第一个字符串为"+matcher.group(1)); System.out.println("匹配到的第二个字符串为"+matcher.group(2)); System.out.println("匹配到的第三个字符串为"+matcher.group(3));&#125; 贪婪模式和非贪婪模式 贪婪与非贪婪模式影响的是被量词修饰的子表达式的匹配行为，贪婪模式在整个表达式匹配成功的前提下，尽可能多的匹配，而非贪婪模式在整个表达式匹配成功的前提下，尽可能少的匹配一般写python爬虫的时候使用的都是非贪婪模式来匹配使用了贪婪模式后会尽可能匹配更多的字符串，即是到了正则表达式定的末尾但是还是会继续向后匹配，看看是否还能匹配，非贪婪模式则是相反，到了正则表达式定义的结束字符就直接停止匹配了贪婪模式: .* , .+非贪婪模式: .*? , .+? 实例123456789101112 //使用了贪婪模式,因此当匹配到第一个&lt;/div&gt;的时候还要向后面匹配看看是否还能匹配到，由于后面还有&lt;/div&gt;结尾的，因此还是能够匹配的，因此匹配到的是:陈加兵&lt;/div&gt;&lt;div&gt;郑元梅 Pattern pattern=Pattern.compile("&lt;div&gt;(.*)&lt;/div&gt;"); //使用了非贪婪模式，因此当匹配到第一个&lt;/div&gt;的时候就不向后面匹配了，直接返回了，因此匹配到的是:陈加兵Pattern pattern1=Pattern.compile("&lt;div&gt;(.*?)&lt;/div&gt;"); String str="&lt;div&gt;陈加兵&lt;/div&gt;&lt;div&gt;郑元梅&lt;/div&gt;";Matcher matcher=pattern1.matcher(str);if(matcher.find())&#123; System.out.println(matcher.groupCount()); //1 System.out.println(matcher.group(1)); //输出匹配到的字符串,此时输出的是:陈加兵,如果使用贪婪模式输出的是：陈加兵&lt;/div&gt;&lt;div&gt;郑元梅&#125; 参考文章 http://www.cnblogs.com/ggjucheng/p/3423731.html http://www.runoob.com/java/java-regular-expressions.html http://blog.csdn.net/lxcnn/article/details/4756030]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java日期格式化]]></title>
      <url>%2F2017%2F06%2F15%2FJava%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%2F</url>
      <content type="text"><![CDATA[日期格式化前言 更多文章请看本人博客https://chenjiabing666.github.io/ 版权所有，如需转载请注明来源 Date Date类表示特定的瞬间精确到毫秒，不过从API可以看出很多的方法已经废弃了，这个类已经在过多使用了，不过还是需要了解一下的，为了后面的学习做铺垫 构造方法 new Date() 常用的方法 long getTime() 返回计算机上面的时间，返回的是毫秒 setTime(long s) 用给定的毫秒值s设置时间 实例12Date date=new Date();System.out.println(date.getTime()); SimpleDateFormat 这个类是一个简单的格式化日期的类，继承与DateFormat,相对于父类来说使用简单 构造方法 new SimpleDateFormat() 使用默认的格式化模板创建对象 new SimpleDateFormat(String pattern) 使用指定的格式化模板创建对象 常用的方法 String format(Date date) 将给定的日期格式化指定的模板的样式,比如2017-01-29 23:22:11 applyPattern(String pattern) 将给定的格式应用于此日期的格式，相当于直接使用new Date(String pattern) Date parse(String d) 将给定的格式化的日期格式字符串转换成Date对象，需要注意的是转化的时候定义的模板一定要和字符串的日期格式的模板一样，否则将会解析不正确的形式 常用的日期格式化的模板 实例 使用默认的模板格式化日期 123SimpleDateFormat dateFormat=new SimpleDateFormat(); //默认的格式String formateString=dateFormat.format(date); //格式化当前的日期System.out.println(formateString); 使用指定的模板格式化日期 123String model="yyyy-MM-dd-FF HH:mm:ss"; //指定格式化的模板SimpleDateFormat dateFormat2=new SimpleDateFormat(model);System.out.println(dateFormat2.format(date)); 将格式化的日期转换成Date类型的，使用的parse(String s)，需要注意的是，下面定义的模板一定要和给定的格式化后的日期格式一样，否则转换后Date类型的毫秒值可能不正确 12345678910 String d = "2017-06-12 22:34:19"; //给出格式化后的日期String pattern = "yyyy-MM-dd HH:mm:ss"; //按照上面的日期格式定义模板，这个一定要完全和上面的一样，否则转换不正确SimpleDateFormat dateFormat = new SimpleDateFormat(pattern);try &#123; Date date = dateFormat.parse(d); //解析成Date类型 System.out.println(dateFormat.format(date));&#125; catch (ParseException e) &#123; System.err.println("解析错误");&#125; 综合使用：计算时间差 12345678910111213Scanner scanner=new Scanner(System.in);System.out.println("请输入年-月-日");String startTime=scanner.next();System.out.println("请输入结束时间(年-月-日)");String endTime=scanner.next();String moudle="yyyy-MM-dd"; //定义时间模板//创建指定模板的解析SimpleDateFormat dateFormat=new SimpleDateFormat(moudle);Date startDate=dateFormat.parse(startTime);//解析开始时间Date endDate =dateFormat.parse(endTime);//解析结束时间long time=startDate.getTime()-endDate.getTime(); //返回两个时间的差，毫秒int day=(int)(time/1000/60/60/24); //转化为天数，1秒等于1000毫秒，一分钟等于60秒，一小时等于60分钟，一天等于24小时System.out.println(day); Calendar Calendar 类是一个抽象类，它为特定瞬间与一组诸如 YEAR、MONTH、DAY_OF_MONTH、HOUR 等 日历字段之间的转换提供了一些方法，并为操作日历字段（例如获得下星期的日期）提供了一些方法。瞬间可用毫秒值来表示，它是距历元（即格林威治标准时间 1970 年 1 月 1 日的 00:00:00.000，格里高利历）的偏移量。 创建对象 Calendar.getInstance() 常用方法 int get(int field) 返回当前对象的一些日期信息 Date getTime() 获得当前日期的Date对象 add(int field,int amount) 根据日历的规则，为给定的日历字段添加或减去指定的时间量。例如，要从当前日历时间减去 5 天，可以通过调用以下方法做到这一点：add(Calendar.DAY_OF_MONTH, -5)。 setTime(Date date) 使用给定的Date对象，设置Calendar时间 实例 get方法获取一些字段的值 1234567891011121314151617181920 Calendar calendar = Calendar.getInstance(); // 创建对象System.out.println(calendar.get(Calendar.YEAR));// 获取年份System.out.println(calendar.get(Calendar.MONTH) + 1);// 月，从0开始，即是输出5表示6月System.out.println(calendar.get(Calendar.DATE));// 获取一个月中的第几天System.out.println(calendar.get(Calendar.HOUR)); // 小时System.out.println(calendar.get(Calendar.MINUTE)); // 分钟System.out.println(calendar.get(Calendar.SECOND)); // 秒System.out.println(calendar.get(Calendar.AM_PM)); // 获得是上午还是下午AM=0,PM=1System.out.println(calendar.get(Calendar.DAY_OF_MONTH)); // 一个月中的第几天System.out.println(calendar.get(Calendar.DAY_OF_WEEK)); // 一周中的第几天，星期日是第一天System.out.println(calendar.get(Calendar.DAY_OF_YEAR));// 一年中的第几天System.out.println(calendar.get(Calendar.HOUR_OF_DAY)); // 一天中的第几小时if (calendar.get(Calendar.AM_PM) == Calendar.AM) &#123; System.out.println("现在是上午");&#125;if (calendar.get(Calendar.MONTH) + 1 == Calendar.JULY) &#123; System.out.println("现在是6月");&#125; Date getTime()方法的使用 12345Calendar calendar=Calendar.getInstance();Date date=calendar.getTime(); //获得Date对象String pattern="yyyy-MM-dd HH:mm:ss";SimpleDateFormat dateFormat=new SimpleDateFormat(pattern);System.out.println(dateFormat.format(date)); add(int field,int amount)方法的使用 123 Calendar calendar=Calendar.getInstance();calendar.add(Calendar.DATE, -2);System.out.println(calendar.get(Calendar.DATE)); 综合实例：计算出当前的准确日期 12345678910111213141516171819 Calendar calendar = Calendar.getInstance();int year = calendar.get(Calendar.YEAR);int month = calendar.get(calendar.MONTH) + 1; // 从0开始算，因此加1int date = calendar.get(Calendar.DATE);int week = calendar.get(Calendar.WEEK_OF_MONTH) + 1; // 从周日开始算，因此加1int hour = calendar.get(Calendar.HOUR);int minute = calendar.get(Calendar.MINUTE);int seconds = calendar.get(Calendar.SECOND);if (calendar.get(Calendar.AM_PM) == Calendar.AM) &#123; System.out.println("现在是" + year + "年" + month + "月" + date + "号" + "星期" + week + "上午" + hour + "点" + minute + "分" + seconds + "秒");&#125; else &#123; System.out.println("现在是" + year + "年" + month + "月" + date + "号" + "星期" + week + "下午" + hour + "点" + minute + "分" + seconds + "秒");&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java反射机制]]></title>
      <url>%2F2017%2F06%2F14%2FJava%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[Java反射机制前言 网页版的jdk的API 离线版API 什么是反射机制 反射是java语言的一个特性，它允程序在运行时（注意不是编译的时候）来进行自我检查并且对内部的成员进行操作。例如它允许一个java的类获取他所有的成员变量和方法并且显示出来。这个能特定我们不常看到，但是在其他的比如C或者C++语言中很不就存在这个特性。一个常见的例子是在JavaBean中，一些组件可以通过一个构造器来操作。这个构造器就是用的反射在动态加载的时候来获取的java中类的属性的。 主要的类 Class 类的实例表示正在运行的 Java 应用程序中的类和接口。Class没有公共的构造方法，Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的 Constructor 提供关于类的单个构造方法的信息以及对它的访问权限(主要提供的是对构造方法使用) Method 提供关于类或接口上单独某个方法（以及如何访问该方法）的信息。所反映的方法可能是类方法或实例方法（包括抽象方法) Field 主要提供对类中的成员变量的访问和使用 Class Class类也使用了泛型，即是Class这种形式的，可以直接使用一个具体的类传入，这样的话就不需要强制转换了，比如Class.newInstance()这样使用默认的构造方法构造一个对象就需要不再需要强制转换了即使用(ClassName)Class.newInstance() 常用的方法 getConstructor(Class[] params) 获取公共的(public)的构造方法，并且限定其中的参数个数和类型可以获得不同的公共构造方法 Constructor[] getConstructors() 返回所有的公共(public)的构造方法 getDeclaredConstructor(Class[] params) 获取所有指定的构造方法，但是需要注意的是当获取私有的构造方法的时候需要使用setAccessible设置访问权限为true才能进行构造，否则出现异常 Constructor[] getDeclaredConstructors() 返所有的构造方法包括public和private，protected修饰的 T newInstance() 返回的是一个调用默认的构造方法(public class_name())实例化的一个Object对象，如果使用泛型那么就返回T类型的，反之返回的是Object需要强制转换才能使用这个对象调用成员函数和成员变量 Class forName(String class_name) 返回class对象，每一个类都有一个方法返回Class对象(类名.class)，注意这里的参数一定是具体的路径，包括包的名字，比如demo.Test Package getPackage() 返回此类所在的包名(package demo) 当然也可以使用Package.getName()获得包的名字(demo)比如class1.getPackage().getName() int getModifiers() 返回的是类的修饰符的整数 类型(修饰符的类型有public private protected)其中得到整数可以使用Modifier中toString(int num)得到public，private，protected的类型,比如Modifier.toString(class1.getModifiers())*Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 返回指定参数的方法Method对象,注意这里仅仅是返回的时公共的方法(public) 比如:Method method=class1.getMethod(&quot;display&quot;,new Class[]{int.class})这里的display是方法的名字，有一个参数，类型为int Method[] getMethods() 获取所有的公共的方法(public)返回的是一个数组(Method) Method getDeclaredMethod(String name,Class&lt;?&gt;... parameterTypes)返回所有的指定的参数的方法(public,private,protected，但是不包括继承的),其中参数可以为null(无参数) Method[] getDeclaredMethods() 获取所有的方法 Field getField(String name) 指定名字的公共成员变量(public) Field[] getFields() 获取所有的公共的成员变量 Field getDeclaredField(String name) 获取所有的指定名称的成员变量(public,protected,private),同样在调用私有成员变量的时候需要先设置访问的权限,field.setAccessible(true) Field[] getDeclaredFields() 获取所有的成员变量(public,protected,private) getSuperclass() 返回表示此 Class 所表示的实体（类、接口、基本类型或 void）的超类的 Class。 URL getResource(String name) 查找指定名称的资源(图片，文件…)注意这个资源一定要和指定类在一个包中，否则返回null，比如查找Test类下的airplane.png图片:Test.class.getResource(&quot;airplane.png&quot;)这里返回的将是绝对路径 获取Class的对象并且实例化 使用Class.forName(String className) 其中className一定是包含包的名字，下面的demo就是包的名字，Test是类的名字。这是最常用的方法，学过JDBC的都知道加载驱动的时候就是使用的Class.forName() 12345/* * 第一种使用forName(String className),其中className一定是包含包的名字，下面的demo就是包的名字，Test是类的名字 */Class cls=Class.forName("demo.Test");Test test=(Test)cls.newInstance(); //这里只是使用了默认的构造方法实例化对象 使用类名.class 1Class cls=Test.class; 使用对象.getClass() 12Test test=new Test();Class cls=test.getClass(); Constructor 主要是用来对类的构造方法进行操作的，可以看出这个也使用了泛型，和上面的Class是一样的，注意这里如果没有使用泛型，那么原本放回T类型的现在都是返回Object 常用的方法 T newInstance(Object parms) 使用带有参数的构造方法实例化对象，如果使用了泛型，那么返回的就是T类型的，反之返回的是Object类型的，需要强制转换 getName() 以字符串的形式返回构造方法的名称，具体的路径包含包名(demo.Test) int getModifiers() 和Class类中的方法一样 Method 主要提供的是对类中的方法的操作 常用的方法 Object invoke(Object obj,object args) 使用得到的Method对象调用方法，obj是类的已经构造好的对象，如果是静态方法直接写null,因为静态方法的调用不需要对象，返回值是Object类型的，如果接受返回值，需要使用强制转换成相应的类型,args是传入的参数,如果有多个参数，那么可以直接在后面用逗号添加或者直接创建数组new Object[]{22,&quot;chenjiabing&quot;}比如：method.invoke(test,22,&quot;chenjiabing&quot;) method.invoke(test,new Object[]{22,&quot;chenjiabing&quot;})注意：如果调用的private类型的方法，那么需要在前面设置访问的权限,method.setAccessible(true) String getName() 返回此方法的名字(display) Modifier getModifiers() 返回此方法的修饰符的类型表示的整数(public,private…),可以使用Modifier.toString()转换成字符串形式 Class getReturnType() 返回这个方法的返回类型 String toString() 返回这个方法表示的字符串的形式 Field 主要提供对类的成员变量的操作 常用方法 String getName() 返回变量名字 Object get(Object obj) 返回此变量在指定对象中的值，因为在构造对象的时候每一个传入的变量的值都不一样，因此需要使用对象obj。obj表示传入的对象，返回的Object类型，因此需要强制转换 void set(Object obj,Object value) 改变obj对象上的变量的值为value Modifier getModifiers() 返回整数表示修饰的类型 String getType() 获取变量的类型(int,String,double float…..) Modifier Modifier 类提供了 static 方法和常量，对类和成员访问修饰符进行解码。修饰符集被表示为整数，用不同的位位置 (bit position) 表示不同的修饰符。 常用的方法 static String toString(int mode) 将代表修饰符的整数形式转换为字符串形式的修饰符，比如将1转换成public static isInterface(int mode) 如果整数参数包括 interface 修饰符，则返回 true，否则返回 false static isStatic(int mode) static isPrivate(int mode) static isPublic(int mode) static isAbstract(int mode) 实例1Modifier.toString(Test.class.getModifiers()) //得到Test类的修饰符 使用 有了上面的铺垫，我们就可以使用上面的这些类进行操作了，在进行操作之前，我们需要先定义一个类Test,放在demo包下，内容如下 12345678910111213141516171819202122232425262728293031323334package demo;import java.util.jar.Attributes.Name;import javax.print.attribute.standard.MediaSize.NA;public class Test &#123; public String name; private int age; public Test() &#123; this.name = "陈加兵"; this.age = 23; &#125; public Test(String name, int age) &#123; this.name = name; this.age = age; &#125; public void display() &#123; System.out.println("name=" + this.name + "----age=" + this.age); &#125; public void set(String name, int age) &#123; this.name = name; this.age = age; &#125; private int getAge() &#123; return this.age; &#125;&#125; 实例化对象 使用Class默认的构造newInstance() 123 Class class1=Class.forName("demo.Test"); //静态加载ClassTest test=(Test)class1.newInstance(); //调用默认的构造方法(public Test())实例化对象，由于没有使用泛型，因此需要强转test.display(); //调用display方法 使用Class中的getConstructor()方法构造对象,需要注意的使用private类型构造方法时一定要先设置访问权限为true-constructor.setAccessible(true); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 /* *调用public Test(String name,int age)得到Constructor的两种形式 * 1.Constructor constructor=class1.getConstructor(new Class[]&#123;String.class,int.class&#125;); * 2.Constructor constructor=class1.getConstructor(String.class,int.class);这个和上面的是一样的，就是使用的参数形式不一样 * * * * *使用newInstance()构造对象的两种方式 * 1.Test test=(Test)constructor.newInstance(new Object[]&#123;"chenjiabing",22&#125;); * 2.Test test=(Test)constructor.newInstance("chenjiabing",22); 只是形式不同而已，不过我还是喜欢上面的形式 * */ /* * 调用public Test(String name,int age) * Class.getConstructor()得到的是公共的构造方法，如果有私有的构造方法，那么就会报错，这时就要使用getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) * Test test=(Test)constructor.newInstance("陈加兵",22); * * * 调用public Test() * Constructor constructor=class1.getConstructor(null); * Test test=(Test)constructor.newInstance(null); * * * 调用private Test(int age) * Constructor constructor=class1.getDeclaredConstructor(new Class[]&#123;int.class&#125;); constructor.setAccessible(true); //因为private类型是不可以直接访问的，因此需要设置访问权限为true Test test=(Test)constructor.newInstance(new Object[]&#123;1000&#125;); */ Class class1=Class.forName("demo.Test"); //访问public Test(String name,int age)// Constructor constructor=class1.getConstructor(new Class[]&#123;String.class,int.class&#125;);// Test test=(Test)constructor.newInstance("陈加兵",22); //访问默认的构造方法// Constructor constructor=class1.getConstructor(null);// Test test=(Test)constructor.newInstance(null); //访问private类型的构造方法 Constructor constructor=class1.getDeclaredConstructor(new Class[]&#123;int.class&#125;); constructor.setAccessible(true); Test test=(Test)constructor.newInstance(new Object[]&#123;1000&#125;); test.display(); 成员方法的操作 使用Class.getMethod()和Class.getDeclaredMethod()方法获取方法，这两个方法的区别前面已经说过了，注意的是调用私有成员方法的之前一定要设置访问权限(method.setAccessible(true)) Method类中的其他方法前面也已经说过了，详细使用请自己尝试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 /* * 获取Method对象的两种方式: * 1.Method method_set=class1.getMethod("set", new Class[]&#123;String.class,int.class&#125;); * 2.Method method_set=class1.getMethod("set", String.class,int.class); * * * 使用Method.invoke()调用方法的两种方式 * 1.Object o=method_set.invoke(test, new Object[]&#123;"陈加兵",200&#125;); * 2.Object object=method_set.invoke(test, "陈加兵",2000); */ /* * 获取公共方法(public)： * 1.Method method=class1.getMethod("display",null); //public void display() * 2.Method method_set=class1.getMethod("set", new Class[]&#123;String.class,int.class&#125;); //获取public void set(String name,int age) * * * 获取私有方法(private,protected) * 1.Method method_getAge=class1.getDeclaredMethod("getAge", null); */ //使用构造方法构造一个Test对象 Class class1 =Class.forName("demo.Test"); Constructor&lt;Test&gt; constructor=class1.getDeclaredConstructor(new Class[]&#123;String.class,int.class&#125;); Test test=constructor.newInstance(new Object[]&#123;"陈加兵",22&#125;); Method method=class1.getMethod("display",null); //获取public void display()方法的Method对象 Object obj=method.invoke(test, null); //调用方法display //获取public void set(String name,int age)// Method method_set=class1.getMethod("set", new Class[]&#123;String.class,int.class&#125;); Method method_set=class1.getMethod("set", String.class,int.class); // Object o=method_set.invoke(test, new Object[]&#123;"陈加兵",200&#125;); Object object=method_set.invoke(test, "陈加兵",2000); test.display(); //获取私有方法private int getAge() Method method_getAge=class1.getDeclaredMethod("getAge", null); method_getAge.setAccessible(true); //必须设置访问权限为true //判断返回值类型是否为int类型的 if("int".equals(method_getAge.getReturnType().toString())) &#123; int ReturnData=(int) method_getAge.invoke(test, null); //调用并且获取返回值 System.out.println(ReturnData); &#125; 成员变量的操作 主要使用的Field类，前面已经详细的说过了 123456789101112131415161718/* * 获取public修饰的成员变量： * 1.Field field=class1.getField("name"); //获取public的成员变量name的Filed对象 * * 获取private，protected修饰的成员变量： * 1. Field field2=class1.getDeclaredField("age"); */ Class class1=Class.forName("demo.Test"); Test test=new Test("陈加兵",1000); Field field=class1.getField("name"); //获取public的成员变量name的Filed对象 System.out.println(field.get(test)); //获得test对象中的name属性的值 //获取private int age的Field对象 Field field2=class1.getDeclaredField("age"); field2.setAccessible(true); //设置访问权限 System.out.println(field2.get(test)); 参考文章 http://www.cnblogs.com/octobershiner/archive/2012/03/18/2404751.html http://www.cnblogs.com/ixenos/p/5699420.html https://yq.aliyun.com/wenzhang/show_17985]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记总结]]></title>
      <url>%2F2017%2F05%2F26%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Java IO学习笔记总结前言 前面的八篇文章详细的讲述了Java IO的操作方法，文章列表如下 基本的文件操作 字符流和字节流的操作 InputStreamReader和OutputStreamWriter操作 内存操作流 管道流 打印流 System对IO的支持 BufferedReader和BufferedWriter 后续字节流 字节流的操作都是基于InputStream和OutputStream这两个抽象类 InputStream InputStream是字节输入流，主要的功能是从文件中读取数据,它的子类有内存操作流 ByteArrayInputStream，管道输入流PipedInputStream，和FileInputStream OutPutStream OutputStream是字节输出流，主要功能是向文件中写入数据，它的常用的子类有ByteArrayOutputStream, FileOutputStream, PipedOutputStream,PrintStream 字符流 字符流的操作都是基于家Writer和Reader这两个抽象类的，一个是输出流，一个是输入流 Writer 写入字符流的操作类，常用的子类有PrintWriter,BufferedWriter,OutputStreamWriter(字节流和字符流之间的桥梁) Reader 用于读取字符流的抽象类,常用的子类有BufferedReader，InputStreamReader 最好用的 其中最高效的输入和输出当然是字符流操作的BufferedReader和BufferedWriter 最便捷的，格式化最好的当然是PrintStream,PrintWriter这两个类都采用了格式化的输入和输出 输出流最好用的 输出流中比较好用的是PrintStream,PrintWriter 输出流最好用的当然是BufferedWriter和PrintWriter的结合，例子如下； 12345678File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt");//用BufferedWriter实例化PrintWriter，显著提高写入的效率PrintWriter printWriter=new PrintWriter(new BufferedWriter(new FileWriter(file)));String name="陈加兵";int age=22;float grade=99.9f;printWriter.printf("姓名:%s,年龄:%s,grade:%s",name,age,grade); //格式化的写入printWriter.close(); 输入流最好用的 本人觉得输入流中BufferedReader功能已经很强大了 综合运用 有时候在写程序的时候，你得到了一个字节流，但是你想要创建的却是字符流对象，怎么办了呢？前面已经说过，字节流转换成字符流对象的桥梁是InputStreamReader和InputStreamWiter他们的作用是传入字节流对象构造字符流对象，因此可以完美的实现字节流转换成字符流，这个是非常重要的 下面使用转换流将System.in转换成字符流并且使用高效流读取控制台输入的数据,代码如下:12345678910 // 读取键盘的输入的数据，System.in是字节流，因此要想创建高效流必须使用转换流InputStreamReaderBufferedReader br = new BufferedReader(new InputStreamReader(System.in));String line;//从键盘读取输入的数据，直到读到bye结束while ((line = br.readLine()) != null) &#123; if ("bye".equals(line)) &#123; break; &#125; System.out.println(line);&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记八]]></title>
      <url>%2F2017%2F05%2F26%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AB%2F</url>
      <content type="text"><![CDATA[BufferedReader和BufferedWriter 这两个类是高效率的提高文件的读取速度，它们为字符输入和输出提供了一个缓冲区，可以显著的调高写入和读取的速度，特别针对大量的磁盘文件读取的时候,下面着重的讲讲这两个类 BufferedReader 从字符输入流中读取文本，缓冲各个字符，从而实现字符、数组和行的高效读取,要特别注意的是这个市针对字符流而不是字节流。 通常，Reader 所作的每个读取请求都会导致对底层字符或字节流进行相应的读取请求。因此，建议用 BufferedReader 包装所有其 read()操作可能开销很高的Reader（如 FileReader 和 InputStreamReader） 构造函数 BufferedReader(Reader in) 创建一个使用默认大小输入缓冲区的缓冲字符输入流。 BufferedReader(Reader in, int sz) 创建一个使用指定大小输入缓冲区的缓冲字符输入流。 实例 可以看出构造函数使用了Reader这个抽象类来初始化，我们前面说过这个是针对字符流的读取，因此可以使用Reader类的两个子类FileReader,InputStreamReader来初始化 1234File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt");BufferedReader bufferedReader=new BufferedReader(new FileReader(file)); //使用FileReader实例化//使用InputStreamReader来实例化BufferedReader bufferedReader=new BufferedReader(new InputStreamReader(new FileInputStream(file))); 常用方法 close() String readLine() 读取一行的数据 int read() 读取一个字符，注意这里的和字节的不一样，这里的汉字占用了一个字节，前面讲到读取字节流的时候使用byte读取汉字占用三个字节 skip(int n) 跳过n个字节 ready() 判断此流是否已准备好被读取。 实例 用于控制台的读取,前面已经说过System.in返回的是InputStream类型的，因此可以使用InputStreamReader实例化,当然这个有点多余了，我们完全可以使用java.util提供的Scanner直接进行输入 123BufferedReader bufferedReader=new BufferedReader(new InputStreamReader(System.in)); String str=bufferedReader.readLine(); //将控制台输入的字符串读取 System.out.println(str); //打印出来 用于文件的读取 1234567891011121314151617181920212223242526 BufferedReader bufferedReader=new BufferedReader(new FileReader(file)); // BufferedReader bufferedReader=new BufferedReader(new InputStreamReader(new FileInputStream(file)));// bufferedReader.skip(2); //跳过两个字节// // 第一种读取的方式 while(bufferedReader.ready()) //判断是否还有字符 &#123; String str=bufferedReader.readLine(); //直接读取一行 System.out.println(str); &#125; bufferedReader.close(); //第二种读取方式 int len=bufferedReader.read(); while(len!=-1) //判断是否读到文件的末尾 &#123; System.out.print((char)len); //强制转化成字符 len=bufferedReader.read(); &#125; //第三种方式，根据readLine读取一行，如果到达了文件的末尾返回null String s; while((s=bufferedReader.readLine())!=null) &#123; System.out.println(S); &#125; BufferedWriter 将文本写入字符输出流，缓冲各个字符，从而提供单个字符、数组和字符串的高效写入。 通常 Writer 将其输出立即发送到底层字符或字节流。除非要求提示输出，否则建议用 BufferedWriter 包装所有其 write() 操作可能开销很高的 Writer（如 FileWriters 和 OutputStreamWriters）。例如 12PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter("foo.out"))); 构造函数 BufferedWriter(Writer out) 创建一个使用默认大小输出缓冲区的缓冲字符输出流。 BufferedWriter(Writer out, int sz) 创建一个使用给定大小输出缓冲区的新缓冲字符输出流。 12File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt");BufferedWriter bufferedWriter=new BufferedWriter(new FileWriter(file)); 注意这里的FileWriter是Writer的子类，因此可以使用其实例化 常用函数 close() flush() newLine() 写入一个与平台相关的换行符 write(int data) 写入一个字符，这里的写入的不是整数 write(String str) 写入一个字符串 write(String str,int off,int len) 写入部分字符串 write(char[] c) write(char[] c,int off,int len) 实例1234567891011121314151617181920File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt");File file1=new File("/tmp"+File.separator+"test");File file2=new File("/tmp"+File.separator+"test"+File.separator+"demo.txt");if(!file1.exists())&#123; file1.mkdir(); System.out.println("文件夹创建成功");&#125;BufferedWriter bufferedWriter=new BufferedWriter(new FileWriter(file));String str="陈加兵";int data=48;String name="chenjiabing";char[] chars=name.toCharArray();bufferedWriter.write(str); //写入一个字符串，当然也可以截取这个字符串的某一段bufferedWriter.newLine(); //写入一个平台自带的换行符，因为每一个操作系统的换行符都不一样bufferedWriter.write(data); //写入的并不是整数，而是这个整数所代表的字符bufferedWriter.newLine();bufferedWriter.write(chars,1,4); //写入字符数组bufferedWriter.flush();bufferedWriter.close() 拓展：通过了上面的学习，你不觉得使用这个类写入文件数据有点烦了，只能写入String char类型的数据，此时我们就想到了前面说过的打印流(PrintWriter)，这是一个便捷的写入文件的类，可以指定任意格式任意类型的数据，同样是输出流，我么可以将他们结合起来，构成一个更加强大的输出流，如下: 12345678File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt");//用BufferedWriter实例化PrintWriter，显著提高写入的效率PrintWriter printWriter=new PrintWriter(new BufferedWriter(new FileWriter(file)));String name="陈加兵";int age=22;float grade=99.9f;printWriter.printf("姓名:%s,年龄:%s,grade:%s",name,age,grade); //格式化的写入printWriter.close(); 综合实例 将一个文件中数据转移到另外一个文件中 123456789101112131415161718192021222324252627282930313233343536373839package IO;import java.io.*;/** * Created by chenjiabing on 17-5-26. */public class demo13 &#123; /** * 常用函数： * newLine() * write(String str) * write(String str,int off,int len) * write(Char[] c) * write(Char[] c,int off,int len) * write(int data) * close() * flush() */ public static void main(String[] args) throws IOException &#123; File file = new File("/tmp" + File.separator + "test" + File.separator + "test.txt"); File file1 = new File("/tmp" + File.separator + "test"); File file2 = new File("/tmp" + File.separator + "test" + File.separator + "demo.txt"); BufferedWriter bufferedWriter = new BufferedWriter(new FileWriter(file2)); BufferedReader bufferedReader = new BufferedReader(new FileReader(file)); while (bufferedReader.ready()) &#123; String str = bufferedReader.readLine(); //读取文件test.txt中的一行数据 bufferedWriter.write(str); //将这一行数据写入文件demo.txt bufferedWriter.newLine(); &#125; bufferedReader.close(); bufferedWriter.flush(); bufferedWriter.close(); &#125;&#125; 参考文章 http://ifeve.com/java-io-char-buffered-filter/ http://www.cnblogs.com/lich/archive/2011/12/11/2284223.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记七]]></title>
      <url>%2F2017%2F05%2F26%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%83%2F</url>
      <content type="text"><![CDATA[System对IO的支持 System是系统的类，其中的方法都是在控制台的输入和输出，但是通过重定向也是可以对文件的输入输出 System中定义了标准输入、标准输出和错误输出流，定义如下: static PrintStream err “标准”错误输出流。 static InputStream in “标准”输入流。 static PrintStream out “标准”输出流。 从上面的定义可以知道这里的返回值都是字节的输入和输出流，因此可以使用PrintStream接受这个返回值，然后利用其进行输出，同样的输入也是可以这样做,当然对于OutputStream和InputStream也是可以的，因为PrintStream是继承OutputStream System.out System.out是一个标准的输出流，可以使用PrintStream和OutputStream接收返回值，然后使用其进行标准的输出,实例如下 12345PrintStream printStream=System.out; //使用PrintStream//OutputStream outputStream=System.out; //使用OutputStream String name="陈加兵"; int age=22; printStream.printf("姓名:%s,年龄:%s",name,age); //使用格式话的输出 其实我还是比较用PrintStream进行格式话的输出的 System.out的重定向输出，可以使用这个将指定的内容输出到文件中，实例如下： 12345678try &#123; File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt"); System.setOut(new PrintStream(new PrintStream(file))); //设置重定向的文件 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; System.out.println("陈加兵的个人博客")；//向文件输入内容 System.in 这是一个标准输入流，可以使用InputStream来接受返回值，然后利用其进行输入，实例如下： 123456789byte[] bytes=new byte[1024]; InputStream inputStream=System.in; //使用InputStream来接收这个返回值 try &#123; inputStream.read(bytes); //读取控制台输入的字符串 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; System.out.println(new String(bytes)); //输出 说实话这种控制台输入的方式不太好，还是使用原来的Scanner比较好 System.in的重定向 12345678910byte[] bytes = new byte[1024];File file = new File("/tmp" + File.separator + "test" + File.separator + "test.txt");try &#123; System.setIn(new FileInputStream(file)); //设置重定向 System.in.read(bytes); //读取文件中字节数据&#125; catch (IOException e) &#123; e.printStackTrace();&#125;System.out.println(new String(bytes)); //打印出文件中的内容 System.err 这是一个标准错误输出流，在IDEA中输出的内容是红色的，和System.out输出的格式一样，只是颜色不一样，因为这里的重定向不太重要也不太常用，这里就不再详细说了，详情请看帮助文档 System.exit public static void exit(int status) 终止当前的java虚拟机，参数用作状态码；根据惯例，非0 的状态码表示异常终止,如System.exit(0) 参考文章 http://www.cnblogs.com/lich/archive/2011/12/11/2284155.html http://ifeve.com/java-io-system-in-system-out-system-err/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记六]]></title>
      <url>%2F2017%2F05%2F25%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AD%2F</url>
      <content type="text"><![CDATA[打印流 在整个IO包中，打印流是输出信息最方便的类，主要包含字节打印流（PrintStream）和字符打印流（PrintWrite）。打印流提供了非常方便的打印功能，可以打印任何的数据类型，例如：小数、整数、字符串等等，相对于前面学习的几个文件的操作来说，这里的打印流是最简便的一个类了 PrintStream 主要功能是格式化的将内容写入文件，并不是打印在控制台上 PrintStream最大的好处就是可以格式化的输出，相信学过c的朋友都知道prinf这格式化输出函数，这里的PrintStream实现了更加简单的格式化输出，不需要使用什么%d,%f了，只需要都是用%s即可，这个很像python PrintStream 打印的所有字符都使用平台的默认字符编码转换为字节。在需要写入字符而不是写入字节的情况下，应该使用 PrintWriter类。 构造函数 PrintStream(File file) 创建具有指定文件且不带自动行刷新的新打印流。 PrintStream(OutputStream out) 创建新的打印流。 PrintStream(OutputStream out, boolean autoFlush) 创建新的打印流，并且设置自动刷新 PrintStream(String fileName) 创建具有指定文件名称且不带自动行刷新的新打印流。 123File file_2=new File("/tmp"+File.separator+"test"+File.separator+"test.txt");PrintStream printStream=new PrintStream(file_2); //直接使用FilePrintStream printStream=new PrintStream(new FileOutputStream(file_2)); //使用OutputStream的子类FileOutputStream 常用的函数 PrintStream append(char c) 在此输入流的后面追加字符。 PrintStream append(CharSequence csq) 将指定字符序列添加到此输出流。 PrintStream append(CharSequence csq, int start, int end) 将指定字符序列的子序列添加到此输出流。 print() 打印常用的数据类型，比如String,char,int ,double,float,boolean,long,short println() 打印常用的数据类型，但是带有换行符 printf(String format, Object... args) 使用指定格式字符串和参数将格式化的字符串写入此输出流的便捷方法。 format(String format, Object... args) 使用指定格式字符串和参数将格式化字符串写入此输出流中。 close() flush() 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 package IO;import java.io.*;/** * Created by chenjiabing on 17-5-25. */ /**test.txt文件中的结果如下: 陈加兵 2299.9 姓名:陈加兵,n年龄:22,成绩:99.9 姓名:陈加兵,n年龄:22,成绩:99.9 c chenjiabi */public class demo9 &#123; public static void main(String[] args) &#123; PrintStream printStream = null; File file_1 = new File("/tmp" + File.separator + "test"); File file_2 = new File("/tmp" + File.separator + "test" + File.separator + "test.txt"); if (!file_1.exists()) &#123; file_1.mkdir(); System.out.println("文件创建成功"); &#125; try &#123;// PrintStream printStream=new PrintStream(file_2); printStream = new PrintStream(new FileOutputStream(file_2)); String name = "陈加兵"; int age = 22; float grade = 99.9f; printStream.println(name);//println() printStream.print(age);//print() printStream.println(grade);//print() printStream.format("姓名:%s,n年龄:%s,成绩:%s%s", name, age, grade, "\n");//format() printStream.printf("姓名:%s,n年龄:%s,成绩:%s%s", name, age, grade, "\n"); printStream.append('c'); //append printStream.append("\nchenjiabing",0,10); //append &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (printStream != null) &#123; printStream.flush(); printStream.close(); &#125; &#125; &#125;&#125; PrintWriter 继承Writer，主要针对的是字符流的操作 向文本输出流打印对象的格式化表示形式。此类实现在 PrintStream中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。 与PrintStream 类不同，如果启用了自动刷新，则只有在调用 println、printf 或 format 的其中一个方法时才可能完成此操作，而不是每当正好输出换行符时才完成。这些方法使用平台自有的行分隔符概念，而不是换行符。 此类中的方法不会抛出 I/O 异常，尽管其某些构造方法可能抛出异常。客户端可能会查询调用 checkError() 是否出现错误。 构造函数 PrintWriter(File file) 使用指定文件创建不具有自动行刷新的新 PrintWriter。 PrintWriter(OutputStream out) 根据现有的 OutputStream 创建不带自动行刷新的新 PrintWriter。 PrintWriter(OutputStream out, boolean autoFlush) 通过现有的 OutputStream 创建新的 PrintWriter。 PrintWriter(String fileName) 创建具有指定文件名称且不带自动行刷新的新 PrintWriter。 常用函数 这里的常用到的函数和PrintStream的差不多就不再详细的列出来了，详情请看帮助文档 实例12345678910111213141516171819202122232425262728package IO;import java.io.*;/** * Created by chenjiabing on 17-5-25. */public class demo10 &#123; public static void main(String[] args) &#123; PrintWriter printWriter=null; File file=new File("/tmp"+File.separator+"test"+File.separator+"file.txt"); try &#123; printWriter=new PrintWriter(new FileOutputStream(file)); printWriter.println("chenjiabing"); printWriter.println("陈加兵"); &#125;catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(printWriter!=null) &#123; printWriter.close(); &#125; &#125; &#125;&#125; 参考文章 http://www.cnblogs.com/lich/archive/2011/12/11/2284093.html http://tool.oschina.net/uploads/apidocs/jdk-zh/java/io/PrintWriter.html http://tool.oschina.net/uploads/apidocs/jdk-zh/java/io/PrintStream.html http://blog.csdn.net/yyyandroid/article/details/7756390]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记五]]></title>
      <url>%2F2017%2F05%2F25%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%94%2F</url>
      <content type="text"><![CDATA[管道流 管道流的主要作用是可以进行两个线程间的通讯，分为管道输出流(PipedOutputStream)、管道输入流（PipedInputStream），如果想要进行管道输出，则必须要把输出流连在输入流之上，在PipedOutputStream类上有如下的一个方法用于连接管道：public void connect(PipedInputStream snk)throws IOException 通常是创建两个单独的线程来实现通信，如果是单个线程的话容易出现线程堵塞，因为输出流最多只能向缓冲区写入1024个字节的数据，如果超出就会出现线程堵塞，因此必须创建多个线程实现缓冲区的释放和存储 PipedOutputStream 管道输出流是管道的发送端，可以将管道输出流连接到管道输入流来创建一个通信管道，通常，数据由某个线程写入 PipedOutputStream对象，并由其他线程从连接的 PipedInputStream 读取。不建议对这两个对象尝试使用单个线程，因为这样可能会造成该线程死锁。如果某个线程正从连接的管道输入流中读取数据字节，但该线程不再处于活动状态，则该管道被视为处于 毁坏 状态。 构造函数 PipedOutputStream() 创建尚未连接到管道输入流的管道输出流。 PipedOutputStream(PipedInputStream snk) 创建连接到指定管道输入流的管道输出流。 常用函数 close() 关闭 void connect(PipedInputStream snk) 将此管道输出流连接到接收者。 void flush() 刷新此输出流并强制写出所有缓冲的输出字节。 void write(byte[] b, int off, int len) 将 len 字节从初始偏移量为 off 的指定 byte 数组写入该管道输出流。 void write(int b) 将指定 byte 写入传送的输出流。 PipedInputStream 管道输入流应该连接到管道输出流；管道输入流提供要写入管道输出流的所有数据字节。通常，数据由某个线程从 PipedInputStream 对象读取，并由其他线程将其写入到相应的 PipedOutputStream。不建议对这两个对象尝试使用单个线程，因为这样可能死锁线程。管道输入流包含一个缓冲区，可在缓冲区限定的范围内将读操作和写操作分离开。 如果向连接管道输出流提供数据字节的线程不再存在，则认为该管道已损坏。 构造函数 PipedInputStream() 创建尚未连接的 PipedInputStream。 PipedInputStream(PipedOutputStream src) 创建 PipedInputStream，使其连接到管道输出流 src。 常用函数 int available() 返回可以不受阻塞地从此输入流中读取的字节数。 void close() 关闭此管道输入流并释放与该流相关的所有系统资源。 void connect(PipedOutputStream src) 使此管道输入流连接到管道输出流 src。 int read() 读取此管道输入流中的下一个数据字节。 int read(byte[] b, int off, int len) 将最多 len 个数据字节从此管道输入流读入 byte 数组。 protected void receive(int b) 接收数据字节。 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package IO;import java.io.IOException;import java.io.PipedInputStream;import java.io.PipedOutputStream;/** * Created by chenjiabing on 17-5-25. *//** * 注意的问题： * 1.写线程正在往缓冲区写数据的时候，但是此时的读线程的管道结束，那么此时的写线程的管道就会发生IOException异常 * 2.读线程正在从缓冲区读数据的时候，但是此时的写线程的管道已经结束了，此时就会引起读线程的管道发生IOException异常 * 3.必须是启用多线程才能实现管道之间的读写，否则会出现堵塞现象，因为这里的PipeOutputStream每次向缓冲区写入的字节数最大是1024，如果不及时的减少缓冲区的数据量就会出现堵塞 */public class demo7 &#123; public static PipedOutputStream outputStream = new PipedOutputStream(); public static PipedInputStream inputStream = new PipedInputStream(); /** * 创建一个写入数据进程，使用的是PipeOutStream，将数据写入管道中 */ public static void send() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; byte[] bytes = new byte[2000]; //创建一个2000字节的数组 while (true) &#123; try &#123; outputStream.write(bytes, 0, 2000); //写入管道，但是这里的缓冲区最多写入1024个字节的数据，因此这个是一次没有写完 System.out.println("写入成功"); &#125; catch (IOException e) &#123; System.out.println("写入失败"); System.exit(1); &#125; &#125; &#125; &#125;).start(); &#125; /** * 使用PipeInputStream创建一个读取的线程 */ public static void receive() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; byte[] bytes = new byte[100]; //一次性只读取100个字节 int len = 0; try &#123; len = inputStream.read(bytes, 0, 100); //读取 while (len != -1) &#123; System.out.println("已经读取了" + len + "个字节"); len = inputStream.read(bytes, 0, 100); &#125; &#125; catch (IOException e) &#123; System.out.println("读取失败"); System.exit(1); &#125; &#125; &#125;).start(); &#125; public static void main(String args[]) &#123; try &#123; inputStream.connect(outputStream); //连接 &#125; catch (IOException e) &#123; System.out.println("连接失败"); System.exit(1); &#125; send(); receive(); &#125;&#125; 注意:从上面的运行结果可以看出，缓冲区最多可以写入1024个字节的数据，所以在缓冲区满了之后上面的send进程就会堵塞等待缓冲区空闲，如果recieve进程不继续读取数据了，那么就会一直出现堵塞 问题 写线程正在往缓冲区写数据的时候，但是此时的读线程的结束读取，那么此时的写线程的管道就会发生IOException异常，可以将上面receive进程中的while(true)去掉就可以清楚的看出 读线程正在从缓冲区读数据的时候，但是此时的写线程的管道已经结束了，此时就会引起读线程的管道发生IOException异常,将上面的send进程中的while(true)去掉就可以实现这个问题 必须是启用多线程才能实现管道之间的读写，否则会出现堵塞现象，因为这里的PipeOutputStream每次向缓冲区写入的字节数最大是1024，如果不及时的减少缓冲区的数据量就会出现堵塞 解决方法 后续更新中………. 参考文章 http://www.cnblogs.com/lich/archive/2011/12/11/2283928.html http://ifeve.com/java-io-%E7%AE%A1%E9%81%93/ http://www.cnblogs.com/chinareny2k/archive/2010/03/24/1693878.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记四]]></title>
      <url>%2F2017%2F05%2F25%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B%2F</url>
      <content type="text"><![CDATA[内存操作流 之前的所有的流操作都是针对文件的，但是有时候只是想要实现数据间转换，此时如果我们想要创建一个文件然后再删除文件，那样显得有点麻烦，因此此时的内存操作流就显得很适合这类的操作，因为它只是在内存中存储，并不会真正的创建文件，内存操作流涉及的两个类是ByteArrayInputStream,ByteArrayOutputStream. ByteArrayInputStream ByteArrayInputStream 包含一个内部缓冲区，该缓冲区包含从流中读取的字节。内部计数器跟踪read方法要提供的下一个字节。 关闭 ByteArrayInputStream无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。 主要的功能是从缓冲区读取字节 构造函数 ByteArrayInputStream(byte[] buf) 创建一个 ByteArrayInputStream，使用 buf 作为其缓冲区数组。 ByteArrayInputStream(byte[] buf, int offset, int length) 创建 ByteArrayInputStream，使用 buf 作为其缓冲区数组。 常用的方法 close() 不过对这个无效，因为关闭之后仍然可以使用函数读取而不报错 int read() 从缓冲区中读取一个字节 int read(byte[] bytes) 将缓冲区中的内容读取到数组中 int read(byte[] bytes,int off,int len) 将最多 len 个数据字节从此输入流读入 byte 数组。 long skip(long n) 从此输入流中跳过n 个输入字节。 void reset() 将此 byte 数组输出流的 count 字段重置为零，从而丢弃输出流中目前已累积的所有输出（清除缓冲区） 实例1234567891011121314151617181920212223public class demo8 &#123; public static void main(String args[]) &#123; String str = "chenjiabing\n陈加兵"; byte[] bytes = str.getBytes(); //创建一个数组 ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes); //使用bytes作为缓冲区数组 int temp = 0; /*第一种方法读取缓冲区中的数据，这个和文件的操作不一样，这个可以直接冲缓冲区中读取数据字节*/ while ((temp = inputStream.read()) != -1) &#123; System.out.print((char) temp); &#125; /*创建数组用于存储读取的内容，下面是第二种读取数据的方法*/ byte[] b = new byte[bytes.length]; try &#123; int len = inputStream.read(b); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; System.out.println(new String(b)); &#125;&#125; ByteArrayOutputStream 此类实现了一个输出流，其中的数据被写入一个byte 数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray() 和 toString() 获取数据。 关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。 构造函数 ByteArrayOutputStream() 创建一个新的 byte数组输出流。 ByteArrayOutputStream(int size) 创建一个新的 byte 数组输出流，它具有指定大小的缓冲区容量（以字节为单位）。 常用函数 int size() 返回缓冲区的当前大小。 byte[] toByteArray() 创建一个新分配的 byte 数组。 String toString() 将缓冲区的字节转换成字符串 void write(byte[] b, int off, int len) 将指定 byte 数组中从偏移量 off 开始的 len 个字节写入此 byte 数组输出流。 void write(int b) 将指定的字节写入此 byte数组输出流。 实例12345678910111213141516171819202122232425262728293031public class demo8 &#123; public static void main(String args[]) &#123; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); String str = "chenjiabing"; try &#123; outputStream.write(str.getBytes()); //将字符串转换成数组然后写入缓冲区 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; outputStream.close(); //这里的关闭无效 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //将缓冲区的数据转换成字符串后输出，这里同样可以看出输出流的关闭根本不影响函数的调用 System.out.println(outputStream.size()); //输出缓冲区的大小 System.out.println(outputStream.toString()); //输出chenjiabing outputStream.reset(); //清除缓冲区的内容，如果不清零那么原先写入的数据还是存在的，但是此时我们已经不需要前面的数据了 try &#123; outputStream.write("陈加兵".getBytes()); //继续向缓冲区写入数据 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; System.out.println(outputStream.size()); //这里的一个汉字占了三个字节 System.out.println(outputStream.toString());//输出陈加兵 &#125;&#125; 综合 下面我们结合上面的两个类将字符串转换大小写 1234567891011121314151617public class demo8 &#123; public static void main(String args[]) &#123; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); String str = "chenjiabing"; ByteArrayInputStream inputStream = new ByteArrayInputStream(str.getBytes()); //实例化输入流 int temp = 0; while ((temp = inputStream.read()) != -1) //读取缓冲区的字节数据 &#123; char c = (char) temp; //将整数转换成字符，ascii码的转换 outputStream.write(Character.toUpperCase(c)); //转换成大写，然后写入输出流的缓冲区中 &#125; System.out.println(outputStream.toString()); //利用输出流输出转换后的字符串，即是去取出内存中的数据 &#125;&#125; 参考文章 http://blog.csdn.net/yyyandroid/article/details/7756390 http://www.cnblogs.com/lich/archive/2011/12/11/2283883.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记三]]></title>
      <url>%2F2017%2F05%2F24%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89%2F</url>
      <content type="text"><![CDATA[Java IO学习笔记三 在整个IO包中，实际上就是分为字节流和字符流，但是除了这两个流之外，还存在了一组字节流-字符流的转换类。 OutputStreamWriter：是Writer的子类，将输出的字符流变为字节流，即：将一个字符流的输出对象变成字节流的输出对象。 InputStreamReader:是Reader的子类，将输入的字节流变为字符流，即：将一个字节流的输入对象变成字符流的输入对象。 一般在操作输入输出内容就需要使用字节或字符流，但是有些时候需要将字符流变成字节流的形式，或者将字节流变为字符流的形式，所以，就需要另外一组转换流的操作类。 InputStreamReader InputStreamReader 是字节流通向字符流的桥梁：它使用指定的 charset 读取字节并将其解码为字符。它使用的字符集可以由名称指定或显式给定，或者可以接受平台默认的字符集。 每次调用 InputStreamReader 中的一个 read() 方法都会导致从底层输入流读取一个或多个字节。要启用从字节到字符的有效转换，可以提前从底层流读取更多的字节，使其超过满足当前读取操作所需的字节。 主要的功能还是从文件中读取内容，不过是一次性的读取多个字节，这个很像它的子类FileReader 构造函数 InputStreamReader(InputStream in) 创建一个使用默认字符集的 InputStreamReader,不过这里的InputStream是抽下类，因此可以使用它的子类FileInputStream实例化，这里的FileInputStream是操作字节流的，显然看出这个类的作用就是字符流和字节流的桥梁 常用方法 close() int read() 读取单个字符 int read(Char[] c) 读取字符存储在字符数组中 int read(char[] cbuf, int offset, int length) 将字符读入数组中的某一部分 boolean ready() 判断此流是否已经准备好用于读取。 实例1234567891011121314151617181920212223242526272829303132333435363738394041package IO;import java.io.*;/** * Created by chenjiabing on 17-5-24. */public class demo4 &#123; public static void main(String args[]) &#123; File file = new File("/tmp" + File.separator + "test" + File.separator + "test.txt"); InputStreamReader inputStreamReader = null; try &#123; inputStreamReader = new InputStreamReader(new FileInputStream(file)); //初始化 char[] c = new char[(int) file.length()]; //创建数组 try &#123; int len = inputStreamReader.read(c); //将内容读取到数组中 System.out.println(len); for (int i = 0; i &lt; c.length; i++) &#123; System.out.print(c[i]); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if(inputStreamReader!=null) &#123; try &#123; inputStreamReader.close(); //关闭 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 注意：从上面的代码中可以看到这个和FileReader的操作是一样的，只是构造的方法不一样 OutputStreamWriter OutputStreamWriter 是字符流通向字节流的桥梁：可使用指定的 charset 将要写入流中的字符编码成字节。它使用的字符集可以由名称指定或显式给定，否则将接受平台默认的字符集。 每次调用 write() 方法都会导致在给定字符（或字符集）上调用编码转换器。在写入底层输出流之前，得到的这些字节将在缓冲区中累积。可以指定此缓冲区的大小，不过，默认的缓冲区对多数用途来说已足够大。注意，传递给 write() 方法的字符没有缓冲。 主要的功能还是向文件中写入文件 构造函数 OutputStreamWriter(OutputStream out) 创建使用默认字符编码的 OutputStreamWriter。这里同样是抽象类，所以用它的子类FileOutputStream实例化 常用方法 close() flush() write(String str) 写入字符串 void write(String str, int off, int len) 写入字符串的某一部分。 write(int c) 写入单个字符 void write(char[] cbuf, int off, int len) 写入字符数组的某一部分。 实例12345678910111213141516171819202122232425262728293031323334353637383940414243package IO;import java.io.*;/** * Created by chenjiabing on 17-5-24. */public class demo5 &#123; public static void main(String[] args) &#123; File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt"); OutputStreamWriter outputStreamWriter=null; try &#123; outputStreamWriter=new OutputStreamWriter(new FileOutputStream(file,true)); String str="陈加兵\n"; int data=48; String name="chenjiabing"; try &#123; outputStreamWriter.write(str); outputStreamWriter.write(data); outputStreamWriter.write(name,0,2); //写入字符串的一部分 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if(outputStreamWriter!=null) &#123; try &#123; outputStreamWriter.flush(); outputStreamWriter.close(); &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 从上面可以看出OutputStreamWriter和FileWriter的用法一样 综合使用 上面我们说了OutputStreamWriter和InputStreamWriter是字节流和字符流之间的桥梁，可以实现之间的转换，下面我们使用这两个之间的相互转换完成高效流的创建123456789/* * InputStreamReader实现了将字节流FileInputStream转换为字符流，然后使用转换来的字节流创建高效流，从而实现高效的读写 */File file = new File("/tmp/demo.txt");FileInputStream fileInputStream = new FileInputStream(file); // 创建字节输入流InputStreamReader inputStreamReader = new InputStreamReader( fileInputStream); // 转换为字符输入流BufferedReader bufferedReader = new BufferedReader(inputStreamReader); // 创建高效流对象 参考文章 http://www.cnblogs.com/lich/archive/2011/12/11/2283848.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记二]]></title>
      <url>%2F2017%2F05%2F24%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C%2F</url>
      <content type="text"><![CDATA[Java IO学习笔记二流的概念 在程序中所有的数据都是以流的方式进行传输或保存的，程序需要数据的时候要使用输入流读取数据，而当程序需要将一些数据保存起来的时候，就要使用输出流完成。 程序中的输入输出都是以流的形式保存的，流中保存的实际上全都是字节文件。 字节流和字符流 实际上字节流在操作时本身不会用到缓冲区（内存），是文件本身直接操作的，而字符流在操作时使用了缓冲区，通过缓冲区再操作文件 在java.io包中操作文件内容的主要有两大类：字节流、字符流，两类都分为输入和输出操作。在字节流中输出数据主要是使用OutputStream完成，输入使的是InputStream，在字符流中输出主要是使用Writer类完成，输入流主要使用Reader类完成。（这四个都是抽象类） 操作流程 在Java中IO操作也是有相应步骤的，以文件操作为例，主要的操作流程如下： 使用File类打开一个文件 通过字节流或字符流的子类，指定输出的位置 进行读/写操作 关闭输入/输出 字节流 字节流主要是操作byte类型数据，以byte数组为准，主要操作类就是OutputStream、InputStream FileOutputStream 文件输出流是用于将数据写入 File 或 FileDescriptor 的输出流。文件是否可用或能否可以被创建取决于基础平台。特别是某些平台一次只允许一个 FileOutputStream（或其他文件写入对象）打开文件进行写入。在这种情况下，如果所涉及的文件已经打开，则此类中的构造方法将失败。 FileOutputStream 用于写入诸如图像数据之类的原始字节的流。要写入字符流，请考虑使用 FileWriter。 主要的功能就是用来向文件中写入内容的 构造函数 FileOutputStream(File file) 创建一个向指定 File 对象表示的文件中写入数据的文件输出流。 FileOutputStream(File file, boolean append) 如果在文件后面追加内容，如果append为true则追加内容 FileOutputStream(String name) 创建一个向具有指定名称的文件中写入数据的输出文件流。 FileOutputStream(String name, boolean append) 创建一个向具有指定 name 的文件中写入数据的输出文件流。 常用的方法 close() 关闭文件输出流 void write(byte[] b) 将 b.length 个字节从指定 byte 数组写入此文件输出流中。 void write(byte[] b, int off, int len) 将指定 byte 数组中从偏移量 off 开始的 len 个字节写入此文件输出流，这里需要注意的是中文所占字节数为3，英文所占字节数为1 void write(int b) 将指定字节写入此文件输出流，这个是按照ascii码写入文件的，并不是直接写入的是整数 实例123456789101112131415161718192021222324252627282930313233343536373839package File_demo;import java.io.*;public class demo &#123; public static void main(String[] args) &#123; FileOutputStream outputStream = null; File file = new File("/tmp" + File.separator + "test.txt"); try &#123; outputStream = new FileOutputStream(file); try &#123; int data = 48; String name = "陈加兵\n"; //使用\n换行 byte[] bytes = name.getBytes(); //将字符串转换成byte数组 outputStream.write(bytes, 0, 3); //将中文字符串的第一个字写入，这里一个中文占了三个字节 String age = "chenjiabing\n"; outputStream.write(age.getBytes()); outputStream.write(data); //这里的写入的acsii码中的( &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (outputStream != null) &#123; try &#123; outputStream.close(); //关闭文件流 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 当然也可以一个一个的字节输出 1234567891011121314151617import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.OutputStream;public class Test11 &#123; public static void main(String[] args) throws IOException &#123; File f = new File("d:" + File.separator+"test.txt"); OutputStream out=new FileOutputStream(f);//如果文件不存在会自动创建 String str="Hello World"; byte[] b=str.getBytes(); for(int i=0;i&lt;b.length;i++)&#123; out.write(b[i]); &#125; out.close(); &#125;&#125; FileInputStream FileInputStream 从文件系统中的某个文件中获得输入字节。哪些文件可用取决于主机环境。 FileInputStream 用于读取诸如图像数据之类的原始字节流。要读取字符流，请考虑使用 FileReader。 主要的功能是读取文件中的内容 构造函数 FileInputStream(File file) 通过打开一个到实际文件的连接来创建一个 FileInputStream，该文件通过文件系统中的File对file指定。 FileInputStream(String name) 通过打开一个到实际文件的连接来创建一个 FileInputStream，该文件通过文件系统中的路径名 name 指定。 常用方法 int read() 从输入流中读取数据字节，如果到达文件的末尾就返回-1 int read(byte[] b) 将文件中的内容读取到byte数组中，如果到达文件末尾返回-1 int read(byte[] b, int off, int len) 从此输入流中将最多 len 个字节的数据读入一个 byte 数组中,这个用于截取字节流，注意这里中文是占三个字节 long skip(long n) 从输入流中跳过并丢弃 n 个字节的数据，一旦跳过字节那么就从跳过的字节的后面开始读取 int available()返回的数据是输入流中的字节数，如果没有字节就返回0，因此可以用这个函数判断文件中是否还有内容 实例 针对知道的文件的大小然后创建一个数组存储，之后将数组转换成字符串，当然我们也可以一个一个的读取 1234567891011121314151617181920212223242526272829File file=new File("/tmp"+File.separator+"test.txt"); FileInputStream inputStream=null; try &#123; inputStream=new FileInputStream(file); try &#123; byte[] bytes=new byte[(int)file.length()]; //file.length返回文件的大小，这样就不会浪内存空间了 int flag=inputStream.read(bytes); //将文件的内容读入到数组中 System.out.println(new String(bytes)); //将bytes数组转换成字符串输出 System.out.println(flag); &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if(inputStream!=null) &#123; try &#123; inputStream.close(); &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 一个一个的读文件 1234567891011121314151617181920212223242526272829303132333435File file=new File("/tmp"+File.separator+"test.txt"); FileInputStream inputStream=null; try &#123; inputStream=new FileInputStream(file); try &#123; int len=0; //读取的字节 int i=0; //下标 byte[] bytes=new byte[(int)file.length()]; //创建数组 while((len=inputStream.read())!=-1) //判断是否读取到文件的末尾 &#123; bytes[i]=(byte)len; //将读到的整形数据转换成bytes类型的，存储在数组中 i++; &#125; System.out.println(new String(bytes)); //转换成字符串 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if(inputStream!=null) &#123; try &#123; inputStream.close(); &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 使用available控制结束 12345678910111213141516171819202122232425262728293031323334353637File file = new File("/tmp" + File.separator + "test.txt"); FileInputStream inputStream = null; try &#123; inputStream = new FileInputStream(file); try &#123; byte[] bytes = new byte[(int) file.length()]; //file.length返回文件的大小，这样就不会浪内存空间了 int i = 0; while (inputStream.available() != 0) &#123; try &#123; bytes[i] = (byte) inputStream.read(); i++; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(new String(bytes)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 字符流 在程序中一个字符等于两个字节，那么java提供了Reader、Writer两个专门操作字符流的类。 前面已经说过字符流要用到缓冲区，因此在关闭字符流的时候一定要刷新缓冲区,清空缓冲区中的内容 字符输出流FileWriter 用来写入字符文件的便捷类。此类的构造方法假定默认字符编码和默认字节缓冲区大小都是可接受的。 FileWriter 用于写入字符流。要写入原始字节流，请考虑使用 FileOutputStream。 主要功能是向文件中写入内容 构造函数 FileWriter(File file) 根据给定的 File 对象构造一个 FileWriter 对象。 FileWriter(File file,boolean append) 追加 FileWriter(String fileName) 根据给定的文件名构造一个 FileWriter 对象。 FileWriter(String fileName, boolean append) 根据给定的文件名以及指示是否附加写入数据的 boolean 值来构造 FileWriter 对象。 常用方法 write(String str) 将字符写入文件 write(String str,int offest,int len) 截取字符串部分内容写入文件 write(int c) 写入单个字符，并不是整数 write(Char[] buf) 写入字符数组 close() 关闭流，在关闭之前必须刷新缓冲区 flush() 刷新缓冲区 实例123456789101112131415161718192021222324252627282930313233File file=new File("/tmp"+File.separator+"test"+File.separator+"test.txt"); File f1=new File("/tmp"+File.separator+"test"); if(!f1.exists()) &#123; f1.mkdir(); System.out.println("文件创建成功"); &#125; FileWriter fileWriter=null; try &#123; fileWriter=new FileWriter(file); String str="hello chenjiabing\n"; String name="陈加兵"; int data=48; fileWriter.write(str); //写入字符串 fileWriter.write(name); //写入中文字符串，这里直接写入不用转换成byte数组了 fileWriter.write(data); //写入单个字符 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(fileWriter!=null) &#123; try &#123; fileWriter.flush(); //刷新缓冲区 fileWriter.close(); //关闭字符流 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 注意: 这里字符流如果不关闭的话，那么就会就会写入文件失败，文件中没有内容，但是如果只有flush而没有close文件还是会写入成功的 字符输入流FileReader 用来读取字符文件的便捷类。此类的构造方法假定默认字符编码和默认字节缓冲区大小都是适当的 主要的功能是读取文件内容 构造函数 FileReader(File file) 在给定从中读取数据的 File 的情况下创建一个新 FileReader。 FileReader(String fileName) 在给定从中读取数据的文件名的情况下创建一个新 FileReader。 常用函数 int read(char[] cbuf) 将字符读入数组。 int read() 读取单个字符，之后使用char类型强制转换成字符就行 read(char[] cbuf, int off, int len) 将字符读入数组的某一部分。 boolean ready() 判断是否准备读取此流，如果读到文件末尾那么就返回false long skip(long n) 跳过字符。 实例 用字符数组读取 12345678910111213141516171819202122232425File file = new File("/tmp" + File.separator + "test" + File.separator + "test.txt"); FileReader fileReader = null; try &#123; fileReader = new FileReader(file); char[] c = new char[(int) file.length()]; //根据文件的大小申请数组大小，不浪费 try &#123; int len = fileReader.read(c); //将文件的内容读取到字符数组中 for (int i = 0; i &lt; c.length; i++) &#123; System.out.println(c[i]); //将一个一个字符输出 &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (fileReader != null) &#123; try &#123; fileReader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 使用ready控制是否读到文件末尾，当然也可以使用int read()==-1判断 12345678910111213141516171819202122232425File file = new File("/tmp" + File.separator + "test" + File.separator + "test.txt"); FileReader fileReader = null; try &#123; fileReader = new FileReader(file); char[] c = new char[(int) file.length()]; //根据文件的大小申请数组大小，不浪费 try &#123; while(fileReader.ready()) //判断是否读到文件末尾 &#123; System.out.println((char)fileReader.read()); //转换成字符 &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (fileReader != null) &#123; try &#123; fileReader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 参考文章 http://www.cnblogs.com/lich/archive/2011/12/11/2283700.html http://www.cnblogs.com/absfree/p/5415092.html http://blog.csdn.net/zxman660/article/details/7875799 http://blog.csdn.net/cynhafa/article/details/6882061]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java IO学习笔记一]]></title>
      <url>%2F2017%2F05%2F23%2FJava-IO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
      <content type="text"><![CDATA[Java IO学习笔记一File File是文件和目录路径名的抽象表示形式，总的来说就是java创建删除文件目录的一个类库，但是作用不仅仅于此，详细见官方文档 构造函数 File(File parent, String child) 根据 parent 抽象路径名和 child 路径名字符串创建一个新 File 实例。 File(String pathname) 通过将给定路径名字符串转换为抽象路径名来创建一个新 File 实例。 File(String parent, String child) 根据 parent 路径名字符串和 child 路径名字符串创建一个新 File 实例。 File(URI uri) 通过将给定的 file: URI 转换为一个抽象路径名来创建一个新的 File 实例。 实例123File file=new File("/tmp/demo"); //File(String pathname)File file=new File("/tmp","demo"); //File(String parent, String child) 常用方法字段 static String pathSeparator 与系统有关的路径分隔符，通常是: static String separator 与系统有关的默认名称分隔符，为了方便，它被表示为一个字符串。linux是/ 1File file=new File("/tmp"+File.separator+"demo"); //使用分隔符创建一个路径 方法摘要 boolean canExecute() 测试文件或者目录是否是可执行的，测试可执行权限 boolean canRead() 测试可读权限 boolean canWrite() 测试可写权限 boolean setExecutable(boolean executable) 设置文件或者目录的执行权限 setExecutable(boolean executable, boolean ownerOnly) 设置执行权限，如果第二个为true那么只有创建这个文件的用户拥有执行权限 boolean setReadable(boolean readable) 设置可读的权限 boolean setReadable(boolean readable, boolean ownerOnly) 同上 boolean setReadOnly() 标记此抽象路径名指定的文件或目录，从而只能对其进行读操作。 boolean setWritable(boolean writable) 设置可写的权限 boolean createNewFile() 创建一个文件，这里创建的不是目录 boolean mkdir() 创建文件夹 File getAbsoluteFile() 返回此抽象路径名的绝对路径名形式。 String getAbsolutePath() 返回此抽象路径名的绝对路径名字符串。 String getName() 返回由此抽象路径名表示的文件或目录的名称。 boolean isDirectory() 测试此抽象路径名表示的文件是否是一个目录。 boolean isFile() 测试此抽象路径名表示的文件是否是一个标准文件。 boolean isHidden() 测试此抽象路径名指定的文件是否是一个隐藏文件。 String[] list() 返回一个字符串数组，这些字符串指定此抽象路径名表示的目录中的文件和目录。 File[] listFiles() 返回一个抽象路径名数组，这些路径名表示此抽象路径名表示的目录中的文件。 实例创建文件12345678910111213141516File file=new File("/tmp/demo.txt"); if(file.exists())//如果文件存在就删除这个文件 &#123; file.delete(); &#125; else &#123; try&#123; file.createNewFile(); //创建一个文件 file.setExecutable(false); //设置执行权限 &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 创建文件夹1234567891011121314151617181920File file=new File("/tmp","test"); if(file.exists()) &#123; if(file.isDirectory()) //如果是一个文件夹 &#123; System.out.println("这是一个文件夹"); file.delete(); &#125; else if(file.isFile()) //如果是一个文件 &#123; System.out.println("这是一个文件"); &#125; &#125; else &#123; file.mkdir(); file.setWritable(false); //设置权限为不可读 &#125; 列出全部文件list 这个函数列出的是文件的名字并不是文件的路径 12345File f=new File("d:"+File.separator); String[] str=f.list(); //这里列出的仅仅是文件的名字，并不是文件的路径 for(String s:str)&#123; System.out.println(s); &#125; listFiles 这个列出的是文件的绝对路径 12345File f=new File("d:"+File.separator); File[] files=f.listFiles(); for(File file:files)&#123; System.out.println(file); &#125; 参考文章 http://www.cnblogs.com/lich/archive/2011/12/10/2283445.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python实现微信接口]]></title>
      <url>%2F2017%2F05%2F15%2Fpython%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%8E%A5%E5%8F%A3%2F</url>
      <content type="text"><![CDATA[python实现微信接口(itchat)安装 sudo pip install itchat 登录 itchat.auto_login() 这种方法将会通过微信扫描二维码登录，但是这种登录的方式确实短时间的登录，并不会保留登录的状态，也就是下次登录时还是需要扫描二维码，如果加上hotReload==True,那么就会保留登录的状态，至少在后面的几次登录过程中不会再次扫描二维码，该参数生成一个静态文件itchat.pkl用于存储登录状态 退出及登录完成后调用的特定的方法 这里主要使用的是灰调函数的方法,登录完成后的方法需要赋值在 loginCallback中退出后的方法,需要赋值在 exitCallback中.若不设置 loginCallback的值, 将会自动删除二维码图片并清空命令行显示. 12345678910import itchat, timedef lc(): print("Finash Login!")def ec(): print("exit")itchat.auto_login(loginCallback=lc, exitCallback=ec)time.sleep()itchat.logout() #强制退出登录 回复消息send send(msg=&quot;Text Message&quot;, toUserName=None) 参数： msg : 文本消息内容 @fil@path_to_file : 发送文件 @img@path_to_img : 发送图片 @vid@path_to_video : 发送视频 toUserName : 发送对象, 如果留空, 将发送给自己. 返回值 True or False 实例代码 1234567# coding-utf-8import itchatitchat.auto_login()itchat.send("Hello World!")ithcat.send("@fil@%s" % '/tmp/test.text')ithcat.send("@img@%s" % '/tmp/test.png')ithcat.send("@vid@%s" % '/tmp/test.mkv') send_msg send_msg(msg=&#39;Text Message&#39;, toUserName=None),其中的的msg是要发送的文本，toUserName是发送对象, 如果留空, 将发送给自己，返回值为True或者False 实例代码 123import itchatitchat.auto_login()itchat.send_msg("hello world.") send_file send_file(fileDir, toUserName=None) fileDir是文件路径, 当文件不存在时, 将打印无此文件的提醒，返回值为True或者False 实例代码 1234mport itchatitchat.auto_login()itchat.send_file("/tmp/test.txt") send_image send_image(fileDir, toUserName=None) 参数同上 实例代码 12345import itchatitchat.auto_login()itchat.send_img("/tmp/test.txt") send_video send_video(fileDir, toUserName=None) 参数同上 实例代码 1234import itchatitchat.auto_login()itchat.send_video("/tmp/test.txt") 注册消息方法 itchat 将根据接受到的消息类型寻找对应的已注册的方法.如果一个消息类型没有对应的注册方法, 该消息将会被舍弃.在运行过程中也可以动态注册方法, 注册方式与结果不变. 注册方法 不带具体对象注册, 将注册为普通消息的回复方法. 1234567import itchatfrom itchat.content import *@itchat.msg_register(TEXT) #这里的TEXT表示如果有人发送文本消息，那么就会调用下面的方法def simple_reply(msg): #这个是向发送者发送消息 itchat.send_msg('已经收到了文本消息，消息内容为%s'%msg['Text'],toUserName=msg['FromUserName']) return "T reveived: %s" % msg["Text"] #返回的给对方的消息，msg["Text"]表示消息的内容 带对象参数注册, 对应消息对象将调用该方法，其中isFriendChat表示好友之间，isGroupChat表示群聊，isMapChat表示公众号 123456import itchatfrom itchat.content import *@itchat.msg_register(TEXT, isFriendChat=True, isGroupChat=True,isMpChat=True)def text_reply(msg): msg.user.send("%s : %s" % (mst.type, msg.text)) 消息类型向注册方法传入的 msg 包含微信返回的字典的所有内容.itchat 增加 Text, Type(也就是参数) 键值, 方便操作.itcaht.content中包含所有的消息类型参数, 如下表 参数 l类型 Text 键值 TEXT 文本 文本内容(文字消息) MAP 地图 位置文本(位置分享) CARD 名片 推荐人字典(推荐人的名片) SHARING 分享 分享名称(分享的音乐或者文章等) PICTURE 下载方法 图片/表情 RECORDING 语音 下载方法 ATTACHMENT 附件 下载方法 VIDEO 小视频 下载方法 FRIENDS 好友邀请 添加好友所需参数 SYSTEM 系统消息 更新内容的用户或群聊的UserName组成的列表 NOTE 通知 通知文本(消息撤回等) 附件的下载与发送 itchat 的附件下载方法存储在 msg 的 Text 键中.发送的文件名(图片给出的默认文件名), 都存储在 msg 的 FileName 键中.下载方法, 接受一个可用的位置参数(包括文件名), 并将文件响应的存储.注意：下载的文件存储在指定的文件中，直接将路径与FileName连接即可，如msg[&quot;Text&quot;](&#39;/tmp/weichat&#39;+msg[&#39;FileName&#39;]) 123456@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])def download_files(msg): #msg.download(msg['FileName']) #这个同样是下载文件的方式 msg['Text'](msg['FileName']) #下载文件 #将下载的文件发送给发送者 itchat.send('@%s@%s' % ('img' if msg['Type'] == 'Picture' else 'fil', msg["FileName"]), msg["FromUserName"]) 群消息 增加了三个键值，如下： isAt 判断是否 @ 本号 ActualNickName : 实际 NickName(昵称) Content : 实际 Content 测试程序 1234567891011import itcahtfrom itchat.content import TEXT@itchat.msg_register(TEXT, isGroupChat=True)def text_reply(msg): if(msg.isAt): #判断是否有人@自己 #如果有人@自己，就发一个消息告诉对方我已经收到了信息 itchat.send_msg("我已经收到了来自&#123;0&#125;的消息，实际内容为&#123;1&#125;".format(msg['ActualNickName'],msg['Text']),toUserName=msg['FromUserName'])itchat.auto_login()itchat.run() 注册消息的优先级 总的来说就是后面注册同种类型的消息会覆盖之前注册的消息，详情见文档https://itchat.readthedocs.io/zh/latest/ 消息内容 注意：所有的消息内容都是可以用键值对来访问的，如msg[&quot;FromUserName]就是查看发送者，itchat.search_friends(userName=msg[&#39;FromUserName&#39;])[&#39;NickName&#39;]查看的是当发送者昵称 一般消息一般的消息都遵循以下的内容： 12345678910111213141516171819202122232425262728&#123; "FromUserName": "", "ToUserName": "", "Content": "", "StatusNotifyUserName": "", "ImgWidth": 0, "PlayLength": 0, "RecommendInfo": &#123;&#125;, "StatusNotifyCode": 0, "NewMsgId": "", "Status": 0, "VoiceLength": 0, "ForwardFlag": 0, "AppMsgType": 0, "Ticket": "", "AppInfo": &#123;&#125;, "Url": "", "ImgStatus": 0, "MsgType": 0, "ImgHeight": 0, "MediaId": "", "MsgId": "", "FileName": "", "HasProductId": 0, "FileSize": "", "CreateTime": 0, "SubMsgType": 0&#125; 初始化消息123456789101112131415161718192021222324252627MsgType: 51 FromUserName: 自己ID ToUserName: 自己ID StatusNotifyUserName: 最近联系的联系人ID Content: &lt;msg&gt; &lt;op id='4'&gt; &lt;username&gt; # 最近联系的联系人 filehelper,xxx@chatroom,wxid_xxx,xxx,... &lt;/username&gt; &lt;unreadchatlist&gt; &lt;chat&gt; &lt;username&gt; # 朋友圈 MomentsUnreadMsgStatus &lt;/username&gt; &lt;lastreadtime&gt; 1454502365 &lt;/lastreadtime&gt; &lt;/chat&gt; &lt;/unreadchatlist&gt; &lt;unreadfunctionlist&gt; # 未读的功能账号消息，群发助手，漂流瓶等 &lt;/unreadfunctionlist&gt; &lt;/op&gt; &lt;/msg&gt; 文本消息1234MsgType: 1 FromUserName: 发送方ID ToUserName: 接收方ID Content: 消息内容 图片消息 itchat 增加了 Text 键, 键值为 下载该图片的方法. 123456789MsgType: 3 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取图片，用于表示每一条消息 Content: &lt;msg&gt; &lt;img length="6503" hdlength="0" /&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;/msg&gt; 拓展：如果想要得到Content中的具体内容可以使用正则表达式匹配出来 视频消息 **itchat 增加了 Text 键, 键值为 下载该视频的方法. 123456789MsgType: 62FromUserName: 发送方IDToUserName: 接收方IDMsgId: 用于获取小视频Content: &lt;msg&gt; &lt;img length="6503" hdlength="0" /&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;/msg&gt; 地理位置消息 itchat 增加了 Text 键, 键值为 该地点的文本形式. 123456789MsgType: 1 FromUserName: 发送方ID ToUserName: 接收方ID Content: http://weixin.qq.com/cgi-bin/redirectforward?args=xxx OriContent:&lt;?xml version="1.0"?&gt;&lt;msg&gt; &lt;location x="34.195278" y="117.177803" scale="16" label="江苏省徐州市铜山区新区海河路" maptype="0" poiname="江苏师范大学大学生公寓园区" /&gt;&lt;/msg&gt; 名片消息 itchat 增加了Text 键, 键值为 该调用 add_friend 需要的属性. 123456789101112131415161718192021222324MsgType: 42 FromUserName: 发送方ID ToUserName: 接收方ID Content: &lt;?xml version="1.0"?&gt; &lt;msg bigheadimgurl="" smallheadimgurl="" username="" nickname="" shortpy="" alias="" imagestatus="3" scene="17" province="" city="" sign="" sex="1" certflag="0" certinfo="" brandIconUrl="" brandHomeUrl="" brandSubscriptConfigUrl="" brandFlags="0" regionCode="" /&gt; RecommendInfo: &#123; "UserName": "xxx", # ID，这里的是昵称 "Province": "xxx", "City": "xxx", "Scene": 17, "QQNum": 0, "Content": "", "Alias": "xxx", # 微信号 "OpCode": 0, "Signature": "", "Ticket": "", "Sex": 0, # 1:男, 2:女 "NickName": "xxx", # 昵称 "AttrStatus": 4293221, "VerifyFlag": 0 &#125; 下面是添加好友的测试代码 1234567@itchat.msg_register(itchat.content.CARD,isFriendChat=True)def simply(msg): print msg['Text'] print msg['Content'] itchat.add_friend(userName=msg['Text']['UserName']) #添加推荐的好友 print msg['RecommendInfo'] print msg['RecommendInfo']['UserName'] 语音消息 *itchat增加了Text键,键值为下载该语音文件的方法,下载下来的是MP3的格式 123456789MsgType: 34 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取语音 Content: &lt;msg&gt; &lt;voicemsg endflag="1" cancelflag="0" forwardflag="0" voiceformat="4" voicelength="1580" length="2026" bufid="216825389722501519" clientmsgid="49efec63a9774a65a932a4e5fcd4e923filehelper174_1454602489" fromusername="" /&gt; &lt;/msg&gt; 下载方法：msg[&#39;Text&#39;](msg[&#39;FileName&#39;]) 动画表情 itchat添加了Text键，键值为下载该图片表情的方法。注意：本人亲测对于一些微信商店提供的表情是不能下载成功的,这里的自带的表情emoji是属于TEXT类别的，因此如果将其注册为PICTURE消息类型的话是不可以监测到的 12345678MsgType: 47 FromUserName: 发送方ID ToUserName: 接收方ID Content: &lt;msg&gt; &lt;emoji fromusername = "" tousername = "" type="2" idbuffer="media:0_0" md5="e68363487d8f0519c4e1047de403b2e7" len = "86235" productid="com.tencent.xin.emoticon.bilibili" androidmd5="e68363487d8f0519c4e1047de403b2e7" androidlen="86235" s60v3md5 = "e68363487d8f0519c4e1047de403b2e7" s60v3len="86235" s60v5md5 = "e68363487d8f0519c4e1047de403b2e7" s60v5len="86235" cdnurl = "http://emoji.qpic.cn/wx_emoji/eFygWtxcoMF8M0oCCsksMA0gplXAFQNpiaqsmOicbXl1OC4Tyx18SGsQ/" designerid = "" thumburl = "http://mmbiz.qpic.cn/mmemoticon/dx4Y70y9XctRJf6tKsy7FwWosxd4DAtItSfhKS0Czr56A70p8U5O8g/0" encrypturl = "http://emoji.qpic.cn/wx_emoji/UyYVK8GMlq5VnJ56a4GkKHAiaC266Y0me0KtW6JN2FAZcXiaFKccRevA/" aeskey= "a911cc2ec96ddb781b5ca85d24143642" &gt;&lt;/emoji&gt; &lt;gameext type="0" content="0" &gt;&lt;/gameext&gt; &lt;/msg&gt; 普通链接或应用分享消息 主要针对的是分享的文章等等 12345678910111213141516171819202122MsgType: 49AppMsgType: 5FromUserName: 发送方IDToUserName: 接收方IDUrl: 链接地址FileName: 链接标题Content: &lt;msg&gt; &lt;appmsg appid="" sdkver="0"&gt; &lt;title&gt;&lt;/title&gt; &lt;des&gt;&lt;/des&gt; &lt;type&gt;5&lt;/type&gt; &lt;content&gt;&lt;/content&gt; &lt;url&gt;&lt;/url&gt; &lt;thumburl&gt;&lt;/thumburl&gt; ... &lt;/appmsg&gt; &lt;appinfo&gt; &lt;version&gt;&lt;/version&gt; &lt;appname&gt;&lt;/appname&gt; &lt;/appinfo&gt; &lt;/msg&gt; 音乐链接消息 主要针对的是音乐 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758MsgType: 49 AppMsgType: 3 FromUserName: 发送方ID ToUserName: 接收方ID Url: 链接地址 FileName: 音乐名 AppInfo: # 分享链接的应用 &#123; Type: 0, AppID: wx485a97c844086dc9 &#125; Content: &lt;msg&gt; &lt;appmsg appid="wx485a97c844086dc9" sdkver="0"&gt; &lt;title&gt;&lt;/title&gt; &lt;des&gt;&lt;/des&gt; &lt;action&gt;&lt;/action&gt; &lt;type&gt;3&lt;/type&gt; &lt;showtype&gt;0&lt;/showtype&gt; &lt;mediatagname&gt;&lt;/mediatagname&gt; &lt;messageext&gt;&lt;/messageext&gt; &lt;messageaction&gt;&lt;/messageaction&gt; &lt;content&gt;&lt;/content&gt; &lt;contentattr&gt;0&lt;/contentattr&gt; &lt;url&gt;&lt;/url&gt; &lt;lowurl&gt;&lt;/lowurl&gt; &lt;dataurl&gt; http://ws.stream.qqmusic.qq.com/C100003i9hMt1bgui0.m4a?vkey=6867EF99F3684&amp;amp;guid=ffffffffc104ea2964a111cf3ff3edaf&amp;amp;fromtag=46 &lt;/dataurl&gt; &lt;lowdataurl&gt; http://ws.stream.qqmusic.qq.com/C100003i9hMt1bgui0.m4a?vkey=6867EF99F3684&amp;amp;guid=ffffffffc104ea2964a111cf3ff3edaf&amp;amp;fromtag=46 &lt;/lowdataurl&gt; &lt;appattach&gt; &lt;totallen&gt;0&lt;/totallen&gt; &lt;attachid&gt;&lt;/attachid&gt; &lt;emoticonmd5&gt;&lt;/emoticonmd5&gt; &lt;fileext&gt;&lt;/fileext&gt; &lt;/appattach&gt; &lt;extinfo&gt;&lt;/extinfo&gt; &lt;sourceusername&gt;&lt;/sourceusername&gt; &lt;sourcedisplayname&gt;&lt;/sourcedisplayname&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;thumburl&gt; http://imgcache.qq.com/music/photo/album/63/180_albumpic_143163_0.jpg &lt;/thumburl&gt; &lt;md5&gt;&lt;/md5&gt; &lt;/appmsg&gt; &lt;fromusername&gt;&lt;/fromusername&gt; &lt;scene&gt;0&lt;/scene&gt; &lt;appinfo&gt; &lt;version&gt;29&lt;/version&gt; &lt;appname&gt;摇一摇搜歌&lt;/appname&gt; &lt;/appinfo&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;/msg&gt; 群消息 itchat 增加了三个群聊相关的键值: isAt : 判断是否 @ 本号 ActualNickName : 实际 NickName Content : 实际 Content 12345MsgType: 1FromUserName: @@xxxToUserName: @xxxContent: @xxx:&lt;br/&gt;xxx 红包消息12345MsgType: 49 AppMsgType: 2001 FromUserName: 发送方ID ToUserName: 接收方ID Content: 未知 系统消息1234567MsgType: 10000 FromUserName: 发送方ID ToUserName: 自己ID Content: "你已添加了 xxx ，现在可以开始聊天了。" "如果陌生人主动添加你为朋友，请谨慎核实对方身份。" "收到红包，请在手机上查看" 账号类型 tchat 为三种账号都提供了 整体获取方法与搜索方法. 好友get_friends itchat.get_friends() 返回完整的好友列表 每个好友为一个字典, 其中第一项为本人的账号信息; 传入update=True, 将更新好友列表并返回, get_friends(update=True) search_friends itchat.get_friends() 好友搜索，有以下四种方式 仅获取自己的用户信息 12# 获取自己的用户信息，返回自己的属性字典itchat.search_friends() 获取特定 UserName 的用户信息 12345678910# 获取特定UserName的用户信息itchat.search_friends(userName='@abcdefg1234567') ## 获取发送信息的好友的详细信息@itchat.msg_register(itchat.content.TEXT,isFriendChat=True)def reply(msg): print msg['FromUserName'] print itchat.search_friends(userName=msg['FromUserName']) #详细信息 print itchat.search_friends(userName=msg['FromUserName'])['NickName'] #获取昵称 获取备注,微信号, 昵称中的任何一项等于name键值的用户. (可以与下一项配置使用.) 比如在我的微信中有一个备注为autolife的人，我可以使用这个方法搜索出详细的信息 12# 获取任何一项等于name键值的用户itchat.search_friends(name='autolife') 获取备注,微信号, 昵称分别等于相应键值的用户. (可以与上一项配置使用.) 1234# 获取分别对应相应键值的用户itchat.search_friends(wechatAccount='littlecodersh')# 三、四项功能可以一同使用itchat.search_friends(name='LittleCoder机器人', wechatAccount='littlecodersh') update_friend 主要用于好友更新 特定用户: 传入用户UserName, 返回指定用户的最新信息. 用户列表: 传入 UserName 组成的列表, 返回用户最新信息组成的列表 1memberList = itchat.update_friend('@abcdefg1234567') 公众号get_mps 将返回完整的工作号列表 每个公众号为一个字典, 传入 update=True 将更新公众号列表, 并返回. search_mps 获取特定UserName的公众号 12# 获取特定UserName的公众号，返回值为一个字典itchat.search_mps(userName='@abcdefg1234567') 获取名字中还有特定字符的公众号. 12# 获取名字中含有特定字符的公众号，返回值为一个字典的列表itchat.search_mps(name='LittleCoder') 当两项都是勇士, 将仅返回特定UserName的公众号. 群聊 get_chatrooms : 返回完整的群聊列表. search_chatrooms : 群聊搜索. update_chatroom : 获取群聊用户列表或更新该群聊. 群聊在首次获取中不会获取群聊的用户列表, 所以需要调用该命令才能获取群聊成员. 传入群聊的 UserName , 返回特定群聊的详细信息. 传入UserName组成的列表, 返回指定用户的最新信息组成的列表. 1memberList = itchat.update_chatroom('@@abcdefg1234567', detailedMember=True) 创建群聊,增加/删除群聊用户: 由于之前通过群聊检测是否被好友拉黑的程序, 目前这三个方法都被严格限制了使用频率. 删除群聊需要本账号为管理员, 否则无效. 将用户加入群聊有直接加入与发送邀请, 通过 useInvitation 设置. 超过 40 人的群聊无法使用直接加入的加入方式. 1234567memberList = itchat.get_frients()[1:]# 创建群聊, topic 键值为群聊名称.chatroomUserName = itchat.create_chatroom(memberList, "test chatroom")# 删除群聊内的用户itchat.delete_member_from_chatroom(chatroomUserName, memberList[0])# 增加用户进入群聊.itchat.add_member_into_chatroom(chatroomUserName, memberList[0], useInvitation=False) 方法汇总1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253itchat.add_friend itchat.new_instance itchat.add_member_into_chatroom itchat.originInstance itchat.auto_login itchat.returnvalues itchat.check_login itchat.run itchat.components itchat.search_chatrooms itchat.config itchat.search_friends itchat.configured_reply itchat.search_mps itchat.content itchat.send itchat.core itchat.send_file itchat.Core itchat.send_image itchat.create_chatroom itchat.send_msg itchat.delete_member_from_chatroom itchat.send_raw_msg itchat.dump_login_status itchat.send_video itchat.get_chatrooms itchat.set_alias itchat.get_contact itchat.set_chatroom_name itchat.get_friends itchat.set_logging itchat.get_head_img itchat.set_pinned itchat.get_mps itchat.show_mobile_login itchat.get_msg itchat.start_receiving itchat.get_QR itchat.storage itchat.get_QRuuid itchat.update_chatroom itchat.instanceList itchat.update_friend itchat.load_login_status itchat.upload_file itchat.log itchat.utils itchat.login itchat.VERSION itchat.logout itchat.web_init itchat.msg_register 实例 下面是博主写的一个程序，该程序的主要功能是监控撤回消息，并且如果有消息撤回就会撤回的消息发送给你，以后再也不用担心看不到好友的撤回的消息了，由于注释写的很详细，因此这里就不在详细的讲解了，直接贴代码 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106# coding:utf-8import itchatfrom itchat.content import TEXTfrom itchat.content import *import sysimport timeimport rereload(sys)sys.setdefaultencoding('utf8')import osmsg_information = &#123;&#125;face_bug=None #针对表情包的内容@itchat.msg_register([TEXT, PICTURE, FRIENDS, CARD, MAP, SHARING, RECORDING, ATTACHMENT, VIDEO],isFriendChat=True, isGroupChat=True, isMpChat=True)def handle_receive_msg(msg): global face_bug msg_time_rec = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()) #接受消息的时间 msg_from = itchat.search_friends(userName=msg['FromUserName'])['NickName'] #在好友列表中查询发送信息的好友昵称 msg_time = msg['CreateTime'] #信息发送的时间 msg_id = msg['MsgId'] #每条信息的id msg_content = None #储存信息的内容 msg_share_url = None #储存分享的链接，比如分享的文章和音乐 print msg['Type'] print msg['MsgId'] if msg['Type'] == 'Text' or msg['Type'] == 'Friends': #如果发送的消息是文本或者好友推荐 msg_content = msg['Text'] print msg_content #如果发送的消息是附件、视屏、图片、语音 elif msg['Type'] == "Attachment" or msg['Type'] == "Video" \ or msg['Type'] == 'Picture' \ or msg['Type'] == 'Recording': msg_content = msg['FileName'] #内容就是他们的文件名 msg['Text'](str(msg_content)) #下载文件 # print msg_content elif msg['Type'] == 'Card': #如果消息是推荐的名片 msg_content = msg['RecommendInfo']['NickName'] + '的名片' #内容就是推荐人的昵称和性别 if msg['RecommendInfo']['Sex'] == 1: msg_content += '性别为男' else: msg_content += '性别为女' print msg_content elif msg['Type'] == 'Map': #如果消息为分享的位置信息 x, y, location = re.search( "&lt;location x=\"(.*?)\" y=\"(.*?)\".*label=\"(.*?)\".*", msg['OriContent']).group(1, 2, 3) if location is None: msg_content = r"纬度-&gt;" + x.__str__() + " 经度-&gt;" + y.__str__() #内容为详细的地址 else: msg_content = r"" + location elif msg['Type'] == 'Sharing': #如果消息为分享的音乐或者文章，详细的内容为文章的标题或者是分享的名字 msg_content = msg['Text'] msg_share_url = msg['Url'] #记录分享的url print msg_share_url face_bug=msg_content##将信息存储在字典中，每一个msg_id对应一条信息 msg_information.update( &#123; msg_id: &#123; "msg_from": msg_from, "msg_time": msg_time, "msg_time_rec": msg_time_rec, "msg_type": msg["Type"], "msg_content": msg_content, "msg_share_url": msg_share_url &#125; &#125; )##这个是用于监听是否有消息撤回@itchat.msg_register(NOTE, isFriendChat=True, isGroupChat=True, isMpChat=True)def information(msg): #这里如果这里的msg['Content']中包含消息撤回和id，就执行下面的语句 if '撤回了一条消息' in msg['Content']: old_msg_id = re.search("\&lt;msgid\&gt;(.*?)\&lt;\/msgid\&gt;", msg['Content']).group(1) #在返回的content查找撤回的消息的id old_msg = msg_information.get(old_msg_id) #得到消息 print old_msg if len(old_msg_id)&lt;11: #如果发送的是表情包 itchat.send_file(face_bug,toUserName='filehelper') else: #发送撤回的提示给文件助手 msg_body = "告诉你一个秘密~" + "\n" \ + old_msg.get('msg_from') + " 撤回了 " + old_msg.get("msg_type") + " 消息" + "\n" \ + old_msg.get('msg_time_rec') + "\n" \ + "撤回了什么 ⇣" + "\n" \ + r"" + old_msg.get('msg_content') #如果是分享的文件被撤回了，那么就将分享的url加在msg_body中发送给文件助手 if old_msg['msg_type'] == "Sharing": msg_body += "\n就是这个链接➣ " + old_msg.get('msg_share_url') # 将撤回消息发送到文件助手 itchat.send_msg(msg_body, toUserName='filehelper') # 有文件的话也要将文件发送回去 if old_msg["msg_type"] == "Picture" \ or old_msg["msg_type"] == "Recording" \ or old_msg["msg_type"] == "Video" \ or old_msg["msg_type"] == "Attachment": file = '@fil@%s' % (old_msg['msg_content']) itchat.send(msg=file, toUserName='filehelper') os.remove(old_msg['msg_content']) # 删除字典旧消息 msg_information.pop(old_msg_id)itchat.auto_login(hotReload=True)itchat.run() 参考文章 文档：https://itchat.readthedocs.io/zh/latest/ http://www.cnblogs.com/yanjingnan/p/6831464.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python发送邮件]]></title>
      <url>%2F2017%2F05%2F13%2Fpython%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[python发送邮件准备 python中发送邮件主要用的是smtplib和email两个模块，下面主要对这两个模块进行讲解 在讲解之前需要准备至少两个测试的邮箱，其中要在邮箱的设置中开启smtplib协议才可以进行发送和接受 smtplib smtplib.SMTP( [host [, port [, local_hostname[,timeout]]]]) host是SMTP主机的服务器，其中163邮箱的是smtp.163.com,其他的可以在网上找到，port是端口号，这里默认的是25，local_hostname是你主机的SMTP,如果SMTP在你的本机上，你只需要指定服务器地址为 localhost 即可。timeout是设置的连接的限制时间，如果超过这个时间还没有连接上那么就会出现错误 SMTP.set_debuglevel(level)：设置是否为调试模式。默认为False，即非调试模式，表示不输出任何调试信息。如果设置为1就表示输出调试信息 SMTP.connect([host[, port]])：连接到指定的smtp服务器。参数分别表示smpt主机和端口。注意: 也可以在host参数中指定端口号（如：smpt.yeah.net:25），这样就没必要给出port参数。 SMTP.login(user, password) 登录服务器，这里的user是邮箱的用户名，但是这里的password并不是你邮箱的密码，当你开启SMTP的时候会提示你设置一个密码，这里的密码就是对应的密码 SMTP.sendmail(from_addr, [to_addrs,], msg[, mail_options, rcpt_options]) 发送邮件，from_addr是发送方也就是你的邮箱地址，to_addr是接受方的地址，当然这里的可以填上多个邮箱账号发送给多个账号，如果有多个账号需要使用列表传递参数 SMTP.quit()断开连接 email emial模块用来处理邮件消息，包括MIME和其他基于RFC 2822的消息文档。使用这些模块来定义邮件的内容，是非常简单的。其包括的类有（更加详细的介绍可见：http://docs.python.org/library/email.mime.html）： class email.mime.base.MIMEBase(_maintype, _subtype, **_params)：这是MIME的一个基类。一般不需要在使用时创建实例。其中_maintype是内容类型，如text或者image。_subtype是内容的minor type类型，如plain或者gif。 **_params是一个字典，直接传递给Message.add_header()。 class email.mime.multipart.MIMEMultipart([_subtype[, boundary[, _subparts[, _params]]]]：MIMEBase的一个子类，多个MIME对象的集合，_subtype默认值为mixed。boundary是MIMEMultipart的边界，默认边界是可数的。当需要发送附件的时候使用的就是这个类 class email.mime.application.MIMEApplication(_data[, _subtype[, _encoder[, **_params]]])：MIMEMultipart的一个子类。 class email.mime.audio. MIMEAudio(_audiodata[, _subtype[, _encoder[, **_params]]])： MIME音频对象 class email.mime.image.MIMEImage(_imagedata[, _subtype[, _encoder[, **_params]]])：MIME二进制文件对象。主要用来发送图片 普通文本邮件 class email.mime.text.MIMEText(_text[, _subtype[, _charset]])：MIME文本对象，其中_text是邮件内容，_subtype邮件类型，可以是text/plain（普通文本邮件），html/plain(html邮件), _charset编码，可以是gb2312等等。 普通文本邮件发送的实现，关键是要将MIMEText中_subtype设置为plain。首先导入smtplib和mimetext。创建smtplib.smtp实例，connect邮件smtp服务器，login后发送，具体代码如下* 1234567891011121314151617181920212223# 一个格式化邮件的函数，可以用来使用def _format_addr(s): name, addr = parseaddr(s) return formataddr(( Header(name, 'utf-8').encode(), addr.encode('utf-8') if isinstance(addr, unicode) else addr))from_addr='××××××××' #你的邮箱地址from_password='×××××××' #你的密码# to_email='chenjiabing666@yeah.net'to_email='××××××' #要发送的邮箱地址msg=MIMEText('乔装打扮，不择手段','plain','utf-8') #这里text=乔装打扮，不择手段msg['From'] = _format_addr(u'Python爱好者 &lt;%s&gt;' % from_addr) #格式化发件人msg['To'] = _format_addr(u'管理员 &lt;%s&gt;' % to_email) #格式化收件人msg['Subject'] = Header(u'来自SMTP的问候……', 'utf-8').encode() #格式化主题stmp='smtp.163.com'server=smtplib.SMTP(stmp,port=25,timeout=30) #连接，设置超时时间30sserver.login(from_addr,from_password) #登录server.set_debuglevel(1) #输出所有的信息server.sendmail(from_addr,to_email,msg.as_string()) #这里的as_string()是将msg转换成字符串类型的,如果你想要发给多个人，需要讲to_email换成一个列表 发送html邮件 还是用MIMEText来发送，不过其中的_subType设置成html即可，详细代码如下： 12345678910111213141516171819202122232425def _format_addr(s): name, addr = parseaddr(s) return formataddr(( Header(name, 'utf-8').encode(), addr.encode('utf-8') if isinstance(addr, unicode) else addr))from_addr='××××××××' #你的邮箱地址from_password='×××××××' #你的密码# to_email='chenjiabing666@yeah.net'to_email='××××××' #要发送的邮箱地址html="""&lt;p&gt;&lt;h1 style="color:red"&gt;大家好&lt;/h1&gt;&lt;/p&gt;"""msg=MIMEText(html,'html','utf-8') #这里text=html,设置成html格式的msg['From'] = _format_addr(u'Python爱好者 &lt;%s&gt;' % from_addr) #格式化发件人msg['To'] = _format_addr(u'管理员 &lt;%s&gt;' % to_email) #格式化收件人msg['Subject'] = Header(u'来自SMTP的问候……', 'utf-8').encode() #格式化主题stmp='smtp.163.com'server=smtplib.SMTP(stmp,port=25,timeout=30) #连接，设置超时时间30sserver.login(from_addr,from_password) #登录server.set_debuglevel(1) #输出所有的信息server.sendmail(from_addr,to_email,msg.as_string()) #这里的as_string()是将msg转换成字符串类型的,如果你想要发给多个人，需要讲to_email换成一个列表 附件的发送 发送带附件的邮件，首先要创建MIMEMultipart()实例，然后构造附件，如果有多个附件，可依次构造，最后利用smtplib.smtp发送，具体实力如下： 123456789101112131415161718192021222324252627282930313233343536373839404142from email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextimport smtplibfrom email.mime.image import MIMEImagefrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.header import Headerdef _format_addr(s): name, addr = parseaddr(s) return formataddr(( Header(name, 'utf-8').encode(), addr.encode('utf-8') if isinstance(addr, unicode) else addr))from_addr='××××××××' #你的邮箱地址from_password='×××××××' #你的密码# to_email='chenjiabing666@yeah.net'to_email='××××××' #要发送的邮箱地址msg=MIMEMultipart() #创建实例text=MIMEText('&lt;h2 style="color:red"&gt;陈加兵&lt;/h2&gt;&lt;br/&gt;&lt;p&gt;大家好&lt;/p&gt;','html','utf-8')msg.attach(text) #添加一个正文信息，这里实在正文中显示的信息#创建一个文本附件，这里是从指定文本中读取信息，然后创建一个文本信息att1=MIMEText(open('/home/chenjiabing/文档/MeiZi_img/full/file.txt','rb').read(),'plain','utf-8')att1["Content-Type"] = 'application/octet-stream' #指定类型att1["Content-Disposition"] = 'attachment; filename="123.txt"'#这里的filename可以任意写，写什么名字，邮件中显示什么名字msg.attach(att1) #向其中添加附件img_path='/home/chenjiabing/文档/MeiZi_img/full/file.jpg' #图片路径image=MIMEImage(open(img_path,'rb').read()) #创建一个图片附件image.add_header('Content-ID','&lt;0&gt;') #指定图片的编号,这个会在后面用到image.add_header('Content-Disposition', 'attachment', filename='test.jpg') image.add_header('X-Attachment-Id', '0')msg.attach(image) #添加附件stmp='smtp.163.com'server=smtplib.SMTP(stmp,port=25,timeout=30) #连接，设置超时时间30sserver.login(from_addr,from_password) #登录server.set_debuglevel(1) #输出所有的信息server.sendmail(from_addr,to_email,msg.as_string()) #这里的as_string()是将msg转换成字符串类型的,如果你想要发给多个人，需要讲to_email换成一个列表 将图片嵌入到正文信息中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566from email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextimport smtplibfrom email.mime.image import MIMEImagefrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.header import Headerdef _format_addr(s): name, addr = parseaddr(s) return formataddr(( Header(name, 'utf-8').encode(), addr.encode('utf-8') if isinstance(addr, unicode) else addr))from_addr='××××××××' #你的邮箱地址from_password='×××××××' #你的密码# to_email='chenjiabing666@yeah.net'to_email='××××××' #要发送的邮箱地址msg=MIMEMultipart() #创建实例html="""&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;下面演示嵌入图片&lt;/p&gt;&lt;section&gt;&lt;img src='cid:0' style='float:left'/&gt;&lt;img src='cid:1' style='float:left'/&gt;&lt;/setcion&gt;&lt;/body&gt;&lt;/html&gt;"""text=MIMEText('&lt;h2 style="color:red"&gt;陈加兵&lt;/h2&gt;&lt;br/&gt;&lt;p&gt;大家好&lt;/p&gt;','html','utf-8')msg.attach(text) #添加一个正文信息，这里实在正文中显示的信息#创建一个文本附件，这里是从指定文本中读取信息，然后创建一个文本信息att1=MIMEText(open('/home/chenjiabing/文档/MeiZi_img/full/file.txt','rb').read(),'plain','utf-8')att1["Content-Type"] = 'application/octet-stream' #指定类型att1["Content-Disposition"] = 'attachment; filename="123.txt"'#这里的filename可以任意写，写什么名字，邮件中显示什么名字msg.attach(att1) #向其中添加附件## 创建一个图片附件img_path='/home/chenjiabing/文档/MeiZi_img/full/file.jpg' #图片路径image=MIMEImage(open(img_path,'rb').read()) #创建一个图片附件image.add_header('Content-ID','&lt;0&gt;') #指定图片的编号,image.add_header('Content-Disposition', 'attachment', filename='test.jpg') image.add_header('X-Attachment-Id', '0')msg.attach(image) #添加附件#创建第二个图片附件img_path_1='/home/chenjiabing/文档/MeiZi_img/full/test.jpg' #图片路径image1=MIMEImage(open(img_path,'rb').read()) #创建一个图片附件image1.add_header('Content-ID','&lt;1&gt;') #指定图片的编号,这个就是在上面对应的cid:1的那张图片，因此这里的编号一定要对应image1.add_header('Content-Disposition', 'attachment', filename='img.jpg') image1.add_header('X-Attachment-Id', '0')msg1.attach(image) #添加附件stmp='smtp.163.com'server=smtplib.SMTP(stmp,port=25,timeout=30) #连接，设置超时时间30sserver.login(from_addr,from_password) #登录server.set_debuglevel(1) #输出所有的信息server.sendmail(from_addr,to_email,msg.as_string()) #这里的as_string()是将msg转换成字符串类型的,如果你想要发给多个人，需要讲to_email换成一个列表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python制作电子书]]></title>
      <url>%2F2017%2F05%2F13%2Fpython%E5%88%B6%E4%BD%9C%E7%94%B5%E5%AD%90%E4%B9%A6%2F</url>
      <content type="text"><![CDATA[python制作pdf电子书准备 制作电子书使用的是python的pdfkit这个库，pdfkit是 wkhtmltopdf 的Python封装包，因此在安装这个之前要安装wkhtmltopdf 安装wkhtmltopdf sudo apt-get install wkhtmltopdf (ubantu下，不过这里安装的时候可能对应的版本不同，会出现错误，如果不行的话还请自己百度下，我安装的时候是可以的) windows下的用户直接到wkhtmltopdf官网下载稳定版本，然后直接安装即可，但是安装之后需要注意的是一定要将其添加到环境变量中，否则会出现找不到路径的问题 python安装依赖包 以下都是我们需要用到的库 pip install requests pip install BeautifulSoup4 pip install pdfkit pdfkit的用法初级了解函数 pdfkit.from_url([url,],&#39;demo.pdf&#39;) 这个是直接传入一个url或者一个url列表，然后通过这个函数直接将其网页转换成demo.pdf,注意这里只能转换静态文本，如果使用js一些脚本的话是不能直接转换的 pdfkit.from_string(&quot;&lt;h1&gt;&lt;a href=&quot;https://chenjiabing666.gituhb.io&quot;&gt;陈加兵的博客&lt;/a&gt;&lt;/h1&gt;&quot;,&#39;demo.pdf&#39;) 这个是直接讲一个字符串转换成pdf格式的电子书，里面可以直接传一个字符串，也可以用html标签包裹这个字符串 pdfkit.from_file([file_name,],&#39;demo.pdf&#39;) 这个是直接传入一个文件或者一个列表即是多个文件，不过这里传入的文件一般都是html格式的文件 进阶 当然知道这个是多么枯燥，生成的电子书书也不能添加各种的样式，下面我们将会介绍一些添加的样式的方法 options 这个参数是上面函数的可选参数，其中制定了一些选项，详情请见http://wkhtmltopdf.org/usage/wkhtmltopdf.txt, 你可以移除选项名字前面的 ‘–’ .如果选项没有值, 使用None, Falseor ,* 作为字典值，例子如下： 12345678910111213141516options = &#123; 'page-size': 'Letter', 'margin-top': '0.75in', 'margin-right': '0.75in', 'margin-bottom': '0.75in', 'margin-left': '0.75in', 'encoding': "UTF-8", 'custom-header': [ ('Accept-Encoding', 'gzip') ], 'cookie': [ ('cookie-name1', 'cookie-value1'), ('cookie-name2', 'cookie-value2'), ], 'outline-depth': 10, &#125; cover 这个参数是用来制作封面的，也是函数中的一个参数，如果想要实现的话可以先写一个html文本，在其中嵌入几张图片或者文字作为封面，然后写入出传入函数即可 123456789101112131415161718options = &#123; 'page-size': 'Letter', 'margin-top': '0.75in', 'margin-right': '0.75in', 'margin-bottom': '0.75in', 'margin-left': '0.75in', 'encoding': "UTF-8", 'custom-header': [ ('Accept-Encoding', 'gzip') ], 'cookie': [ ('cookie-name1', 'cookie-value1'), ('cookie-name2', 'cookie-value2'), ], 'outline-depth': 10, &#125;cover='demo.html'pdfkit.from_file('demo.html','demo.pdf',cover=cover,options=options) css 这里的css也是函数中的一个可选参数，这个参数主要的作用作用就是在其中定义自己喜欢的样式，当然这里也可以传入一个列表，定义多个样式css文件，当然没有这个参数也可以实现定义自己的样式，只需要在自己的html模板中定义内嵌的样式，或者直接用&lt;link&gt;引用外面的样式即可，本人亲试是可以的，具体的使用如下 12css='demo.css'pdfkit.from_file('demo.html','demo.pdf',options=options,cover=cover,css=css) 注意 这里生成pdf的时候可能出现中文的乱码，请一定在html模板开头指定字体utf-8-&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; 可能在爬取生成的时候会出现ascii错误，只需要在py文件开头写下： 1234import sysimport threadingreload(sys)sys.setdefaultencoding('utf8') 写入文件的时候不想python3一样可以指定编码格式，这里我使用的是codecs库，可以向python3一样指定其中的编码格式 实战 本人爬了廖雪峰老师的python2.7的教程，并且做成了电子书，截图如下 注意 这里并没有使用框架，如果有兴趣的朋友可以用框架写一个爬取全站的 这里的主要用到的是BeautifulSoup和requests,详情可以看我的博客中的BeautifulSoup用法,后续还会更新requests的用法 源代码请见https://github.com/chenjiabing666/liaoxuefeng_pdfkit 参考文章 http://mp.weixin.qq.com/s/LH8nEFfVH4_tvYWo46CF5Q http://www.cnblogs.com/taceywong/p/5643978.html http://beautifulsoup.readthedocs.io/zh_CN/latest/#id44]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[回溯算法]]></title>
      <url>%2F2017%2F05%2F10%2F%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[回溯算法主要思想 回溯算法的基本思想是：从一条路往前走，能进则进，不能进则退回来，换一条路再试。八皇后问题就是回溯算法的典型，第一步按照顺序放一个皇后，然后第二步符合要求放第2个皇后，如果没有位置符合要求，那么就要改变第一个皇后的位置，重新放第2个皇后的位置，直到找到符合条件的位置就可以了。回溯在迷宫搜索中使用很常见，就是这条路走不通，然后返回前一个路口，继续下一条路。回溯算法说白了就是穷举法。不过回溯算法使用剪枝函数，剪去一些不可能到达 最终状态（即答案状态）的节点，从而减少状态空间树节点的生成。回溯法是一个既带有系统性又带有跳跃性的的搜索算法。它在包含问题的所有解的解空间树中，按照深度优先的策略，从根结点出发搜索解空间树。算法搜索至解空间树的任一结点时，总是先判断该结点是否肯定不包含问题的解。如果肯定不包含，则跳过对以该结点为根的子树的系统搜索，逐层向其祖先结点回溯。否则，进入该子树，继续按深度优先的策略进行搜索。回溯法在用来求问题的所有解时，要回溯到根，且根结点的所有子树都已被搜索遍才结束。而回溯法在用来求问题的任一解时，只要搜索到问题的一个解就可以结束。这种以深度优先的方式系统地搜索问题的解的算法称为回溯法，它适用于解一些组合数较大的问题。回溯算法也叫试探法，它是一种系统地搜索问题的解的方法。回溯算法的基本思想是：从一条路往前走，能进则进，不能进则退回来，换一条路再试。用回溯算法解决问题的一般步骤为： 定义一个解空间，它包含问题的解。 利用适于搜索的方法组织解空间。 利用深度优先法搜索解空间。 利用限界函数避免移动到不可能产生解的子空间。 解决迷宫问题解决思想 将迷宫问题对应为二维数组，数组中只有两种值0和1，其中0，1分别表示通路和墙。不过在解决这个问题的时候一般要在最外面添加一个围墙，这里设置每个围墙都为1，这样有利于防止当走到了迷宫的出口处还会向前走，这个并不一定，只是最一般的方法，也是最有利于理解的方法。这里的利用到了回溯法，需要走到了一个位置，然后向四处试探，如果有一个方向可以走了就将当前的点压入栈，并且标记当前点以便于区分是否走过，如果四处都无出路，只需要回到前一个走到的点，然后从前一个点再换一个方向重新走 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import java.util.Stack;/** * Created by chenjiabing on 17-5-5. */class position &#123; public int row; public int col; public position(int row, int col) &#123; this.col = col; this.row = row; &#125; public position() &#123; row = 0; col = 0; &#125; public String toString() &#123; return "(" + (row - 1) + " ," + (col - 1) + ")"; &#125; //这里由于四周围上了墙，所以这里的输出就要在原来的基础上减一&#125;class Main &#123; private int[][] maze = null; private Stack&lt;position&gt; stack = null; //创建一个栈用于存储状态 private int row; //行数 private int col; boolean[][] p = null; //这里的p是用来标记已经走过的点，初始化为false public boolean end(int i, int j) &#123; return i == row &amp;&amp; j == col; &#125; public Main(int[][] maze) &#123; stack = new Stack&lt;position&gt;(); row = maze[0].length;// 行数 col = maze.length; //列数 p = new boolean[row + 2][col + 2]; for (int i = 0; i &lt; row; i++) &#123; for (int j = 0; j &lt; col; j++) &#123; p[i][j] = false; //初始化 &#125; &#125; this.maze = maze; &#125; public void findPath() &#123; //创建一个新的迷宫，将两边都围上墙，也就是在四周都填上1的墙，形成新的迷宫，主要的目的就是防止走到迷宫的边界的出口的位置还会继续向前走 //因此需要正确的判断是否在边界线上，所以要在外围加上一堵墙, int[][] temp = new int[row + 2][col + 2]; for (int i = 0; i &lt; row + 2; i++) &#123; for (int j = 0; j &lt; col + 2; j++) &#123; temp[0][j] = 1; //第一行围上 temp[row + 1][j] = 1; //最后一行围上 temp[i][0] = temp[i][col + 1] = 1; //两边的围上 &#125; &#125; // 将原始迷宫复制到新的迷宫中 for (int i = 0; i &lt; row; ++i) &#123; for (int j = 0; j &lt; col; ++j) &#123; temp[i + 1][j + 1] = maze[i][j]; &#125; &#125; int i = 1; int j = 1; p[i][j] = true; stack.push(new position(i, j)); //这里是是将走到的点入栈，然后如果前后左右都走不通的话才出栈 while (!stack.empty() &amp;&amp; !end(i, j)) &#123; //下面就开始在四周试探，如果有路就向前走，顺序分别是右，下，上，左，当然这是随便定义的，不过一般都是现向下和右的 if (temp[i][j + 1] == 0 &amp;&amp; p[i][j + 1] == false)//这里如果不在四周加上墙，那么在到达边界判断的时候就会出现超出数组的索引的错误，因为到达边界再加一就会溢出 &#123; p[i][j + 1] = true; stack.push(new position(i, j + 1)); j++; &#125; else if (temp[i + 1][j] == 0 &amp;&amp; p[i + 1][j] == false)//如果下面可以走的话，讲当前点压入栈，i++走到下一个点 &#123; p[i + 1][j] = true; stack.push(new position(i + 1, j)); i++; &#125; else if (temp[i][j - 1] == 0 &amp;&amp; p[i][j - 1] == false) &#123; p[i][j - 1] = true; stack.push(new position(i, j - 1)); j--; &#125; else if (temp[i - 1][j] == 0 &amp;&amp; p[i - 1][j] == false) &#123; p[i - 1][j] = true; stack.push(new position(i - 1, j)); i--; &#125; else //前后左右都不能走 &#123; System.out.println(i + "---------" + j); stack.pop(); //这个点不能走通，弹出 if (stack.empty()) //如果此栈中已经没有点了，那么直接跳出循环 &#123; System.out.println("没有路径了，出不去了"); return; //直接退出了，下面就不用找了 &#125; i = stack.peek().row; //获得最新点的坐标 j = stack.peek().col; &#125; //如果已经到达了边界，那么直接可以出去了，不需要继续向前走了，这里是规定边界的任意为0的位置都是出口 //如果不加这个判断的话，那么当到达边界的时候，只有走到不能再走的时候才会输出路线，那种线路相对这个而言是比较长的 if (j == temp[0].length - 2) &#123; //如果已经到达边界了，那么当前的位置就是出口，就不需要再走了 Stack&lt;position&gt; pos = new Stack&lt;position&gt;(); System.out.println("路径如下："); for (int count = 0; count &lt; stack.size(); count++) &#123; System.out.println(stack.elementAt(count)); &#125; &#125; &#125; &#125; public static void main(String args[]) &#123; int[][] maze = &#123; &#123;0, 1, 0, 0, 0&#125;, &#123;0, 1, 0, 1, 0&#125;, &#123;0, 0, 0, 0, 0&#125;, &#123;0, 1, 1, 1, 0&#125;, &#123;0, 0, 0, 1, 0&#125; &#125;; Main main = new Main(maze); main.findPath(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[跳跃链表]]></title>
      <url>%2F2017%2F05%2F09%2F%E8%B7%B3%E8%B7%83%E9%93%BE%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[数据结构之跳跃链表简介 总的来说跳跃链表最大的好处就是提高了检索了的速率，可以说说是大幅度的提高，相对于单链表来说是一种高效率的检索结构 原理 跳跃表的结构是：假如底层有10个节点， 那么底层的上一层理论上就有5个节点，再上一层理论上就有2个或3个节点，再上一层理论上就有1个节点。所以从这里可以看出每一层的节点个数为其下一层的1/2个元素，以此类推。从这里我们可以看到，从插入时我们只要保证上一层的元素个数为下一层元素个数的1/2，我们的跳跃表就能成为理想的跳跃表。那么怎么才能保证我们插入时上层元素个数是下层元素个数的1/2呢，？很简单 抛硬币就可以解决了，假设元素X要插入跳跃表，最底层是肯定要插入X的，那么次低层要不要插入呢，我们希望上层元素个数是下层的1/2，那么我们有1/2的概率要插入到次低层，这样就来抛硬币吧，正面就插入，反面就不插入，次次底层相对于次低层，我们还是有1/2的概率插入，那么就继续抛硬币吧 ， 以此类推元，素X插入第n层的概率是(1/2)的n次。这样，我们能在跳跃表中插入一个元素了。基本的样子如下图： 代码实现(java语言)节点定义123456789101112131415package skip;public class Node&#123; public Integer value; //插入的数据 public Node left; //分别对应的四个方向的指针 public Node down; public Node right; public Node up; public Node(Integer value) //构造函数 &#123; this.value=value; down=up=right=left=null; &#125;&#125; 表的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199package skip;import java.util.Random;public class SkipList &#123; private Node head; //最上面一侧的头结点，这里使用的是双链表 private Node tail; //最上面一层的尾节点，这里的头尾节点是不存储数据的，数据域全是null private int level; //表中的最高的层数，就是总共的层数 private int size; //插入节点的个数，头尾节点除外 private Random random; //用来判断是否需要增加高度的随机函数 public SkipList() &#123; level = 0; //level默认是0层，就是只有最下面的一层 head = new Node(null); tail = new Node(null); head.right = tail; //这里初始化成一个只有一层的双链表 tail.left = head; size = 0; //size初始化为0 random = new Random(); &#125; //这个函数的作用是找到插入节点的前面一个节点，这里默认的是将表升序存储 public Node findFirst(Integer value) &#123; Node p = head; while (true) &#123; //判断要插入的位置，当没有查到尾节点并且要插入的数据还是比前面的大的话，就将节点右移，知道找到合适的位置 //这里需要注意的是这里的head代表不一定是最底层的，因此这里的查找都是从最高层进行查找的，如果满足条件就要向下移动 //直到最底层 while (p.right.value != null &amp;&amp; p.right.value &lt;= value) &#123; p = p.right; &#125; //向下移动，直到到达最后一层 if (p.down != null) &#123; p = p.down; &#125; else &#123; //到达最底层跳出即可 break; &#125; &#125; return p; //此时这里的p就是要插入节点的前面一个节点 &#125; //这是插入函数，这里先执行插入，然后判断是否需要增加高度 public void insert(int value) &#123; Node curr = findFirst(value); //先找到插入位置的前面一个节点 Node q = new Node(value); //新建一个插入的节点 //下面执行插入步骤，这个和双链表是一样的步骤 q.right = curr.right; q.left = curr; curr.right.left = q; curr.right = q; int i = 0; //表示当前节点所在的层数，开始插入的是在下面插入的，所以开始的时候是在0层 //这里判断是否需要增加高度，每一层相对域下面来说都有二分之一的概率，也就是说每一层增加的概率是（1/2）^n //通俗的说就是每一层的节点是将会保证是下面一层的1/2 while (random.nextDouble() &lt; 0.5) &#123; if (i &gt;= level) &#123; //如果当前插入的节点所处的层数大于等于最大的层数，那么就需要增加高度了，因为这里要保证头尾节点的高度是最高的 //下面的代码就是在头尾节点的上插入新的节点，以此来增加高度 Node p1 = new Node(null); Node p2 = new Node(null); p1.right = p2; p1.down = head; p2.left = p1; p2.down = tail; head.up = p1; //将头尾节点上移，成为最顶层的节点，这就是为什么每次插入和查询的时候都是最上面开始查询的，因为这里的head默认的就是从最上面开始的 tail.up = p2; head = p1; tail = p2; level++; //最高层数加一 &#125; while (curr.up == null) &#123; //当然增加高度就是在插入节点上面新插入一个节点，然后将之与插入的节点相连 //既然这里新插入节点增高了，那么就需要找到与新插入节点上面的那个节点相连接，这里我们将新插入节点的前面的同等高度的节点与之相连 curr = curr.left; &#125; curr = curr.up; //通过前面的一个节点找到与之相连的节点 //下面就是创建一个节点插入到插入节点的头上以此来增加高度，并且这个节点与前面一样高的节点相连 Node e = new Node(value); e.left = curr; e.right = curr.right; curr.right.left = e; //此时的curr就是与之同等高度的节点 curr.right = e; e.down = q; q.up = e; q = e; //将新插入的节点上移到最上面，因为后面可能还要在这里增加高度，就是在最上面插入新的一模一样的节点 i++; //增加当前所处的高度，这里一定能要记得写上，如果还要继续增加的话，需要判读是否需要增加头尾节的高度 &#125; size++; //节点加一 &#125; //下面是打印每一层节点的情况 public void display() &#123; while (level &gt;= 0) &#123; Node p = head; while (p != null) &#123; System.out.print(p.value + "--------&gt;"); p = p.right; &#125; System.out.println(); System.out.println("*****************************"); level--; head = head.down; &#125; &#125; /*在链表中查找某个值是否存在，如果存在找到的节点，当然先从最高层开始查找，如果找到了在比这个值小的最后一个值，那么就顺着这个值的下面开始寻找，按照上面的步骤 再次寻找，如过这个值正好等于要找的值，就返回true，形象的来说就是形成一个梯度的感觉。注意这里返回的节点一定是最底层的节点，利于下面的删除操作 * */ public Node search(int value) &#123; Node p = head; while (true) &#123; /*这里一定要写成p.right.value!=null,如果写成p.right!=null运行可能有错误， 因为这里的尾节点的值为null，但是它的节点不是空的，如果成这样的话,那么节点可能会找到尾节点都没有找到，此时在判断value的值就出现错误 相当与判断tail.right.value&lt;=value,这个肯定是不行的，因为这个节点不存在，是空的更别说值了 */ //从最高层开始判断找到比这个小的最后一个值，就是找到一个节点的前面比value小的，后面的节点的值比value大的 while (p.right.value != null &amp;&amp; p.right.value &lt;= value) &#123; p = p.right; //如果没有找到就后移直到找到这个节点 &#125; //如果找到的这个节点不是最底层的话，就向下移动一层，然后循环再次寻找，总之就是从最高层开始，一层一层的寻找 if (p.down != null) &#123; //这个表示上面的循环没有找到的相等的，那么就向下移动一层 p = p.down; &#125; else &#123; //如果到了最底层了，这里的值仍然没有找到这个值，那么就表示不存在这个值 if (p.value == value) &#123; //判断是否存在value相等的值// System.out.println(p.value + "-----&gt;"); return p; //返回节点 &#125; return null; //仍然没有找到返回null &#125; &#125; &#125; /* 这里是利用上面的查找函数，找到当前需要删除的节点，当然这个节点是最底层的节点，然后循环从最底层开始删除所有的节点 * */ public void delete(int value) &#123; Node temp = search(value); //这里返回的必须是最底层的节点，因为要从最下面的往上面全部删除所有层的节点，否则的话可能在某一层上仍然存在这个节点 while (temp != null) &#123; temp.left.right = temp.right; temp.right.left = temp.left; temp = temp.up; //节点上移，继续删除上一层的节点 &#125; &#125; public static void main(String args[]) &#123; SkipList skipList = new SkipList(); Random random = new Random(); skipList.insert(33); skipList.insert(44); skipList.insert(11); skipList.insert(10); skipList.insert(22); skipList.insert(22); for (int i = 0; i &lt; 500; i++) &#123; int value = (int) (random.nextDouble() * 1000); skipList.insert(value);// System.out.println(value); &#125; Node p = skipList.search(22); if (p != null) &#123; System.out.println(p.value); &#125; else System.out.println("没有找到"); skipList.delete(33); skipList.display(); &#125;&#125; 源码地址 跳跃链表 双链表 单链表 参考文章 java实现跳跃链表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git常用命令]]></title>
      <url>%2F2017%2F05%2F07%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[git常用操作第一次连接远程仓库的配置配置user.name 和user.email git config --global user.name &quot;name&quot; 设置你的用户名 git config --global user.email &quot;emil&quot; 设置用户的email账号 生成密钥 ssh-keygen -t rsa -C &quot;your email&quot; 其中填的是你的注册的github的账号，输入之后如果不需要输入密码的话，连续输入三个回车即可，最后在你的在终端输入 cd ~/.ssh 进入到你的文件下可以看到有两个文件id_rsa和id_rsa.pub,最后复制你的id_rsa.pub中的内容到github中的账号中即可 ssh -T git@github.com 如果上面的步骤已经完成了，那么就是验证是否完成了，输入上述语句，如果出现信息，那么证明说明你已经成功了 管理修改 通常我们在提交之后会想要修改，当然我们是在文件上直接修改，但是修改后在git上输入git status查看此时的工作区的状态，你会发现出现了出现了如下的语句： 12345678910On branch masterYour branch is ahead of &apos;origin/master&apos; by 2 commits. (use &quot;git push&quot; to publish your local commits)Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: file.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 从上面的提示可以看出我们有如下方案： 首先执行-&gt;git add file.txt,然后重新提交git commit -m &#39;modified file.txt 撤销修改(没有提交的[commit]) 这里的撤销修改仅仅是对于没有提交的撤销(git commit -m &#39;&#39;),在下面会讲到如何撤销提交后的撤销 未git add 当我们修改后会出现上面的提示，前面已经贴过了，这里就不再贴代码了，根据提示，我们可以git checkout -- file.txt来丢弃工作区的修改，之后就可以看见先前的修改已经不见了 已经git add 当我们修改文件后并且git add 添加到暂存区了，那么查看状态git status,出现的提示如下 1234567On branch masterYour branch is ahead of &apos;origin/master&apos; by 2 commits. (use &quot;git push&quot; to publish your local commits)Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: file.txt 根据上面提示的方法：输入git reset HEAD file.txt,可以看到文件回到未git add的状态了，这时如果你想要丢弃修改，使用git checkout -- file.txt,之后就可以看到你的修改已经不见了 删除文件 其实删除也是一种修改操作，我们在文件管理器中直接使用rm删除文件，这时输入git status可以看到如下的提示： 1234567891011On branch masterYour branch is ahead of &apos;origin/master&apos; by 2 commits. (use &quot;git push&quot; to publish your local commits)Changes not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) deleted: file.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)PS G:\file&gt; git checkout -- file.txt 如果你不想删除了，想要恢复原来的文件，使用git checkout -- file.txt 这个命令可以让撤销修改，也可以撤销删除，起到一键还原的作用 如果你想要继续删除,那么有两种方法： first:git add file.txt,second:git commit -m &#39;&#39; first:git rm file.txt,second:git commit -m &#39;&#39; 注意： git rm file 可以用来删除提交到版本库中的文件，一般删除要执行以下命令：git rm file.txt,git commit -m &#39;delete&#39;，注意在git commit之前还是可以取消删除的，使用git checkout -- file.txt，可以一键取消删除 创建与合并分支常用命令： git checkout -b dev 创建并且切换到dev分支 git checkout dev 切换到dev分支 git branch 查看所有的分支，带有*的是当前所处的分支 git branch -d dev 删除dev分支，一般在合并之后删除 git branch -D dev ：强制删除分支，一般在没有合并就删除分支会出现不能删除，这是就要使用强制删除这个分支的命令 git merge dev 将dev分支合并到当前分支,使用到Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 git merge --no-ff -m &quot;merge with no-ff&quot; dev 强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 git log --graph --pretty=oneline --abbrev-commit 查看分支历史 创建合并 首先我们创建一个dev分支,使用命令：git checkout -b dev(创建一个dev分支，并且切换到dev分支上)，我们可以使用git branch查看所有的分支 现在在改变之前master分支上的file.txt文件内容，之后git add file.txt,并且提交到版本库中了(git commit -m &#39;file.txt&#39;)，此时使用git checkout master切换到master分支上，查看file.txt的文件内容，可以看到里面的内容并没有改变，由此可知两个分支是独立的，如果你在一个分之上创建了文件并且提交到版本库中了，切换到另外一个分支上，此时可以发现原来创建的文件不见了，因为那是另外一个分支的文件，当然我们可以合并分支，使用git merge dev,这两个命令将dev分支合并到当前分支 Bug分支管理 如果正在一个分支上工作，另外一个分支上的程序有一个Bug需要马上修改，但是此时这个分支上的东西还需要很长时间才能完成，这应该怎么办呢？难道要放弃当前分支上的修改吗？当然不是了，幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作，具体步骤如下： git stash 将当前的工作状态暂时存储在stash中，输出如下信息 12Saved working directory and index state WIP on dev: 6224937 add mergeHEAD is now at 6224937 add merge 此时可以使用git status 查看当前的分支上的状态，可以知道当前的的工作区就是干净的，因此可以放心的修复另外一个分支上的的Bug了 git checkout master 切换分支，修复Bug git checkout dev 修复好Bug继续回到上一个分支干活 git stash list 可以看到工作现场还在，输出如下信息： 1stash@&#123;0&#125;: WIP on dev: 6224937 add merge 如果有多个修改的内容，这里的信息肯定不止一条 git stash apply：恢复修改，但是这只是恢复stash的内容并不会删除，这里建议使用git stash pop 既恢复了又删除了stash中内容，注意这里只能恢复一条数据，此时使用git status查看状态，可以看到已经出现修改的内容了 git stash list ：此时查看当前stash中的内容可以看到已经什么都没了，当然这只是清除一条，如果本来有多个，那么还是会有其他内容的 常用命令 git stash 将当前的分支上的工作暂存到stash中 git stash list 列出stash中的所有暂存的内容 git stash pop 恢复并且删除stash中的内容 git stash apply 恢复但是步删除stash中的内容 远程仓库的操作常用的命令 git remote -v 查看远程仓库的详细信息 git remote add remote-name URL 添加远程仓库 git remote rename origin pb 将远程仓库的origin改为pb，此时使用git remote 查看可以知道这里已经没有origin了，变成了pb git remote rm origin 将远程仓库origin删除 git push origin master 将内容提交到远程仓库origin的master上，当然这里亦可以使用其他的分支 git clone URL 克隆一个远程仓库，这里的URL是远程仓库的地址 git pull origin 将远程仓库中更新的数据拉到本地 git checkout -b branch-name origin/branch-name 在本地创建和远程仓库对应的分支，最好分支的名字相同 git push origin branch-name 推送到远程仓库的分支 注意 同一个文件夹中可以添加很多远程仓库，不过可以在提交的时候需要指定远程仓库的名字，比如在你的文件夹下有origin和pb两个远程仓库，可以使用git remote -v查看详细的信息，此时你在版本库中已经有想要推送的文件了，那么使用git push origin master就可以指定推送到origin远程仓库中 实例 假如你新建一个文件夹，此时要在里面添加远程仓库，具体实现如下： git clone URL 将一个仓库克隆来的同时也具有推送的权限了，这时就可以使用git remote add origin URL来添加远程仓库了 如果没有使用clone的方法创建一个版本库，那么先git init 然后git remote add origin URL 添加远程仓库，之后就是将本地仓库和远程仓库对应了，使用git pull origin master 来拉取远程仓库中内容，当然这也可以分两步，使用如下： git fetch origin master 这是将远程仓库中的文件拉取到本地，但是没有与本地的master合并，因此本地的master分支不能追踪远程仓库中的分支 git merge origin/master 将远程仓库和本地的master分支合并，那么就可以使用本地的master分支追踪远程仓库了，这就完成了 无论clone还是pull都只是拉取远程的master分支，但是一般远程仓库中还有其他的分支，那么怎么办呢？拉取远程仓库的次分支步骤如下： git checkout -b dev origin/dev 拉去远程仓库中的dev仓库到本地的dev分支]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy爬取淘宝女郎]]></title>
      <url>%2F2017%2F05%2F07%2Fscrapy%E7%88%AC%E5%8F%96%E6%B7%98%E5%AE%9D%E5%A5%B3%E9%83%8E%2F</url>
      <content type="text"><![CDATA[scrapy抓取淘宝女郎准备工作 首先在淘宝女郎的首页这里查看，当然想要爬取更多的话，当然这里要查看翻页的url,不过这操蛋的地方就是这里的翻页是使用javascript加载的，这个就有点尴尬了，找了好久没有找到，这里如果有朋友知道怎样翻页的话，麻烦告诉我一声，谢谢了…，不过就这样坐以待毙了吗，所以就在chrome上搜，结果看到有人直接使用的这个网页,我当时一看感觉神奇的样子，这就是简化版的首页啊，只需要改变page的数字就可以实现遍历了，不过还是有点小失落，为什么人家就能找到呢，这个我还是希望知道的朋友能够分享一下，我也会查看相关的资料，把这个空缺不上的，好了，现在开我们的工作了 我们的目的是抓取册以及相关的信息，所以我们需要随便打开一个淘女郎的相册页面，然后随便进入一个相册即可，很显然这里的相册是异步加载的，因此我们需要抓包，这里我抓到了含有相册的url以及相关信息的json数据，如下图： 然后我们查看它的url为https://mm.taobao.com/album/json/get_album_photo_list.htmuser_id=687471686&amp;album_id=10000702574&amp;top_pic_id=0&amp;cover=%2F%2Fimg.alicdn.com%2Fimgextra%2Fi2%2F687471686%2FTB1TlwDLFXXXXbxaXXXXXXXXXXX_!!2tstar.png&amp;page=1&amp;_ksTS=1494097545509_154&amp;callback=jsonp15 通过我尝试之后这条url可以简化为: https://mm.taobao.com/album/json/get_album_photo_list.htm?user_id={0}&amp;album_id={1}&amp;top_pic_id=0&amp;page={2}&amp;_ksTS=1493654931946_405 其中user_id是每一个女郎对的id,ablum_id时每一个相册的id,这里一个女郎有多个相册，因此这个id是不同的，但是page就是要翻页的作用了,可以看到我去掉了callback=json155这一项，因为如果加上这一项，返回的数据就不是json类型的数据，其中page是在抓包的时候点击翻页才会在下面出现的，可以看到同一个相册返回的除了page不同之外，其他的都是相同的，因此这里通过page来实现翻页的数据 上面分析了每一个相册的url数据的由来，可以看到我们下面需要找到user_id,ablum_id这两个数据. user_id的获取：我们打开首页,然后打开chrome的调试工具，可以看到每一个 女郎的url中都包含user_id这一项，因此我们只需要通过这个实现翻页然后获取每一个女郎的url,之后用正则将user_id匹配出来即可,代码如下 123456ps=response.xpath('//p[@class="top"]') for p in ps: item=JrtItem() href=p.xpath('a/@href').extract() #这个得到的是一个数组url if href: item['user_id']=self.pattern_user_id.findall(href[0])[0] #用则正匹配出user_id,其中的正则为 pattern_user_id=re.compile(r'user_id=(\d+)') ablum_id的获取：想要获取ablum_id当然要在相册的页面查找，于是我们在相册页面抓包获得了如下图的页面 通过上图我们清晰的知道每一个相册的里面包含多少相册，但最令人开心的是在这个页面中不是动态加载，因此我们可以查看它的源码，当我们查看源码的时候，我们可以看到和user_id一样，这里的ablum_id包含在了href中，因此我们只需要找到每一张相册的url，然后用正则匹配处来即可，其中这个页面的url简化为: https://mm.taobao.com/self/album/open_album_list.htm?_charset=utf-8&amp;user_id%20={0}&amp;page={1} 所以我们可以通过上面得到的user_id构成请求即可,代码如下： 12345678910## 解析得到ablum_id，根据ablum_id解析请求出每一个相册的json数据 def parse_ablum_id(self,response): if response.status==200: print response.url item = response.meta['item'] soup = BeautifulSoup(response.text, 'lxml') divs = soup.find_all('div', class_='mm-photo-cell-middle') for div in divs: href = div.find('h4').find('a').get('href') items = self.pattern_ablum_id.findall(href) #这里就得到了ablum_id 上面已经获得了user_id和ablum_id，那么现在就可以请求每一个相册的json数据了，这个就不用多说了，详情请看源代码 MongoDB存储安装方式 Windows下安装请看我的MogoDB干货篇 ubantu直接用sudo apt-get install安装即可 安装对应python的包：pip install pymongo 安装完成以后就可以连接了，下面贴出我的连接代码 1234567891011121314from pymongo import MongoClientclass MongoDBPipelines(object): collection_name = 'taobao' def open_spider(self,spider): self.client = MongoClient('localhost', 27017) #连接，这里的27017是默认的额端口号 self.db = self.client['python'] #python是自己的数据库，当然这里不用提前建好也可以 def close_spider(self, spider): self.client.close() def process_item(self,item,spider): self.db[self.collection_name].update(&#123;'picId':item['picId']&#125;, &#123;'$set': dict(item)&#125;, True) return item 现在这就算好了，当然这里还有很多东西需要优化的，像代理池。。。最后本人想在暑期找一个地方实习，但是一直没有好的地方，希望有实习的地方推荐的可以联系我，在这里先谢谢了 推荐 最后推荐博主的一些源码 scrapy爬取妹子网站实现图片的存储，这个只是一个演示怎样存储图片的实例，因此不想过多的投入时间去爬，因此写的不是很详细 scrapy爬取知乎用户的详细信息]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MongoDB干货篇之更新数据]]></title>
      <url>%2F2017%2F05%2F01%2FMongoDB%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%2F</url>
      <content type="text"><![CDATA[MongoDB干货篇之数据更新常用的函数 update(&lt;query&gt;,&lt;update&gt;,&lt;upsert&gt;,&lt;multi&gt;),其中&lt;query&gt;表示筛选的条件，&lt;update&gt;是要更新的数据 updateMany() 更新所有匹配到的数据 upsert upsert是一个布尔类型的数据，如果为true时，当根据query条件没有找到匹配的数据时，就表示插入此条数据，如果为false就表示不插入数据 下面将会在一个空的集合中更新数据1234567//就会插入此条数据，因为没有找到匹配的信息db.user.update(&#123;'name':'chenjiabing','age':22,'sex':"Man"&#125;,&#123;$set:&#123;'hobby':'read'&#125;&#125;,&#123;'upsert':true&#125;); db.user.update(&#123;'name':'chenjiabing','age':22,'sex':"Man"&#125;,&#123;$set:&#123;'hobby':'read'&#125;&#125;,true); //和上面的语句等价//输出 db.user.find()&#123; "_id" : ObjectId("59067b70856d5893a687655f"), "age" : 22, "name" : "chenjiabing", "sex" : "Man", "hobby" : "read" &#125; multi 如果这个参数为true,就把按条件查出来多条记录全部更新。默认为false,如果为true的话和updateMany()一样的效果 下面将会更新所有匹配到的数据 1db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$set:&#123;'hobby':'code'&#125;&#125;,&#123;'multi':true&#125;); 字段更新操作符 Field Update Operators$set $set用来指定一个键的值。如果这个键不存在，则创建它。注意这里的更新默认是只更新第一条匹配到的数据，如果第一条匹配的数据已经满足修改后的条件，那么将不会执行下面匹配的信息 下面我们将会添加一条信息在数据库中 1db.user.insert(&#123;"name":'jack',"age":22,"sex":'Man','school':&#123;'name':'jsnu','city':'xuzhou'&#125;&#125;); 运行下面的代码，将该用户的兴趣设置为“读书”并添加至文档中(此时文档中hobby键是不存在，该条文档就会创建它) 1db.user.update(&#123;name:'jack'&#125;,&#123;$set:&#123;'hobby':'read'&#125;&#125;) 下面将会修改用户的年龄 1db.user.update(&#123;'name':'jack'&#125;,&#123;$set:&#123;'age':20&#125;&#125;) 下面用$set修改数据类型，将sex设置为1 1db.user.update(&#123;'name':'jack'&#125;,&#123;$set:&#123;'sex':1&#125;&#125;) 下面用$set修改内嵌文档，必须指定文档的名字和键值 1db.user.update(&#123;name:'jack'&#125;,&#123;$set:&#123;'school.name':'shida','school.city':'beijing'&#125;&#125;) $unset 从文档中移除指定的键 下面将要删除上面插入的hobby键 1db.user.update(&#123;name:'jack'&#125;,&#123;$unset:&#123;'hobby':1&#125;&#125;) //这里的值是任意给的，随便什么值 $inc $inc修改器用来增加已有键的值，或者在键不存在时创建一个键$inc就是专门来增加（和减少）数字的。$inc只能用于整数、长整数或双精度浮点数。要是用在其他类型的数据上就会导致操作失败 例如毎次有人访问该博文，该条博文的浏览数就加1，用键pageViews保存浏览数信息。这个键值上面没有定义过，所以会自动创建一个 1db.user.update(&#123;name:'jack'&#125;,&#123;$inc:&#123;'pageViews':1&#125;&#125;); //起初没有就会自动创建一个键 下面演示增加和减少 123db.user.update(&#123;name:'jack'&#125;,&#123;$inc:&#123;'pageViews':100&#125;&#125;) ; //这里是在上面的基础上加上100，此时变成了101db.user.update(&#123;name:'jack'&#125;,&#123;$inc:&#123;"pageViews":-100&#125;&#125;) ; //这里是在上面的基础上减去100,此时还是变成了1 $rename 语法：{$rename: { &lt;old name1&gt;: &lt;new name1&gt;, &lt;old name2&gt;: &lt;new name2&gt;, ... } } $rename操作符可以重命名字段名称，新的字段名称不能和文档中现有的字段名相同。 下面重新插入一条数据，并且改变这条数据的键的名称 123db.user.insert(&#123;name:'chenjiabing','age':22,'sex':'Man','school':&#123;'name':'jsnu','city':'beijing'&#125;&#125;);db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$rename:&#123;'age':'Age'&#125;&#125;) //重命名age为Age 下面将要演示怎样改变内嵌文档的键的名称，注意一定要带上文档的名字 1db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$rename:&#123;'school.name':'school.Name','school.city':'school.City'&#125;&#125;); 如果重命名的字段字和集合中原有的字段名字相同的话就会覆盖原有的字段名称，那么就会造成数据的丢失 1234567db.user.update(&#123;name:'chenjiabing'&#125;,&#123;'$rename':&#123;'sex','age'&#125;&#125;); //这里sex变成age和原来的age相同，那么原来的age就会丢失db.user.find(&#123;name:'chenjiabing'&#125;); //输出，可以看到原来的age没有了,变成了覆盖之后的&#123; "_id" : ObjectId("590674ce30b9f88dd43d7ee4"), "name" : "chenjiabing", "age" : "Man", "school" : &#123; "name" : "jsnu", "city" : "beijing" &#125; &#125; 如果指定的字段不存在，那么将不会更新，对原来的字段没有影响 1db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$rename:&#123;value:'name'&#125;&#125;); //将不会有任何的改变，因为value这个字段根本不存在 $rename操作符也可以将子文档中键值移到其他子文档中 12345db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$rename:&#123;'school.name':'contact.name'&#125;&#125;);// 这里将会将school.name这个字段的值移到contact.name之中，如果contact不存在，那么就会创建一个//输出&#123; "_id" : ObjectId("590674ce30b9f88dd43d7ee4"), "name" : "chenjiabing", "age" : "Man", "school" : &#123; "city" : "beijing" &#125;, "contact" : &#123; "name" : "jsnu" &#125; &#125; 数组更新操作符 Array Update Operators 只能用在键值为数组的键上的数组操作。 $ (query) 语法:{ &quot;&lt;array&gt;.$&quot; : value } 当对数组字段进行更新时，且没有明确指定的元素在数组中的位置，我们使用定位操作符$标识一个元素，数字都是以0开始的。 注意: 定位操作符(“$”)作为第一个匹配查询条件的元素的占位符，也就是在数组中的索引值。 数组字段必须出现查询文档中。 向集合中插入两条数据 12db.students.insert(&#123; "_id" : 1, "grades" : [ 78, 88, 88 ] &#125;);db.students.insert(&#123; "_id" : 2, "grades" : [ 88, 90, 92 ] &#125;); 执行下列操作 1234//查询匹配的文档中，数组有2个88，只更新第一个匹配的元素，也就是"grades.1"db.students.update( &#123; _id: 1, grades: 88 &#125;, &#123; $set: &#123; "grades.$" : 82 &#125; &#125;) ;//查询文档中没有出现grades字段，查询报错db.students.update( &#123; _id: 2 &#125;, &#123; $set: &#123; "grades.$" : 82 &#125; &#125; ); $push 如果指定的键已经存在，会向已有的数组末尾加入一个元素，要是没有就会创建一个新的数组。 下面我们将使用$push对该文档添加一条评论信息。 1234567//将会创建一个comments数组，因为一开始这个数组没有存在db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$push:&#123;comments:&#123;'name':'jack','content':'hello thanks'&#125;&#125;&#125;)//继续添加一条，在comments的末尾进行添加，此时comments变成两条数据了db.user.update(&#123;name:'chenjiabing'&#125;,&#123;$push:&#123;comments:&#123;'name':'john','content':'hello'&#125;&#125;&#125;) $pull 语法：db.collection.update( { field: &lt;query&gt; }, { $pull: { field: &lt;query&gt; } } ); $pull操作符移除指定字段值为数组，且匹配$pull操作符移除指定字段值为数组，且匹配$pull语句声明的查询条件的所有元素。 执行如下操作 123456789101112//插入一条文档db.profiles.insert(&#123; votes: [ 3, 5, 6, 7, 7, 8 ] &#125;);//移除数组中所有元素7db.profiles.update( &#123; votes: 3 &#125;, &#123; $pull: &#123; votes: 7 &#125; &#125; );//移除数组中所有大于6的元素db.profiles.update( &#123; votes: 3 &#125;, &#123; $pull: &#123; votes: &#123; $gt: 6 &#125; &#125; &#125; );//Result&#123; votes: [ 3, 5, 6, 8 ] &#125;&#123; votes: [ 3, 5, 6 ] &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MongoDB干货篇之查询数据]]></title>
      <url>%2F2017%2F04%2F30%2FMongoDB%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%2F</url>
      <content type="text"><![CDATA[MongoDB干货篇之查询准备工作 在开始之前我们应该先准备数据方便演示，这里我插入的了几条数据，数据如下：12345678910111213141516171819202122232425262728293031323334db.user.insertMany([&#123;name:'jack',age:22,sex:'Man',tags:['python','c++','c'],grades:[22,33,44,55],school:&#123;name:'shida',city:'xuzhou'&#125;&#125;,&#123;name:'jhon',age:33,sex:null,tags:['python','java'],grades:[66,22,44,88],school:&#123;name:'kuangda',city:'xuzhou'&#125;&#125;,&#123;name:'xiaoming',age:33,tags:['python','java'],grades:[66,22,44,88],school:&#123;name:'kuangda',city:'xuzhou'&#125;&#125;]) find() 其中query表示查找的条件，相当于mysql中where子句,projection列出你想要查找的数据，格式为db.collection.find(find(&lt;query filter&gt;, &lt;projection&gt;)) 实例： 下面不带参数的查找，将会查找出所有的结果 12345678910111213141516171819202122232425 db.find().pretty(); //输出结果 &#123; &quot;_id&quot; : ObjectId(&quot;59056f81299fe049404b2899&quot;), &quot;name&quot; : &quot;jack&quot;, &quot;age&quot; : 22, &quot;tags&quot; : [ &quot;python&quot;, &quot;c++&quot;, &quot;c&quot; ], &quot;grades&quot; : [ 22, 33, 44, 55 ], &quot;school&quot; : &#123; &quot;name&quot; : &quot;shida&quot;, &quot;city&quot; : &quot;xuzhou&quot; &#125; &#125; 下面找出满足name为jack的数据，并且只输出name,age,这里的_id是默认输出的，如果不想输出将将它设置为0，想要输出那个字段将它设置为1 12345678910db.user.find(&#123;name:'jack'&#125;,&#123;name:1,age:1&#125;)//输出结果&#123; "_id" : ObjectId("59056f81299fe049404b2899"), "name" : "jack", "age" : 22 &#125;db.user.find(&#123;name:'jack'&#125;,&#123;name:1,age:1，_id:0&#125;)//输出结果&#123;"name" : "jack", "age" : 22 &#125; **注意这里的一个 projection不能 同时 指定包括和排除字段，除了排除 _id字段。 在 显式包括 字段的映射中，_id 字段是唯一一个您可以 显式排除 的。 查询内嵌文档 上述例子中插入的school数据就表示内嵌文档 完全匹配查询 完全匹配查询表示school中的查询数组必须和插入的数组完全一样，顺序都必须一样才能查找出来 1234567891011db.user.find(&#123;name:'jack',school:&#123;name:'shida',city:'xuzhou'&#125;&#125;);//输出结果&#123; "_id" : ObjectId("59056f81299fe049404b2899"), "name" : "jack", "age" : 22, "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125;//下面是指定输出的字段，这里的school.name表示只输出school文档中name字段，必须加引号db.user.find(&#123;name:'jack',school:&#123;name:'shida',city:'xuzhou'&#125;&#125;,&#123;name:1,age:1,'school.name':1&#125;);//输出结果&#123; "_id" : ObjectId("59056f81299fe049404b2899"), "name" : "jack", "age" : 22, "school" : &#123; "name" : "shida" &#125; &#125; 键值对查询 可以通过键值对查询，不用考虑顺序，比如&#39;school.name&#39;:&#39;shida&#39;，表示查询学校名字为shida的数据，这里的引号是必须要的 12345db.user.find(&#123;'school.name':'shida'&#125;,&#123;name:1,school:1&#125;);//输出结果&#123; "_id" : ObjectId("59056f81299fe049404b2899"), "name" : "jack", "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125; 查询操作符 下面我们将配合查询操作符来执行复杂的查询操作，比如元素查询、 逻辑查询 、比较查询操作。我们使用下面的比较操作符&quot;$gt&quot; 、&quot;$gte&quot;、 &quot;$lt&quot;、 &quot;$lte&quot;(分别对应&quot;&gt;&quot;、 &quot;&gt;=&quot; 、&quot;&lt;&quot; 、&quot;&lt;=&quot;) 实例 下面查询年龄在20-30之间的信息 123456db.user.find(&#123;age:&#123;$gt:20,$lt:30&#125; &#125;)//输出&#123; "_id" : ObjectId("59056f81299fe049404b2899"), "name" : "jack", "age" : 22, "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125; $ne $ne表示不相等，例如查询年龄不等于22岁的信息 1234db.user.find(&#123;age:&#123;$ne:22&#125;&#125;)//输出&#123; "_id" : ObjectId("59057c16f551d8c9003d31e0"), "name" : "jhon", "age" : 33, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125; slice $slice操作符控制查询返回的数组中元素的个数。此操作符根据参数{ field: value } 指定键名和键值选择出文档集合，并且该文档集合中指定array键将返回从指定数量的元素。如果count的值大于数组中元素的数量，该查询返回数组中的所有元素的。 语法：db.collection.find( { field: value }, { array: {$slice: count }}); 下面将查询grades中的前两个数 12345db.user.find(&#123;name:'jack'&#125;,&#123;grades:&#123;$slice:2&#125;,name:1,age:1,'school.name':1&#125;);//输出，可以看出这里的grades只输出了前面两个&#123; "_id" : ObjectId("59057c16f551d8c9003d31df"), "name" : "jack", "age" : 22, "grades" : [ 22, 33 ], "school" : &#123; "name" : "shida" &#125; &#125; 下面将输出后3个数据 1234db.user.find(&#123;name:'jhon'&#125;,&#123;grades:&#123;$slice:-3&#125;,name:1&#125;);//输出&#123; "_id" : ObjectId("59057c16f551d8c9003d31e0"), "name" : "jhon", "grades" : [ 22, 44, 88 ] &#125; 下面介绍指定一个数组作为参数。数组参数使用[ skip , limit ] 格式，其中第一个值表示在数组中跳过的项目数,第二个值表示返回的项目数。 123456db.user.find(&#123;name:'jack'&#125;,&#123;grades:&#123;$slice:[2,2]&#125;,name:1&#125;); //这里将会跳过前面的两个，直接得到后面的两个数据//输出&#123; "_id" : ObjectId("59057c16f551d8c9003d31df"), "name" : "jack", "grades" : [ 44, 55 ] &#125; $exists 如果$exists的值为true,选择存在该字段的文档,若值为false则选择不包含该字段的文档 下面将会查询不存在sex这一项的信息 1234567891011db.user.find(&#123;sex:&#123;$exists:false&#125;&#125;)//结果&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cd"), "name" : "xiaoming", "age" : 33, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125;db.user.find(&#123;sex:&#123;$exists:true&#125;&#125;);//结果&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cb"), "name" : "jack", "age" : 22, "sex" : "Man", "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125;&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cc"), "name" : "jhon", "age" : 33, "sex" : null, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125; $or 执行逻辑OR运算,指定一个至少包含两个表达式的数组，选择出至少满足数组中一条表达式的文档。语法：{ $or: [ { &lt;expression1&gt; }, { &lt;expression2&gt; }, ... , { &lt;expressionN&gt; } ] } 下面将要查找age等于22或者age等于33的值 1234567db.user.find(&#123;$or:[&#123;age:22&#125;,&#123;age:33&#125;]&#125;)//结果&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cb"), "name" : "jack", "age" : 22, "sex" : "Man", "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125;&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cc"), "name" : "jhon", "age" : 33, "sex" : null, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125;&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cd"), "name" : "xiaoming", "age" : 33, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125; 下面将会查找出年龄为22或者33并且姓名为jack的人的信息 12345db.user.find(&#123;name:'jack',$or:[&#123;age:33&#125;,&#123;age:22&#125;]&#125;)//结果&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cb"), "name" : "jack", "age" : 22, "sex" : "Man", "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125; $and 指定一个至少包含两个表达式的数组，选择出满足该数组中所有表达式的文档。$and操作符使用短路操作，若第一个表达式的值为“false”,余下的表达式将不会执行。语法：{ $and: [ { &lt;expression1&gt; }, { &lt;expression2&gt; } , ... , { &lt;expressionN&gt; } ] } 下面将会查找年龄在20-30之间的信息，对于下面使用逗号分隔符的表达式列表，MongoDB会提供一个隐式的$and操作： 12345db.user.find(&#123;$and:[&#123;age:&#123;$gt:20&#125;&#125;,&#123;age:&#123;$lt:30&#125;&#125;]&#125;)//上述语句相当于db.user.find(&#123;age:&#123;$gt:20&#125;,age:&#123;$lt:30&#125;&#125;)//结果&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cb"), "name" : "jack", "age" : 22, "sex" : "Man", "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125; $in 匹配键值等于指定数组中任意值的文档。类似sql中in，只要匹配一个value就会输出语法：{ field: { $in: [&lt;value1&gt;, &lt;value2&gt;, ... &lt;valueN&gt; ] } } 下面将会查找grades中存在22,33之间的任意一个数的信息 1234567 db.user.find(&#123;grades:&#123;$in:[22,33]&#125;&#125;) //输出 &#123; "_id" : ObjectId("59058460fe58ed1089f2a5cb"), "name" : "jack", "age" : 22, "sex" : "Man", "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125;&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cc"), "name" : "jhon", "age" : 33, "sex" : null, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125;&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cd"), "name" : "xiaoming", "age" : 33, "tags" : [ "python", "java" ], "grades" : [ 66, 22, 44, 88 ], "school" : &#123; "name" : "kuangda", "city" : "xuzhou" &#125; &#125; $nin 匹配键不存在或者键值不等于指定数组的任意值的文档。类似sql中not in(SQL中字段不存在使用会有语法错误). 查询出grades中不存在100或者44的文档 1db.user.find(&#123;grades:&#123;$nin:[100,44]&#125;&#125;) $not 执行逻辑NOT运算，选择出不能匹配表达式的文档 ，包括没有指定键的文档。$not操作符不能独立使用，必须跟其他操作一起使用 语法:{ field: { $not: { } } } 查询年龄不大于30的信息 1234db.user.find(&#123;age:&#123;$not:&#123;$gt:30&#125;&#125;&#125;)//输出&#123; "_id" : ObjectId("59058460fe58ed1089f2a5cb"), "name" : "jack", "age" : 22, "sex" : "Man", "tags" : [ "python", "c++", "c" ], "grades" : [ 22, 33, 44, 55 ], "school" : &#123; "name" : "shida", "city" : "xuzhou" &#125; &#125; 迭代游标的查询 学过高级语言的朋友都知道迭代的问题，像java,下面使用迭代的方法查询 1234567891011121314151617var cursor=db.usr.find();//这里使用迭代输出所有的数据while(cursor.hasNext()) //这里的hasNext()是判断是否下一个中还有可迭代的值，如果没有返回false&#123; printjson(cursor.next()); //这里的cursor.next是迭代的输出，printjson是代替print(tojson()) &#125;print cursor.count() //输出其中有多少个数据cursor.forEach(printjson); //forEach输出var document=cursor.toArray(); //将迭代对象转换成数组print document[0]; //以数组的形式输出]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python爬虫之BeautifulSoup]]></title>
      <url>%2F2017%2F04%2F29%2Fpython%E7%88%AC%E8%99%AB%E4%B9%8BBeautifulSoup%2F</url>
      <content type="text"><![CDATA[python爬虫之BeautifulSoup简介 Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。Beautiful Soup已成为和lxml、html6lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲的速度。 安装 pip install BeautifulSoup4 easy_install BeautifulSoup4 创建BeautifulSoup对象 首先应该导入BeautifulSoup类库 from bs4 import BeautifulSoup 下面开始创建对像，在开始之前为了方便演示，先创建一个html文本，如下： 1234567891011html = """&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class="story"&gt;...&lt;/p&gt;""" 创建对象：soup=BeautifulSoup(html,&#39;lxml&#39;),这里的lxml是解析的类库，目前来说个人觉得最好的解析器了，一直在用这个，安装方法：pip install lxml Tag Tag就是html中的一个标签，用BeautifulSoup就能解析出来Tag的具体内容，具体的格式为soup.name,其中name是html下的标签，具体实例如下： print soup.title输出title标签下的内容，包括此标签，这个将会输出&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt; print soup.head 注意： 这里的格式只能获取这些标签的第一个，后面会讲到获取多个标签的方法。其中对于Tag有两个重要的属性name和attrs,分别表示名字和属性,介绍如下： name:对于Tag，它的name就是其本身，如soup.p.name就是p attrs是一个字典类型的，对应的是属性-值，如print soup.p.attrs,输出的就是{&#39;class&#39;: [&#39;title&#39;], &#39;name&#39;: &#39;dromouse&#39;},当然你也可以得到具体的值，如print soup.p.attrs[&#39;class&#39;],输出的就是[title]是一个列表的类型，因为一个属性可能对应多个值,当然你也可以通过get方法得到属性的，如：print soup.p.get(&#39;class&#39;)。还可以直接使用print soup.p[&#39;class&#39;] get get方法用于得到标签下的属性值，注意这是一个重要的方法，在许多场合都能用到，比如你要得到&lt;img src=&quot;#&quot;&gt;标签下的图像url,那么就可以用soup.img.get(&#39;src&#39;),具体解析如下： 1print soup.p.get("class") #得到第一个p标签下的src属性 string 得到标签下的文本内容，只有在此标签下没有子标签，或者只有一个子标签的情况下才能返回其中的内容，否则返回的是None具体实例如下： 123print soup.p.string #在上面的一段文本中p标签没有子标签，因此能够正确返回文本的内容print soup.html.string #这里得到的就是None,因为这里的html中有很多的子标签 get_text() 可以获得一个标签中的所有文本内容，包括子孙节点的内容，这是最常用的方法 搜索文档树find_all( name , attrs , recursive , text , **kwargs ) find_all是用于搜索节点中所有符合过滤条件的节点 1.name参数：是Tag的名字，如p,div,title ….. soup.find_all(&quot;p&quot;) 查找所有的p标签，返回的是[&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;]，可以通过遍历获取每一个节点，如下： 123ps=soup.find_all("p")for p in ps: print p.get('class') #得到p标签下的class属性 传入正则表达式：soup.find_all(re.compile(r&#39;^b&#39;)查找以b开头的所有标签，这里的body和b标签都会被查到 传入类列表：如果传入列表参数,BeautifulSoup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有&lt;a&gt;标签和&lt;b&gt;标签 1soup.find_all(["a", "b"]) 2.KeyWords参数，就是传入属性和对应的属性值，或者一些其他的表达式 soup.find_all(id=&#39;link2&#39;),这个将会搜索找到所有的id属性为link2的标签。传入正则表达式soup.find_all(href=re.compile(&quot;elsie&quot;)),这个将会查找所有href属性满足正则表达式的标签 传入多个值：soup.find_all(id=&#39;link2&#39;,class_=&#39;title&#39;) ,这个将会查找到同时满足这两个属性的标签，这里的class必须用class_传入参数，因为class是python中的关键词 有些属性不能通过以上方法直接搜索，比如html5中的data-*属性，不过可以通过attrs参数指定一个字典参数来搜索包含特殊属性的标签，如下： 1234# [&lt;div data-foo="value"&gt;foo!&lt;/div&gt;]data_soup.find_all(attrs=&#123;"data-foo": "value"&#125;) #注意这里的atts不仅能够搜索特殊属性，亦可以搜索普通属性soup.find_all("p",attrs=&#123;'class':'title','id':'value'&#125;) #相当与soup.find_all('p',class_='title',id='value') 3.text参数：通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True12345678soup.find_all(text="Elsie")# [u'Elsie'] soup.find_all(text=["Tillie", "Elsie", "Lacie"])# [u'Elsie', u'Lacie', u'Tillie'] soup.find_all(text=re.compile("Dormouse"))[u"The Dormouse's story", u"The Dormouse's story"] 4.limit参数：find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果. 文档树中有3个tag符合搜索条件,但结果只返回了2个,因为我们限制了返回数量,代码如下： 123soup.find_all("a", limit=2)# [&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,# &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;] 5.recursive 参数:调用tag的 find_all() 方法时,BeautifulSoup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False find( name , attrs , recursive , text , **kwargs ) 它与 find_all() 方法唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果,就是直接返回第一匹配到的元素，不是列表，不用遍历，如soup.find(&quot;p&quot;).get(&quot;class&quot;) css选择器 我们在写 CSS 时，标签名不加任何修饰，类名前加点，id名前加#，在这里我们也可以利用类似的方法来筛选元素，用到的方法是 soup.select()，返回类型是 list 通过标签名查找123456print soup.select('title') #[&lt;title&gt;The Dormouse's story&lt;/title&gt;]print soup.select('a')#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;] 通过类名查找12print soup.select('.sister')#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;] 通过id名查找12print soup.select('#link1')#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 组合查找 学过css的都知道css选择器，如p #link1是查找p标签下的id属性为link1的标签 12345print soup.select('p #link1') #查找p标签中内容为id属性为link1的标签#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;]print soup.select("head &gt; title") #直接查找子标签#[&lt;title&gt;The Dormouse's story&lt;/title&gt;] 属性查找 查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。 123456print soup.select('a[class="sister"]')#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]print soup.select('a[href="http://example.com/elsie"]')#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 同样，属性仍然可以与上述查找方式组合，不在同一节点的空格隔开，同一节点的不加空格,代码如下： 12print soup.select('p a[href="http://example.com/elsie"]')#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 以上的 select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容 1234567soup = BeautifulSoup(html, 'lxml')print type(soup.select('title'))print soup.select('title')[0].get_text()for title in soup.select('title'): print title.get_text() 修改文档树 Beautiful Soup的强项是文档树的搜索,但同时也可以方便的修改文档树,这个虽说对于一些其他的爬虫并不适用，因为他们都是爬文章的内容的，并不需要网页的源码并且修改它们，但是在我后续更新的文章中有用python制作pdf电子书的,这个就需要用到修改文档树的功能了，详情请见本人博客 修改tag的名称和属性1234567html="""&lt;p&gt;&lt;a href='#'&gt;修改文档树&lt;/a&gt;&lt;/p&gt;"""soup=BeautifulSoup(html,'lxml')tag=soup.a #得到标签a，可以使用print tag.name输出标签tag['class']='content' #修改标签a的属性class和divtag['div']='nav' 修改.string 注意这里如果标签的中还嵌套了子孙标签，那么如果直接使用string这个属性会将这里的所有的子孙标签都覆盖掉 1234567891011html="""&lt;p&gt;&lt;a href='#'&gt;修改文档树&lt;/a&gt;&lt;/p&gt;"""soup=BeautifulSoup(html,'lxml')tag=soup.atag.string='陈加兵的博客' #这里会将修改文档树变成修改的内容print tagsoup.p.string='陈加兵的博客' #这里修改了p标签的内容，那么就会覆盖掉a标签，直接变成的修改后的文本print soup append append的方法的作用是在在原本标签文本后面附加文本，就像python中列表的append方法 12345678html="""&lt;p&gt;&lt;a href='#'&gt;修改文档树&lt;/a&gt;&lt;/p&gt;"""soup=BeautifulSoup(html,'lxml')soup.a.append("陈加兵的博客") #在a标签和面添加文本，这里的文本内容将会变成修改文档树陈加兵的博客print soupprint soup.a.contents #这里输出a标签的内容，这里的必定是一个带有两个元素的列表 注意这里的append方法也可以将一个新的标签插入到文本的后面，下面将会讲到 new_tag 相信学过js的朋友都知道怎样创建一个新的标签，这里的方法和js中的大同小异，使用的new_tag 1234567891011html="""&lt;p&gt;&lt;p&gt;"""soup=BeautifulSoup(html,'lxml')tag=soup.pnew_tag=soup.new_tag('a') #创建一个新的标签anew_tag['href']='#' #添加属性new_tag.string='陈加兵的博客' #添加文本print new_tag tag.append(new_tag) #将新添加的标签写入到p标签中print tag insert Tag.insert() 方法与 Tag.append() 方法类似,区别是不会把新元素添加到父节点 .contents 属性的最后,而是把元素插入到指定的位置.与Python列表总的 .insert() 方法的用法下同: 1234567891011html="""&lt;p&gt;&lt;p&gt;"""soup=BeautifulSoup(html,'lxml')tag=soup.pnew_tag=soup.new_tag('a')new_tag['href']='#'new_tag.string='陈加兵的博客'tag.append("欢迎来到") #这里向p标签中插入文本，这个文本在contents下的序号为0tag.insert(1,new_tag) #在contents序号为1的位置插入新的标签，如果这里修改成0，那么将会出现a标签将会出现在欢饮来到的前面print tag 注意这的1是标签的内容在contents中的序号，可以用print tag.contents查看当前的内容 insert_before() 和 insert_after() insert_before() 方法在当前tag或文本节点前插入内容,insert_after() 方法在当前tag或文本节点后插入内容: 12345678910111213soup = BeautifulSoup("&lt;b&gt;stop&lt;/b&gt;")tag = soup.new_tag("i")tag.string = "Don't"soup.b.string.insert_before(tag)soup.b# &lt;b&gt;&lt;i&gt;Don't&lt;/i&gt;stop&lt;/b&gt;soup.b.i.insert_after(soup.new_string(" ever "))soup.b# &lt;b&gt;&lt;i&gt;Don't&lt;/i&gt; ever stop&lt;/b&gt;soup.b.contents# [&lt;i&gt;Don't&lt;/i&gt;, u' ever ', u'stop'] clear clear用来移除当前节点的所有的内容，包括其中的子孙节点和文本内容 123456789101112html="""&lt;p&gt;&lt;p&gt;"""soup=BeautifulSoup(html,'lxml')tag=soup.pnew_tag=soup.new_tag('a')new_tag['href']='#'new_tag.string='陈加兵的博客'tag.append("欢迎来到")tag.insert(1,new_tag)tag.clear() #这里将会移除所有内容print tag 参考文章 中文文档http://beautifulsoup.readthedocs.io/zh_CN/latest/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MongoDB干货篇之安装]]></title>
      <url>%2F2017%2F04%2F28%2FMongoDB%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E5%AE%89%E8%A3%85%2F</url>
      <content type="text"><![CDATA[MongoDB干货篇之安装安装 下载地址 点击安装,选择自定义，后选择安装路径，不过最好安装在根目录下(C盘)，然后点解next,这里我安装的路径是C:\MongoDB 创建文件夹:在C:\MongoDB下创建一个文件夹data,然后在data文件夹下创建db,log两个子文件夹,在log文件下创建一个MongoDB.log文档，总得来说创建了C:\MongoDB\data,C:\MongoDB\data\db,C:\MongoDB\data\log,C:\MongoDB\data\log\MongoDB.log 在C:\MongoDB\bin文件夹下运行cmd.exe进入dos命令，执行以下命令： 然后在cmd下输入mongod -dbpath &quot;C:\MongoDB\data\db,将会看到一些信息，说明已经安装成功了 测试连接 在C:\MongoDB\bin文件夹下运行cmd.exe,输入mongo或者mongo.exe,将会出现连接的信息，说明已经连接成功了 然后在另外一个cmd.exe在bin目录下运行mongo可以看到已经连接上MongoDB了，注意上面打开的终端不能关闭，否则不能成功连接，这是比较麻烦的，需要每次连接都要启动，下面我们需要把它安装为windows服务 安装程windows服务注意在管理员的cmd.exe中运行以下命令，否则在MongoDB.log文件里出现遭到拒绝 运行cmd，进入bin目录，执行以下命令: mongod --dbpath &quot;C:\MongoDB\data\db&quot; --logpath &quot;D:\MongoDB\data\log\MongoDB.log&quot; --install --serviceName &quot;MongoDB&quot;,这里的服务名为MongoDB，可以在C:\MongoDB\data\log\MongoDB.log文件里查看相关信息，如果出现遭到拒绝就是没有在管理员的权限下执行命令 接下来就是启动服务了，现在在cmd.exe中运行NET START MongoDB，如果看到服务成功启动，那么就成功了，但是我在启动的时候出现48错误，下面将会做出解决方法： 先删除服务:mongod --dbpath &quot;C:\MongoDB\data\db&quot; --logpath &quot;C:\MongoDB\data\log\MongoDB.log&quot; --remove --serviceName &quot;MongoDB&quot; 删除MongoDB目录下的mongod.lock 然后就是重新安装了,执行以下命令： mongod --logpath &quot;C:\MongoDB\data\log\MongoDB.log&quot; --logappend --dbpath &quot;C:\Mongodb\data&quot; --directoryperdb --serviceName &quot;MongoDB&quot; --serviceDisplayName &quot;MongoDB&quot; --install 接下来重新启动服务，net start MongoDB,可以看到成功启动了 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BootStrap干货篇之表单]]></title>
      <url>%2F2017%2F04%2F26%2FBootStrap%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E8%A1%A8%E5%8D%95%2F</url>
      <content type="text"><![CDATA[BootStrap干货篇之表单基本介绍 单独的表单控件会被自动赋予一些全局样式。所有设置了 .form-control 类的 &lt;input&gt;、&lt;textarea&gt; 和 &lt;select&gt; 元素都将被默认设置宽度属性为 width: 100%;。 将 label元素和前面提到的控件包裹在 .form-group 中可以获得最好的排列。 基本实例： 1234567891011121314151617181920212223 &lt;div class=&apos;container&apos;&gt; &lt;form&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputEmail1&quot;&gt;Email address&lt;/label&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; id=&quot;exampleInputEmail1&quot; placeholder=&quot;Email&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputPassword1&quot;&gt;Password&lt;/label&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; id=&quot;exampleInputPassword1&quot; placeholder=&quot;Password&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputFile&quot;&gt;File input&lt;/label&gt; &lt;input type=&quot;file&quot; id=&quot;exampleInputFile&quot;&gt; &lt;p class=&quot;help-block&quot;&gt;Example block-level help text here.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot;&gt; Check me out &lt;/label&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-default&quot;&gt;Submit&lt;/button&gt;&lt;/form&gt; &lt;/div&gt; 说明：这里的form-control是对所有的输入控件而言的,源码中将width设置为100%，表示会将这个输入控件占满一整行，form-group是用来对label和input更好的排版的，其中还有form-group-sm,form-group-lg，源码中分别利用这个对带有form-control的控件设置了不同的高度，具体看源码，不过正常情况下还是使用form-group 内联表单 为 &lt;form&gt; 元素添加 .form-inline 类可使其内容左对齐并且表现为inline-block级别的控件。只适用于视口（viewport）至少在 768px 宽度时（视口宽度再小的话就会使表单折叠）从源码中可以看到对form-inline下的form-group,form-control,form-control-static,input-group,radio,checkbox都是用了display:inline-block 注意： 在 Bootstrap 中，输入框和单选/多选框控件默认被设置为 width: 100%; 宽度。在内联表单，我们将这些元素的宽度设置为width: auto;，因此，多个控件可以排列在同一行。根据你的布局需求，可能需要一些额外的定制化组件。 一定要有label标签，如果不想要label标签可以设置.sr-only将其隐藏如果你没有为每个输入控件设置 label 标签，屏幕阅读器将无法正确识别。对于这些内联表单，你可以通过为 label 设置 .sr-only 类将其隐藏。还有一些辅助技术提供label标签的替代方案，比如 aria-label、aria-labelledby或 title 属性。如果这些都不存在，屏幕阅读器可能会采取使用 placeholder 属性，如果存在的话，使用占位符来替代其他的标记，但要注意，这种方法是不妥当的。 实例: 1234567891011121314151617&lt;form class=&quot;form-inline&quot;&gt; &lt;!--指定了form-inline类--&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;!--label中的for标签是用于绑定组件的，如果指定了for标签，input中的id也和for标签的内容相同，那么就会当鼠标点击&lt;label&gt;内容时会自动聚焦在input上--&gt; &lt;label class=&quot;sr-only&quot; for=&quot;exampleInputEmail3&quot;&gt;Email address&lt;/label&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; id=&quot;exampleInputEmail3&quot; placeholder=&quot;Email&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label class=&quot;sr-only&quot; for=&quot;exampleInputPassword3&quot;&gt;Password&lt;/label&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; id=&quot;exampleInputPassword3&quot; placeholder=&quot;Password&quot;&gt; &lt;/div&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot;&gt; Remember me &lt;/label&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-default&quot;&gt;Sign in&lt;/button&gt;&lt;/form&gt; 水平表单 水平表单通过指定为form指定form-horizontal类来设定，其中可以使用BootStrap的栅栏系统设置水平间距，其中的form-group的div就表示一行了，相当于&lt;div class=&#39;row&#39;&gt;&lt;/div&gt;,因此只需要在label和input中指定列就行了，但是input标签不能直接使用，要在外面加上div 实例： 12345678910111213141516171819202122232425262728&lt;form class=&quot;form-horizontal&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;inputEmail3&quot; class=&quot;col-sm-2 control-label&quot;&gt;Email&lt;/label&gt; &lt;div class=&quot;col-sm-10&quot;&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; id=&quot;inputEmail3&quot; placeholder=&quot;Email&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;!--相当与&lt;div class=&apos;row&apos;&gt;&lt;/div&gt;--&gt; &lt;label for=&quot;inputPassword3&quot; class=&quot;col-sm-2 control-label&quot;&gt;Password&lt;/label&gt; &lt;div class=&quot;col-sm-10&quot;&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; id=&quot;inputPassword3&quot; placeholder=&quot;Password&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;div class=&quot;col-sm-offset-2 col-sm-10&quot;&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot;&gt; Remember me &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;div class=&quot;col-sm-offset-2 col-sm-10&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-default&quot;&gt;Sign in&lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/form&gt; 说明上面的label标签中的control-label主要的作用是设置文字的对齐方式为左对齐，如果不加这个将会在右边出现很大的空白 多选和单选框 多选框（checkbox）用于选择列表中的一个或多个选项，而单选框（radio）用于从多个选项中只选择一个。其中提供的类有checkbox,checkbox-inline,radio,radio-inline 内联单选和多选框 通过将 .checkbox-inline 或 .radio-inline 类应用到一系列的多选框（checkbox）或单选框（radio）控件上，可以使这些控件排列在一行。 实例： 12345678910111213141516171819202122232425262728&lt;label class=&quot;checkbox-inline&quot;&gt; &lt;input type=&quot;checkbox&quot; id=&quot;inlineCheckbox1&quot; value=&quot;option1&quot;&gt; 1&lt;/label&gt;&lt;label class=&quot;checkbox-inline&quot;&gt; &lt;input type=&quot;checkbox&quot; id=&quot;inlineCheckbox2&quot; value=&quot;option2&quot;&gt; 2&lt;/label&gt;&lt;label class=&quot;checkbox-inline&quot;&gt; &lt;input type=&quot;checkbox&quot; id=&quot;inlineCheckbox3&quot; value=&quot;option3&quot;&gt; 3&lt;/label&gt;&lt;label class=&quot;radio-inline&quot;&gt; &lt;input type=&quot;radio&quot; name=&quot;inlineRadioOptions&quot; id=&quot;inlineRadio1&quot; value=&quot;option1&quot;&gt; 1&lt;/label&gt;&lt;label class=&quot;radio-inline&quot;&gt; &lt;input type=&quot;radio&quot; name=&quot;inlineRadioOptions&quot; id=&quot;inlineRadio2&quot; value=&quot;option2&quot;&gt; 2&lt;/label&gt;&lt;label class=&quot;radio-inline&quot;&gt; &lt;input type=&quot;radio&quot; name=&quot;inlineRadioOptions&quot; id=&quot;inlineRadio3&quot; value=&quot;option3&quot;&gt; 3&lt;/label&gt;&lt;div class=&quot;checkbox-inline&quot;&gt; &lt;label for=&quot;sex&quot;&gt;&lt;input type=&quot;checkbox&quot;&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;checkbox-inline&quot;&gt; &lt;label for=&quot;sex&quot;&gt;&lt;input type=&quot;checkbox&quot;&gt;男&lt;/label&gt; &lt;/div&gt; 不带label文本的Checkbox 和 radio 如果需要 &lt;label&gt; 内没有文字，输入框（input）正是你所期望的。 目前只适用于非内联的 checkbox和 radio。 请记住，仍然需要为使用辅助技术的用户提供某种形式的 label（例如，使用 aria-label）。 实例： 12345678910&lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; id=&quot;blankCheckbox&quot; value=&quot;option1&quot; aria-label=&quot;...&quot;&gt; &lt;/label&gt;&lt;/div&gt;&lt;div class=&quot;radio&quot;&gt; &lt;label&gt; &lt;input type=&quot;radio&quot; name=&quot;blankRadio&quot; id=&quot;blankRadio1&quot; value=&quot;option1&quot; aria-label=&quot;...&quot;&gt; &lt;/label&gt;&lt;/div&gt; 下拉列表（select） 实例： 1234567&lt;select class=&quot;form-control&quot;&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt;&lt;/select&gt; 静态控件 如果需要在表单中将一行纯文本和 label 元素放置于同一行，为&lt;p&gt;标签设置为form-control-static 实例： 1234567891011121314&lt;form class=&quot;form-horizontal&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label class=&quot;col-sm-2 control-label&quot;&gt;Email&lt;/label&gt; &lt;div class=&quot;col-sm-10&quot;&gt; &lt;p class=&quot;form-control-static&quot;&gt;email@example.com&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;inputPassword&quot; class=&quot;col-sm-2 control-label&quot;&gt;Password&lt;/label&gt; &lt;div class=&quot;col-sm-10&quot;&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; id=&quot;inputPassword&quot; placeholder=&quot;Password&quot;&gt; &lt;/div&gt; &lt;/div&gt;&lt;/form&gt; 参考文章 中文官网 文档手册 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scrapyd部署爬虫]]></title>
      <url>%2F2017%2F04%2F24%2FScrapyd%E9%83%A8%E7%BD%B2%E7%88%AC%E8%99%AB%2F</url>
      <content type="text"><![CDATA[Scrapyd部署爬虫准备工作 安装scrapyd: pip install scrapyd 安装scrapyd-client : pip install scrapyd-client 安装curl:[安装地址](http://ono60m7tl.bkt.clouddn.com/curl.exe),安装完成以后将所在目录配置到环境变量中 开始部署 修改scrapy项目目录下的scrapy.cfg文件，修改如下 123[deploy:JD_Spider] #加上target :nameurl = http://localhost:6800/ #将前面的#删除project = JD #project的名字，可以使用默认的，当然也可以改变 在任意目录下的打开终端，输入scrapyd,观察是否运行成功，运行成功的话，就可以打开http://localhost:6800看是否正常显示，如果正常显示则看到下面的这张图,这里的JD是部署之后才能看到的，现在是看不到的，所以没出现也不要担心： 在项目的根目录下运行如下的命令：python E:\python2.7\Scripts\scrapyd-deploy target -p project,这里的E:\python2.7\Scripts\是你的python安装目录，Scripts是安装目录下的一个文件夹，注意前面一定要加上python,target是在前面scrapy.cfg中设置的deploy:JD_Spider，JD_Spider就是target,project 是JD,因此这个完整的命令是python E:\python2.7\Scripts\scrapyd-deploy JD_Spider -p JD,现在项目就部署到上面了，这下网页上就有JD了，详情请见上图 验证是否成功，你可以在网页上看有没有显示你的工程名字，另外在根目录下输入python E:\python2.7\Scripts\scrapyd-deploy -l就能列出你所有部署过的项目了 启动爬虫：curl http://localhost:6800/schedule.json -d project=myproject -d spider=spider_name,这里的project填入的是项目名，spider_name填入的是你的爬虫中定义的name,运行我的实例完整的代码为：curl http://localhost:6800/schedule.json -d project=JD -d spider=spider，这里将会显示如下信息： 12#这里的jobid比较重要，下面会用到这个取消爬虫&#123;"status": "ok", "jobid": "3013f9d1283611e79a63acb57dec5d04", "node_name": "DESKTOP-L78TJQ7"&#125; 取消爬虫：curl http://localhost:6800/cancel.json -d project=myproject -d job=jobid,jobid就是上面的提到过的，如果取消我的这个实例代码如：curl http://localhost:6800/cancel.json -d project=JD -d job=3013f9d1283611e79a63acb57dec5d04,那么它的状态就会变成如下： 1&#123;"status": "ok", "prevstate": "running", "node_name": "DESKTOP-L78TJQ7"&#125; 列出项目：curl http://localhost:6800/listprojects.json,下面将会出现你已经部署的项目 删除项目：curl http://localhost:6800/delproject.json -d project=myproject 列出版本：curl http://localhost:6800/listversions.json?project=myproject,这里的project是项目的名字，是在scrapy.cfg设置的 列出爬虫：curl http://localhost:6800/listspiders.json?project=myproject这里的project是项目的名字，是在scrapy.cfg设置的 列出job:curl http://localhost:6800/listjobs.json?project=myproject这里的project是项目的名字，是在scrapy.cfg设置的 删除版本：curl http://localhost:6800/delversion.json -d project=myproject -d version=r99，这里的version是自己的项目版本号，在删除之前需要查看版本号 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy大战京东商城]]></title>
      <url>%2F2017%2F04%2F23%2Fscrapy%E5%A4%A7%E6%88%98%E4%BA%AC%E4%B8%9C%E5%95%86%E5%9F%8E%2F</url>
      <content type="text"><![CDATA[SCrapy爬虫大战京东商城引言 上一篇已经讲过怎样获取链接，怎样获得参数了，详情请看python爬取京东商城普通篇 代码详解 首先应该构造请求，这里使用scrapy.Request,这个方法默认调用的是start_urls构造请求，如果要改变默认的请求，那么必须重载该方法，这个方法的返回值必须是一个可迭代的对象，一般是用yield返回，代码如下： 12345def start_requests(self): for i in range(1,101): page=i*2-1 #这里是构造请求url的page,表示奇数 url=self.start_url+str(page) yield scrapy.Request(url,meta=&#123;'search_page':page+1&#125;,callback=self.parse_url) #这里使用meta想回调函数传入数据，回调函数使用response.meta['search-page']接受数据 下面就是解析网页了，从上面看出这里的解析回调函数是parse_url,因此在此函数中解析网页。这里还是和上面说的一样，这个url得到的仅仅是前一半的信息，如果想要得到后一半的信息还有再次请求，这里还有注意的就是一个技巧：一般先解析出一个数据的数组，不急着取出第一个数，先要用if语句判断，因为如果得到的是[]，那么直接取出[0]是会报错的，这只是一个避免报错的方法吧，代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def parse_url(self,response): if response.status==200: #判断是否请求成功 # print response.url pids = set() #这个集合用于过滤和保存得到的id,用于作为后面的ajax请求的url构成 try: all_goods = response.xpath("//div[@id='J_goodsList']/ul/li") #首先得到所有衣服的整个框架，然后从中抽取每一个框架 for goods in all_goods: #从中解析每一个 # scrapy.shell.inspect_response(response,self) #这是一个调试的方法，这里会直接打开调试模式 items = JdSpiderItem() #定义要抓取的数据 img_url_src = goods.xpath("div/div[1]/a/img/@src").extract() # 如果不存在就是一个空数组[]，因此不能在这里取[0] img_url_delay = goods.xpath( "div/div[1]/a/img/@data-lazy-img").extract() # 这个是没有加载出来的图片，这里不能写上数组取第一个[0] price = goods.xpath("div/div[3]/strong/i/text()").extract() #价格 cloths_name = goods.xpath("div/div[4]/a/em/text()").extract() shop_id = goods.xpath("div/div[7]/@ data-shopid").extract() cloths_url = goods.xpath("div/div[1]/a/@href").extract() person_number = goods.xpath("div/div[5]/strong/a/text()").extract() pid = goods.xpath("@data-pid").extract() # product_id=goods.xpath("@data-sku").extract() if pid: pids.add(pid[0]) if img_url_src: # 如果img_url_src存在 print img_url_src[0] items['img_url'] = img_url_src[0] if img_url_delay: # 如果到了没有加载完成的图片，就取这个url print img_url_delay[0] items['img_url'] = img_url_delay[0] # 这里如果数组不是空的，就能写了 if price: items['price'] = price[0] if cloths_name: items['cloths_name'] = cloths_name[0] if shop_id: items['shop_id'] = shop_id[0] shop_url = "https://mall.jd.com/index-" + str(shop_id[0]) + ".html" items['shop_url'] = shop_url if cloths_url: items['cloths_url'] = cloths_url[0] if person_number: items['person_number'] = person_number[0] # if product_id: # print "************************************csdjkvjfskvnk***********************" # print self.comments_url.format(str(product_id[0]),str(self.count)) # yield scrapy.Request(url=self.comments_url.format(str(product_id[0]),str(self.count)),callback=self.comments) #yield scrapy.Request写在这里就是每解析一个键裤子就会调用回调函数一次 yield items except Exception: print "********************************************ERROR**********************************************************************" yield scrapy.Request(url=self.search_url.format(str(response.meta['search_page']),",".join(pids)),callback=self.next_half_parse) #再次请求，这里是请求ajax加载的数据，必须放在这里，因为只有等到得到所有的pid才能构成这个请求，回调函数用于下面的解析 从上面代码的最后可以看出最后就是解析ajax加载的网页了，这里调用的next_half_parse函数，和解析前面一个网页一样，这里需要的注意的是，如果前面定义的数据没有搜索完毕是不能使用yield items的，必须将items通过meta传入下一个回调函数继续完善后才能yield items,这里就不需要了，代码如下： 12345678910111213141516171819202122232425262728293031323334353637#分析异步加载的网页 def next_half_parse(self,response): if response.status==200: print response.url items=JdSpiderItem() #scrapy.shell.inspect_response(response,self) #y用来调试的 try: lis=response.xpath("//li[@class='gl-item']") for li in lis: cloths_url=li.xpath("div/div[1]/a/@href").extract() img_url_1=li.xpath("div/div[1]/a/img/@src").extract() img_url_2=li.xpath("div/div[1]/a/img/@data-lazy-img").extract() cloths_name=li.xpath("div/div[4]/a/em/text()").extract() price=li.xpath("div/div[3]/strong/i/text()").extract() shop_id=li.xpath("div/div[7]/@data-shopid").extract() person_number=li.xpath("div/div[5]/strong/a/text()").extract() if cloths_url: print cloths_url[0] items['cloths_url']=cloths_url[0] if img_url_1: print img_url_1[0] items['img_url']=img_url_1 if img_url_2: print img_url_2[0] items['img_url']=img_url_2[0] if cloths_name: items['cloths_name']=cloths_name[0] if price: items['price']=price[0] if shop_id: items['shop_id']=shop_id[0] items['shop_url']="https://mall.jd.com/index-" + str(shop_id[0]) + ".html" if person_number: items['person_number']=person_number[0] yield items #又一次的生成，这里是完整的数据，因此可以yield items except Exception: print "**************************************************" 当然这里还用到了设置请求池，mysql存储，没有使用到ip代理，这个在我前面的博客中又讲到，这里就不再赘述了，想看源代码的朋友请点击这里 小技巧 人们会抱怨为什么自己的爬虫在中途断开就要重头开始爬，为什么不能从断开那里开始爬呢，这里提供一个方法：在配置文件settings.py中加入JOBDIR=file_name,这里的file_name是一个文件的名字 设置下载延迟防止被ban:DOWNLOAD_DELAY = 2:设置每一次的间隔时间 RANDOMIZE_DOWNLOAD_DELAY = True:这个是随机设置延迟时间 在设置的时间的0.5-1.5倍之间，这样可以更有效的防止被ban,一般是配套使用的 ROBOTSTXT_OBEY = False :这里是表示不遵循robots.txt文件，默认是True表示遵循，这里将之改成False CONCURRENT_REQUESTS :设置最大请求数，这里默认的时16，我们可以根据自己电脑的配置改的大一点来加快请求的速度 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python爬虫大战京东商城]]></title>
      <url>%2F2017%2F04%2F23%2Fpython%E7%88%AC%E8%99%AB%E5%A4%A7%E6%88%98%E4%BA%AC%E4%B8%9C%E5%95%86%E5%9F%8E%2F</url>
      <content type="text"><![CDATA[python大规模爬取京东主要工具 scrapy BeautifulSoup requests 分析步骤 打开京东首页，输入裤子将会看到页面跳转到了这里，这就是我们要分析的起点 我们可以看到这个页面并不是完全的，当我们往下拉的时候将会看到图片在不停的加载，这就是ajax,但是当我们下拉到底的时候就会看到整个页面加载了60条裤子的信息，我们打开chrome的调试工具，查找页面元素时可以看到每条裤子的信息都在&lt;li class=&#39;gl-item&#39;&gt;&lt;/li&gt;这个标签中，如下图： 接着我们打开网页源码就会发现其实网页源码只有前30条的数据，后面30条的数据找不到，因此这里就会想到ajax，一种异步加载的方式，于是我们就要开始抓包了，我们打开chrome按F12，点击上面的NetWork,然后点击XHR,这个比较容易好找,下面开始抓包，如下图： 从上面可以找到请求的url，发现有很长的一大段，我们试着去掉一些看看可不可以打开，简化之后的url=https://search.jd.com/s_new.php?keyword=%E8%A3%A4%E5%AD%90&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;offset=3&amp;wq=%E8%A3%A4%E5%AD%90&amp;page={0}&amp;s=26&amp;scrolling=y&amp;pos=30&amp;show_items={1}这里的showitems是裤子的id,page是翻页的，可以看出来我们只需要改动两处就可以打开不同的网页了，这里的page很好找，你会发现一个很好玩的事情，就是主网页的page是奇数，但是异步加载的网页中的page是偶数，因此这里只要填上偶数就可以了，但是填奇数也是可以访问的。这里的show_items就是id了，我们可以在页面的源码中找到，通过查找可以看到id在li标签的data-pid中，详情请看下图 上面我们知道怎样找参数了，现在就可以撸代码了 代码讲解 首先我们要获取网页的源码，这里我用的requests库，安装方法为pip install requests，代码如下: 1234def get_html(self): res = requests.get(self.url, headers=self.headers) html = res.text return html #返回的源代码 根据上面的分析可以知道，第二步就是得到异步加载的url中的参数show_items,就是li标签中的data-pid,代码如下： 12345678def get_pids(self): html = self.get_html() soup = BeautifulSoup(html, 'lxml') #创建BeautifulSoup对象 lis = soup.find_all("li", class_='gl-item') #查找li标签 for li in lis: data_pid = li.get("data-pid") #得到li标签下的data-pid if (data_pid): self.pids.add(data_pid) #这里的self.pids是一个集合，用于过滤重复的 下面就是获取前30张图片的url了，也就是主网页上的图片，其中一个问题是img标签的属性并不是一样的，也就是源码中的img中不都是src属性，一开始已经加载出来的图片就是src属性，但是没有加载出来的图片是data-lazy-img，因此在解析页面的时候要加上讨论。代码如下： 12345678910111213141516def get_src_imgs_data(self): html = self.get_html() soup = BeautifulSoup(html, 'lxml') divs = soup.find_all("div", class_='p-img') # 图片 # divs_prices = soup.find_all("div", class_='p-price') #价格 for div in divs: img_1 = div.find("img").get('data-lazy-img') # 得到没有加载出来的url img_2 = div.find("img").get("src") # 得到已经加载出来的url if img_1: print img_1 self.sql.save_img(img_1) self.img_urls.add(img_1) if img_2: print img_2 self.sql.save_img(img_2) self.img_urls.add(img_2) 前三十张图片找到了，现在开始找后三十张图片了，当然是要请求那个异步加载的url，前面已经把需要的参数给找到了，下面就好办了，直接贴代码： 12345678910111213141516171819def get_extend_imgs_data(self): # self.search_urls=self.search_urls+','.join(self.pids) self.search_urls = self.search_urls.format(str(self.search_page), ','.join(self.pids)) #拼凑url,将获得的单数拼成url,其中show_items中的id是用','隔开的，因此要对集合中的每一个id分割，page就是偶数，这里直接用主网页的page加一就可以了 print self.search_urls html = requests.get(self.search_urls, headers=self.headers).text #请求 soup = BeautifulSoup(html, 'lxml') div_search = soup.find_all("div", class_='p-img') #解析 for div in div_search: img_3 = div.find("img").get('data-lazy-img') #这里可以看到分开查找img属性了 img_4 = div.find("img").get("src") if img_3: #如果是data-lazy-img print img_3 self.sql.save_img(img_3) #存储到数据库 self.img_urls.add(img_3) #用集合去重 if img_4: #如果是src属性 print img_4 self.sql.save_img(img_4) self.img_urls.add(img_4) 通过上面就可以爬取了，但是还是要考虑速度的问题，这里我用了多线程，直接每一页面开启一个线程，速度还是可以的，感觉这个速度还是可以的，几分钟解决问题，总共爬取了100个网页,这里的存储方式是mysql数据库存储的，要用发哦MySQLdb这个库，详情自己百度，当然也可以用mogodb但是还没有学呢，想要的源码的朋友请看GitHub源码 拓展写到这里可以看到搜索首页的网址中keyword和wq都是你输入的词，如果你想要爬取更多的信息，可以将这两个词改成你想要搜索的词即可，直接将汉字写上，在请求的时候会自动帮你编码的，我也试过了，可以抓取源码的，如果你想要不断的抓取，可以将要搜索的词写上文件里，然后从文件中读取就可以了。以上只是一个普通的爬虫，并没有用到什么框架，接下来将会写scrapy框架爬取的，请继续关注我的博客哦！！！ 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JQuery干货篇之处理元素]]></title>
      <url>%2F2017%2F04%2F22%2FJQuery%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E5%A4%84%E7%90%86%E5%85%83%E7%B4%A0%2F</url>
      <content type="text"><![CDATA[JQuery干货篇之处理元素 注意这里用的还是我前两篇用的例子，详情请看我的博客 attrattr() 方法设置或返回被选元素的属性值。 语法： $(selector).attr(attribute) 返回被选元素的属性值。 $(selector).attr(attribute,value) 设置被选元素的属性和值 $(selector).attr(attribute,function(index,oldvalue)) 设置被选元素的属性和值。 参数 描述 attribute 规定属性的名称。 function(index,oldvalue) 规定返回属性值的数。该函数可接收并使用选择器的 index 值和当前属性值。 实例：12345678910111213141516171819202122 $("img").filter(":first").attr('src'); //得到属性$("img").each(function (index,elem) &#123; if(index%2==0) $(elem).attr("src",'lily.png'); //设置属性 console.log($(elem).attr("src")); &#125;) $("img").attr('src',function (index,oldValue) &#123; //这里的oldValue表示原来属性的值，index是索引 if(oldValue=="rose.png") return 'lily.png'; else return 'astor.png'; &#125;) attrs=&#123; //使用映射对象一次设置多个值 src:'lily.png', style: 'border: thick double red' &#125;; $("img:eq(1)").attr(attrs); removeAttr removeAttr() 方法从被选元素中移除属性。 语法： $(selector).removeAttr(attribute) 这里的attribute是属性的名字 实例： 1$("img:first").removeAttr("src"); //删除属性src addClass addClass() 方法向被选元素添加一个或多个类 语法： $(selector).addClass(class) 这里的class是类名如果需要添加多个类，中间用空格隔开 $(selector).addClass(function(index,oldclass)) 这里的index是索引，oldClass是原来就有的类名，都是可选参数。这个函数的返回的就是要添加的类名 实例： 12345678910111213$("img:even").addClass("redBar"); //向偶数的img添加类redBar$("img").addClass(function (index,currentClass) &#123; //这里的currentClass就是原来有的类名，可选 if(index==1) return 'blueBar'; //第二个img应用blueBar这个类 else return 'redBar'; //这里需要注意的是，对同一个img应用类的时候，因为这个类的定义有优先级，上面定义会被后面定义的覆盖，所以要注意类定义的位置 &#125;) $("img").filter(":odd").addClass("redBar").end().filter(":even").addClass("blueBar"); //链式调用 $("img").addClass("blueBar redBar"); //添加两个类 hasClass hasClass() 方法检查被选元素是否包含指定的class 语法： $(selector).hasClass(class) //返回值是false和true 实例： 1console.log($("img:odd").hasClass("redBar")); toggleClass toggleClass() 对设置或移除被选元素的一个或多个类进行切换。该方法检查每个元素中指定的类。如果不存在则添加类，如果已设置则删除之。这就是所谓的切换效果 语法： $(selector).toggleClass(class,switch) class必需的，用来规定添加或移除class的指定元素，如需规定若干 class，请使用空格来分隔类名。switch是boolean可选参数，规定是否添加或移除class $(selector).toggleClass(function(index,class),switch) index表示索引，class表示选择器当前拥有的类 实例： 123456789101112131415161718192021222324$("img").toggleClass("redBar"); //这里对所有的img在redBar这个类之间切换$("img").toggleClass("redBar blueBar"); //在两个类之间来回的切换$("&lt;button&gt;ToggleClass&lt;/button&gt;").appendTo("#buttonDiv").click(function (e) &#123; $("img").toggleClass('redBar blueBar'); //在两种class之间切换，如果有就删除，没有的就添加 e.preventDefault(); &#125;) //下面添加一个按钮，完成同时添加多个图片的效果 $("&lt;button&gt;ToggleClass&lt;/button&gt;").appendTo("#buttonDiv").click(function (e) &#123; $("img").toggleClass(function (index,currentClass) &#123; if(index%2==0) return 'blueBar'; //动态的切换，这里是偶数就切换blue else return 'redBar blueBar'; //这里是奇数的图片在两种颜色来回的切换 &#125;); e.preventDefault(); &#125;) css css() 方法返回或设置匹配的元素的一个或多个样式属性，这里只说css，还有其他的设置css样式请看w3School 语法： $(selector).css(name) 返回第一个匹配元素的 CSS属性值。name是css属性的名称 $(selector).css(name,value) 设置所有匹配元素的指定 CSS 属性。name表示属性名称，value表示属性的值 $(selector).css(name,function(index,value)) 此函数返回要设置的属性值。接受两个参数，index为元素在对象集合中的索引位置，value 是原先的属性值。name表示要设置的属性名称，返回值就是要设置的属性值 实例： 1234567891011$("label").css('font-size','30px'); //设置字体大小$("label").css('font-size','+=10'); //使用相对值设置属性值，在原有的基础上加上10console.log($("h1").css('font-family')); //获取h1标签的字体var cssValues=&#123; 'border':'thick double red', 'font-size':'1.5em'&#125;;$("label").css(cssValues); //同时设置多个属性 text text() 方法方法设置或返回被选元素的文本内容。当该方法用于返回一个值时，它会返回所有匹配元素的组合的文本内容(会删除 HTML 标记) 语法： $(selector).text() 当该方法用于返回一个值时，它会返回所有匹配元素的组合的文本内容（会删除 HTML 标记）。 $(selector).text(content) 当该方法用于设置值时，它会覆盖被选元素的所有内容。 $(selector).text(function(index,oldcontent)) index表示索引,oldcontent表示选择器当前的文本内容 html html() 方法返回或设置被选元素的内容 (inner HTML)。如果该方法未设置参数，则返回被选元素的当前内容。 语法： $(selector).html() 当使用该方法返回一个值时，它会返回第一个匹配元素的内容。 $(selector).html(content) 当使用该方法设置一个值时，它会覆盖所有匹配元素的内容。 $(selector).html(function(index,oldcontent)) 使用函数来设置所有匹配元素的内容。index - 可选。接收选择器的index 位置,oldcontent - 可选。接收选择器的当前内容 val val() 方法返回或设置被选元素的值,元素的值是通过 value 属性设置的。该方法大多用于 input 元素,如果该方法未设置参数，则返回被选元素的当前值 语法： $(selector).val(value) 设置文本域的值为value $(selector).val() 得到文本域的值 $(selector).val(function(index,oldvalue)) 设置文本域的值，这里函数的返回值将会用来设置文本域的值，index表示元素索引，oldvalue表示选择器当前文本域的值 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JQuery干货篇之操控DOM]]></title>
      <url>%2F2017%2F04%2F21%2FJQuery%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E6%93%8D%E6%8E%A7DOM%2F</url>
      <content type="text"><![CDATA[JQuery干货篇之插入元素本次使用的html,css还是我上一篇的源代码，详情请看上一篇文章 分类 插入子元素：append,prepend ,appendTo,prependTo 封装包裹元素：wrap,wrapAll,wrapInner 插入兄弟元素：after,before,insertAfter,insertBefore 替换元素：replaceWith,replaceAll 删除元素：remove,deatch,unwrap,empty 创建新元素通常在把新元素插入到DOM中的目标位置之前，要先创建一个新元素才能将它插入到指定位置 使用$创建元素 $(&lt;div&gt;&lt;img src=&#39;rose.png&#39; alt=&#39;玫瑰&#39;&gt;&lt;/div&gt;) clone 克隆元素，使用clone方法以已有的元素为模子生成新的元素，这个在后面的插入元素起到关键作用，如果在要引用html中的一个标签内容的话，不使用clone方法，那么就会将这段内容移动，因此这里使用clone会很方便，详细请看append的用法实例 实例： 1$("div.dcell").clone(); //这里的clone方法必须是JQuery对象调用 使用DOM API创建新元素 DOM API是用js操作的，其实jquery在幕后悄悄的调用DOM API 实例： 1234567891011121314 var divElem=document.createElement("div"); //创建一个div元素 divElem.classList.add("dcell"); //为div添加class=dcellvar imgElem=document.createElement("img");imgElem.src="lily.png";divElem.appendChild(imgElem); //在新创建的元素后面插入imgvar newElem=$(divElem);newElem.each(function (index,elem) &#123; console.log(elem.tagName+" "+elem.className);&#125;); append 把参数指定的元素插入到所有的JQuery内含元素内容末尾成为他们的最后一个子元素，形式有append(html),append(Jquery),append(HTMLElements[])，append(function()) 实例： 12345678910111213141516171819202122232425//这里使用append元素创建了一个div元素，在末尾插入元素成为div的子元素// var orchildElems = $("&lt;div class='dcell'&gt;&lt;/div&gt;").append("&lt;img src='orchid.png'/&gt;") .append("&lt;label for='orchild'&gt;Orchild:&lt;/label&gt;") .append("&lt;input name='orchild' value='0' required&gt;"); var newElems = $("&lt;div class='dcell'&gt;&lt;/div&gt;").append("&lt;img src='lily.png'/&gt;") .append("&lt;label for='lily'&gt;Lily:&lt;/label&gt;") .append("&lt;input name='lily' value='0' required&gt;") .css("border", 'thick double red'); $("div.drow").append(orchildElems); //在末尾插入数据，这里的参数是jquery对象 $("div.drow").append(function(index,elem)&#123; if(elem.id=='row1') return orchildElems; else if(this.id='row2') return newElems; &#125;) $("div.drow").last().append(orchildElem,newElems); //在其中添加两个参数，插入的先后按照参数的先后位置，当然其中的参数个数没有限制 prepend 和append完全相反,向当前元素的前面插入html节点作为当前元素的子元素,形式有prepen d(Jquery),prepend(html),prepend(htmlElemnts[]),prepend(function()) 实例： 123456789101112131415161718 var orchildElems = $("&lt;div class='dcell'&gt;&lt;/div&gt;").append("&lt;img src='orchid.png'/&gt;") .append("&lt;label for='orchild'&gt;Orchild:&lt;/label&gt;") .append("&lt;input name='orchild' value='0' required&gt;");$("div.dcell").prepend(orchildElems); //将orchildElems插入到div.dcell的最前面，作为他的子元素$("div.dcell").prepend("&lt;img src='lily.png'&gt;"); //将参数html的内容插入到前面，作为子元素$("div.drow").append(function (index) &#123; //参数是函数，index是索引，返回的内容就是要插入到前面的内容 if (this.id == 'row1') return orchildElem; //返回的对象可以是jquery对象，也可以是html标签，如：return "&lt;img src='lily.png'&gt; else if (this.id = 'row2') return newElems; &#125;); appendTo appendTo是和append一样的函数，都是将指定的元素插入到指定元素的前面作为子元素，但是他们的参数就不同了，append是将指定的参数插入到当前调用它的的结果集中，而appendTo是将当前调用它的结果集插入到指定的参数中，主要的形式有appendTo(jquery),append(HTMLELments[]) 实例： 123456$("&lt;img src='lily.png'&gt;").appendTo($("img").last().parent()); //将图片插入到最后一个dcell中，这里参数是目标位置，开头调用的时想要插入的内容$("img:first").clone().appendTo($("img").last().parent()); //选择第一个图片插入到最后一个dcell中，这里必须用clone，否则就会将这张图片移到目标位置 $($("div.dcell").html()).appendTo($("img").last().parent()); //这里的.html()是获取html文本内容 prependTo .prepend()和.prependTo()实现同样的功能，主要的不同是语法，插入的内容和目标的位置不同。 对于 .prepend() 而言，选择器表达式写在方法的前面，作为待插入内容的容器，将要被插入的内容作为方法的参数。而 .prependTo() 正好相反，将要被插入的内容写在方法的前面，可以是选择器表达式或动态创建的标记，待插入内容的容器作为参数。 after 在匹配元素集合中的每个元素后面插入参数所指定的内容，作为其兄弟节点。形式有after(content[content,]),after(function()),这里的content内容有HTML字符串，DOM 元素，文本节点，元素和文本节点的数组，或者jQuery对象，用来插入到集合中每个匹配元素的后面 实例： 123456789101112131415 var orchildElems = $("&lt;div class='dcell'&gt;&lt;/div&gt;").append("&lt;img src='orchid.png'/&gt;") .append("&lt;label for='orchild'&gt;Orchild:&lt;/label&gt;") .append("&lt;input name='orchild' value='0' required&gt;"); //创建一个dcell内容 $("div.dcell").after(orchildElems); //插入元素作为兄弟元素，在当前元素的后面 $("#row1 div.dcell").after(function (index, html) &#123; //index表示索引，html表示原来的html文本，指的是没有插入之前的html console.log(html); if (index == 0)return orchildElem; //返回的可以是jquery对象，html文本 else if (index == 1) return newElems; &#125;);&#125;); before 根据参数设定，在匹配元素的前面插入内容,形式和after一样，内容也差不多 insertBefore 和prependTo的用法差不多，只是参数是要插入的目标位置，作为兄弟元素插入 实例： 1orchildElems.clone().insertBefore("#row2 div.dcell"); insertAfter 和append用法差不多，只是参数是要插入的目标位置，这里的也是作为兄弟元素插入的 实例： 1orchildElems.insertAfter("#row1 div.dcell"); wrap 在集合中匹配的每个元素周围包裹一个HTML结构，将会作为父元素存在。形式为wrap(html),wrap(jquery),wrap(HtmlElements[]),wrap(function()) 实例： 1234567891011 div=$("&lt;div&gt;&lt;/div&gt;").css("border",'thick double red'); $("div.drow").wrap(div); //在drow外层添加了一个div将作为父元素，可以看到现在的源代码变成了&lt;div style...&gt;&lt;div class='drow'&gt;...&lt;/div&gt;&lt;/div&gt; $(".drow").wrap(function (index) &#123; //index是索引 //if($(this).has("img[src*=astor]").length&gt;0) if(index==0) return div; //只在第一个drow中添加父元素div else return $("&lt;div&gt;&lt;/div&gt;").css("border",'thick double blue');&#125;) unwrap 将匹配元素集合的父级元素删除，保留自身（和兄弟元素，如果存在）在原来的位置。形式为unwrap(),unwrap(selector) 实例： 1234$("div.dcell").css("border",'thick double red'); $("div.dcell").children("img").first().unwrap(); //这里将第一个img元素的父级元素删除，并且保留了其中的子元素 $("div.dcell").children("img").unwrap(":first"); //这里使用参数来筛选要删除父级元素的当前元素，这里选择第一个元素 wrapAll 在集合中所有匹配元素的外面包裹一个HTML结构,也就是为结果集中的所有元素都设置了一个相同的父级元素来包裹所有的元素，形式为wrapAll(html),wrapAll(jquery),wrapAll(htmlElements[]),wrapAll(function()) 实例： 123var div = $("&lt;div&gt;&lt;/div&gt;").css("border", 'thick double red');$("div.drow").wrapAll(div); //这里的div成为了他共有的父级元素，原来的父级元素变成了祖先元素了$("img").wrapAll(div); //这里的img没有共同的父元素，那么就会强制的将所有的元素拉在一起为他们设置一个父级元素 wrapInner 在匹配元素里的内容外包一层结构,也就是为匹配元素的后代元素添加一个父级元素，但是这个父级元素是匹配元素的子代元素，也就是原来的匹配元素变成了祖先元素，形式为wrapInner(html),wrapInner(jquery),wrapInner(htmlElements),wrapInner(function()) 实例： 12var div = $("&lt;div&gt;&lt;/div&gt;").css("border", 'thick double red');$(".dcell").wrapInner(div); //这里的dcell元素将会变成祖先元素，而div将会变成内部后代元素新的父级元素 replaceWith 用提供的内容替换集合中所有匹配的元素并且返回被删除元素的集合,形式为replace(html),replaceWith(jquery),replaceWith(function()) 实例： 12345678910111213 var newElems = $("&lt;div class='dcell'&gt;&lt;/div&gt;").append("&lt;img src='lily.png'&gt;") .append("&lt;label for='lily'&gt;Lily&lt;/label&gt;").append("&lt;input name='lily' value='0' required&gt;").css("border", 'thick double blue');$(".dcell:first").replaceWith(newElems); //用newElems替换第一个dcell$("div.drow img").replaceWith(function () &#123; if (this.src.indexOf("rose") &gt; -1) return $("&lt;img src='lily.png'&gt;").css("border",'thick double red'); //返回的时替换的内容，可以是jquery或者html else if (this.src.indexOf("peony") &gt; -1) return newElems; else return $(this.clone()).css("border",'thick double blue');&#125;) replaceAll 用集合的匹配元素替换每个目标元素。.replaceAll()和.replaceWith()功能类似，但是目标和源相反 实例： 1$("&lt;img src='lily.png'&gt;").replaceAll("#row1 img"); //这里使用&lt;img src='lily.png'&gt;替换所有的img元素 remove 将匹配元素集合从DOM中删除,并且同时移除元素上的事件及 jQuery 数据 实例： 123$("div.dcell").remove(":has(img[src*=rose])"); //删除img$("div.dcell:first()").remove(); //不带参数 detach 从DOM中去掉所有匹配的元素,.detach() 方法和.remove()一样, 除了 .detach()保存所有jQuery数据和被移走的元素相关联。当需要移走一个元素，不久又将该元素插入DOM时，这种方法很有用。 实例： 123$("div.dcell").detach();$("div.dcell").detach(":has(img[src*=rose])"); empty 从DOM中移除集合中匹配元素的所有子节点。 1$(&quot;div.dcell:first&quot;).empty(); //删除所有的子节点 总结 append()和apppendTo()是将元素插入到指定元素的末尾作为其子元素的，其中append()的参数是新创建的节点，appendTo()的参数是将要插入到的元素 prepend()和prependTo() 是将元素插入到指定元素的最前面作为其子元素 after() 是在指定元素之后插入新建的节点，作为指定节点的第一个兄弟节点 ,参数是新建的节点 before() 是在指定元素之前插入新建的节点作为其兄弟节点，这个是紧挨着指定的元素的 insertAfter() 将新建元素插入到指定元素之后作为兄弟节点 参数是指定的元素 insertBefore() 将新建元素插入到指定元素之前作为兄弟节点 参数是指定的元素 remove() 删除所有匹配的元素 无参数 empty() 移除所有匹配元素的后代元素 无参数 参考文章 JQuery中文文档 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JQuery干货篇之选择元素]]></title>
      <url>%2F2017%2F04%2F20%2FJQuery%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B9%8B%E9%80%89%E6%8B%A9%E5%85%83%E7%B4%A0%2F</url>
      <content type="text"><![CDATA[JQuery 干货篇之选择元素实验的HTML+CSS的代码 html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;script src="jquery-3.2.1.min.js" type="text/javascript"&gt;&lt;/script&gt; &lt;link rel="stylesheet" type="text/css" href="main.css"/&gt; &lt;script src="main.js" type="text/javascript"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Jacqui's Flower Shop&lt;/h1&gt;&lt;form method="post"&gt; &lt;div id="oblock"&gt; &lt;div class="dtable"&gt; &lt;div id="row1" class="drow"&gt; &lt;div class="dcell"&gt; &lt;img src="astor.png"/&gt;&lt;label for="astor"&gt;Astor:&lt;/label&gt; &lt;input name="astor" value="0" required&gt; &lt;/div&gt; &lt;div class="dcell"&gt; &lt;img src="daffodil.png"/&gt;&lt;label for="daffodil"&gt;Daffodil:&lt;/label&gt; &lt;input name="daffodil" value="0" required&gt; &lt;/div&gt; &lt;div class="dcell"&gt; &lt;img src="rose.png"/&gt;&lt;label for="rose"&gt;Rose:&lt;/label&gt; &lt;input name="rose" value="0" required&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="row2" class="drow"&gt; &lt;div class="dcell"&gt; &lt;img src="peony.png"/&gt;&lt;label for="peony"&gt;Peony:&lt;/label&gt; &lt;input name="peony" value="0" required&gt; &lt;/div&gt; &lt;div class="dcell"&gt; &lt;img src="primula.png"/&gt;&lt;label for="primula"&gt;Primula:&lt;/label&gt; &lt;input name="primula" value="0" required&gt; &lt;/div&gt; &lt;div class="dcell"&gt; &lt;img src="snowdrop.png"/&gt;&lt;label for="snowdrop"&gt;Snowdrop:&lt;/label&gt; &lt;input name="snowdrop" value="0" required&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="buttonDiv"&gt; &lt;button type="submit"&gt;Place Order&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; css 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061h1 &#123; min-width: 70px; border: thick double black; margin-left: auto; margin-right: auto; text-align: center; font-size: x-large; padding: .5em; color: darkgreen; background-image: url("border.png"); background-size: contain; margin-top: 0;&#125;.dtable &#123; display: table;&#125;.drow &#123; display: table-row;&#125;.dcell &#123; display: table-cell; padding: 10px;&#125;.dcell &gt; * &#123; vertical-align: middle&#125;input &#123; width: 2em; text-align: right; border: thin solid black; padding: 2px;&#125;label &#123; width: 5em; padding-left: .5em; display: inline-block;&#125;#buttonDiv &#123; text-align: center;&#125;#oblock &#123; display: block; margin-left: auto; margin-right: auto; min-width: 700px;&#125;.hover&#123; background: blue; color: white; height:300px; width:300px;&#125; 选择器 :animated :选择正在处理动画的元素 :first :选择第一个元素 :last :选择最后一个元素 :eq(n) :选择第n个元素(从0开始) :even :选择序号为偶数的元素 :odd :选择序号为奇数的元素 :gt(n) :选择序号大于n的元素 :lt(n) :选择序号小于n的元素 :text :选择所有的文本输入框 :contains(text) :选择包含指定文本的元素 file :选择所有文件上传输入框 :button :选择所有的按钮 :checkbox :选择所有的复选框 :hidden :选择隐藏的元素 实例 $(&quot;img:odd&quot;).css(&quot;border&quot;,&quot;thick double red&quot;);选择序号为奇数的img元素$(&quot;img:first&quot;).css(&quot;border&quot;,&quot;thick double red&quot;) 选择第一个img元素 JQuery对象的方法 context 选择元素时使用的上下文对象 $(&quot;img:odd&quot;).context.TagName; each(function()) 在每个选中的元素上运行给定的函数 123 $("img").each(function(index,elem)&#123; console.log(ele.TagName+" "+elem.id);//这里的index表示每一个元素的索引，elem表示每一个元素的htmlElement对象，并不是jquery对象&#125;) index(jquery) || index(selector) 返回给定jquery对象在住对象中的序号，或者返回给定选择器参数的索引 $(&quot;img&quot;).index(&quot;img[src=*astor]&quot;) length || size() 返回的时jquery对象个数 $(&quot;img:odd&quot;).length toArray() 返回一个有jquery对象中包含的htmlEelments数组 var content=$(&quot;img:odd&quot;).toArray() 这里content返回的htmlElements数组 把jquery当成数组12345var content=$("img:odd");for(var i=0;i&lt;content.length;i++)&#123; console.log(content[i].TagName+" "+content[i].src); //这里的content[i]就是htmlElement数组了，$(content[i])就变成了Jquery对象了&#125; add add函数允许我们添加更多的项，常用的有add(htmlElement[]),add(selector),add(jquery) 实例： 1234567$("img:odd").add("img:even").css("border",'thick double red');var jq=$("img[src*=astor]");$("img:even").add(jq).add("img:even").css("border",'thick double red');var label=document.getElementsByTagName("label");$("img:odd").add(label).css("border","thick double red"); slice() 用来获取特定的一组子元素 实例： 123$("img").slice(0,3).css("border","thick double red"); //获取0-2的元素 $("img").slice(3).css("border","thick double red"); //获取3-结束 filter filter可以将不满足指定条件的元素剔除，常用的方法有filter(jquery),filter(htmlElement),filter(function(index)),filter(selector) 实例 1234567891011121314 //这里填入的参数selector$("label").filter("[for*=p]").css("background-color",'blue').css("font-size",'20px').css("border","2px solid red"); $("img").filter(function (index) &#123; //index是每一个元素的索引，如果返回的是true就会选定，false就会剔除这个元素 if(index==4) &#123; return true; &#125; else return false; &#125;).css("border",'thick double red'); var elem=document.getElementsByTagName("label")[1]; //只选择第二个label $("label").filter(elem).css("font-size",'30px') //这里填入的参数是htmlElement对象 not not方法是filter方法的补充，主要是删除匹配条件的元素，而filter则是保留满足匹配条件的元素，常用的方法有not(selector),not(htmlElement),not(jquery),not(function(index)) 实例： 123456789$("label").not("[for*=p]").css("background-color",'red'); //选择for不带p的label元素 $("label").not(function (index) &#123; //哪个元素返回true就删除，false保留 if(index==0) return true; //这里就会删除第一个label元素，保留后面的元素 else return false; &#125;).css("background-color","yellow"); has 选择拥有指定后代的选择器 实例：1234$("div.dcell").has("img[src*=astor]").css("border","thick double red"); //选择子代拥有img属性src带有astor的div.dcell元素var s=$("[for*=astor]");$("div.dcell").has(s).css("border","thick double red"); //参数为jquery对象 map 以一个函数为参数，map方法能够帮助我们灵活的处理一个jquery对象，从而得到满足需要的一个jquery对象。针对源jquery对象中的每一个元素都调用一次这个函数，而函数返回的HtmlElement对象将会变成一个jquery对象，参数是function(index,elem),其中`index是序号，elem是jquery对象中的每一个HTMLElelments对象，这里必须要有返回值，不然没有意义 实例： 12345678910$("div.dcell").map(function(index,elem)&#123; return elem.getElementsByTagName("img")[0]; //这里的elem是$(div.dcell)中的每一个HtmlElement对象，返回的是img元素&#125;).css("border",'thick double red'); //可以很清楚的看到这里返回的htmlElement对象变成了Jquery对象，因为调用了函数css$("img").map(function(index,elem)&#123; if(index==1) return elem; //返回的是第二个img的HtmlElement对象，但是经过map的包装就会变成jquery对象&#125;).css("border",'thick double red'); //可以很清楚的看到这里返回的htmlElement对象变成了Jquery对象，因为调用了函数css is is方法确定jquery对象中的某个或者某些元素是否满足测试条件，其中的形式有is(selector),is(HtmlElement),is(jquery),is(function(index))如果结果集中至少有一个元素匹配指定的条件，那么就返回true,否则false 实例：1234567891011console.log($("img").is("[src*=astor]"));//这里是判断img中的src属性有没有astor字段的，如果存在返回true$("img").is(function(index)&#123;&#125;)var c=$("img").is(function (index) &#123; //函数中如果至少有一个返回true，那么就会返回true，index是索引 return this.getAttribute('src')=='rose.png'; //判断属性 &#125;); console.log(c); end 当我们调用方法链来修改结果集的时候，jquery维护者一个历史结果集的查找，我们可以利用end回退到历史的结果集中,end用来扔掉当前的结果集，返回到上一层结果集 实例： 1234$("img").filter("[src*=astor]").end().css("border",'thick double red'); //这里回退到$("img")这个结果集中$("div.dcell").find("img").filter(":odd").filter(":eq(0)").end().end().css("border",'thick double red'); //这里调用了两个end将结果集回退到$("div.dcell").find("img")中 addBack 得到当前结果集和上一个结果集的合集 实例 123456$("div.dcell").children("img").addBack().css("border",'thick double red');//这里得到的是$("div.dcell")和$("div.dcell").children("img")的合集，并且应用css$("img").slice(0,3).filter("[src*=astor]").addBack().css("border",'thick double red');//$("img").slice(0,3)和$("img").slice(0,3).filter("[src*=astor]")的合集//这里的选择器参数过滤的是原结果集，相当于$("img").slice(0,3).filter("[src*=daff]")，$("img").slice(0,3).filter("[src*=astor]").addBack("[src*=daff]").css("border",'thick double red'); children children是用来访问子元素的，形式有childern(),children(selector),其中第一个是用来得到结果集中所有的子元素，第二个是用来过滤得到的子元素，保留满足selector的子元素 实例： 123$("div.dcell").children().css("border",'thick double red');//得到所有div.dcell的子元素，包括其中的img和input元素$("div.dcell").children("img").css("border",'thick double red');//得到所有子元素中的img元素 find find是用来得到结果集中的所有的后代元素，这里是后代元素，并不是只有子元素，还包括孙子。。。，形式有find(),find(selector),find(htmlElement),find(jquery),find(htmlElment[])，这里会自动去掉含有重复的元素，因此可以用来过滤元素 实例 1234$("div.dcell").find("img"); //找到div.dcell的后代元素imgvar content=document.getElementsByTagName("input");$("div.dcell").find(content).filter(":first").css("font-size",'1.5em');//找到div.dcell后代元素中的input元素 parent 选取结果集中的父元素，这里表示一层关系就是父元素，并不是祖先元素，形式有parent(),parent(selector) 实例：123$("img").parent(); //选取img的父元素$("img").parent(":first"); //选取img父元素中的第一个元素 parents 选取祖先元素，包括父元素，形式有parents(),parents(selector) 实例：123456$("img").parents().each(function(index,elem)&#123; //选取所有的祖先元素 console.log(elem.TagName+" "+elem.id);&#125;)$("img").parents("div.dcell").css("border",'thick double red'); //选择所有的div.dcell元素 parentsUntil 选择祖先元素，知道找到这个当前祖先元素匹配参数选择器为止,parentsUntil(selector),parentsUntil(selector,selector)，其中带有两个参数选择器中的第二个参数是用来筛选所得到的结果集，第一个是用来定位直到这个元素为止 实例： 123$("img").parentsUntil("div.drow");//找img的祖先元素，直到div.drow为止，不包括div.drow $("img").parentsUntil("div.drow",":first").css("border",'thick double red'); //这里选择了结果集中的第一个元素应用了样式 closest 得到结果集中元素的祖先元素中匹配selector选择器最接近的那个祖先元素，形式为closest(selector),closest(selctor,context),closest(htmlElemtent),closest(jquery) 实例： 12345678910$("img").closest("div.drow").each(function (index,elem) &#123; //选择满足div.drow的祖先元素，这里的最接近就是辈分最接近，这里的两个class=drow的div都是最接近的，因为这俩个是同级的关系 console.log(elem.tagName+" "+elem.id); &#125;); var jq=$("#row1,#row2,form"); //传入jquery对象 $("img").filter("[src*=astor]").closest(jq).each(function (index,elem) &#123; //这里选取的是最接近第一张图的祖先元素，当然是&lt;div id="row1"&gt; console.log(elem.tagName+" "+elem.id); &#125;) offestParent 得到距离最近的祖先定位元素，使用fixed,absolute,relative定位的元素，形式为offestParent() siblings 得到所有的兄弟元素，可选的selector用来过滤结果，形式为siblings(),siblings(selector) 实例： 123$("img").siblings().css("font-size",'1.4em');// 得到img的所有兄弟元素，这里是input$("img").siblings(":last"); //得到img所有兄弟元素中的最后一个元素 prev 得到上一个兄弟元素，形式为prev(),prev(selector)，其中的selector是用来过滤结果的 实例： 1$("input").prev().css("border",'thick double red'); //这里得到input的上一个元素Label元素 prevAll 得到当前元素的所有的上面的兄弟元素，形式为prevALl(),prevAll(selector) 实例： 123$("input").prevAll().css("border",'thick double red'); //得到input上面的所有的兄弟元素$("input").prev("img").css("border",'thick double red'); //得到input上面的所有的img元素 prevUntil 这个和parentsUntil一样，直到匹配selector就结束了，不包括 实例： 1$("input").prevUntil("i").css("border",'thick double red'); next 选择当前元素下面的一个兄弟元素，和prev一样 nextAll 选择当前元素下面的所有兄弟元素，和prevAll一样 nextUntil 和prevUntil一样 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux干货篇一]]></title>
      <url>%2F2017%2F04%2F13%2FLinux%E5%B9%B2%E8%B4%A7%E7%AF%87%E4%B8%80%2F</url>
      <content type="text"><![CDATA[Linux干货篇一虚拟机的安装(VMware) 选择文件-&gt;新建虚拟机 选择自定义 设置安装来源，选择稍后安装 选择安装的操作系统，选择Linux,然后选择自己安装的对应版本即可 设置虚拟机的安装路径，自己选择 指定磁盘容量，选择默认20G,然后选择将虚拟磁盘存储为单个文件 设置cpu数量，内存大小，默认即可 设置Linux安装镜像文件路径 点击开启虚拟机即可根据对应的设置安装 目录文件 /boot:存放系统引导时所需要的文件，包括Linux内核以及引导程序(BootLoader) /bin:存放可执行程序 /etc:存放系统配置文件 /home:普通用户的主目录所在位置 /lib:存放基本的共享文件和内核模块 /mnt(mount):用户为需要挂载的文件系统提供挂载点 /proc(process):存放与内核进程有关的信息 /root:根用户的主目录 /tmp(temporary):存放临时性文件 /usr(user):存放可共享的只读文件 /var(variable):存放各类的数据文件 ls重要选项 -a(all) 列出目录中的所有项，包括”.”开头的隐藏文件 -l(list) 以列表的方式显示文件 -R(recursive) 用于递归列出子目录中的内容，如果在选择的目录下还有子文件夹，那么可以列出子文件夹中的文件 -d仅仅列出目录本身的信息实例 ls -al /etc 以列表的方式列出ect目录下的所有文件 pwd 显示当前路径cd(切换目录) cd .. 跳闸到当前目录的上一级 cd ~ 跳转到当前用户的主目录 例子 cd /tmp/testdir 跳转到tmp文件下的testdir目录 stat 获取关于某文件的基本信息，包括创建的信息，大小，时间。。。。 实例 stat test 查看test文件的基本信息 touch 创建或者更新一个文件的访问和修改的时间，如果一个文件存在，那么更新这个文件的创建时间，但是文件的内容不会改变，如果文件不存在，那么就会在当前目录下创建一个文件 实例 touch /tmp/testdir/test 在指定路径下创建一个test文件，如果存在那么会更新创建的时间，可以使用stat命令查看创建时间 mkdir(创建目录) mkdir /tmp/testdir/test_file 在/tmp/testdir目录下创建一个test_file文件夹 mv 移动或者重命名文件或目录 重要选项 b(backup):若存在同名文件，覆盖前先备份原来的文件 f(force):强制覆盖同名的文件 实例12345mkdir /tmp/testdir //创建一个目录testdirtouch test1 test2 //创建两个文件test1 test2mv -b test1 test2 //移动test1为test2,这里会先备份原来的test2为test2~mv -b test1 /tmp/testdir1/test //移动文件到指定目录下 cp(copy) 复制文件和目录 选项 -b: 若存在同名文件，覆盖前先备份 -f :强制覆盖同名文件 -r : 以递归的方式复制文件，就是复制文件夹，如果不使用这个，那么文件夹就无法复制 实例 cp /tmp/testdir tmp/testdir1 复制文件夹，这里表示不能复制，因此要加上-r选项才能复制文件夹 -&gt; cp -r /tmp/testdir /tmp/testdir1 可以复制，复制到/tmp文件夹下命名为testdir1 cp -b /tmp/testdir/test1 /tmp/testdir1/test 将文件test1复制到testdir1文件夹下命名为test rm 删除命令 选项 -f 强制删除 -r 删除文件夹（递归删除） 实例 rm -rf /tmp/testdir 强制删除testdir目录 rmdir 删除目录，但是要求目录必须是空的，这里实用性不大，一般用rm -r cat 查看文件内容 重要选项 -n 显示行数 实例 cat -n /tmp/testdir/test 查看文件test的内容，显示行数 more 分屏显示文件内容，首先显示一屏后如果还有内容，按回车键在显示下一行，按Space显示下一屏的内容 实例 more /tmp/testdir/test tail 显示文本文件结尾的部分，默认显示最后10行 重要选项 -n 指定显示的行数 head 显示开头的内容，与tail类似 wc 一次显示文本文件的行数，单词数，字节数 重要选项 -c 显示文件字节数 -l(line) 显示文件行数 -w(word) 显示文件单词数 实例 wc -cl /tmp/testdir/test 查看文件的字数和文件的行数 date查看或者修改系统命令 实例 date 查看系统时间 date 09012017 修改系统时间为2017-09-01 who列出当前系统的登录用户 重要选项 -r 显示系统当前的运行级 -q 显示当前所有登录的用户名称和在线人数 shutdown关闭重启系统 重要选项 -r(reboot) 重启系统 -h(halt) 关闭系统 -P(poweroff) 关闭系统同时关闭电源 注意上面选项均可给出数字参数指定多少分钟之后执行操作 实例 shutdown -h 10 设置10分钟后关闭系统 clear清楚当前终端的屏幕内容 man显示命令的使用手册，按上下键移动光标，Q键退出 实例 man cat 快速查询cat命令的手册 histroy查看shell命令的历史记录 实例 histroy 5 显示最近的5条记录 vim调用vim编辑器，按i键插入，w键保存，q键退出，wq保存后退出 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy爬取豆瓣全站]]></title>
      <url>%2F2017%2F04%2F08%2Fscrapy%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E5%85%A8%E7%AB%99%2F</url>
      <content type="text"><![CDATA[Scrapy爬取豆瓣读书全站分析网页 首先打开豆瓣读书中的分类浏览，可以看到其中有很多的分类 豆瓣应该是一个比较好爬的网站，所有的数据都不是ajax加载的，我们打开谷歌的F12或者是火狐的FireBug可以很轻松的找到每一个分类的链接 这里我们使用scrapy中的一个linkextractors库,这个库的作用是会根据提供的限制，自动爬取和深入每一个页面并且提取需要的链接，如果想要找到每一个分类的url,只需Rule(LinkExtractor(allow=&#39;/tag/&#39;,restrict_xpaths=&quot;//div[@class=&#39;article&#39;]&quot;),follow=True),这里的allow是一个正则表达式，用来筛选分类url,restrict_xpaths是限制在哪个结构中筛选url,这里限制的是在&lt;div class=&#39;article&#39;&gt;这个盒模型中，follow表示是否深入，这里当然是要深入,这里就能得到每一个分类url了，自己可以在回调函数中测试下，输入所得的url,可以使用respose.url 得到所有的分类url，就可以继续深入到每一步作品所在的页面了，如下图! 但是我们需要不止是这一页，我们要爬的时全站，因此这里必须实现翻页，我们可以看到页面底部清楚的写着下一页，我们通过解析页面同样可以得到url,如下图所示 可以看到所有的url的规则，我们就可以用正则表达式限制，以获取我们的需要，我们可以写出翻页的代码 1Rule(LinkExtractor(allow="\?start=\d+\&amp;type=",restrict_xpaths="//div[@class='pa&gt;ginator']"),follow=True), 最后一步就是打开每一部书的网页得到所需的信息了，我们就可以通过这里通过解析网页还是可以很清楚的知道url,这里就不再详细的说怎么解析了，这里可以看到所有的url都在li标签中，如下图 我们打开li标签可以很清楚的看大url的规律，因此这里还是用到上面说的库解析深入，连同上面的代码如下 123Rule(LinkExtractor(allow='/tag/',restrict_xpaths="/ /div[@class='article']"),follow=True),#第一步Rule(LinkExtractor(allow="\?start=\d+\&amp;type=",restrict_xpaths="//div[@class='pa&gt;ginator']"),follow=True), #第二步翻翻页Rule(LinkExtractor(allow="/subject/\d+/$",restrict_&gt;xpaths="//ul[@class='subject-list']"),callback='parse_item')#得到所需网页的url 到了这里总算是大功告成了，下面就需要解析自己的所需要的信息了,这里附上网页 下面就是写自己解析代码了，这里就不需要详细的说了，详细内容请看源码,值得注意的是爬取的网页速度不要太快，豆瓣会禁IP的，这里可以采用一些反爬虫措施,如请求头的更换，ip地址的更换，下一篇会详细解说。 参考文档： scrapy中文文档 最后附上本人的github地址,不要忘了给个star哦 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[matplotlib绘制图形基础]]></title>
      <url>%2F2017%2F04%2F01%2Fmatplotlib%E7%BB%98%E5%88%B6%E5%9B%BE%E5%BD%A2%E5%9F%BA%E7%A1%80%2F</url>
      <content type="text"><![CDATA[matplotlib绘制基本图形折线图12345678import matplotlib.pyplot as pltimport numpy as npx=np.arange(0,10,1) #创建一个0-10之间以1为间隔的numpy数组y=x+10 plt.plot(x,y,color='red',linestyle='--',marker='&gt;',linewidth=3,label='example one') #绘制图形plt.savefig('first.png',dpi=50) #保存图形，dpi表示plt.legend() #显示图例plt.show() #显示图形 图形展示说明plt.plot()可以直接绘制折线，其中marker是折线上的标记，linewidth是折线的宽度，label是图例，如果要想显示就要设置plt.legend(),linestyle是折线的风格，color是颜色 饼状图123456789101112131415import matplotlib.pyplot as pltslices = [2,3,4,9] #指定每一个切片的大小，这里就是每块的比例activities = ['sleeping','eating','working','playing'] #指定标签cols = ['c','m','r','b'] #y颜色plt.pie(slices, labels=activities, colors=cols, #指定每一个区块的颜色 startangle=90, #开始角度，默认是0度，从x轴开始，90度从y轴开始 shadow= True, #阴影效果 explode=(0,0.1,0,0), #拉出第二个切片，如果全为0就不拉出，这里的数字是相对与圆心的距离 autopct='%1.1f%%') #显示百分比plt.title('Interesting Graph\nCheck it out') #设置标题plt.show() 图片展示 散点图12345678import numpy as npimport matplotlib.pyplot as pltx=np.random.rand(1000)y=np.random.rand(len(x))plt.scatter(x,y,color='r',alpha=0.3,label='example one',marker='o') #绘图plt.legend()#plt.axis([0,2,0,2]) #设置坐标的范围plt.show() 图片展示 直方图123456789import matplotlib.pyplot as pltimport numpy as npx=np.random.randint(1,1000,200)axis=plt.gca() #得到当前的绘图对象axis.hist(x,bins=35,facecolor='r',normed=True,histtype='bar',alpha=0.5)#bins表示直方图的个数，histtype表示直方图的样式，normed如果为True就将直方归一化，显示概率密度，默认是Falseaxis.set_xlabel("Values") #设置x的标签axis.set_ylabel("Frequency") axis.set_title("HIST")plt.show() 图片展示 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy设置请求池]]></title>
      <url>%2F2017%2F03%2F26%2Fscrapy%E8%AE%BE%E7%BD%AE%E8%AF%B7%E6%B1%82%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[scrapy设置”请求池”引言 相信大家有时候爬虫发出请求的时候会被ban，返回的是403错误，这个就是请求头的问题，其实在python发出请求时，使用的是默认的自己的请求头，网站管理者肯定会不允许机器访问的，但是有些比较low的网站还是可以访问的，有时候网站管理者看到同一个请求头在一秒内请求多次，傻子都知道这是机器在访问，因此会被ban掉，这时就需要设置请求池了，这个和ip代理池是一个概念 爬虫请求常见的错误 200：请求成功 处理方式：获得响应的内容，进行处理201：请求完成，结果是创建了新资源。新创建资源的 URI 可在响应的实体中得到 处理方式：爬虫中不会遇到202：请求被接受，但处理尚未完成 处理方式：阻塞等待204：服务器端已经实现了请求，但是没有返回新的信 息。如果客户是用户代理，则无须为此更新自身的文档视图。 处理方式：丢弃300：该状态码不被 HTTP/1.0 的应用程序直接使用， 只是作为 3XX 类型回应的默认解释。存在多个可用的被请求资源。 处理方式：若程序中能够处理，则进行进一步处理，如果程序中不能处理，则丢弃301：请求到的资源都会分配一个永久的 URL，这样就可以在将来通过该 URL 来访问此资源 处理方式：重定向到分配的 URL302：请求到的资源在一个不同的 URL 处临时保存 处理方式：重定向到临时的 URL304 请求的资源未更新 处理方式：丢弃400 非法请求 处理方式：丢弃401 未授权 处理方式：丢弃403 禁止 处理方式：丢弃404 没有找到 处理方式：丢弃5XX 回应代码以“5”开头的状态码表示服务器端发现自己出现错误，不能继续执行请求 处理方式：丢弃 话不多说直接撸代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from scrapy import logimport randomfrom scrapy.downloadermiddlewares.useragent import UserAgentMiddlewareclass RotateUserAgentMiddleware(UserAgentMiddleware):# for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.phpuser_agent_list = [ "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 " "(KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1", "Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 " "(KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11", "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 " "(KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6", "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 " "(KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6", "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 " "(KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1", "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 " "(KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5", "Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 " "(KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5", "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3", "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3", "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3", "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3", "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3", "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3", "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3", "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 " "(KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3", "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 " "(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24", "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 " "(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"]def process_request(self, request, spider): ua = random.choice(self.user_agent_list) if ua: # 显示当前使用的useragent print "********Current UserAgent:%s************" % ua # 记录 log.msg('Current UserAgent: ' + ua) request.headers.setdefault('User-Agent', ua) 说明 这里的思路就是在下载器中间件中对request设置请求，这里是使用request.headers.setdefault(&quot;User-Agent&quot;,user_agent)这个函数设置请求头，对于下载器中间件在我博客前面的文章已经有说明，想要了解的请点击 注意 这里还要说明的是设置了请求池还要在配置文件settins中设置一下，具体设置方法和设置代理ip一样，详情请看scrapy代理ip的设置 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scrapy中使用cookie免于验证登录和模拟登录]]></title>
      <url>%2F2017%2F03%2F26%2FScrapy%E4%B8%AD%E4%BD%BF%E7%94%A8cookie%E5%85%8D%E4%BA%8E%E9%AA%8C%E8%AF%81%E7%99%BB%E5%BD%95%E5%92%8C%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%2F</url>
      <content type="text"><![CDATA[Scrapy中使用cookie免于验证登录和模拟登录引言 python爬虫我认为最困难的问题一个是ip代理，另外一个就是模拟登录了，更操蛋的就是模拟登录了之后还有验证码，真的是不让人省心，不过既然有了反爬虫，那么就有反反爬虫的策略，这里就先介绍一个cookie模拟登陆，后续还有seleminum+phantomjs模拟浏览器登录的文章。还不知道cookie是什么朋友们，可以点击这里 cookie提取方法： 打开谷歌浏览器或者火狐浏览器，如果是谷歌浏览器的按F12这个键就会跳出来浏览器控制台，然后点击Network，之后就是刷新网页开始抓包了，之后在抓到的页面中随便打开一个，就能看到cokie了，但是这里的cookie并不符合python中的格式，因此需要转换格式，下面提供了转换的代码 1234567891011121314151617181920212223# -*- coding: utf-8 -*-class transCookie:def __init__(self, cookie): self.cookie = cookiedef stringToDict(self): ''' 将从浏览器上Copy来的cookie字符串转化为Scrapy能使用的Dict :return: ''' itemDict = &#123;&#125; items = self.cookie.split(';') for item in items: key = item.split('=')[0].replace(' ', '') value = item.split('=')[1] itemDict[key] = value return itemDictif __name__ == "__main__":cookie = "你复制的cookie"trans = transCookie(cookie)print trans.stringToDict() 补充说明： 只需要将你网页上的cookie复制到上述代码中直接运行就可以了 使用cookie操作scrapy 直接撸代码 123456789101112131415161718# -*- coding: utf-8 -*-import scrapyfrom scrapy.conf import settings #从settings文件中导入Cookie，这里也可以室友from scrapy.conf import settings.COOKIEclass DemoSpider(scrapy.Spider):name = "demo"#allowed_domains = ["csdn.com"]start_urls = ["http://write.blog.csdn.net/postlist"]cookie = settings['COOKIE'] # 带着Cookie向网页发请求\headers = &#123; 'Connection': 'keep - alive', # 保持链接状态 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.82 Safari/537.36'&#125;def start_requests(self): yield scrapy.Request(url=self.start_urls[0],headers=self.headers,cookies=self.cookie)# 这里带着cookie发出请求def parse(self, response): print response.body 说明 这里是scrapy工程目录下spiders目录下的主要的解析网页的py文件相信学过scrapy的应该不会陌生，上述代码中的cookie值是放在Settings文件中的，因此使用的时候需要导入，当然你也可以直接将cookie粘贴到这个文件中 注意 虽说这里使用直接使用cookie可以省去很多麻烦，但是cookie的生命周期特别的短，不过小型的项目足够使用了，向那些需要爬两三天甚至几个月的项目就不适用了，因此在隔一段时间就要重新换cookie的值，虽说有很多麻烦，但是我还是比较喜欢这种方法的，因为可以省去不少脑筋 作者说 本人秉着方便他人的想法才开始写技术文章的，因为对于自学的人来说想要找到系统的学习教程很困难，这一点我深有体会，我也是在不断的摸索中才小有所成，如果你们觉得我写的不错就帮我推广一下，让更多的人看到。另外如果有什么错误的地方也要及时联系我，方便我改进，谢谢大家对我的支持。 最后欢迎大家看看我的其他scrapy文章 scrapy设置代理ip scrapy架构初探 scrapy初试 scrapy下载器中间件 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy设置代理ip]]></title>
      <url>%2F2017%2F03%2F26%2Fscrapy%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86ip%2F</url>
      <content type="text"><![CDATA[scrapy代理的设置 在我的上一篇文章介绍了scrapy下载器中间件的使用,这里的scrapyIP的代理就是用这个原理实现的，重写了下载器中间件的process_request(self,request,spider)这个函数,这个函数的主要作用就是对request进行处理。 话不多说直接撸代码 123456789101112131415161718192021222324import random import scrapyimport loggingclass proxMiddleware(object):#proxy_list=[&#123;'http': 'http://123.157.146.116:8123'&#125;, &#123;'http': 'http://116.55.16.233:8998'&#125;, &#123;'http': 'http://115.85.233.94:80'&#125;, &#123;'http': 'http://180.76.154.5:8888'&#125;, &#123;'http': 'http://139.213.135.81:80'&#125;, &#123;'http': 'http://124.88.67.14:80'&#125;, &#123;'http': 'http://106.46.136.90:808'&#125;, &#123;'http': 'http://106.46.136.226:808'&#125;, &#123;'http': 'http://124.88.67.21:843'&#125;, &#123;'http': 'http://113.245.84.253:8118'&#125;, &#123;'http': 'http://124.88.67.10:80'&#125;, &#123;'http': 'http://171.38.141.12:8123'&#125;, &#123;'http': 'http://124.88.67.52:843'&#125;, &#123;'http': 'http://106.46.136.237:808'&#125;, &#123;'http': 'http://106.46.136.105:808'&#125;, &#123;'http': 'http://106.46.136.190:808'&#125;, &#123;'http': 'http://106.46.136.186:808'&#125;, &#123;'http': 'http://101.81.120.58:8118'&#125;, &#123;'http': 'http://106.46.136.250:808'&#125;, &#123;'http': 'http://106.46.136.8:808'&#125;, &#123;'http': 'http://111.78.188.157:8998'&#125;, &#123;'http': 'http://106.46.136.139:808'&#125;, &#123;'http': 'http://101.53.101.172:9999'&#125;, &#123;'http': 'http://27.159.125.68:8118'&#125;, &#123;'http': 'http://183.32.88.133:808'&#125;, &#123;'http': 'http://171.38.37.193:8123'&#125;]proxy_list=[ "http://180.76.154.5:8888", "http://14.109.107.1:8998", "http://106.46.136.159:808", "http://175.155.24.107:808", "http://124.88.67.10:80", "http://124.88.67.14:80", "http://58.23.122.79:8118", "http://123.157.146.116:8123", "http://124.88.67.21:843", "http://106.46.136.226:808", "http://101.81.120.58:8118", "http://180.175.145.148:808"]def process_request(self,request,spider): # if not request.meta['proxies']: ip = random.choice(self.proxy_list) print ip #print 'ip=' %ip request.meta['proxy'] = ip 主要的原理： 给出一个代理列表，然后在这个列表中随机取出一个代理，设置在request中，其中request.meta[&#39;proxy&#39;]就是设置代理的格式 但是现在主要的问题就是没有代理ip可用，如果去买的话又太贵了，自己玩玩买代理不值当，所以只好自己写爬虫去爬取免费的代理了，但是免费的代理存活的时间是有限的，这是个非常麻烦的事情，我提供的方法就是实现自己的一个ip代理池，每天定时更新自己的代理池，具体的实现方法会在下一篇文章中介绍，现在提供一段代码用来爬取西刺网站的代理 直接撸代码，接招吧 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#coding:utf-8import requestsfrom bs4 import BeautifulSoupimport threadingimport Queueclass Get_ips():def __init__(self,page): self.ips=[] self.urls=[] for i in range(page): self.urls.append("http://www.xicidaili.com/nn/" + str(i)) self.header = &#123;"User-Agent": 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0'&#125; #self.file=open("ips",'w') self.q=Queue.Queue() self.Lock=threading.Lock()def get_ips(self): for url in self.urls: res = requests.get(url, headers=self.header) soup = BeautifulSoup(res.text, 'lxml') ips = soup.find_all('tr') for i in range(1, len(ips)): ip = ips[i] tds = ip.find_all("td") ip_temp = "http://" + tds[1].contents[0] + ":" + tds[2].contents[0] # print str(ip_temp) self.q.put(str(ip_temp))def review_ips(self): while not self.q.empty(): ip=self.q.get() try: proxy=&#123;"http": ip&#125; #print proxy res = requests.get("http://www.baidu.com", proxies=proxy,timeout=5) self.Lock.acquire() if res.status_code == 200: self.ips.append(ip) print ip self.Lock.release() except Exception: pass #print 'error'def main(self): self.get_ips() threads=[] for i in range(40): threads.append(threading.Thread(target=self.review_ips,args=[])) for t in threads: t.start() for t in threads: t.join() return self.ipsdef get_ip():my=Get_ips(4)return my.main()get_ip() 实现的原理 这里用到了BeautifulSoup解析页面，然后将提取到的代理交给队列，然后再通过共享队列分配给线程，这里主要开启线程通过设置代理ip访问一个网站，因为访问网站的时间比较长，因此要开起多个线程，相信大家能够学习设置代理ip了应该都是比较上手的了，这里具体的代码就不一一解释了，如果代码有什么问题可以及时联系我，我的联系方式在关于我的一栏中有提到 补充 想要ip应用起来，还要在配置文件settings中添加DOWNLOADER_MIDDLEWARES = { &#39;demo.proxy.proxMiddleware&#39;:400 }这里的demo是工程的名字，proxy是py文件的名,proxMiddleware是类的名字 当然这里可能你觉得proxy_list写在这里有点冗余，你可以在配置文件中定义，然后将配置文件的内容import到py文件中 以上全是博主慢慢摸索出来的，可以说自学一门技术真的很难，学习python爬虫已经有两三个月了，可以说全是自己通过看项目，网上查资料才有了今天的成功，不过现在还有几个问题没有解决，就是分布式爬虫、移动端爬取，博主接下来就要主攻这两个方面，学好之后会在自己的博客上分享学习心得的，因为网上没有系统的学习教程，对于自学的人来说实在是太痛苦了 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy的下载器中间件]]></title>
      <url>%2F2017%2F03%2F25%2Fscrapy%E7%9A%84%E4%B8%8B%E8%BD%BD%E5%99%A8%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[scrapy中的下载器中间件下载中间件 下载器中间件是介于Scrapy的request/response处理的钩子框架。 是用于全局修改Scrapy request和response的一个轻量、底层的系统。 编写下载器中间件 1. process_request(request, spider)当每个request通过下载中间件时，该方法被调用。process_request() 必须返回其中之一: 返回 None 、返回一个 Response 对象、返回一个 Request对象或raise IgnoreRequest 。 如果其返回 None ，Scrapy将继续处理该request，执行其他的中间件的相应方法，直到合适的下载器处理函数(download handler)被调用， 该request被执行(其response被下载)。 如果其返回 Response 对象，Scrapy将不会调用 任何 其他的 process_request() 或 process_exception() 方法，或相应地下载函数； 其将返回该response。 已安装的中间件的 process_response() 方法则会在每个response返回时被调用。 如果其返回 Request 对象，Scrapy则停止调用 process_request方法并重新调度返回的request。当新返回的request被执行后， 相应地中间件链将会根据下载的response被调用。 如果其raise一个 IgnoreRequest 异常，则安装的下载中间件的 process_exception() 方法会被调用。如果没有任何一个方法处理该异常， 则request的errback(Request.errback)方法会被调用。如果没有代码处理抛出的异常， 则该异常被忽略且不记录(不同于其他异常那样)。 参数: request (Request 对象) – 处理的request spider (Spider 对象) – 该request对应的spider 2. process_response(request, response, spider) process_response() 必须返回以下之一: 返回一个 Response对象、 返回一个Request 对象或raise一个 IgnoreRequest 异常。 如果其返回一个 Response (可以与传入的response相同，也可以是全新的对象)， 该response会被在链中的其他中间件的 process_response() 方法处理。 如果其返回一个 Request 对象，则中间件链停止， 返回的request会被重新调度下载。处理类似于 process_request() 返回request所做的那样。 如果其抛出一个 IgnoreRequest 异常，则调用request的errback(Request.errback)。 如果没有代码处理抛出的异常，则该异常被忽略且不记录(不同于其他异常那样)。 参数: request (Request对象) – response所对应的request response (Response 对象) – 被处理的response spider (Spider 对象) – response所对应的spider 3.process_exception(request, exception, spider) 当下载处理器(download handler)或 process_request() (下载中间件)抛出异常(包括 IgnoreRequest 异常)时， Scrapy调用 process_exception() 。 process_exception() 应该返回以下之一: 返回 None 、 一个 Response 对象、或者一个 Request 对象。 如果其返回 None ，Scrapy将会继续处理该异常，接着调用已安装的其他中间件的 process_exception() 方法，直到所有中间件都被调用完毕，则调用默认的异常处理。 如果其返回一个 Response 对象，则已安装的中间件链的 process_response() 方法被调用。Scrapy将不会调用任何其他中间件的 process_exception() 方法。 如果其返回一个 Request 对象， 则返回的request将会被重新调用下载。这将停止中间件的 process_exception() 方法执行，就如返回一个response的那样。 参数: request (是 Request 对象) – 产生异常的request exception (Exception 对象) – 抛出的异常 spider (Spider 对象) – request对应的spider 总结： 总的来说下载器中间件就是起到处理request请求并且返回response的作用，一切从网页爬取的url发起的请求会组成一个请求队列，然后一个一个排队经过下载器中间件，之后下载器中间件会对request做出相应的处理，比如添加请求头，添加代理等等，然后通过process_response返回一个response，之后就是用得到的response做出相应的分析，当然这里的内容页可以不实现，但是如果要爬取大型的网站，会遇到被ban的可能就要在下载器中间件这里着手，设置一些相应的请求头，ip代理等等内容。以上纯属个人逐渐摸索总结出来的内容，如果有什么错误欢迎指正 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy初试]]></title>
      <url>%2F2017%2F03%2F25%2Fscrapy%E5%88%9D%E8%AF%95%2F</url>
      <content type="text"><![CDATA[scrapy初试 创建项目 打开cmd，在终端输入scrapy startproject tutorial,这里将在指定的文件夹下创建一个scrapy工程 其中将会创建以下的文件： scrapy.cfg: 项目的配置文件 tutorial/: 该项目的python模块。之后您将在此加入代码。 tutorial/items.py: 项目中的item文件. tutorial/pipelines.py: 项目中的pipelines文件. tutorial/settings.py: 项目的设置文件. tutorial/spiders/: 放置spider代码的目录. 定义item Item是保存爬取到的数据的容器；其使用方法和python字典类似， 并且提供了额外保护机制来避免拼写错误导致的未定义字段错误。 类似在ORM中做的一样，您可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field的类属性来定义一个Item。 (如果不了解ORM, 不用担心，您会发现这个步骤非常简单) 首先根据需要从dmoz.org获取到的数据对item进行建模。 我们需要从dmoz中获取名字，url，以及网站的描述。 对此，在item中定义相应的字段。编辑 tutorial 目录中的 items.py 文件: 12345import scrapyclass DmozItem(scrapy.Item):title = scrapy.Field()link = scrapy.Field()desc = scrapy.Field() 一开始这看起来可能有点复杂，但是通过定义item， 您可以很方便的使用Scrapy的其他方法。而这些方法需要知道您的item的定义. 编写第一个爬虫 在工程的根目录下打开终端输入scrapy genspider demo douban.com这里的demo是spders文件下的主要py文件douban.com是要爬取的域名，会在demo.py中的 allowed_domains中显示，主要的功能就是限制爬取的url spider代码中内容解析 name: 用于区别Spider。 该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。 start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。 parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request对象。 以下是spider目录下的demo.py的代码 1234567891011121314import scrapyclass DmozSpider(scrapy.Spider):name = "dmoz"allowed_domains = ["dmoz.org"]start_urls = [ "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/", "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"]def parse(self, response): filename = response.url.split("/")[-2] with open(filename, 'wb') as f: f.write(response.body) spider的爬取 进入工程的根目录下打开终端输入：scrapy crawl dmoz spider中的数据存取 在工程的根目录下打开终端输入scrapy crawl dmoz -o items.json这里是将数据存储到json文件中]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java中的IO操作]]></title>
      <url>%2F2017%2F03%2F25%2Fjava%E4%B8%AD%E7%9A%84IO%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[java中IO操作读取文件中的内容 使用Scanner读取文本中的内容 相信大家都知道Scanner console=new Scanner(System.in)是用来读取控制台上输入的内容，但是这里是用来读取文件的内容，原理是一样的，只是对象不同罢了，这里用到的是File对象，用来创建一个文件对象 123456Scanner input=new Scanner(new File("hello.txt"));//创建一个对象inputwhile(input.hasNextLine()) //这里用来判断是否还有内容， 以免读到最后发生错误&#123;String content=input.nextLine();System.out.println(content);&#125; 这里顺便补充一下Scannner中的几个函数： nextLine():读取一行的内容，包括空格，换行 nextInt():读取一个整型内容 nexDouble():读取一个双精度的浮点数 next():读取下一个内容，无论什么类型，其中遇到空格和换行默认是一个标记（即是跳过）和nextLine()类似 hasNext():用来判断文件中的还有下一个内容，无论什么类型的 hasNextInt() hasNextDouble()://相似，不在赘述 使用FileReader读取 用来读取字符文件的便捷类。此类的构造方法假定默认字符编码和默认字节缓冲区大小都是适当的。要自己指定这些值，可以先在 FileInputStream上构造一个 InputStreamReader。FileReader 用于读取字符流。要读取原始字节流，请考虑使用 FileInputStream。 //这里使用new File创建一个对象，同样的也可以直接将文件的绝对路径传入 FileReader file=new FileReader(new File(&quot;hello.txt&quot;)); while(file.ready()) //用来判断是否还有字符可读 { int content=file.read(); //这里的read是读取将单个字符 返回的是int，即是ascii码,这里官方文档说返回的是读取的字符数，但是我实验了一下返回的ascii码 System.out.println((char)content); //所以要将ascii码转换成字符 } file.close(); 常用的几个方法： read(): return int 上面介绍过 read(char[] cbuf,int int length):将内容读入到一个char类型的数组，length是读取的字符数，offest是偏移量 使用BufferedReader的类实现高效的读取文件 123456//传入一个reader创建一个对象 BufferedReader file= new BufferedReader(new FileReader("hello.txt")); System.out.println(file.skip(3));//实现将指针跳过3个字符 System.out.println((char)file.read()); //read的方法，和FileReader中的read一样 String line=file.readLine(); //读取一行 System.out.println(line); 常用的方法： readLine() read()：如果到了末尾返回-1 read(char [],int off,int length):和FileReader中的一样 ready():判断是否还可以读取，一般和read配对使用 skip(long n):跳过的字符数 close() 文件的写入 用FileWriter写入文件 12345/*创建将对象f传入FileWriter,其中Filewriter有两个参数，第一个是File对象后者是一个String(即是文件的路径），第二个参数是boolean类型的，表示是否在文件的末尾追加内容，默认的是false表示不用在末尾追加，如果想要在末尾追加要写入另外一个参数true,当然这里可以用更加简洁的方式创建：FileWriter file=new FileWriter("hello.txt",false);*/FileWriter file=new FileWriter(f,true);file.write("chenjiabing");//写入函数writefile.close(); //最后必须关闭文件的输入流，否则写入将会失败，这里不想c和c++ 其中Filewriter中的方法还有 flush：刷新缓存流 close append():当前的领会的就是写入数组:append(Arrays.toString(list)); getEncoding():返回此流使用的字符编码 用PrintStream写入文件 这里同样的是和System.out.println()一样的原理，System.out.println只是内部实现了PrintStream，这里是用来将指定的内容写入到文件中而已 12345PrintStream output=new PrintStream(new File("hello.txt"));//创建一个写入的对象outputoutput.print("flan");output.println("vmlkfamla");output.println("vmslfkmadvmfs;dm"); 这里是用BufferedWriter类写入文件(一个高效的写入方式) 简单介绍 将文本写入字符输出流，缓冲各个字符，从而提供单个字符、数组和字符串的高效写入。可以指定缓冲区的大小，或者接受默认的大小。在大多数情况下，默认值就足够大了。该类提供了 newLine() 方法，它使用平台自己的行分隔符概念，此概念由系统属性 line.separator 定义。并非所有平台都使用新行符 (‘\n’) 来终止各行。因此调用此方法来终止每个输出行要优于直接写入新行符。通常 Writer 将其输出立即发送到底层字符或字节流。除非要求提示输出，否则建议用 BufferedWriter 包装所有其 write() 操作可能开销很高的 Writer（如 FileWriters 和 OutputStreamWriters）。例如， PrintWriter out= new PrintWriter(new BufferedWriter(new FileWriter(&quot;foo.out&quot;))); 将缓冲 PrintWriter对文件的输出。如果没有缓冲，则每次调用 print() 方法会导致将字符转换为字节，然后立即入到文件，而这是极其低效的。 例子 12345BufferedWriter input=new BufferedWriter(new FileWriter("hello.txt")); input.write("这是一个文件读入的方法"); input.newLine(); input.write("一个高效的方法"); input.close(); 其他的方法 close() flush() newLine():写入一个换行，因为每一个操作系统上的换行符可能不一样，不能系统的都用”\n”表示 write() 详情参见API 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy架构初探]]></title>
      <url>%2F2017%2F03%2F25%2Fscrapy%E6%9E%B6%E6%9E%84%E5%88%9D%E6%8E%A2%2F</url>
      <content type="text"><![CDATA[scrapy架构初探引言 Python即时网络爬虫启动的目标是一起把互联网变成大数据库。单纯的开放源代码并不是开源的全部，开源的核心是“开放的思想”，聚合最好的想法、技术、人员，所以将会参照众多领先产品，比如，Scrapy，ScrapingHub，import io等。 本文简单讲解一下Scrapy的架构。没错，通用提取器gsExtractor就是要集成到Scrapy架构中。 请注意，本文不想复述原文内容，而是为了开源Python爬虫的发展方向找参照，而且以9年来开发网络爬虫经验作为对标，从而本文含有不少笔者主观评述，如果想读Scrapy官方原文，请点击Scrapy官网的Architecture。 scrapy数据流 Scrapy中的数据流由执行引擎控制，下面的原文摘自Scrapy官网，我根据猜测做了点评，为进一步开发GooSeeker开源爬虫指示方向： The Engine gets the first URLs to crawl from the Spider and schedules them in the Scheduler, as Requests. URL谁来准备呢？看样子是Spider自己来准备，那么可以猜测Scrapy架构部分（不包括Spider）主要做事件调度，不管网址的存储。看起来类似GooSeeker会员中心的爬虫罗盘，为目标网站准备一批网址，放在罗盘中准备执行爬虫调度操作。所以，这个开源项目的下一个目标是把URL的管理放在一个集中的调度库里面。 The Engine asks the Scheduler for the next URLs to crawl. 看到这里其实挺难理解的，要看一些其他文档才能理解透。接第1点，引擎从Spider中把网址拿到以后，封装成一个Request，交给了事件循环，会被Scheduler收来做调度管理的，暂且理解成对Request做排队。引擎现在就找Scheduler要接下来要下载的网页地址。 The Scheduler returns the next URLs to crawl to the Engine and the Engine sends them to the Downloader, passing through the Downloader Middleware (request direction). 从调度器申请任务，把申请到的任务交给下载器，在下载器和引擎之间有个下载器中间件，这是作为一个开发框架的必备亮点，开发者可以在这里进行一些定制化扩展。 Once the page finishes downloading the Downloader generates a Response (with that page) and sends it to the Engine, passing through the Downloader Middleware (response direction). 下载完成了，产生一个Response，通过下载器中间件交给引擎。注意，Response和前面的Request的首字母都是大写，虽然我还没有看其它Scrapy文档，但是我猜测这是Scrapy框架内部的事件对象，也可以推测出是一个异步的事件驱动的引擎，就像DS打数机的三级事件循环一样，对于高性能、低开销引擎来说，这是必须的。 The Engine receives the Response from the Downloader and sends it to the Spider for processing, passing through the Spider Middleware (input direction). 再次出现一个中间件，给开发者足够的发挥空间。 The Spider processes the Response and returns scraped items and new Requests (to follow) to the Engine. 每个Spider顺序抓取一个个网页，完成一个就构造另一个Request事件，开始另一个网页的抓取。 The Engine passes scraped items and new Requests returned by a spider through Spider Middleware (output direction), and then sends processed items to Item Pipelines and processed Requests to the Scheduler. 引擎作事件分发 The process repeats (from step 1) until there are no more requests from the Scheduler. 持续不断地运行。 版权信息所有者：chenjiabing如若转载请标明出处：chenjiabing666.github.io6]]></content>
    </entry>

    
  
  
</search>
